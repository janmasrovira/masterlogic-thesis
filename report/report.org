# [Ss]ection[[:space:]]+\[\[\([^]]*\)]]
# [Dd]efinition[[:space:]]+\[\[\([^]]*\)]]
# [tT]able[[:space:]]+\[\[\([^]]*\)]]
# [tT]heorem[[:space:]]+\[\[\([^]]*\)]]
# [lL]emma[[:space:]]+\[\[\([^]]*\)]]
#+latex_compiler: xelatex
#+latex_class: scrreprt
#+options: H:4
#+options: toc:nil

#+latex_header: \usepackage{hyperref}
#+latex_header: \usepackage{mathpartir}
#+latex_header: \usepackage{graphicx}
#+latex_header: \usepackage{unicode-math}
#+latex_header: \usepackage{fontspec}
#+latex_header: \usepackage[x11names, table]{xcolor}
#+latex_header: \usepackage[margin=2.5cm]{geometry}
#+latex_header: \usepackage{lmodern}
#+latex_header: \setmonofont{FreeMono}
#+latex_header: \usepackage{cancel}
#+latex_header: \usepackage{amsthm}
#+latex_header: \usepackage{float}
#+latex_header: \usepackage{newunicodechar}
#+latex_header: \usepackage[toc,indexonlyfirst,docdef=restricted]{glossaries-extra}
#+latex_header: \usepackage[style=numeric-comp, maxbibnames=10]{biblatex}
#+latex_header: \usepackage{multicol}
#+latex_header: \usepackage{stmaryrd}
#+latex_header: \usepackage{spverbatim}
#+latex_header: \usepackage{pdfpages}
#+latex_header: \usepackage[capitalise, nameinlink]{cleveref}
#+latex_header: \newcommand{\?}{'\nobreak\hspace{0pt}}

#+latex_header: \bibliography{refs}
#+latex_header: \makeglossaries

#+latex_header: \hypersetup{colorlinks=true,urlcolor=RoyalBlue4,linkcolor=Salmon4,citecolor=Green4}
#+latex_header: \newcommand{\ie}[0]{i.e.}
#+latex_header: \newcommand{\todo}[0]{\textcolor{red}{pending}}
#+latex_header: \newcommand{\pend}[0]{\textcolor{Tomato3}{pending }}
#+latex_header: \newcommand{\red}[1]{\textcolor{red}{#1 }}

#+macro: begindef @@latex:\begin{definition}@@
#+macro: enddef @@latex:\end{definition}@@

#+macro: begincoro @@latex:\begin{corollary}@@
#+macro: endcoro @@latex:\end{corollary}@@

#+macro: beginremark @@latex:\begin{remark}@@
#+macro: endremark @@latex:\end{remark}@@

#+macro: begintheorem @@latex:\begin{theorem}@@
#+macro: endtheorem @@latex:\end{theorem}@@

#+macro: beginlemma @@latex:\begin{lemma}@@
#+macro: endlemma @@latex:\end{lemma}@@

#+macro: beginproof @@latex:\begin{proof}@@
#+macro: endproof @@latex:\end{proof}@@


#+macro: defglossary @@latex:\newglossaryentry{$1}{name=$2,description={$3}}@@
#+macro: defacronym @@latex:\newacronym{$1}{$2}{$3}@@


#+latex_header: \newtheorem{theorem}{Theorem}
#+latex_header: \numberwithin{theorem}{chapter}

#+latex_header: \theoremstyle{definition}

#+latex_header: \newtheorem{corollary}[theorem]{Corollary}
#+latex_header: \theoremstyle{definition}
#+latex_header: \newtheorem{lemma}[theorem]{Lemma}
#+latex_header: \theoremstyle{definition}
#+latex_header: \newtheorem{definition}[theorem]{Definition}
#+latex_header: \theoremstyle{definition}
#+latex_header: \newtheorem{remark}[theorem]{Remark}
#+latex_header: \theoremstyle{definition}
#+latex_header: \newtheorem{example2}[theorem]{Example}

#+latex_header: \newglossaryentry{agdaprf}{name={\includegraphics[height=\baselineskip]{img/agda}},description={A definition or theorem formalized in Agda}}
#+latex_header: \newglossaryentry{coqprf}{name={\includegraphics[height=\baselineskip]{img/coq}},description={A definition or theorem formalized in Coq}}

#+macro: beginmulticols @@latex:\begin{multicols}{$1}@@
#+macro: endmulticols @@latex:\end{multicols}@@

#+latex_header: \newcommand{\joost}[1]{\textcolor{purple}{\textbf Joost: #1}}
#+latex_header: \newcommand{\jan}[1]{\textcolor{blue}{\textbf Jan: #1}}
#+latex_header: \newcommand{\luka}[1]{\textcolor{green}{\textbf Luka: #1}}
#+macro: joost @@latex:\joost{$1}@@
#+macro: jan @@latex:\jan{$1}@@
#+macro: luka @@latex:\luka{$1}@@

#+macro: agda @@latex:\gls{agdaprf}\glsadd{agdaprf}@@
#+macro: agdaimg @@latex:\gls{agdaprf}@@
#+macro: coq @@latex:\gls{coqprf}\glsadd{coqprf}@@
#+macro: cond [[cond:$1][Condition $1]]
#+macro: scond [[cond:$1][$1]]
#+macro: scondr [[cond:$1][$1]]--[[cond:$2][$2]]
#+macro: ordfr [[ordfr:$1][OF-$1]]
#+macro: genfr [[ordfr:$1][GF-$1]]
#+macro: sgenfr [[ordfr:$1][$1]]
#+macro: latex @@latex:$1@@

#+latex_header: \newcommand{\prin}[1]{\ensuremath{\mathsf{#1}}}
#+latex_header: \newcommand{\il}[0]{\prin{IL}}
#+latex_header: \newcommand{\pa}[0]{\prin{PA}}
#+latex_header: \newcommand{\gl}[0]{\prin{GL}}
#+latex_header: \newcommand{\kgen}[1]{\text{($\mathsf{#1}$)\textsubscript{gen}}}
#+latex_header: \newcommand{\kord}[1]{\text{($\mathsf{#1}$)}}
#+latex_header: \newcommand{\ilall}[0]{\ensuremath{\mathsf{IL}}(All)}
#+latex_header: \newcommand{\rep}[1]{‚åú#1‚åù}
#+latex_header: \newcommand{\prov}[2]{\ensuremath{\sf{Prov}_{#1}(#2)}}
#+latex_header: \newcommand{\fm}[0]{\ensuremath{\mathsf{Fm}}}
#+latex_header: \newcommand{\var}[0]{\ensuremath{\mathsf{Var}}}
#+latex_header: \renewcommand{\sf}[1]{\ensuremath{\mathsf{#1}}}
#+latex_header: \newcommand{\el}[1]{\ensuremath{\mathsf{El}(#1)}}
#+latex_header: \newcommand{\set}[0]{\ensuremath{\mathsf{Set}}}
#+latex_header: \newcommand{\type}[0]{\ensuremath{\mathsf{Type}}}

#+latex_header: \newcommand{\this}[0]{chapter}

{{{defglossary(gvm,model,Generalized Veltman model)}}}
{{{defglossary(gvf,frame,Generalized Veltman frame)}}}
{{{defglossary(ovf,frame,Ordinary Veltman frame)}}}
{{{defglossary(ovm,model,Ordinary Veltman model)}}}
{{{defglossary(forcing-gen,{\ensuremath{‚ä©^{gen}_M}},Forcing relation for generalized semantics)}}}
{{{defglossary(forcing-ord,{\ensuremath{‚ä©^{ord}_M}},Forcing relation for ordinary semantics)}}}
{{{defglossary(choice-set,choice set,Choice set)}}}
{{{defglossary(noetherian,Noetherian,Conversely well-founded relation)}}}
{{{defglossary(elemequivworlds,modally equivalent worlds,Two worlds that force the same formulas)}}}
{{{defglossary(elemequivmodels,modally equivalent models,Two models which have modally equivalent worlds)}}}
{{{defglossary(il,\il{},Base logic for interpretability logics)}}}
#+latex_header: \newglossaryentry{dependent-pair}{name={dependent pair},description={A pair in which the type of the second component may depend on the first component}}
#+latex_header: \newglossaryentry{sum type}{name={sum type},description={A disjunction of two ore more types}}
#+latex_header: \newglossaryentry{decidable model}{name={decidable model},description={A model whose forcing relation is decidable}}
#+latex_header: \newglossaryentry{multi decidable model}{name={multi-decidable model},description={A model whose forcing relation is decidable for sets}}
#+latex_header: \newglossaryentry{Rel}{name={\texttt{Rel}},description={Homogeneous relation}}
#+latex_header: \newglossaryentry{REL}{name={\texttt{REL}},description={Heterogeneous relation}}
#+latex_header: \newglossaryentry{Pred}{name={\texttt{Pred}},description={A predicate or a subset}}

# remember to invoke with \ilall{} and not \ilall so that the space at the end
# is inserted if needed.


# Missing monospaced characters
#+latex_header: \setmathfont{XITS Math}
#+latex_header: \newfontfamily{\myfont}{XITS Math}
#+latex_header: \newunicodechar{ùïé}{\makebox[1em]{\myfontùïé}}
#+latex_header: \newunicodechar{·µ¢}{\makebox[0.5em]{\textsubscript{i}}}
#+latex_header: \newunicodechar{‚±º}{\makebox[0.5em]{\textsubscript{j}}}
#+latex_header: \newunicodechar{‚Çñ}{\makebox[0.5em]{\textsubscript{k}}}
#+latex_header: \newunicodechar{‚Çô}{\makebox[0.5em]{\textsubscript{n}}}
#+latex_header: \newunicodechar{‚Çò}{\makebox[0.5em]{\textsubscript{m}}}
#+latex_header: \newunicodechar{·µ§}{\makebox[0.5em]{\textsubscript{u}}}
#+latex_header: \newunicodechar{‚Çó}{\makebox[0.5em]{\textsubscript{l}}}
#+latex_header: \newunicodechar{‚∏¥}{\makebox[0.5em]{,}}
#+latex_header: \newunicodechar{ÔΩõ}{\ensuremath{\{}}
#+latex_header: \newunicodechar{ÔΩù}{\ensuremath{\}}}
#+latex_header: \newunicodechar{ùî∏}{\ensuremath{ùî∏}}
#+latex_header: \newunicodechar{ùîπ}{\ensuremath{ùîπ}}
#+latex_header: \newunicodechar{ùîª}{\ensuremath{ùîª}}
#+latex_header: \newunicodechar{ùîº}{\ensuremath{ùîº}}
#+latex_header: \newunicodechar{ùîΩ}{\ensuremath{ùîΩ}}
#+latex_header: \newunicodechar{ùîæ}{\ensuremath{ùîæ}}
#+latex_header: \newunicodechar{ùí±}{\ensuremath{ùí±}}
#+latex_header: \newunicodechar{ùíû}{\ensuremath{ùíû}}
#+latex_header: \newunicodechar{‚Ñ±}{\ensuremath{‚Ñ±}}



# inexact replacements. I don't know how to exactly replace these as they do
# not exist in Latin Modern Math.
#+latex_header: \newunicodechar{‚¶É}{\ensuremath{‚ü¶}}
#+latex_header: \newunicodechar{‚¶Ñ}{\ensuremath{‚üß}}
#+latex_header: \newunicodechar{‚¶Ö}{\ensuremath{‚ü¶}}
#+latex_header: \newunicodechar{‚¶Ü}{\ensuremath{‚üß}}

#+latex_header: \setmathfont{Latin Modern Math}
#+latex_header: \newcommand{\horrule}[1]{\rule{\linewidth}{#1}}

\begin{titlepage}
  \begin{center}

    \textsc{\Large Master's thesis to obtain the degree\\ Master in pure and applied logic}
     \\[1.4cm]

    % \horrule{0.5pt} \\[0.4cm]
    { \huge \bfseries Interpretability logics and generalized Veltman semantics in Agda \\[0.01cm] }

    \horrule{0.7pt} \\[2cm]
    % \horrule{1.6pt}
    % \sectionlinetwo{black}{87}

    ~\textsc{\LARGE Jan Mas Rovira}

    ~\\[1.2cm]
    \begin{tabular}[!htb]{ll}
    \text{\large Supervised by } &\textsc{\Large Joost J. Joosten} \\
    \text{\large and } &\textsc{\Large Luka Mikec}
    \end{tabular}
    ~\\[6.2cm]

    \begin{figure}[H]
      \centering
      \includegraphics[width=9cm]{img/ub_logo}
    \end{figure}
    \vfill

    \text{\Large Facultat de Filosofia de Barcelona and}\\
    \text{\Large Facultat de Matem√†tiques de Barcelona}\\
    {\Large November 2020}

  \end{center}
\end{titlepage}

#+begin_abstract
\begin{center}
\text{\Huge Abstract}
~\\[0.5cm]
\end{center}

Sufficiently strong arithmetical theories such as \pa{} can formalize
their interpretability predicate. This predicate expresses the concept of relativized
interpretability between finite extensions of the theory. Interpretability logics
study the provable structural behaviour of the interpretability predicate.

Interpretability logics extend the provability logic \gl{}. As such, interpretability logics
inherit a number of similarities from \gl{}. For instance, the possibility to give relational semantics.
In this thesis we focus on the study of two variations of relational semantics √† la Kripke
known as \textit{ordinary Veltman semantics} and \textit{generalized Veltman semantics}.

In the literature we find various definitions of generalized Veltman semantics. In particular,
there are several conditions of \textit{quasi-transitivity}, a property that generalized frames must satisfy.
We study the interrelations between all of these conditions and discuss their adequacy.

In this thesis we compare the expressiveness of ordinary and generalized Veltman semantics. Furthermore,
we give procedures that under some assumptions transform, while preserving modal theoremhood,
ordinary models to generalized models and vice versa.

We study the frame conditions of various relevant interpretability principles
present in the literature. Moreover, we provide novel frame conditions for the
the principle \prin{R_1} and the \prin{R^n} series of principles from \cite{two-new-series}
with respect to generalized Veltman semantics.

We have formalized our findings in Agda, which is a state-of-the-art proof assistant
based on an intuitionistic theory which features dependent types.
Apart from giving a solid base to our claims, we hope that our Agda library will
provide a rallying point for researchers willing to formalize theorems in the
field of interpretability logics, or at least, to encourage more research in that direction.
Our work is, to our knowledge, the first attempt at formalizing interpretability logics in any proof assistant.
#+end_abstract
\newpage

\renewcommand{\abstractname}{Resum}
#+begin_abstract

\begin{center}
\text{\Huge Resum}
~\\[0.5cm]
\end{center}

Teories aritm√®tiques suficientment fortes tals com \pa{} poden formalitzar el
seu predicat {{{latex(d\?interpretabilitat)}}}. Aquest predicat expressa el
concepte d'interpretabilitat relativitzada entre extensions finites de la
teoria. Les l√≤giques d'interpretabilitat estudien el comportament estructural
demostrable del predicat d'interpretabilitat.

Les l√≤giques d'interpretabilitat estenen la l√≤gica de demostrabilitat \gl. Com a tals,
hereten algunes semblances de \gl{}. Per exemple, la possibilitat de definir una sem√†ntica
relacional. En aquesta tesi ens centrem en l'estudi de dues variacions de sem√†ntiques relacionals
a l'estil Kripke que es coneixen com \textit{sem√†ntica ordin√†ria Veltman} i \textit{sem√†ntica generalitzada Veltman}.

En la literatura trobem v√†ries definicions de sem√†ntica generalitzada Veltman. En particular,
hi ha diverses condicions de \textit{quasi-transitivitat}, una propietat que els marcs
 generalitzats de Veltman han de satisfer.
Estudiem les interrelacions entre aquestes condicions i comentem la seva pertin√®ncia.

En aquesta tesi comparem l'expressivitat de les sem√†ntiques Veltman ordin√†ries i
generalitzades. A m√©s, descrivim procediments que sota certes hip√≤tesis
transformen, preservant els teoremes modals, models ordinaris Veltman a models
generalitzats Veltman i viceversa.

Estudiem les condicions de marc per diversos principis d'interpretabilitat que
es troben a la literatura. A m√©s, donem noves condicions de marc pel principi
\prin{R_1} i la s√®rie de principis \prin{R^n} presentats en
\cite{two-new-series} respecte sem√†ntica generalitzada Veltman.

Hem formalitzat les nostres aportacions en Agda, que √©s un assistent de demostraci√≥ modern
basat en una l√≤gica intu√Øcionista amb tipus dependents. A banda de donar solidesa als
nostres aven√ßos, esperem que la nostra llibreria d'Agda pugui ser un punt de trobada
pels investigadors que desitgin formalitzar teoremes en el camp de les l√≤giques d'interpretabilitat,
o si m√©s no, que encoratgi m√©s investigaci√≥ en aquesta direcci√≥.
La nostra llibreria √©s, que sapiguem, el primer intent de formalitzar l√≤giques d'interpretabilitat
en algun assistent de la demostraci√≥.
#+end_abstract
\newpage

\renewcommand{\abstractname}{Acknowledgements}
#+begin_abstract
  \begin{center}
  \text{\Huge Acknowledgments}
  ~\\[0.5cm]
  \end{center}

  We want to express our gratitude to Nicola Olivetti, Rineke Verbrugge and the
  rest of the organizing committee of Advances in Modal Logic 2020 (Helsinki)
  for allowing us to present there an extended abstract of this thesis. We want
  to extend our gratitude to all the reviewers who gave valuable feedback.

  We want to express our gratitude to Rineke Verbrugge. She kindly agreed to
  publish a manuscript by hers, which has significant value historical and
  mathematical value in the field of interpretability logics, as an appendix of
  this thesis.

  I want to thank my supervisors Joost and Luka. Their incredible work ethic and
  vast knowledge on the field have been a source of inspiration throughout this
  thesis. I am ever grateful for their patience and valuable corrections.

  I want to thank Esperanza Buitrago for proof-reading the thesis and
  providing helpful feedback.

  # I want to thank Peter Dybjer for introducing me to the wonderful language of
  # Agda while I was a student at Chalmers. Also I want to thank him for the
  # pointers regarding the underlying logic of Agda.

  I would like to thank all the teachers in the Master in Pure and Applied
  logic from the University of Barcelona, with a special thanks to Ramon
  Jansana. I feel privileged for having been part of this master.

  I want to share the joy that I am feeling at the time of finishing this thesis
  with my very good friends from the master Mart√≠n and Stefano. I really hope
  that we can meet again somewhere in Raval rather sooner than later.
#+end_abstract

\newpage
#+toc: headlines 2
\newpage

* Introduction
** Overview of interpretability logics
   <<sec:overview>> This thesis studies interpretability logics. These logics
   were originally conceived (cite:visser1997overview,joosten2020overview) to
   study the provably structural behaviour of formalized relative
   interpretability. In this overview we will give some context and definitions
   to understand what this means.

   We begin by giving a short introduction on provability logics. For more
   information refer to cite:sep-logic-provability. The reason to start here is
   that interpretability logics extend provability logics. Furthermore the
   ecosystem of interpretability logics is similar to the one of provability
   logics, albeit more complex, thus it will help establish an idea of the
   problems that we will tackle further in the thesis.

   Since G√∂del's incompleteness theorems, we have been interested in studying
   how much arithmetical theories like Peano Arithmetic can say about
   themselves, more precisely, about their provability capacity. As we know,
   sufficiently strong arithmetical theories like \pa{} can represent, by means
   of a clever syntactical encoding, their provability predicate, \prov{T}{A},
   which states ``formula $A$ is provable in $T$''. A landmark result on this
   predicate G√∂del's second incompleteness theorem
   (cite:godel1931formal,sep-goedel-incompleteness) and L√∂b's theorem
   (cite:lob1955solution,sep-logic-provability). G√∂del second incompleteness
   theorem states that consistent and sufficiently strong theories like \pa{}
   cannot proof their own consistency. L√∂b's theorem, states that \pa{} proves
   $\prov{T}{\rep{A}}‚ÜíA$ only if \pa{} proves $A$. L√∂b's theorem can be
   formalized in the language of \pa{} thus:
   \[\pa‚ä¢\prov{\pa}{\rep{\prov{\pa}{\rep{A}} ‚ÜíA}}‚Üí\prov{\pa}{\rep{A}}.\] This
   result sparked an interest in studying provability logic from a modal point
   of view which yielded the axiomatization of the propositional provability
   logic \gl{}, named after G√∂del and L√∂b. The logic \gl{} extends propositional
   classical logic and its language consists of the language of propositional
   logic $‚ü®‚Üí,‚ä•‚ü©$ plus the modal operator $‚ñ°$, which stands for the provability
   predicate. In this language L√∂b's theorem reads as \[‚ñ°(‚ñ°A‚ÜíA)‚Üí‚ñ°A.\] The above
   /principle/ is in fact one of the axioms of \gl{}. The importance of \gl{}
   depends on the arithmetical soundness and completeness theorems that we will
   present shortly, but first we need to introduce the concept of /arithmetical
   realization/. An arithmetical realization $*$ is a map from modal formulas in
   the language of \gl{} to arithmetical sentences of $T$ such that it satisfies
   the following:
   \begin{flalign*}
   p^* &\text{ is a $T$-sentence};\\
   ‚ä•^* &= (0=1) ; \\
   (A ‚Üí B)^* &= A^*‚ÜíB^*; \\
   (‚ñ°A)^* &= \prov{T}{\rep{A}}.
   \end{flalign*}
   Note that specifying how an arithmetical realization $*$ acts on
   propositional variables fixes the behaviour of $*$ on all modal formulas.

   The arithmetical soundness theorem states that if $\gl{}‚ä¢A$ then $\pa{}‚ä¢A^*$
   for any realization $*$. Solovay proved (cite:solovay1976provability) that
   arithmetical completeness, which is the converse of soundness, also holds.

   Provability logics have Kripke (relational) semantics. As a reminder, a
   Kripke model is a tuple $‚ü®W,R,V‚ü©$ where $W$ is a non-empty set of worlds, $R$
   is a binary relation on worlds and $V‚äÜW√ó\var{}$ is a valuation. Then we
   define a forcing relation $‚ä©$ that relates worlds and modal formulas. We
   write $w‚ä©A$ to say that world $w$ forces $A$:
   1. $w‚äÆ‚ä•$;
   2. if $p$ is a propositional variable, then $w‚ä©p$ iff: $‚ü®w,p‚ü©‚ààV$;
   3. if $A$ and $B$ are formulas, then $w‚ä©A‚ÜíB$ iff: if $w‚ä©A$ then $w‚ä©B$;
   4. if $A$ is a formula, then $w‚ä©‚ñ°A$ iff: if $wRu$ then $u‚ä©A$.
   In order to state a powerful modal soundness and completeness theorem we
   ought to restrict the class of frames that we consider. We say that a frame
   $‚ü®W,R‚ü©$ is a $\text{\gl{}-frame}$ if $R$ is transitive and conversely
   well-founded, that is, there are no infinite ascending chains $w‚ÇÄRw‚ÇÅR‚Ä¶$. Then
   we have that \[\gl{}‚ä¢A‚áî(‚ü®W,R,V‚ü©‚ä©A \text{ for any \gl{}-frame $‚ü®W,R‚ü©$ and
   valuation $V$).} \] With this we conclude the introduction to provability
   logics and continue with interpretability logics.

   We introduce the concept of /interpretation/ as a first step towards
   understanding interpretability logics. Given two theories $V$ and $U$, an
   interpretation of $V$ into $U$ is a translation $f$ from \text{$V$-formulas}
   to \text{$U$-formulas} such that if $V‚ä¢A$ then $U‚ä¢f(A)$. As such, we work
   with the notion of /theorem's interpretability/. Moreover, we will allow for
   domain relativization. In the history of mathematics we find numerous
   examples (cite:visser1997overview) of theorems that use interpretations as a
   cornerstone in their proofs. For instance, G√∂del's incompleteness theorems
   translate syntactical constructions into natural numbers. As another example
   we have that G√∂del's interpretation of \prin{ZF} plus the axiom of
   constructibility ($V=L$) in \sf{ZF} serves as a proof of relative consistency
   of the continuum hypothesis with respect to \prin{ZF}.

   Interpretability logics, as the name foretells, studies the behaviour of
   interpretations. There are a number of things that we need to specify. We do
   not study the behaviour of interpretations between two arbitrary theories.
   Instead, we fix a base theory $T$ and we only consider interpretability
   between finite extensions of such a theory. Thus when we say that $T+A$
   interprets $T+B$ we assume that $A$ and $B$ are sentences. In
   interpretability logics we only consider first order arithmetical theories
   which are recursively enumerable and are sequential[fn::A sequential theory
   is an arithmetical which can code and decode sequences of elements.].
   Moreover, we are only concerned with the provable, within $T$,
   interpretability properties. In other words, we study the behaviour of the
   binary formalized interpretability predicate $\sf{Int}_T(.,.)$. Naturally,
   the predicate $\sf{Int}_T(\rep{A},\rep{B})$ precisely holds when we can $T+A$
   interprets $T+B$. For a theory $T$, we denote the logic that describes the
   behaviour of the interpretability predicate of $T$ as $\sf{IL}(T)$. The
   language of $\sf{IL}(T)$ extends the language of \sf{GL} with the binary
   modal operator $‚ñ∑$, thus the language becomes $‚ü®‚ä•,‚Üí,‚ñ°,‚ñ∑‚ü©$. In order to give a
   more detailed definition of $\sf{IL}(T)$ we first extend the definition of
   arithmetical realization with an extra clause for the $‚ñ∑$ case. An
   arithmetical realization $*$ is a map from formulas in $\sf{IL}(T)$ to
   sentences in the language of $T$. Moreover, it must satisfy the following
   constraints:
   \begin{flalign*}
   p^* &\text{ is a $T$-sentence};\\
   ‚ä•^* &= (0=1);\\
   (A‚ÜíB)^*&= A^*‚ÜíB^* ; \\
   (‚ñ°A)^*&= \sf{Prov}_T(‚åúA‚åù) ; \\
   (A‚ñ∑B)^*&= \sf{Int}_T(‚åúA‚åù,‚åúB‚åù).
   \end{flalign*}
   Then we define the interpretability logic of a theory $T$ in the following
   way: \[\sf{IL}(T)‚âî\{A\ |\ T‚ä¢A^* \text{ for any realization } *\ \}.\]

   There is an important difference with respect to provability logics that we
   need to highlight here. In provability logics we have that \sf{GL} is an
   axiomatization of the provability logics for all sufficiently strong
   consistent arithmetical theories. However, we do not have an equivalent Swiss
   army knife that works for all theories in interpretability logics. In other
   words, we do not have a single axiomatization of $\sf{IL}(T)$. Instead, we
   define different logics for various classes of theories. There is a basic
   logic which we call \il{} that serves as the base for all these variants. We
   define these variants as extensions of \il{} by adding axiom schemas to it as
   we will see later in this overview. The logic \il{} extends the \sf{GL} logic
   with five new axiom schemas. We will precisely define the logic \il{} and
   comment on the significance of the new axiom schemas in cref:sec:il.

   The logic \il{} has two relational semantics, which are the main topic of
   this thesis, known as /ordinary Veltman semantics/ (introduced by Frank
   Veltman in cite:Veltman-relative) and /generalized Veltman semantics/
   (introduced by Rineke Verbrugge in cite:Verbrugge). Ordinary Veltman
   semantics are defined in much the same spirit as Kripke semantics for
   \sf{GL}. However, ordinary Veltman frames have an additional family of
   relations indexed by each of the worlds[fn::Alternatively, we may refer to
   $S$ as a ternary relation, where the first component corresponds to the index
   of the family.]: $\{S_w:w‚ààW\}$. Each of the $S_w$ is a binary relation which
   relates two worlds. The family of relations $S$ is used to model the
   behaviour of the binary modal operator $‚ñ∑$.

   In generalized Veltman semantics each of the $S_w$ relations, instead of
   relating two individual worlds, relates an individual world to a set of
   worlds. This type of definition seems to be inspired by the neighborhood
   semantics that exist for other modal logics with unary modal operators.
   Neighborhood semantics have not been studied yet for interpretability logics.
   Both kinds of Veltman semantics are suitable for \il{} as we have soundness
   (which we present in this thesis) and completeness proofs
   (cite:Veltman-relative).

   As we have already mentioned, \il{} is just the logic that we use as a base
   in interpretability logics, thus, each time we extend it with an axiom scheme
   (or principle, as we call them) we will need to find new semantics for it.
   Given a collection of principles, we get the semantics for the extension of
   \il{} with these principles by finding their frame condition. More precisely,
   a /frame condition/ for a principle \prin{X} is a first (or higher) order
   formula $ùíû_\prin{X}$ such that for every Veltman frame $F$ we have
   \[F‚ä®ùíû_\prin{X} ‚áî ‚ü®F,V‚ü©‚ä©\sf{X} \text{ for any valuation $V$ and instance of
   \prin{X}.} \] To give an example, let us put our focus on the
   interpretability logic of \sf{PA}. It happens
   (cite:berarducci1990interpretability,shavrukov1988logic) that the
   axiomatization of \sf{IL(PA)} is given by adding the so called principle
   \sf{M} to the logic \il{}. We denote this new logic as $\sf{ILM}$. The
   principle \prin{M} is defined as follows: \[\sf{M}‚âî(A ‚ñ∑ B) ‚Üí ((A ‚àß ‚ñ° C) ‚ñ∑ (B
   ‚àß ‚ñ° C)).\] Then, consider the following condition:
   #+begin_center
   $C_\prin{M}‚âî$ if $xS_wy$ and $yRz$ then $xRz$.
   #+end_center
   Then, if we consider the class of Veltman frames that satisfy condition
   $C_\prin{M}$, we have soundness and completeness of \sf{ILM} and thus the
   presented condition is a suitable frame condition for \sf{M}. There are
   plenty of principles similar to \sf{M} in the literature. In this thesis we
   list a number of interpretability principles, including \sf{M}, and we
   present their frame condition for both ordinary and generalized Veltman
   semantics.

   Some principles, like \sf{M}, are useful because they allow us to axiomatize
   the interpretability logic for certain classes of theories. However, there
   are other principles which are interesting because they are arithmetically
   valid in a large number of theories. These principles play a crucial role in
   the search of an axiomatization for the theory \ilall{}. The theory \ilall{}
   is defined to be the intersection of the interpretability logics of all
   reasonable arithmetical theories
   (cite:Visser1990,Visser:1991:FormalizationOfInterpretability). Finding an
   axiomatization of this logic, as already hinted, remains an open problem,
   however a lot of progress has been made in the form of finding lower bounds
   for this logic
   (cite:joosten-master,two-new-series,joosten2020interpretability). In this
   thesis we study the frame conditions for two series of principles: \prin{R^n}
   and \prin{R_n}, which appear in the current best known lower bound of
   \ilall{}.

** Original contributions
   This thesis includes the following original contributions:
   1. We have found a generalized frame condition for $\prin{R‚ÇÅ}$ (in
      collaboration with Mikec). See cref:theorem:R_1.
   2. We have found a generalized frame condition for $\prin{R‚Åø}$. See
      cref:theorem:R^n.
   3. We performed a detailed analysis of the quasi-transitivity conditions
      available in the literature for generalized semantics. See cref:sec:trans.
   4. We analyzed how a monotonicity condition for generalized semantics that is
      often assumed or taken as part of the definition for generalized frames
      interacts with the quasi-transitivity conditions present in the
      literature. Furthermore, we justify why in a sense assuming such condition
      if it is not required by the definition is harmless. See cref:sec:mono.
   5. We discovered a proof in a published article which needs to be repaired.
      See cref:sec:flawed-proof.
   6. We compare the expressiveness of ordinary and generalized Veltman models.
      As part of this, we worked out all the details of a proof in an
      unpublished manuscript by Verbrugge (cite:Verbrugge). We attach this
      manuscript in cref:pdf:Verbrugge.
   7. We present the implementation of a verified language to write Hilbert
      style proofs (for the logic \prin{IL}) in Agda with paper-like syntax.
      See cref:sec:edsl.
   8. We give details for an embedding of propositional intuitionistic logic
      into Martin L√∂f's logical framework. This result is expected. Our
      contribution has been to provide detailed definitions and proofs, which we
      were unable to find somewhere else. The proof detailed proof that $n+0=n$
      in Martin L√∂f's logical framework is also original. See cref:sec:def-new-types.
   9. During the development of this thesis we have coauthored two publications:
      - /An overview of Generalised Veltman Semantics/
        (cite:joosten2020overview). In this publication we give an up-to-date
        overview of interpretability logics with a focus on generalized semantics.
      - /Generalised Veltman Semantics in Agda/ (cite:masrovira2020generalised).
        In this publication we focus on the frame conditions for generalized
        Semantics for the principle \prin{R_1} and the series \prin{R^n}. We
        also comment on the Agda formalization. This extended abstract was
        presented in August in the peer-reviewed AiML2020 conference in Helsinki
        (online).
   10. We have implemented an Agda library for interpretability logics which
       includes every theorem and proof marked with {{{agdaimg}}} that is presented
       in this thesis. It is worth pointing out that we started from scratch
       since there was no previous published work of interpretability logics in
       Agda, or in any other proof assistant. The library comprises ~5000
       lines of code and is freely available online:
       \begin{center}
       \href{https://gitlab.com/janmasrovira/interpretability-logics}
             {gitlab.com/janmasrovira/interpretability-logics}
       \end{center}
       We also provide the Agda code in the annex of this thesis. See
       cref:src:agda.

       *Note*: Throughout this thesis we present the proofs (in English) of all
       the lemmas and theorems listed. Often we skip details or we only present
       part of the proofs. It is important that we emphasize that when we mark a
       proof with the {{{agdaimg}}} symbol it means that the whole proof (not
       only the commented part) has been formalized down to the definitions in
       Agda.

   11. We have reimplemented a small portion of the Agda library in the Coq
       proof assistant (cite:coq). This portion includes the definitions of the
       theorems and proofs marked with {{{coq}}}. Namely this subset is composed
       of the definition of ordinary Veltman semantics, the axiomatization of
       the logic \il{} and its proof of soundness. The library comprises ~500
       lines of code and is available online:
       \begin{center}
       \href{https://gitlab.com/janmasrovira/coq-interpretability-logics}
            {gitlab.com/janmasrovira/coq-interpretability-logics}
       \end{center}
       We also provide the Coq code in the annex of this thesis. See
       cref:src:coq.

** Notation
   <<sec-notation>>

   In this chapter we will fix notation that is used throughout the thesis. Of
   course, it makes most sense to skip the section at first and come back to it
   while reading the remainder of the thesis.

*** Text
    Here we list a number of notational conventions that we use in the text of
    the thesis:

   1. If $R$ and $R'$ are binary relations, then $wRuR'v$ means $wRu$ and $uR'v$.
      For instance $wRuS_xv$ means $wRu$ and $uS_xv$. Another example: $wRu‚ä©A$
      means $wRu$ and $u‚ä©A$.
   2. $Y‚ä©A$ iff for all $y‚ààY$ we have $y‚ä©A$.
   3. $Y‚äÆA$ iff there is some $y‚ààY$ such that $y‚äÆA$;
   4. $‚ü¶A‚üß‚âî\{w:w‚ä©A\}$.
   5. When we write a dot after the quantification of some variables, the scope
      of the variables extends to the rightmost part of what follows, of course,
      without escaping parentheses. Hence the formula $‚àÄx‚àÉy.Pxy‚àß‚àÄz.Pyz$ is
      equivalent to $‚àÄx‚àÉy(Pxy‚àß‚àÄz(Pyz))$.
   6. We use commas to denote conjunction, so $‚àÄx.A(x),B(x)$ should be
      read as for all $x$ we have $A(x)$ and $B(x)$.
   7. If \prin{X} is a principle (or axiom schema), we denote by \prin{ILX} the
      logic which consists in adding the axiom schema \prin{X} to the logic
      \il{}. We will write \prin{ILXY} to denote that we add principles \prin{X}
      and \prin{Y} to the \il{}, and so on.
   8. In lambda calculus and Martin L√∂f's logical framework
      (cref:sec:logic-agda), we write $e[x‚Ü¶a]$ to say that all free occurrences
      of $x$ in $e$ are replaced by $a$. We write $e[x‚ÇÅ‚Ü¶a‚ÇÅ,‚Ä¶,x‚Çô‚Ü¶a‚Çô]$ instead of
      $(‚Ä¶(e[x‚ÇÅ‚Ü¶a‚ÇÅ])‚Ä¶)[x‚Çô‚Ü¶a‚Çô]$.

*** Diagrams
    <<sec:notation-diagrams>> Throughout the thesis we present some diagrams to
    represent ordinary and generalized Veltman frames. We believe that diagrams
    can help the reader have a better understanding of the underlying formula.
    However, diagrams are not meant to be a replacement as they cannot
    unambiguously convey all the information in the formula. Here we list some
    conventions that we use to help the reader understand the presented diagrams.

    - *Straight arrows*: We use straight arrows to represent the $R$ relation.
      For instance we represent $xRy$ thus:
      #+attr_latex: :float t :width 0.20\textwidth :placement [H]
      [[file:img/xRy.pdf]]

    - *Curvy arrows*: We use curvy arrows to represent the $S$ relation. For
      instance, if we have $xS_wy$ we will draw a curvy line from $x$ to $y$
      with label $S_w$ as drawn below. In the case that we are drawing a
      generalized Veltman frame then $Y$ is a set of worlds which we draw as a circle.
      #+attr_latex: :float t :width 0.50\textwidth :placement [H]
      [[file:img/xSwy.pdf]]

    - *Circles and frames*: Circles denote sets of worlds in generalized Veltman frames. As
      expected, we will draw inner circles to denote subsets and intersected
      circles to denote that the intersection is nonempty. For instance, to
      denote that we have $V'‚äÜV$ we will draw the left picture. If we want to
      express that $V‚à©V'‚â†‚àÖ$ we will draw the right picture.
      \nopagebreak[4]
      #+attr_latex: :float t :width 0.35\textwidth :placement [H]
      [[file:img/circles.pdf]]

      We will use framed variables to denote singleton sets. We will represent
      the singleton set $\{y\}$ as \boxed{y} in a diagram.

    - *Quantfier annotations*: When a variable that represents a world or a set
      of worlds in the formula, we may tag that variable with the corresponding
      quantifier. We only follow this convention in cases when we think it
      improves the readability of the diagram. For instance, if we want to
      express the condition $‚àÄy(‚àÄx(xRy)‚áí‚àÉz(yRz))$ we will draw the picture
      below. As a rule of thumb we do not annotate the quantification of
      variables which are universally quantified for the whole formula or which
      are free.
      #+attr_latex: :float nil :width 0.14\textwidth :placement [H]
      [[file:img/quantifier.pdf]]

    - *Red and black ink*: We use black ink for conditions which appear in a
      negative position (assumptions) and red ink for conditions which appear in
      a positive position (consequences). Thus, the intended meaning of color is
      that ``if everything drawn in black holds, then what is drawn in red must
      hold''. For instance, in order to represent the transitivity condition
      $xRyRz‚áíxRz$ we would draw the following:
      #+attr_latex: :float nil :width 0.14\textwidth :placement [H]
      [[file:img/notation-trans.pdf]]
** The language of modal interpretability
   <<sec:language>>

   The symbols of interpretability logics are $‚ä•,‚Üí,‚ñ∑$.

   {{{begindef}}} *Modal formula* {{{agda}}} {{{coq}}} The set of well-formed
   modal formulas, which we denote with \fm{}, is defined recursively as usual:
   1. /Variable/. If $x$ is a variable, then $x$ is a formula. We assume that we
      have an infinite countable set of variables. In particular we shall define
      $\var{}‚âî‚Ñï$. However, we use non-capital letters to refer to
      variables.
   2. /Bottom/. The constant $‚ä•$ is a formula.
   3. /Implication/. If $A$ and $B$ are formulas, then $(A‚ÜíB)$ is a formula.
   4. /Interprets/. If $A$ and $B$ are formulas, then $(A‚ñ∑B)$ is a formula.

   We will always drop outer parentheses.
   {{{enddef}}}

   {{{begindef}}} *Convenience operators* {{{agda}}} {{{coq}}} We define the
   usual operators and constants in the following way:
   1. $¬¨ A ‚âî A ‚Üí ‚ä•$;
   2. $‚ä§ ‚âî ¬¨ ‚ä•$;
   3. $A ‚à® B ‚âî (¬¨ A) ‚Üí B$;
   4. $A ‚àß B ‚âî ¬¨ (A ‚Üí ¬¨ B)$;
   5. $A ‚Üî B ‚âî (A ‚Üí B) ‚àß (B ‚Üí A)$;
   6. $‚ñ° A ‚âî (¬¨ A) ‚ñ∑ ‚ä•$;
   7. $‚ô¢ A ‚âî ¬¨ ‚ñ° ¬¨ A$.

   The precedence from higher to lower of the operators is in the following
   order: \[‚àß,‚à®,‚ñ∑,‚Üí\]

   The scope of unary symbols $‚ñ°,‚ô¢,¬¨$ is as small as possible. Thus $‚ñ°A‚àß¬¨¬¨B$ is
   the same as $(‚ñ°A)‚àß(¬¨¬¨B)$. Also, $‚Üí$ has right associativity.

   As an example consider: \[A ‚ñ∑ B ‚Üí A ‚àß ‚ñ° C ‚ñ∑ B ‚àß ‚ñ° C\] It should be read as:
     \[(A ‚ñ∑ B) ‚Üí ((A ‚àß ‚ñ° C) ‚ñ∑ (B ‚àß ‚ñ° C))\] Even though the notation with no
     parenthesis is acceptable with the rules that we have given, we will often add
     parentheses to facilitate reading non-trivial formulas. {{{enddef}}}
** Logic \il
   <<sec:il>> As explained in the overview (cref:sec:overview), the logic \il{}
   is the logic that we use as the base for other interpretability logics. The
   logic \il{} extends \gl{} with five new axiom schemas denoted by J1--J5.
   These new axioms reflect some facts about formalized interpretability.

   After the definition of \il{} we proceed by showing a number of theorems
   related to it. All of these theorems have been verified by a computer using
   the proof-assistant Agda. In cref:sec:logic-agda we will explain how Agda
   works and what it means for a proof to be formally verified in Agda. In
   cref:sec:agda-thesis we will explain how we have formalized the presented
   theorems and their respective proofs in Agda. The Agda proofs of the theorems
   presented in this section can be found in cref:src:il.properties.

   {{{begindef}}} {{{agda}}} {{{coq}}} \glsadd{il} The logic \il{} encompasses
   all classical theorems in the new language (given by C1, C2 and C3), all
   theorems of \prin{GL} in the new language (given by L and K) plus some new
   axiom schemas:
   - C1: $A ‚Üí (B ‚Üí A)$;
   - C2: $(A ‚Üí (B ‚Üí C)) ‚Üí ((A ‚Üí B) ‚Üí (A ‚Üí C))$;
   - C3: $(¬¨ A ‚Üí ¬¨ B) ‚Üí (B ‚Üí A)$;
   - K: $‚ñ° (A ‚Üí B) ‚Üí ‚ñ° A ‚Üí ‚ñ° B$;

     This provability principle is known as the /distribution axiom/ and implies
     that if we can prove that $A$ implies $B$, then we can prove $B$ from a
     proof of $A$.
   - L: $‚ñ° (‚ñ° A ‚Üí A) ‚Üí ‚ñ° A$.

     This provability principle corresponds to L√∂bs theorem.
   - J1: $‚ñ° (A ‚Üí B) ‚Üí A ‚ñ∑ B$.

     This interpretability principle expresses the fact that if a theory $T$ can
     prove that $A$ is at least as strong as $B$, then $T+A$ interprets $T + B$
     using the identity interpretation.
   - J2: $(A ‚ñ∑ B) ‚àß (B ‚ñ∑ C) ‚Üí A ‚ñ∑ C$.

     This interpretability principle gives us transitivity for interpretations.
   - J3: $((A ‚ñ∑ C) ‚àß (B ‚ñ∑ C)) ‚Üí (A ‚à® B) ‚ñ∑ C$.

     This interpretability principle allows us to build interpretations by
     cases.
   - J4: $A ‚ñ∑ B ‚Üí (‚ô¢ A ‚Üí ‚ô¢ B)$.

     This interpretability principle reflects the fact that relative
     interpretability gives us a proof of relative consistency.
   - J5: $(‚ô¢ A) ‚ñ∑ A$.

     The last interpretability principle expresses the property that from a
     consistency proof of $A$ we can build an interpretation of $A$ itself. This
     reflects the fact that the Henkin construction can be formalized.

   If $A$ is an instantiation of any of the previous axiom schemas, then $A$ is
   a theorem of $\il{}$, which we denote with $‚ä¢_{\il}A$. Additionally it has
   the following rules:
   - /Necessitation/: if $‚ä¢_{\il}A$ then $Œ†‚ä¢_{\il}‚ñ°A$. Notice that the
     necessitation rule requires $A$ to be provable from an empty set of
     assumptions. In the consequence of the rule ($Œ†‚ä¢_{\il}‚ñ°A$) we allow an
     arbitrary context $Œ†$.
   - /Modus ponens/: if $Œ†‚ä¢_{\il}A‚ÜíB$ and $Œ†‚ä¢_{\il}A$ then $Œ†‚ä¢_{\il}B$.
   - /Identity/: If $A‚ààŒ†$ then $Œ†‚ä¢_{\il}A$.
   {{{enddef}}}

   {{{beginremark}}} While it is acceptable to have an infinite set of
   assumptions $Œ†$, when verifying properties in Agda we have restricted
   ourselves to finite sets and thus we assume that $Œ†$ is finite in the Agda
   proof.
   {{{endremark}}}

   {{{begintheorem}}} *Weakening* {{{agda}}} If $Œ†‚ä¢_{\il}A$ then $B,Œ†‚ä¢_{\il}A$.
   {{{endtheorem}}} {{{beginproof}}} The proof is by induction on the
   proof. In Agda it is done by an induction on the proof. We only need to take
   care of shifting one position the references to assumptions. {{{endproof}}}

   {{{begintheorem}}} *Deduction* {{{agda}}} $Œ†‚ä¢_{\il}A‚ÜíB$ iff $A,Œ†‚ä¢_{\il}B$.
   {{{endtheorem}}} {{{beginproof}}} The $‚áí$ direction is trivial.
   For the other direction we proceed by induction on the proof $A,Œ†‚ä¢_\il{}B$.
   We need to show that if $A,Œ†‚ä¢_\il{}B$ then $Œ†‚ä¢_\il{}A‚ÜíB$. If $B$ is an
   instance of any of the axioms, we can show that $A‚ÜíB$ follows from MP, C1 and
   the corresponding axiom. If $B=‚ñ°B'$ follows from the necessitation rule then
   by definition of the necessitation rule we have $‚ä¢_\il{}B'$ and thus by
   necessitation, C1 and MP we can prove $Œ†‚ä¢_\il{}A‚Üí‚ñ°B'$. If $B$ follows from an
   assumption we have two cases. If $B=A$ then we show $‚ä¢_\il{}A‚ÜíA$ as we do in
   classical logic. If $B‚ààŒ†$ we proceed as before using MP, C1. Finally, if $B$
   is the result of a MP application then we have that $A,Œ†‚ä¢_\il{}C‚ÜíB$ and
   $A,Œ†‚ä¢_\il{}C$ by the IH we have $Œ†‚ä¢_\il{}A‚Üí(C‚ÜíB)$ and $Œ†‚ä¢_\il{}A‚ÜíC$, thus we
   can show $Œ†‚ä¢_\il{}A‚ÜíB$ by the C2 axiom and two applications of MP.
   {{{endproof}}}

   {{{begintheorem}}} *Cut* {{{agda}}} If $Œ†‚ä¢_{\il}B$ and $B,Œ†‚ä¢_{\il}A$ then $Œ†‚ä¢_{\il}A$.
   {{{endtheorem}}} {{{beginproof}}} It follows by an easy induction on the
   proof $Œ† ‚ä¢_\il{} B$.
   {{{endproof}}}

   {{{begintheorem}}} *Structurality* {{{agda}}} If $Œ†‚ä¢_\il{}A$ and $œÉ$ is a
   substitution then $œÉ[Œ†]‚ä¢_{\il}œÉ(A)$. {{{endtheorem}}} {{{beginproof}}} It
   follows by an easy induction on the proof $Œ†‚ä¢_\il{}A$. {{{endproof}}}


   {{{begintheorem}}} \label{thm:conjunction} *Conjunction* {{{agda}}}
   $Œ†‚ä¢_{\il}A‚àßB$ iff $Œ†‚ä¢_{\il}A$ and $Œ†‚ä¢_{\il}B$. {{{endtheorem}}}
   {{{beginproof}}} The key part is to show that $Œ†‚ä¢_\il{}A‚ÜíB‚Üí(A‚àßB)$,
   $Œ†‚ä¢_\il{}A‚àßB‚ÜíA$ and $Œ†‚ä¢_\il{}A‚àßB‚ÜíB$ as we do in classical logic.
   {{{endproof}}}

   {{{begintheorem}}} {{{agda}}} The following formulas are theorems of \il{}:
    1. $‚ä¢_{\il} A ‚Üí A$;
    2. $‚ä¢_{\il} A ‚ñ∑ A$;
    3. $‚ä¢_{\il} (A ‚Üí B) ‚Üí (B ‚Üí C) ‚Üí A ‚Üí C$;
    4. $‚ä¢_{\il} A ‚Üí ¬¨ ¬¨ A$;
    5. $‚ä¢_{\il} (¬¨ ¬¨ A) ‚Üí A$;
    6. $‚ä¢_{\il} (A ‚Üí B) ‚Üí ¬¨ B ‚Üí ¬¨ A$;
    7. $‚ä¢_{\il} A ‚Üí ‚ä§$;
    8. $‚ä¢_{\il} ‚ä• ‚Üí A$;
    9. $‚ä¢_{\il} ¬¨ A ‚Üí A ‚Üí B$;
    10. $‚ä¢_{\il} A ‚àß B ‚Üí A$;
    11. $‚ä¢_{\il} A ‚àß B ‚Üí B$;
    12. $‚ä¢_{\il} (A ‚Üí B ‚Üí C) ‚Üí B ‚Üí A ‚Üí C$;
    13. $‚ä¢_{\il} A ‚Üí B ‚Üí A ‚àß B$;
    14. $‚ä¢_{\il} A ‚Üí A ‚à® B$;
    15. $‚ä¢_{\il} B ‚Üí A ‚à® B$;
    16. $‚ä¢_{\il} A ‚ñ∑ (A ‚à® ‚ô¢ A)$;
    17. $‚ä¢_{\il} (A ‚à® ‚ô¢ A) ‚ñ∑ A$;
    18. $‚ä¢_{\il} A ‚Üí B ‚áí ‚ä¢_{\il} ‚ñ° A ‚Üí ‚ñ° B$;
    19. $‚ä¢_{\il} A ‚Üî B ‚áí ‚ä¢_{\il} ‚ñ° A ‚Üî ‚ñ° B$;
    20. $‚ä¢_{\il} ‚ñ° (A ‚àß B) ‚Üî (‚ñ° A ‚àß ‚ñ° B)$;
    21. $‚ä¢_{\il} A ‚Üí B ‚áí ‚ä¢_{\il} ‚ô¢ A ‚Üí ‚ô¢ B$;
    22. $‚ä¢_{\il} A ‚Üî B ‚áí ‚ä¢_{\il} ‚ô¢ A ‚Üî ‚ô¢ B$;
    23. $‚ä¢_{\il} ¬¨ (A ‚àß B) ‚Üî ¬¨ A ‚à® ¬¨ B$;
    24. $‚ä¢_{\il} (A ‚à® ¬¨ B) ‚Üí (A ‚àß B ‚à® ¬¨ B)$.
   {{{endtheorem}}} {{{beginproof}}} All proofs have been formalized
   in Agda. Here we only show two examples. Consider theorems 16 and 17, namely
   $A ‚ñ∑ (A ‚à® ‚ô¢ A)$ and $(A ‚à® ‚ô¢ A) ‚ñ∑ A$. To prove 16 we assume that we have
   already showed theorem 14, that is, $‚ä¢_{\il}A‚ÜíA‚à®B$.
   \begin{flalign*}
   &1.\ A‚ÜíA‚à®‚ô¢A & \text{by $A‚ÜíA‚à®B$} \\
   &2.\ ‚ñ° (A‚ÜíA‚à®‚ô¢A) & \text{by Nec} \\
   &3.\ ‚ñ° (A‚ÜíA‚à®‚ô¢A)‚ÜíA‚ñ∑(A‚à®‚ô¢A) & \text{by J1} \\
   &4.\ A‚ñ∑(A‚à®‚ô¢A) & \text{by MP on 2, 3}
   \end{flalign*}
   To prove 17 we assume we have already showed theorem 2, that is,
   $‚ä¢_{\il}A‚ñ∑A$.
   \begin{flalign*}
   &1.\ A‚ñ∑A &\text{} \\
   &2.\ (‚ô¢A‚ñ∑A) &\text{by J5} \\
   &3.\ (A‚ñ∑A)‚àß(‚ô¢A‚ñ∑A) &\text{Conjunction, \cref{thm:conjunction}} \\
   &4.\ (A‚ñ∑A)‚àß(‚ô¢A‚ñ∑A)‚Üí ((A ‚à® ‚ô¢ A) ‚ñ∑ A)& \text{by J3} \\
   &5.\ (A ‚à® ‚ô¢ A) ‚ñ∑ A & \text{by MP 3, 4}
   \end{flalign*}

   In cref:sec:edsl we will present a verified language to write verified
   Hilbert style proofs using a computer with paper-like syntax.
   {{{endproof}}}

** Veltman Semantics
   In this thesis we consider two variants of relational semantics for
   interpretability logics similar to Kripke semantics for other modal logics.

*** Ordinary Veltman semantics
    Ordinary Veltman semantics were the first relational semantics for
    interpretability logics and were introduced by Frank Veltman
    (cite:Veltman-relative).

    All the definitions in this section have been formalized in Agda and can be
    found in cref:src:ordinaryframe,src:ordinaryveltmansemantics. Later in
    cref:sec:agda-ord-semantics we will comment on the Agda implementation of
    ordinary Veltman semantics.

    {{{begindef}}} {{{agda}}} {{{coq}}} <<def:ordinary-frames>>
    An ordinary Veltman \gls{ovf} $F=‚ü®W,R,S‚ü©$ is a structure
    constituted by a non-empty set of worlds $W$, a binary relation $R‚äÜW¬≤$ and a
    ternary relation $S‚äÜW√óW√óW$. We write $wRu$ instead of $‚ü®w,u‚ü©‚ààR$ and $uS_wv$
    instead of $‚ü®w,u,v‚ü©‚ààS$. The structure must satisfy the following conditions:

    #+begin_itemize
    \item[OF-1:] <<ordfr:1>> $R$ is transitive;
    \item[OF-2:] <<ordfr:2>> $R$ is conversely well-founded. That is, there is no infinite
       ascending chain $w‚ÇÅRw‚ÇÇR‚Ä¶$;
    \item[OF-3:]  <<ordfr:3>> if $uS_wv$ then $wRu$ and $wRv$;
      #+attr_latex: :float nil :width 0.19\textwidth :placement [H]
      [[file:img/cond1-ord.pdf]]
    \item[OF-4:]  <<ordfr:4>> if $wRu$ then $uS_wu$;
      #+attr_latex: :float nil :width 0.064\textwidth :placement [H]
      [[file:img/refl-ord.pdf]]
    \item[OF-5:]  <<ordfr:5>> if $wRu$ and $uRv$ then $uS_wv$;
      #+attr_latex: :float nil :width 0.16\textwidth :placement [H]
      [[file:img/RStrans-ord.pdf]]
    \item[OF-6:] <<ordfr:6>> for every $w$, $S_w$ is transitive.
    #+end_itemize

    The Agda definition can be found in cref:src:ordinaryframe.
    {{{enddef}}}

    As usual, we can build a model by attaching a valuation to a frame. The
    valuation will tell us which propositional variables are true in each world.

    {{{begindef}}} {{{agda}}} {{{coq}}} An ordinary Veltman \gls{ovm} $M=‚ü®F,V‚ü©$
    is a structure constituted by an ordinary Veltman frame $F$ and a valuation
    $V‚äÜW√ó\var{}$. If $F=‚ü®W,R,S‚ü©$ we will write $M=‚ü®W,R,S,V‚ü©$ instead of
    $M=‚ü®‚ü®W,R,S‚ü©,V‚ü©$.

    The Agda definition can be found in cref:src:ordinaryveltmansemantics.
    {{{enddef}}}


    We will proceed by defining a forcing relation. The forcing relation tells
    us what formulas are forced (hold) in each world.

    {{{begindef}}} {{{agda}}} {{{coq}}} <<def:ord-forcing>> Given a model $M$,
    we define a forcing relation $\gls{forcing-ord}‚äÜW √ó \fm{}$. We write $M,w‚ä©A$
    instead of $‚ü®w,A‚ü©‚àà\gls*{forcing-ord}$ or simply $w‚ä©A$ when the model is
    clear from the context. We write $w‚äÆA$ when $‚ü®w,A‚ü©‚àâ‚ä©_M$.
    1. $w‚äÆ‚ä•$;
    2. if $p‚àà\var{}$, then $w‚ä©p$ iff $‚ü®w,p‚ü©‚ààV$;
    3. if $A,B‚àà\fm{}$, then $w‚ä©A‚ÜíB$ iff if $w‚ä©A$ then $w‚ä©B$;
    4. if $A,B‚àà\fm{}$, then $w‚ä©A‚ñ∑B$ iff if $wRu$ and $u‚ä©A$ then there exists
       some $v$ such that $v‚ä©B$ and $uS_wv$. Below we draw the condition for a
       world $w$ to force $A‚ñ∑B$.
      #+attr_latex: :float nil :width 0.24\textwidth :placement [H]
      [[file:img/ArhdB-ord.pdf]]

    The Agda definition can be found in cref:src:ordinaryveltmansemantics.
    {{{enddef}}}

    If $M$ is an ordinary Veltman model and $A$ a formula, we write $M‚ä©A$ to
    denote that for every world $w$ we have $M,w‚ä©A$. Similarly, if $F$ is an
    ordinary Veltman frame and $A$ a formula, we write $F‚ä©A$ to denote that for
    every valuation $V$ we have $‚ü®F,V‚ü©‚ä©A$.

    {{{beginlemma}}} {{{agda}}} {{{coq}}} <<coro:ord-semantics>> Let $M$ be an
    ordinary Veltman model and let $w$ be a world in $M$. It can be shown that:
    1. If $A,B‚àà\fm{}$, then $w‚ä©A‚àßB$ iff $w‚ä©A$ and $w‚ä©B$;
    2. If $A,B‚àà\fm{}$, then $w‚ä©A‚à®B$ iff $w‚ä©A$ or $w‚ä©B$;
    3. if $A‚àà\fm{}$, then $w‚ä©¬¨A$ iff $w‚äÆA$;
    4. if $A‚àà\fm{}$, then $w‚ä©‚ñ°A$ iff for every $u$ such that $wRu$ we have $u‚ä©A$;
    5. if $A‚àà\fm{}$, then $w‚ä©‚ô¢A$ iff there exists $u$ such that $wRu$ and $u‚ä©A$.
    {{{endlemma}}} {{{beginproof}}} Here we show the case
    for $w‚ä©‚ñ°A$. Assume $w‚ä©‚ñ°A$ and let $u$ be a world such that $wRu$. If $u‚ä©A$
    we are done, otherwise we have $u‚ä©¬¨A$. As described before $w‚ä©‚ñ°A$ is
    notation for $w‚ä©(¬¨ A) ‚ñ∑ ‚ä•$, thus there exists $z$ such that $uS_wz‚ä©‚ä•$, but
    this is a contradiction.

    For the other direction assume that we have a world $w$ and for every $u$
    such that $wRu$ we have $u‚ä©A$. We see that $w‚ä©(¬¨A)‚ñ∑‚ä•$ clearly holds as there
    is no $u$ such that $wRu‚ä©¬¨A$.

    The Agda proof can be found in
    cref:src:ordinaryveltmansemantics.properties. {{{endproof}}}

    {{{begintheorem}}} *Decidability* {{{agda}}} If $W$ is finite and $R,S,V$
    are decidable relations, then the forcing relation associated to the model
    $M‚âî‚ü®W,R,S,V‚ü©$ is decidable. {{{endtheorem}}} {{{beginproof}}} We have
    implemented a verified algorithm that given the mentioned conditions, a
    world $w$ and a formula $A$, constructs either a proof of $M,w‚ä©A$ or a proof
    of $M,w‚äÆA$. The implementation can be found in
    cref:src:ordinaryveltmansemantics.finite. {{{endproof}}}

    {{{begintheorem}}} *Local soundness for ordinary semantics* {{{agda}}}
    {{{coq}}} If $Œ†‚ä¢_{\il}A$ and $M$ is an ordinary model with a world
    $w$ such that $w‚ä©Œ†$, then $w‚ä©A$. {{{endtheorem}}}
    {{{beginproof}}} The proof
    is by induction on the proof $Œ†‚ä¢_{\il}A$. The cases for necessitation and modus
    ponens follow immediately from the IH. If $A$ is an instance of C1, C2 or C3
    then it is routine to check that all of these axioms hold in $w$. For axioms
    L and K we proceed as we do for \gl{} and Kripke semantics. In
    cref:sec:agda-L we show how we proved soundness for L in Agda. Finally we
    need to check soundness for axioms J1--J5.
    - J1: $‚ñ° (A ‚Üí B) ‚Üí A ‚ñ∑ B$. Assume $w‚ä©‚ñ°(A‚ÜíB)$ and $wRu‚ä©A$, then it follows
      that $u‚ä©B$ and by condition 4 of ordinary frames we get $uS_wu‚ä©B$.
    - J2: $A ‚ñ∑ B ‚àß B ‚ñ∑ C ‚Üí A ‚ñ∑ C$. Assume $w‚ä©A‚ñ∑B$ and $w‚ä©B‚ñ∑C$ and $wRu‚ä©A$. It
      follows that there exists $v$ such that $uS_wv‚ä©B$, then we have $wRv$ from
      definition of ordinary frame and thus there exists $z$ such that $vS_wz‚ä©C$.
      Finally by transitivity of $S_w$ we get $uS_wz‚ä©C$.
    - J3: $(A ‚ñ∑ C ‚àß B ‚ñ∑ C) ‚Üí (A ‚à® B) ‚ñ∑ C$. Assume $w‚ä©A‚ñ∑C$ and $w‚ä©B‚ñ∑C$ and
      $wRu‚ä©A‚à®B$. If $u‚ä©A$ then since $w‚ä©A‚ñ∑C$ we have that there exists $v$ such
      that $uS_wv‚ä©C$. On the other hand if $u‚ä©B$ we proceed analogously.
    - J4: $A ‚ñ∑ B ‚Üí ‚ô¢ A ‚Üí ‚ô¢ B$. Assume $w‚ä©A‚ñ∑B$ and $w‚ä©‚ô¢A$. Then there exists $u$
      such that $wRu‚ä©A$. Since $w‚ä©A‚ñ∑B$ it follows that there exists $v$ such
      that $uS_wv‚ä©B$. Finally by {{{ordfr(3)}}} of ordinary frames we have $wRv$
      and thus $w‚ä© ‚ô¢ B$.
    - J5: $‚ô¢ A ‚ñ∑ A$. Assume that there exists $u$ such that $wRu‚ä©‚ô¢A$. Then there
      exists $v$ such that $uRv‚ä©A$. By {{{ordfr(5)}}} of ordinary frames we have
      $uS_wv‚ä©A$.

    The Agda proof can be found in cref:src:il.properties.
    {{{endproof}}}

*** Generalized Veltman semantics
    Generalized Veltman semantics were introduced by Verbrugge in an unpublished
    manuscript (cite:Verbrugge). We were given permission by the author herself
    to include the manuscript in cref:pdf:Verbrugge, where we also include some
    comments about the authorship of some handwritten notes in the document.

    Generalized semantics generalize ordinary Veltman semantics in the
    sense that each $S_w$ relates worlds to sets of worlds. Thanks to this
    change, generalized Veltman semantics turn out to be more convenient and in


    For instance, the logic \prin{ILP_0} (we will define principle \prin{P_0} in
    cref:sec:prin-p0) is complete with respect to its characteristic class of
    generalized Veltman frames but incomplete with respect to ordinary Veltman
    semantics.

    some cases necessary. For instance, the logic \prin{ILP_0} is complete with
    respect to generalized Veltman semantics but incomplete with respect to
    ordinary Veltman semantics.

    In cref:sec:agda-gen-semantics we will comment on the Agda implementation of
    generalized Veltman semantics.

    {{{begindef}}} {{{agda}}} <<def:gen-frame>> A generalized Veltman \gls{gvf}
    $F=‚ü®W,R,S‚ü©$ is a structure constituted by a non-empty set of worlds $W$, a binary
    relation $R‚äÜW¬≤$ and a ternary relation $S‚äÜW√óW√ó(ùí´(W)‚àñ\{‚àÖ\})$. We write $wRu$
    instead of $‚ü®w,u‚ü©‚ààR$ and $uS_wY$ instead of $‚ü®w,u,Y‚ü©‚ààS$. The structure must
    satisfy the following conditions:


    #+begin_itemize
    \item[GF-1:] <<genfr:1>> $R$ is transitive;
    \item[GF-2:] <<genfr:2>> $R$ is conversely well-founded. That is, there is no infinite ascending
       chain $w‚ÇÅRw‚ÇÇR‚Ä¶$;
    \item[GF-3:] <<genfr:3>> if $uS_wY$, then $wRu$ and for all $y‚ààY$ we have $wRy$;
       #+attr_latex: :float nil :width 0.26\textwidth :placement [H]
       [[file:img/cond1-gen.pdf]]
    \item[GF-4:] <<genfr:4>> /quasi-reflexivity/: if $wRu$ then $uS_w\{u\}$;
       #+attr_latex: :float nil :width 0.075\textwidth :placement [H]
       [[file:img/refl-gen.pdf]]
    \item[GF-5:] <<genfr:5>> if $wRu$ and $uRv$ then $uS_w\{v\}$;
       #+attr_latex: :float nil :width 0.17\textwidth :placement [H]
       [[file:img/RStrans-gen.pdf]]
    \item <<genfr:6>> /quasi-transitivity/: if $uS_xY$ and $yS_xZ_y$ for all $y‚ààY$, then
       $uS_x\left(‚ãÉ_{y‚ààY}Z_y\right)$.
       #+attr_latex: :float nil :width 0.32\textwidth :placement [H]
       [[file:img/trans-2.pdf]]

       Notice that we did not label the last condition GF-6. The reason is that
       the above condition is a particular (the standard) condition of
       quasi-transitivity. However, throughout this thesis we explore a total of
       eight notions, see cref:sec:trans. Because of that, we will refer to
       those as quasi-transitivity Condition $j$ for $1‚â§j‚â§8$. If it is clear by
       the context we may simply say Condition $i$.
    #+end_itemize

    The Agda definition can be found in
    cref:src:generalizedframe. {{{enddef}}}

    As we did for ordinary semantics, we may endow a generalized frame with a
    valuation to obtain a generalized model.

    {{{begindef}}} {{{agda}}} A generalized Veltman \gls{gvm} $M=‚ü®F,V‚ü©$ is a
    structure constituted by a generalized Veltman \gls{gvf} $F$ and a valuation
    $V‚äÜW√ó\var{}$.

    The Agda definition can be found in cref:src:generalizedveltmansemantics.
    {{{enddef}}}

    We define the forcing relation in a similarly to ordinary semantics, the
    only difference being in the case for the operator $‚ñ∑$.

    {{{begindef}}} {{{agda}}} Given a model $M$, we define a
    forcing relation $\gls{forcing-gen}‚äÜW √ó \fm{}$. We use the same notational
    conventions as in the ordinary semantics.
    1. $w‚äÆ‚ä•$;
    2. if $p‚àà\var{}$, then $w‚ä©p$ iff $‚ü®w,p‚ü©‚ààV$;
    3. if $A,B‚àà\fm{}$, then $w‚ä©A‚ÜíB$ iff if $w‚ä©A$ then $w‚ä©B$;
    4. if $A,B‚àà\fm{}$, then $w‚ä©A‚ñ∑B$ iff if $wRu$ and $u‚ä©A$ then there exists
       some $Y$ such that $Y‚ä©B$ and $uS_wY$. When we write $Y‚ä©B$ we mean that
       for all $y‚ààY$ we have $y‚ä©B$. Below we draw the condition for a world $w$
       to force $A‚ñ∑B$.
      #+attr_latex: :float nil :width 0.24\textwidth :placement [H]
      [[file:img/ArhdB-gen.pdf]]

    The Agda definition can be found in cref:src:generalizedveltmansemantics.
    {{{enddef}}}

    We have the same notation conventions that we have for ordinary semantics:
    If $M$ is a generalized Veltman model and $A$ a formula, we write $M‚ä©A$ to
    denote that for every world $w$ we have $M,w‚ä©A$. Similarly, if $F$ is a
    generalized Veltman frame and $A$ a formula, we write $F‚ä©A$ to denote that
    for every valuation $V$ we have $‚ü®F,V‚ü©‚ä©A$.

    {{{beginlemma}}} {{{agda}}} We can show the same results presented in
    cref:coro:ord-semantics for generalized semantics:
    1. If $A,B‚àà\fm{}$, then $w‚ä©A‚àßB$ iff $w‚ä©A$ and $w‚ä©B$;
    2. If $A,B‚àà\fm{}$, then $w‚ä©A‚à®B$ iff $w‚ä©A$ or $w‚ä©B$;
    3. If $A‚àà\fm{}$, then $w‚ä©¬¨A$ iff $w‚äÆA$;
    4. If $A‚àà\fm{}$, then $w‚ä©‚ñ°A$ iff for every $u$ such that $wRu$ we have $u‚ä©A$;
    5. If $A‚àà\fm{}$, then $w‚ä©‚ô¢A$ iff there exists $u$ such that $wRu$ and $u‚ä©A$.
    {{{endlemma}}} {{{beginproof}}} Here we show the case for $w‚ä©‚ñ°A$.
    The proof goes in a very similar way to ordinary semantics. Assume $w‚ä©‚ñ°A$
    and let $u$ be a world such that $wRu$. If $u‚ä©A$ we are done, otherwise we
    have $u‚ä©¬¨A$. Since $w‚ä©‚ñ°A$ is notation for $w‚ä©(¬¨ A) ‚ñ∑ ‚ä•$, there exists $Z$
    such that $uS_wZ‚ä©‚ä•$. Since $Z$ is nonempty we have a contradiction.

    For the other direction assume that we have a world $w$ and for every $u$
    such that $wRu$ we have $u‚ä©A$. We see that $w‚ä©(¬¨A)‚ñ∑‚ä•$ clearly holds as there
    is no $u$ such that $wRu‚ä©¬¨A$.

    The Agda formalization can be found in
    cref:src:generalizedveltmansemantics.properties. {{{endproof}}}

    {{{begintheorem}}} <<theorem:il-sound>> *Local soundness for generalized
    semantics* {{{agda}}} If $Œ†‚ä¢_{\il}A$ and $M$ is a generalized Veltman model
    with a world $w$ such that $w‚ä©Œ†$, then $w‚ä©A$. {{{endtheorem}}}

    {{{beginproof}}} We only show the case where $A$ is an instance
    of the J2 ($A ‚ñ∑ B ‚àß B ‚ñ∑ C ‚Üí A ‚ñ∑ C$) axiom. The rest of the cases are proved
    in an analogous way to ordinary Semantics. Also, here we only show it the
    quasi-transitivity property given in cref:def:gen-frame and also for the
    quasi-transitivity {{{cond(8)}}} in cref:fig:table-trans. However, we have
    verified this in Agda for all the alternative quasi-transitivity conditions
    presented in cref:fig:table-trans.

    Assume $w‚ä©A‚ñ∑B$ and $w‚ä©B‚ñ∑C$ and that there exists $u$ such that $wRu‚ä©A$. It
    follows that there exists $V$ such that $uS_wV‚ä©B$. By {{{genfr(3)}}} of a
    generalized frame we have that $‚àÄv‚ààV.wRv‚ä©B$. Then for every $v‚ààV$ we have
    that there exists $Z_v$ such that $vS_wZ_v‚ä©C$. It follows from the
    quasi-transitivity condition that $uS_w(‚ãÉ_{v‚ààV}Z_v)$ and clearly
    $‚ãÉ_{v‚ààV}Z_v‚ä©C$.

    Now for quasi-transitivity {{{cond(8)}}}. Assume $w‚ä©A‚ñ∑B$ and
    $w‚ä©B‚ñ∑C$ and that there exists $u$ such that $wRu‚ä©A$. It follows that there
    exists $V$ such that $uS_wV‚ä©B$. If $V‚ä©C$ we are done, otherwise there exists
    $v‚ààV$ such that $v‚äÆC$. By {{{genfr(3)}}} of a generalized frame we have that
    $wRv$. Since $wRv‚ä©B$ and $w‚ä©B‚ñ∑C$ it follows that there exists $Z$ such that
    $vS_wZ‚ä©C$. Finally since $v‚äÆC$ we know that $v‚àâZ$ so by quasi-transitivity
    Condition 8 we can conclude $uS_wZ‚ä©C$.

    The Agda proof can be found in cref:src:il.properties.
    {{{endproof}}}

** Quasi-transitivity
   <<sec:trans>> In the literature one can find several semantic requirements
   for the quasi-transitivity condition which we present in the table below. We
   observe that in cref:def:gen-frame we used {{{cond(2)}}} from the table
   below. cref:theorem:trans presents some direct implications between
   conditions presented in cref:fig:table-trans.
   cref:theorem:il-sound,theorem:trans-extend are sufficient to argue that all
   of them are appropriate for proving completeness of \il{}. It is worth
   mentioning however, that not all of them are sufficiently expressive to prove
   completeness for extensions of \il{}.

#+name: fig:table-trans
#+caption: Semantic requirements for quasi-transitivity mentioned in the literature.
#+attr_latex: :align c|l|l :float t :center t :placement [H] :font \small
| Nr.         | Semantic requirement for quasi-transitivity                                            | First mentioned in                            |
|-------------+----------------------------------------------------------------------------------------+-----------------------------------------------|
| <<cond:1>>1 | $uS_xY ‚áí ‚àÄ \, \{ Z_y\}_{y‚àà Y} \Big((‚àÄ\, y‚ààY\ yS_xZ_y) ‚áí ‚àÉ V‚äÜ ‚ãÉ_{y‚àà Y}Z_y ‚àß uS_xV\Big)$ | Joosten et al. '20 \cite{joosten2020overview} |
| <<cond:2>>2 | $uS_xY ‚áí ‚àÄ \, \{ Z_y\}_{y‚àà Y} \Big((‚àÄ\, y‚ààY\ yS_xZ_y) ‚áí uS_x‚ãÉ_{y‚àà Y}Z_y\Big)$          | Verbrugge '92 '20 \cite{Verbrugge}            |
| <<cond:3>>3 | $uS_xY ‚áí ‚àÉ\, y‚ààY\, ‚àÄ Y'(yS_xY' ‚áí ‚àÉ \, Y''{‚äÜ}Y' ‚àß uS_xY'')$                             | Joosten et al. \cite{joosten2020overview}     |
| <<cond:4>>4 | $uS_xY ‚áí ‚àÉ\, y‚ààY\, ‚àÄ Y'(yS_xY' ‚áí uS_xY')$                                              | Joosten '98 \cite{joosten-master}             |
| <<cond:5>>5 | $uS_xY ‚áí ‚àÄ\, y‚ààY\, ‚àÄ Y'(yS_xY' ‚áí ‚àÉ \, Y''{‚äÜ}Y' ‚àß uS_xY'')$                             | Joosten et al. '20 \cite{joosten2020overview} |
| <<cond:6>>6 | $uS_xY ‚áí ‚àÄ\, y‚ààY\, ‚àÄ Y'(yS_xY' ‚áí uS_xY')$                                              | Verbrugge '92 \cite{Verbrugge}                |
| <<cond:7>>7 | $uS_xY ‚áí ‚àÄ\, y‚ààY\, ‚àÄ Y'(yS_xY'\wedge y‚àâY' ‚áí ‚àÉ \, Y''{‚äÜ}Y'\ uS_xY'')$                   | Joosten et al. '20 \cite{joosten2020overview} |
| <<cond:8>>8 | $uS_xY ‚áí ‚àÄ\, y‚ààY\, ‚àÄ Y'(yS_xY'\wedge y‚àâY' ‚áí uS_xY')$                                   | Goris, Joosten '09 \cite{a-new-principle}     |
   #+caption: Diagrams for Conditions 2, 4 and 6.
   #+name: fig:diagrams-transitivity
   #+attr_latex: :float t :width 0.96\textwidth :placement [H]
   [[file:img/trans-2-4-6.pdf]]

   \pagebreak
 {{{begintheorem}}} <<theorem:trans>> {{{agda}}} Let $F$ be a generalized
 Veltman frame. Let \[\sf{Mon}‚âî‚àÄw,u,V,Z(uS_wV‚äÜZ‚äÜ\{u:wRu\}‚áíuS_wZ)\] represent the
 monotonicity condition. The following implications hold.

 The first item should be read as $F‚ä®\sf{Mon}‚àß(1)‚Üí(2)$.

 #+attr_latex: :options {3}
 #+begin_multicols
   1. $\sf{Mon} ‚àß (1) ‚áí (2)$
   2. $(2) ‚áí (1)$
   3. $\sf{Mon} ‚àß (3) ‚áí (4)$
   4. $(4) ‚áí (3)$
   5. $(5) ‚áí (1)$
   6. $\sf{Mon} ‚àß (5) ‚áí (2)$
   7. $(5) ‚áí (3)$
   8. $\sf{Mon} ‚àß (5) ‚áí (4)$
   9. $\sf{Mon} ‚àß (5) ‚áí (6)$
   10. $(5) ‚áí (7)$
   11. $\sf{Mon} ‚àß (5) ‚áí (8)$
   12. $(6) ‚áí (1)$
   13. $\sf{Mon} ‚àß (6) ‚áí (2)$
   14. $(6) ‚áí (3)$
   15. $(6) ‚áí (4)$
   16. $(6) ‚áí (5)$
   17. $(6) ‚áí (7)$
   18. $(6) ‚áí (8)$
   19. $\sf{Mon} ‚àß (7) ‚áí (8)$
   20. $(8) ‚áí (7)$
 #+end_multicols
 # {{{endmulticols}}}

 #+caption: Graphical representation of cref:theorem:trans. Blue lines require monotonicity.
 #+name: fig:diagrams-implications
 #+attr_latex: :float t :width 0.45\textwidth :placement [H]
 [[file:img/trans-impl.pdf]]

 {{{endtheorem}}}

 {{{beginproof}}} Here we only show item 13: $\sf{Mon} ‚àß (6) ‚áí (2)$.
 Assume that $F$ is a generalized Veltman frame that satisfies the monotonicity
 condition and the quasi-transitivity {{{cond(6)}}}. Now assume that $uS_xY$ and
 consider an arbitrary family of sets of worlds $\{Y_y:y‚àà Y\}$. Assume also that
 for every $y‚ààY$ we have $yS_xY_y$. Since $Y$ is nonempty we may pick $y_0‚ààY$.
 Then we have that $yS_xY_{y_0}$. Then by quasi-transitivity {{{cond(6)}}} we
 have that $uS_xY_{y_0}$ and since for any $y‚ààY$ we have $yS_xY_y$ it follows by
 {{{genfr(3)}}} of a generalized frame that $Y_y‚äÜ\{v:xRv\}$. Finally we see that
 $Y_{y_0}‚äÜ‚ãÉ_{y‚ààY}Y_y‚äÜ\{v:xRv\}$ and by monotonicity it follows that
 $uS_x(‚ãÉ_{y‚ààY}Y_y)$.

 The Agda proof can be found in cref:src:generalizedframe.properties.
 {{{endproof}}}

 {{{begintheorem}}} <<theorem:trans-extend>> Given an ordinary Veltman model
 $M=‚ü®W,R,S,V‚ü©$ we can find some generalized Veltman model $M'=‚ü®W,R,S',V‚ü©$, where
 we can replace our notion of quasi-transitivity by any of the Conditions
 {{{scond(1)}}}--{{{scond(8)}}}. Furthermore, for every world $w$ and formula $A$:
 \[M,w‚ä©A‚áîM',w‚ä©A.\] {{{endtheorem}}}

 {{{beginproof}}} We prove it for the quasi-transitivity {{{cond(2)}}}. The rest
 can be proven in the same way. Let $M=‚ü®W,R,S,V‚ü©$ be an ordinary model. Let
 $M'‚âî‚ü®W,R,S',V‚ü©$ with $S'$ defined thus: \[S'‚âî\{‚ü®w,x,\{y\}‚ü©:‚ü®w,x,y‚ü©‚ààS\}.\] It is
 easy to observe that $M'$ satisfies {{{genfr(1)}}}, ‚Ä¶, {{{genfr(5)}}}. It is
 also easy to see that it satisfies quasi-transitivity {{{cond(2)}}}. We show
 that they force the same formulas by induction on the complexity of the
 formula. The only interesting case is $A‚ñ∑B$.
   - Assume $M,w‚ä©A‚ñ∑B$ and that for some $x$ we have $wRx‚ä©A$. It follows that
     there exists some $y$ such that $xS_wy‚ä©B$. By definition of $M'$ we have
     $xS'_w\{y\}$ and also $\{y\}‚ä©B$, therefore $M',w‚ä©A‚ñ∑B$.
   - Assume $M,w‚äÆA‚ñ∑B$, then there exists some $x$ such that $wRx‚ä©A$ and
     $‚àÄy(xS_wy‚áíy‚äÆB)$. It is obvious that for $M'$ we have $‚àÄy(xS'_w\{y\}‚áíy‚äÆB)$
     and also $‚àÄY(xS'_wY‚áíY‚äÆB)$, which is the required property.
 {{{endproof}}}

** Monotonicity
   <<sec:mono>>
   Recall the monotonicity condition that we presented in the previous chapter:
  #+begin_center
    if $uS_wV‚äÜZ‚äÜ\{v:wRv\}$ then $uS_wZ$.
  #+end_center

  It happens that this condition can be assumed (and in fact, is a standard
  assumption in the more recent literature) to be satisfied by generalized
  Veltman frames without harm. This is desirable as a good number of proofs and
  definitions (especially definitions related to filtrations) can be simplified
  when assuming the monotonicity condition. By ``can be assumed without harm'',
  we mean that for any generalized Veltman frame, we can find another
  generalized Veltman frame that satisfies the monotonicity condition.
  Moreover, both frames will be modally equivalent when expanded to a generalized
  Veltman model with a valuation. In the following theorem we prove this fact.

  {{{begintheorem}}} <<theorem:mono>> {{{agda}}} Let $F=‚ü®W,R,S‚ü©$ be a
  generalized Veltman frame with quasi-transitivity Condition $i$ for
  $i‚àà\{1,‚Ä¶,8\}$. Let $F'=‚ü®W,R,S'‚ü©$ where $S'$ is the monotone closure of $S$:

  \[S'‚âî\{‚ü®w,x,Y'‚ü© : ‚ü®w,x,Y‚ü©‚ààS, Y‚äÜY'‚äÜ\{u:wRu\}\}.\]

  Then $F'$ is a generalized Veltman frame satisfying quasi-transitivity
  {{{cond(2)}}}. Furthermore, let $V$ be an arbitrary valuation and $A$ an
  arbitrary formula. Let $M‚âî‚ü®F,V‚ü©$ and $M'‚âî‚ü®F',V‚ü©$. We have that for every world
  $w$: \[M,w‚ä©A‚áîM',w‚ä©A.\] {{{endtheorem}}}


  {{{beginproof}}}
  We check conditions listed in cref:def:gen-frame.
  - {{{genfr(1)}}} and {{{genfr(2)}}} are clear since $R$ is unchanged;
  - {{{genfr(3)}}} follows from the fact that in the definition of $S'$ we require
    $Y'‚äÜ\{u:wRu\}$;
  - for {{{genfr(4)}}} and {{{genfr(5)}}} observe that $S‚äÜS'$. Then, since these
    conditions hold for $F$ they also hold for $F'$;
  - for quasi-transitivity {{{cond(2)}}} assume that $uS'_xY'$ and that for
    every $y'‚ààY'$ we have $y'S'_xŒ•_{y'}$. We need to show that
    $uS'_x‚ãÉ_{y'‚ààY'}Œ•_{y'}$. By definition of $S'$ it follows that there exists
    $Y‚äÜY'$ such that $uS_xY$, furthermore, for every $y'‚ààY'$ we have that there
    exists $f(Œ•_{y'})‚äÜŒ•_{y'}$ such that $y'S_xf(Œ•_{y'})$. From $Y‚äÜY'$ it follows
    that for all $y‚ààY$ there exists $f(Œ•_{y})‚äÜŒ•_{y}$ such that $yS_xf(Œ•_{y})$.
    Then by (2) for $F$ it follows that $uS_x‚ãÉ_{y‚ààY}f(Œ•_{y})$. Then see that
    $‚ãÉ_{y‚ààY}f(Œ•_{y})‚äÜ‚ãÉ_{y'‚ààY'}Œ•_{y'}$. It remains to show
    $‚ãÉ_{y'‚ààY'}Œ•_{y'}‚äÜxR\{u:xRu\}$. Consider some $u$ such that there is some
    $y'‚ààY'$ with $u‚ààŒ•_{y'}$. By assumption we have $y'S'_xŒ•_{y'}$ and thus
    $xRu$.
  To show $M,w‚ä©A‚áîM',w‚ä©A$ we proceed by induction on $A$. The only
  interesting case is $A‚ñ∑B$.
  - Assume that $M,w‚ä©A‚ñ∑B$ and that there is some world $x$ such that $wRx$ and
    $M',x‚ä©A$. By IH we have $M,x‚ä©A$, so there exists some $Y$ such that $xS_wY$
    and $M,Y‚ä©B$. By IH we have $M',Y‚ä©B$ and by definition of $S'$ it follows
    that $xS'_wY$, therefore $M',w‚ä©A‚ñ∑B$.
  - Assume that $M,w‚äÆA‚ñ∑B$. It follows that there is some $x$ such that $wRx$,
    $M,x‚ä©A$ and
    #+name: eq:mono-proof1
    #+begin_equation
    ‚àÄY(xS_wY‚áíM,Y‚äÆB).
    #+end_equation
    We want to prove that $‚àÄY'(xS'_wY'‚áíM',Y'‚äÆB)$. Assume that for some $Y'$ we
    have $xS'_wY'$. By definition of $S'$ it follows there exists some $Y$ such
    that $Y‚äÜY'$ and $xS_wY$. Hence by cref:eq:mono-proof1 we have that $M,Y‚äÆB$
    and thus there exists $y‚ààY$ such that $M,y‚äÆB$. By IH we get that $M',y‚äÆB$
    and since $y‚ààY‚äÜY'$ we have $Y'‚äÆB$, so $M',w‚äÆA‚ñ∑B$.

  The Agda proof can be found in cref:src:generalizedframe.properties.
  {{{endproof}}}

  # As we see in cref:theorem:mono taking the monotone closure of each $S_w$ does not
  # change the forcing relation and the resulting frame satisfies quasi-transitivity
  # {{{cond(2)}}}.

  # The previous lemma allows us to safely assume that monotonicity is a condition
  # for a Veltman frame with quasi-transitivity (2).

  {{{beginremark}}} Taking the monotone closure of each $S_w$ is essentially
  different from assuming that each $S_w$ is monotone by definition of the
  frame, as then the forcing relation may change. In the following example we
  present a generalized Veltman model with {{{cond(8)}}} that showcases such
  behaviour.

   #+caption: Example frame: $wRv_0,wRv_1,wRv_2,wRv_3$, $v_0S_w\{v_1\}$, $v_2S_w\{v_3\}$.
   #+name: fig:example-trans
   #+attr_latex: :float t :width 0.33\textwidth :placement [H]
   [[file:img/example.pdf]]

  Let $M$ be a model based on the frame displayed[fn::In the figure we do not
  show the $S_w$ relations required by quasi-reflexivity for clarity.] in
  cref:fig:example-trans such that $‚ü¶p‚üß = \{v_0\}$, $‚ü¶q‚üß = \{v_3\}$. We see that
  $w‚ä©¬¨(p ‚ñ∑ q)$ as $p$ is only true in $v_0$ and we only have $v_0S_w\{v_1\}$ and
  $v_0S_w\{v_0\}$ (by quasi-reflexivity) with $v_0‚äÆq$ and $v_1‚äÆq$. If we take
  the monotonic closure of $S$ we have $v_0S_w \{v_1, v_2\}$ and by
  quasi-transitivity {{{cond(8)}}} we get $v_0S_w \{v_3\}$ and consequently
  $w‚ä©¬¨(p ‚ñ∑ q)$ is no longer true. {{{endremark}}}

* Generalized vs ordinary models
  In this part we explore the expressiveness of ordinary and generalized Veltman
  semantics. In particular, we discuss how we can transform an ordinary model
  into a generalized model and vice versa. Needless to say, we have the
  requirement that the transformation preserves the modal theoremhood of the
  original model. The notion of modal theoremhood is made precise by
  cref:def:mod-equiv-world,def:mod-equiv-model.

  {{{begindef}}} <<def:mod-equiv-world>> *Modally equivalent worlds*.
  \glsadd{elemequivworlds} Given models $M$ and $M'$, we say that two worlds
  $w‚ààM$ and $w'‚ààM'$ are modally equivalent iff for every formula $A$ we have: \[
  M,w‚ä©A‚áîM,w'‚ä©A.\] {{{enddef}}}

  {{{begindef}}} <<def:mod-equiv-model>> *Modally equivalent models*.
  \glsadd{elemequivmodels} Given models $M$ and $M'$, we say that $M$ and $M'$
  are modally equivalent iff for every world $w‚ààM$ there is a world $w'‚ààM'$ such
  that $w$ and $w'$ are modally equivalent. And vice versa, for every world in
  $w'‚ààM'$ there exists a world $w‚ààM$ such that $w$ and $w'$ are modally
  equivalent {{{enddef}}}

  In cref:sec:ord-to-gen we see a straightforward transformation from an
  ordinary Veltman model into a generalized Veltman model. In cref:sec:verbrugge
  we see an involved transformation from a generalized model into an ordinary
  model. This transformation is due to Verbrugge and was described in
  cite:Verbrugge. The proof was originally described to work with
  quasi-transitivity {{{cond(6)}}}. We have slightly improved the result by
  showing that the same transformation also works for {{{cond(3)}}},
  {{{scond(4)}}} and {{{scond(5)}}}. In cref:sec:gen-to-ord-luka we show a
  transformation that achieves the same as Verbrugge's transformation but it is
  much simpler. The simpler transformation was suggested by Mikec during online
  correspondence.

** From ordinary to generalized
   <<sec:ord-to-gen>> In this chapter we present a theorem that shows how an
   ordinary model $M$ naturally gives rise to a generalized model $M$ for any of the
   presented quasi-transitivity conditions. The resulting generalized model $M'$ has
   the same set of worlds as the original and is modally equivalent to $M$.

   {{{begintheorem}}} Let $M=‚ü®W,R,S,V‚ü©$ be an ordinary Veltman model. We define
   ${M'‚âî‚ü®W,R,S',V‚ü©}$ where $S'‚âî\{‚ü®w,u,\{v\}:‚ü®w,u,v‚ü©‚ààS\}$. Now we distinguish two
   cases.
   - If we want $M'$ to satisfy quasi-transitivity {{{cond(2)}}} we take the
     monotone closure of $S'$ as described in cref:theorem:mono;
   - for the rest of the quasi-transitivity conditions we keep $S'$ as defined.
   Then M' is a generalized Veltman frame with quasi-transitivity condition
   $(i)‚àà\{1,‚Ä¶,8\}$. Furthermore, for any world $w$ and formula $A$ we have that
   \[M,w‚ä©A‚áîM',w‚ä©A.\] {{{endtheorem}}} {{{beginproof}}} We observe that the
   transitivity condition for the ordinary models $M$ entails the
   quasi-transitivity {{{cond(6)}}} for the $M'$ generalized model. Keep in mind
   that by definition of $M'$ we only have singleton sets in the third component
   of $S'$. Now assume that $uS'_x\{y\}$ and $yS'_x\{y'\}$. By definition of
   $S'$ it follows that $uS_xyS_xy'$ and by quasi-transitivity of $M$ we have
   $uS_xy'$ and thus $uS_x\{y'\}$. Then, by cref:theorem:trans we know that
   quasi-transitivity {{{cond(6)}}} implies Conditions {{{scond(1)}}},
   {{{scond(3)}}}--{{{scond(8)}}}, thus, the presented transformation works for
   any of those notions of quasi-transitivity. Moreover, if we chose to obtain a
   generalized Veltman frame with quasi-transitivity {{{cond(2)}}}, the same
   reasoning applies since as we know by cref:theorem:mono, taking the monotone
   closure does not alter the modal theory of the model. We leave the rest of
   the details to be worked out by the reader. {{{endproof}}}

** From generalized to ordinary
   <<sec:verbrugge>> In this chapter we show that given a generalized Veltman
   model $M$ with quasi-transitivity condition $(i)‚àà\{3,4,5,6\}$, we can build
   an ordinary Veltman model $M'$ such that for every world in $M$ we can find a
   world in $M'$ which is modally equivalent. The definitions and proofs
   involved in this chapter can be found formalized in Agda in
   cref:src:generalizedveltmansemantics.properties.verbrugge.

   It is worth mentioning that there exists a much simpler transformation which
   we will present in cref:sec:gen-to-ord-luka and works for the same
   quasi-transitivity conditions as the transformation presented here. We still
   believe that this transformation holds value for historical reasons. It was
   the first transformation from generalized to ordinary models and it was
   written by Verbrugge in an unpublished manuscript (cite:Verbrugge). In that
   manuscript there is a comment where the author says that the transformation
   may also hold for {{{cond(2)}}} although she has not checked it yet.
   Unfortunately some steps in the proof do not work if we take a generalized
   model with quasi-transitivity {{{cond(2)}}}. In cite:vukovic2008bisimulations
   a variation of this transformation is presented with the claim that it works
   for {{{cond(2)}}}. However, as we will comment in cref:sec:flawed-proof, the
   proof of the claim is in need of repair.

   For the rest of this chapter we fix a generalized Veltman model $M‚âî‚ü®W, R, S,
   V‚ü©$.

   We define an ordinary Veltman model $M'‚âî‚ü®W',R',S',V'‚ü©$ where
   \begin{flalign*}
   W'‚âî&\{‚ü®x,A‚ü©:A‚äÜW^2, \\ &(W1)\ ‚àÄ‚ü®u,v‚ü©‚ààA\ ‚àÉY(xS_uY,v‚ààY), \\
   & (W2)\ ‚àÄu‚àÄV(xS_uV‚áí‚àÉv‚ààV(‚ü®u,v‚ü©‚ààA)\}; \\
   R'‚âî&\{‚ü®‚ü®x,A‚ü©,‚ü®y,B‚ü©‚ü© : xRy,‚àÄw‚àÄz(wRx‚áí‚ü®w,z‚ü©‚ààB‚áí‚ü®w,z‚ü©‚ààA)\}; \\
   S'‚âî&\{‚ü®‚ü®w,C‚ü©,‚ü®x,A‚ü©,‚ü®y,B‚ü©‚ü© : ‚ü®w,C‚ü©R'‚ü®x,A‚ü©,‚ü®w,C‚ü©R'‚ü®y,B‚ü©, ‚àÄv(‚ü®w,v‚ü©‚ààB‚áí‚ü®w,v‚ü©‚ààA) \}; \\
   V'‚âî&\{‚ü®‚ü®x, A‚ü©,p‚ü©: ‚ü®x,p‚ü©‚ààV, ‚ü®x,A‚ü©‚ààW',p‚àà\var{}\}.
   \end{flalign*}

   {{{beginlemma}}} {{{agda}}} The structure $‚ü®W',R',S',V'‚ü©$ is an ordinary
   Veltman model. {{{endlemma}}} {{{beginproof}}} Here we check that the $S'_w$
   is a transitive relation for each $w‚ààW'$. It is routine to check that the
   rest of the requirements are satisfied. Assume that we have
   \[‚ü®x,A‚ü©S'_{‚ü®w,D‚ü©}‚ü®y,B‚ü©S'_{‚ü®w,D‚ü©}‚ü®z,C‚ü©\]. We want to show
   $‚ü®x,A‚ü©S'_{‚ü®w,D‚ü©}‚ü®z,C‚ü©$, thus by the definition of $S'$ we need to prove the
   following:
   1. $‚ü®w,D‚ü©R'‚ü®x,A‚ü©$: it follows from the definition of $S'$ and
      $‚ü®x,A‚ü©S'_{‚ü®w,D‚ü©}‚ü®y,B‚ü©$;
   2. $‚ü®w,D‚ü©R'‚ü®z,C‚ü©$: it follows from the definition of $S'$ and
      $‚ü®y,B‚ü©S'_{‚ü®w,D‚ü©}‚ü®z,C‚ü©$;
   3. $‚àÄv(‚ü®w,v‚ü©‚ààC‚áí‚ü®w,v‚ü©‚ààA)$: from $‚ü®x,A‚ü©S'_{‚ü®w,D‚ü©}‚ü®y,B‚ü©$ and the definition of
      $S'$ we get that \[‚àÄv(‚ü®w,v‚ü©‚ààB‚áí‚ü®w,v‚ü©‚ààA).\] Likewise, from
      $‚ü®y,B‚ü©S'_{‚ü®w,D‚ü©}‚ü®z,C‚ü©$ and the definition of $S'$ we get that
      \[‚àÄv(‚ü®w,v‚ü©‚ààC‚áí‚ü®w,v‚ü©‚ààB).\] Then, from the composition of the previous
      formulas we get the desired fact.
   {{{endproof}}}

   We will now introduce two conditions. These conditions offer a convenient way
   to show that the transformation works for various conditions of
   quasi-transitivity. In fact, the presented transformation works for a
   generalized Veltman frame with quasi-transitivity {{{cond(3)}}}, 4, 5 or 6.

   Let the conditions $(C_0)$ and $(C_1)$ be defined thus:
   \begin{flalign*}
   (C‚ÇÄ)&‚âî‚àÄw‚àÄx‚àÄV.xS_wV‚áí‚àÉy‚ààV.‚àÄb‚àÄV'.yS_bV'‚áí‚àÉv‚ààV'. (b=w ‚áí xS_b\{v\}), (bRw ‚áí wS_b\{v\}); \\
   (C‚ÇÅ)&‚âî‚àÄw‚àÄb‚àÄx‚àÄV.wRx‚áíxS_bV‚áí‚àÉv‚ààV.xS_b\{v\},(bRw‚áíwS_b\{v\}).
   \end{flalign*}
   {{{begintheorem}}} {{{agda}}}
   If $M$ satisfies both conditions $(C_0)$ and $(C_1)$ then
   for any world $‚ü®w,C‚ü©‚ààW'$ and formula $D$:
   \[w‚ä©D‚áî‚ü®w,C‚ü©‚ä©D\]
   {{{endtheorem}}}
   {{{beginproof}}}
   We proceed by induction on the formula. Here we only consider the
   case $D‚ñ∑E$ as the other cases are easy.
   - \boxed{‚áí} Assume $w‚ä©D‚ñ∑E$ and let $C$ be such that $‚ü®w,C‚ü©‚ààW'$. We
     want to prove $‚ü®w,C‚ü©‚ä©D‚ñ∑E$. Assume that for some $‚ü®x,A‚ü©‚ààW'$ we have
     $‚ü®w,C‚ü©R'‚ü®x,A‚ü©‚ä©D$. By IH it follows that $x‚ä©D$ and hence there exists $V$
     such that $xS_wV‚ä©E$. By $(C_0)$ there is some $y‚ààV$ such that

     #+name: eq:verb-y-cond
     \begin{equation}
     ‚àÄbV'.yS_bV'‚áí‚àÉv‚ààV'. (b=w ‚áí xS_b\{v\}), (bRw ‚áí wS_b\{v\})
     \end{equation}

     We proceed by showing that there is some $B$ such that
     $‚ü®x,A‚ü©S'_{‚ü®w,C‚ü©}‚ü®y,B‚ü©$. Let $B$ be defined thus:
     \[B‚âî\{‚ü®u,v‚ü©: ‚àÉY.yS_uY,v‚ààY,(u=w‚áí‚ü®w,v‚ü©‚ààA),(uRw‚áí‚ü®u,v‚ü©‚ààC)\}\]

     To show $‚ü®y,B‚ü©‚ààW'$ we need to prove that $(W1)$ and $(W2)$ hold. The
     condition $(W1)$ follows immediately from the definition of $B$. To show
     $(W2)$ assume that for some $b$ and $V$ we have $yS_bV$. We need to see
     that there exists $v‚ààV$ such that $‚ü®b,v‚ü©‚ààB$. From $yS_bV$ and
     cref:eq:verb-y-cond we get that there exists $v‚ààV'$ such that
     \begin{flalign}
     b=w &‚áí xS_b\{v\} \label{eq:verb-b=w}, \\
     bRw &‚áí wS_b\{v\} \label{eq:verb-2}
     \end{flalign}
     To show that $‚ü®b,v‚ü©‚ààB$ we first see that $b=w‚áí‚ü®w,v‚ü©‚ààA$. Assume $b=w$, then
     by \cref{eq:verb-b=w} it follows that $xS_b\{v\}$ and therefore by condition
     $(W2)$ for $A$ it follows $‚ü®b,v‚ü©‚ààA$. We proceed likewise and use
     \cref{eq:verb-2} to show $bRw‚áí‚ü®b,v‚ü©‚ààC$. This concludes the proof that
     $‚ü®y,B‚ü©‚ààW'$.

     We now check the conditions for $‚ü®x,A‚ü©S'_{‚ü®w,C‚ü©}‚ü®y,B‚ü©$. We already have
     $‚ü®w,C‚ü©R'‚ü®x,A‚ü©$ by assumption. To see that $‚ü®w,C‚ü©R'‚ü®y,B‚ü©$ we first observe
     that $wRy$ holds since $xS_wV$ and $y‚ààV$. Then assume that for some $b,z$ we
     have $bRw$ and $‚ü®b,z‚ü©‚ààB$. Then from the definition of $B$ it follows that
     $‚ü®b,z‚ü©‚ààC$. The condition $‚àÄv(‚ü®w,v‚ü©‚ààB‚áí‚ü®w,v‚ü©‚ààA)$ follows immediately from the
     definition of $B$.

     Finally, since $V‚ä©E$ and $y‚ààV$ we have $y‚ä©E$ and thus by IH it follows that
     $‚ü®y,B‚ü©‚ä©E$.

   - \boxed{‚áê} We proceed by contraposition. Assume $w‚äÆD‚ñ∑E$, then there exists
     $x$ such that $wRx$ and
     #+name: eq:verb-neg
     \begin{equation}
     ‚àÄY(vS_wY‚áí‚àÉy‚ààY(y‚äÆE)).
     \end{equation}

     Let $A$ be defined thus:
     \[A‚âî \{‚ü®b,v‚ü©:(‚àÉY.xS_bY,v‚ààY),(b=w‚áíM,v‚äÆE),(bRw‚áí‚ü®b,v‚ü©‚ààC)\}.\]

     We first show that $‚ü®x,A‚ü©‚ààW'$. Condition $(W1)$ follows directly from the
     definition of $A$. To show that $(W2)$ holds assume that for some $b$ and
     $V$ we have $xS_bV$. We need to see that for some $v‚ààV$ we have $‚ü®b,v‚ü©‚ààA$.
     Since $wRx$ and $xS_bV$ it follows from condition $(C_1)$ that there exists
     $v‚ààV$ such that
     \begin{flalign}
     &xS_b\{v\}, \label{eq:verb-neg-b=w} \\
     bRw‚áí&wS_b\{v\}. \label{eq:verb-neg-bRw}
     \end{flalign}
     The first condition to show $‚ü®b,v‚ü©‚ààA$, namely that $‚àÉY.xS_bY,v‚ààY$, is met
     trivially. For the next condition assume $b=w$, then see that we have
     $xS_w\{v\}$ by \cref{eq:verb-neg-b=w} and thus by cref:eq:verb-neg it
     follows that $v‚äÆE$. For the remaining condition assume $bRw$, then by
     \cref{eq:verb-neg-bRw} we have $wS_b\{v\}$ and thus by $(W2)$ for $C$ we
     have $‚ü®b,v‚ü©‚ààC$. Therefore we conclude $‚ü®b,v‚ü©‚ààA$ and thus $‚ü®x,A‚ü©‚ààW'$.

     To see that $‚ü®w,C‚ü©R'‚ü®x,A‚ü©$ we already have $wRx$ by assumption. The
     remaining condition, $‚àÄbz(bRx‚áí‚ü®b,z‚ü©‚ààA‚áí‚ü®b,z‚ü©‚ààC)$, follows directly from the
     definition of $A$.

     Since $x‚ä©D$, it follows from the IH that $‚ü®x,A‚ü©‚ä©D$.

     Lastly, assume that for some $‚ü®y,B‚ü©‚ààW'$ we have $‚ü®x,A‚ü©S'_{‚ü®w,C‚ü©}‚ü®y,B‚ü©$. By
     definition of $S'$ we have $xS_wy$ and thus $wRy$. By quasi-reflexivity of
     $S$ we then have $yS_w\{y\}$ and thus by $(W2)$ for $B$ we have $‚ü®w,y‚ü©‚ààB$.
     By definition of $S'$ we also have that $‚àÄv(‚ü®w,v‚ü©‚ààB‚áí‚ü®w,v‚ü©‚ààA)$, hence
     $‚ü®w,y‚ü©‚ààA$. By definition of $A$ it follows that $y‚äÆE$ and by IH we have
     $‚ü®y,B‚ü©‚äÆE$, which concludes the proof.
   {{{endproof}}}

   {{{begintheorem}}} <<thm:conds>> {{{agda}}} If a generalized Veltman frame
   satisfies quasi-transitivity {{{cond(3)}}}, 4, 5 or 6, then it satisfies
   conditions $(C_0)$ and $(C_1)$. {{{endtheorem}}}

   {{{beginproof}}} Here we prove the property for a generalized
   Veltman frame satisfying quasi-transitivity {{{cond(3)}}}. Conditions
   {{{scond(4)}}}--{{{scond(6)}}} imply {{{cond(3)}}} as shown in
   cref:theorem:trans.

   Assume $F$ is a generalized Veltman frame satisfying quasi-transitivity
   {{{cond(3)}}}.
   It is easy to observe that the following property holds:
   #+name: eq:verb-trans-prop
   \begin{equation}
   uS_xY ‚áí ‚àÉ\, y‚ààY\, ‚àÄ z(yS_x\{z\} ‚áí uS_x\{z\}).
   \end{equation}
   - \boxed{(C‚ÇÄ)} Assume that for some $w,x,V$ we have $xS_wV$. Then by
     cref:eq:verb-trans-prop there is some $y‚ààV$ such that
     #+name: eq:verb-trans-y
     \begin{equation}
      ‚àÄ z(yS_w\{z\} ‚áí xS_w\{z\}).
     \end{equation}

     Now assume that for some $b,V'$ we have $yS_bV'$. It follows by
     cref:eq:verb-trans-prop that there is some $v‚ààV'$ such that
     #+name: eq:verb-trans-v
     \begin{equation}
      ‚àÄ z(vS_b\{z\} ‚áí yS_b\{z\}).
     \end{equation}
     Assume that $b=w$, we need to see that $xS_b\{v\}$. From $xS_wV$ and $y‚ààV$
     it follows that $wRy$. Then by quasi-reflexivity we have $yS_w\{y\}$ and by
     cref:eq:verb-trans-y we get $xS_w\{v\}$ which is the same as $xS_b\{v\}$. Assume
     that $bRw$, we need to see that $wS_b\{v\}$. From $bRwRy$ we have
     $wS_b\{y\}$ and from property cref:eq:verb-trans-prop we get
     #+name: eq:verb-trans-Sbyz
     \begin{equation}
     ‚àÄz(yS_b\{z\}‚áíwS_b\{z\}).
     \end{equation}
     Then since $yS_bV'$ and $v‚ààV'$ we have $bRv$ so by quasi-reflexivity we have
     $vS_b\{v\}$. Finally by cref:eq:verb-trans-v we get $yS_b\{v\}$ and by
     cref:eq:verb-trans-Sbyz we get $wS_b\{v\}$.
   - \boxed{(C_1)} Assume that for some $w,b,x,V$ we have $wRxS_bV$.
     By cref:eq:verb-trans-prop it follows that there is some $v‚ààV$ such that
     #+name: eq:verb-trans-SbxV
     \begin{equation}
      ‚àÄz(vS_b\{z\} ‚áí xS_b\{z\}).
     \end{equation}
     We first see that $xS_b\{v\}$. From $xS_bV$ and $v‚ààV$ we get $bRv$ and by
     quasi-reflexivity we get $vS_b\{v\}$. Then by cref:eq:verb-trans-SbxV we have
     $xS_b\{v\}$. Assume $bRw$, we need to see $wS_b\{v\}$. By quasi-reflexivity
     we get $vS_b\{v\}$ and by cref:eq:verb-trans-SbxV we get $xS_b\{v\}$. By $bRwRx$
     we get $wS_b\{x\}$ and thus by cref:eq:verb-trans-prop we have
     #+name: eq:verb-Sbwx
     \begin{equation}
     ‚àÄz(xS_b\{z\}‚áíwS_b\{z\}).
     \end{equation}
     Finally by $xS_b\{v\}$ and cref:eq:verb-Sbwx we get $wS_b\{v\}$.
   {{{endproof}}}
** From generalized to ordinary (a simpler approach)
   <<sec:gen-to-ord-luka>> In this chapter we present a transformation that
   achieves the same effect as the one presented in cref:sec:verbrugge.
   However, the process described here is much simpler as it does not modify the
   set of worlds. The definitions and proofs in this chapter can be found
   formalized in Agda in cref:src:generalizedveltmansemantics.properties.luka.

   {{{begintheorem}}} {{{agda}}} Let $M$ a generalized Veltman model with
   quasi-transitivity {{{cond(3)}}}, {{{scond(4)}}}, {{{scond(5)}}} or
   {{{scond(6)}}}. By cref:theorem:trans we shall assume without loss of
   generality that $M$ satisfies quasi-transitivity {{{cond(3)}}}. We remind the
   reader that the condition reads thus: \[uS_xY ‚áí ‚àÉ\, \textcolor{blue}{y}‚ààY\, ‚àÄ
   Y'(yS_xY' ‚áí ‚àÉ \, Y''{‚äÜ}Y' ‚àß uS_xY'').\] For every $‚ü®x,u,Y‚ü©$ such that $uS_xY$
   we fix the $y$ that is highlighted in blue and name it $y_{xuY}$.

   We define $M'‚âî‚ü®W,R,S',V‚ü©$ with $S'‚âî\{‚ü®w,x,v‚ü©:‚àÉY.wS_xY‚àß y_{xwY}=v\}$. Then
   $M'$ is an ordinary Veltman frame. Furthermore models $M$ and $M'$ are
   modally equivalent, that is, it holds that for every $w‚ààW$ and $A‚àà\fm$ we
   have \[M,w‚ä©A‚áîM',w‚ä©A.\]

   {{{endtheorem}}} {{{beginproof}}} Here we only check that the
   transitivity condition holds. It is not hard to check that the rest of the
   conditions also hold.

   Assume that we have $xS'_wyS'_wz$. By definition of $S'$ it follows that we
   have $xS'_w\{y\}S'_w\{z\}$ and furthermore $y$ and $z$ satisfy
   quasi-transitivity {{{cond(3)}}}. In particular for $y$ it holds that
   $‚àÄY(yS_wz‚áí‚àÉY'‚äÜY‚àßxS_wY')$. If we set $Y‚âî\{z\}$ then have that there exists
   $Y'‚äÜ\{z\}$ such that $xS_wY'$. Since $Y'$ must be nonempty we have that
   $Y'=\{z\}$ and thus $xS_w\{z\}$. Finally by definition of $S'$ we have
   $xS'_wz$.
   {{{endproof}}}
   # I tried reconstructing the remainder of Mladen's proof and got stuck on
   # another issue. Instead of trying to fix it, I started playing with another
   # formulation of the same (or similar) construction which I think is much more
   # convenient:

   # For every $u S_w V$ and $v \in V$, put $u_{(w, v)} S_w \{v\}$,
   # where $u_{(w, v)}$ is a fresh world that inherits transitions that the world
   # $u$ was a part of. The construction should be performed recursively, starting
   # with R-leaves $w$, then proceeding with their direct R-ancestors etc. Finally,
   # remove all transition $u S_w V$ where $|V| > 1$.

   # Unless I'm missing something, it is almost obvious that this preserves truth
   # values. There are details to be spelled out though, for example what does
   # $u_{(w, v)}$ inherit exactly (it shouldn't be too hard, I actually did
   # something similar in the old version of the IL complexity paper).

** A proof in need of repair
   <<sec:flawed-proof>> As we all know, mathematical proofs can get long and
   tedious to follow. It is an art to guide the reader through the key steps of
   the proof and prevent them from getting lost in the details. In order to
   achieve that, a resource that is often used is to omit details of trivial
   claims during the proof. Omitting details saves a lot of time and usually
   there is no harm in it. However, we may mistakenly believe that something is
   trivial, whereas in reality it may not be trivial, or in the worst case, it
   may not even be true. If the mistake is overlooked, we may end up building on
   top of an inconsistent basis. Needless to say, this is an unacceptable
   situation which we should try to avoid at all costs. In this chapter we
   present an example of a published proof where some steps remain unjustified.
   We discovered these gaps while trying to formalize the proof in Agda. We
   proceed by giving some context to the proof.

   The transformations from a generalized to an ordinary Veltman model given in
   cref:sec:verbrugge,sec:gen-to-ord-luka work for simple notions of
   quasi-transitivity but do not seem to work directly for {{{cond(2)}}}, which
   is the standard. In cite:vukovic2008bisimulations a transformation which is
   claimed to work for {{{cond(2)}}} is presented. We studied the transformation
   and started to formalize in Agda the proof of its correctness following the
   proof of Proposition 2.8 in cite:vukovic2008bisimulations.

   # new
   Despite our strong efforts to fill in the missing steps, we could not
   reproduce the original reasoning. Although we did not find an explicit
   counterexample, the original author agrees with us that the missing steps
   could render the proof invalid. The validity of Proposition 2.8 of
   cite:vukovic2008bisimulations comes into question and until this is resolved,
   we may consider the problem of finding transformation from a generalized
   model (with {{{cond(2)}}}) to an ordinary model such that it preserves some
   structure of the original model to be an open question once again. By
   ``preserves some structure'' we mean that we should have a property of the
   form: \[M,w‚ä©A‚áîM',f(w)‚ä©A\ \ \ \text{for every }w‚ààW,A‚àà\fm{}.\] Where $f$ is a
   map from the set of worlds of $M$ to the set of worlds of $M'$.

   # old
   # Despite our best efforts we could not follow some steps which are claimed
   # to be obvious in the original paper. After that, we decided to ask the
   # original author for a clarification. He kindly replied but was unable to find
   # a satisfying fix for the holes in the proof. After further investigation we
   # realized that the proof had fundamental flaws which could not be fixed
   # easily. Sadly, we have to conclude that Proposition 2.8 of
   # cite:vukovic2008bisimulations is no longer a proven theorem. Thus, the
   # problem of finding transformation from a generalized model (with Condition
   # (2)) to an ordinary model such that it preserves some structure of the
   # original model remains an open question. By ``preserves some structure'' we
   # mean that we should have a property of the form: \[M,w‚ä©A‚áîM',f(w)‚ä©A\ \ \
   # \text{for every }w‚ààW,A‚àà\fm{}.\] Where $f$ is a map from the set of worlds of
   # $M$ to the set of worlds of $M'$.

   We believe that this example should be taken as a humbling reminder that we
   are humans and we make mistakes. Even if a proof has been through skilled
   reviewers from a well established journal it is still suspect of being flawed
   in some subtle way. For this reason, we believe that computer checked proofs
   should gain relevance in all fields of logic and mathematics. We know that
   nowadays proof assistants are far from perfect and usually require a lot of
   time investment both on learning and in formalizing big scale mathematical
   proofs. However, the confidence level that they offer certainly outweighs
   their negatives in some situations.
*** The details
    In this \this{} we present the details to better understand which are the
    problematic steps in the proof. For that, we copy[fn::with very slim
    adaptations to accommodate our notation.] Definitions 2.5, 2.7 and
    Propositions 2.6, 2.8 in cite:vukovic2008bisimulations.

    The definitions and theorems in this section can be found formalized in Agda
    in cref:src:generalizedveltmansemantics.properties.vukovic. Note that
    Proposition 2.8 does not have a finished proof due to the reasons that we
    will expose.

    *Definition 2.5* of cite:vukovic2008bisimulations {{{agda}}} Let $F=‚ü®W,R,\{S_w:w‚ààW\}‚ü©$
    be a generalized Veltman frame. Let $W'$ consist of all pairs $‚ü®v,C‚ü©$, where
    $v‚ààW$ and $C$ is a set of ordered pairs $‚ü®x,y‚ü©‚ààW¬≤$ such that:
    1. If $xRv$, then $‚ü®x,v‚ü©‚ààC$;
    2. for each $x‚ààW$ and each $V‚äÜW[x]$ such that $vS_xV$ there are $V'‚äÜW[x]$ and
       $y‚ààV'$ such that $V‚äÜV'$ and $‚ü®x,y‚ü©‚ààC$;
    3. if $‚ü®x,y‚ü©‚ààC$, then there is $V‚äÜW[x]$ such that $vS_xV$ and $y‚ààV$.
    We define a relation $R'‚äÜW'√óW'$ by
    \[‚ü®w,A‚ü©R'‚ü®u,B‚ü© \text{ iff: } wRu \text{ and } ‚àÄx‚àÄy(xRw ‚áí‚ü®x,y‚ü©‚ààB‚áí‚ü®x,y‚ü©‚ààA)\]
    We define a relation $S'_{‚ü®w,A‚ü©}$ for each $‚ü®w,A‚ü©‚ààW'$ by
    \[‚ü®u,B‚ü©S'_{‚ü®w,A‚ü©}‚ü®v,C‚ü© \text{ iff: } ‚ü®w,A‚ü©R'‚ü®u,B‚ü© \text{ and } ‚ü®w,A‚ü©R'‚ü®v,C‚ü© \text{ and }
    ‚àÄy(‚ü®w,y‚ü©‚ààC‚áí‚ü®w,y‚ü©‚ààB)\]
    We denote an ordered triple $‚ü®W',R',\{S'_{w'}:w'‚ààW'\}‚ü©$ by $\mathrm{of}(F)$.

    *Proposition 2.6* of cite:vukovic2008bisimulations {{{agda}}} Let $M$ be a generalized
    Veltman frame, then $\mathrm{of}(M)$ is an ordinary Veltman frame.
    {{{beginproof}}} The proof is omitted in the original paper and
    we omit it here too. However, the proof has been formalized in Agda and can
    be found in cref:src:generalizedveltmansemantics.properties.vukovic.
    {{{endproof}}}

    *Definition 2.7* of cite:vukovic2008bisimulations {{{agda}}} Let $M=‚ü®F,V‚ü©$
    be a generalized Veltman model, then we define V' by \[‚ü®‚ü®w,A‚ü©,p‚ü©‚ààV' \text{
    iff: } ‚ü®w,p‚ü©‚ààV.\] We denote the model $‚ü®\mathrm{of}(F),V'‚ü©$ by
    $\mathrm{o}(M)$.

    *Proposition 2.8* of cite:vukovic2008bisimulations: Let
    $M=‚ü®W,R,\{S_w:w‚ààW\},V‚ü©$ be a generalized Veltman model. Let
    \[\mathrm{o}(M)=‚ü®W',R',\{S'_{w'}‚ààW'\},V‚ü©.\]
    Then for each formula $œï$ and each $‚ü®w,A‚ü©‚ààW'$ we have
    \[W,w‚ä©œï \text{ iff: } \mathrm{o}(M),‚ü®w,A‚ü©‚ä©œï.\]

    /Partial proof/. The proof goes by induction on the formula $œï$. The only
    interesting case is $‚ñ∑$. Now, suppose that $w‚ä©œï‚ñ∑œà$. We want to show
    $‚ü®w,A‚ü©‚ä©œï‚ñ∑œà$. Assume $‚ü®w,A‚ü©R'‚ü®u,B‚ü©$ and $‚ü®u,B‚ü©‚ä©œï$. By IH we have $u‚ä©œï$. Then
    from $‚ü®w,A‚ü©‚ä©œï‚ñ∑œà$ we get that there exists a set of worlds $V‚ÇÄ‚äÜ\{x:wRx\}$
    such that $uS_wV_0$ and $v‚ä©œà$ for each $v‚ààV‚ÇÄ$. Let $v‚ÇÄ$ be any element of
    the set $V‚ÇÄ$.

    In the proof it is claimed that the following holds: \[‚àÄx (xRw \text{ and }
    xRv‚ÇÄ ‚áí ‚ü®x,v‚ÇÄ‚ü©‚ààA). \] However, details on why this holds are not given. This is
    one of the steps that has not yet been repaired neither by us or the author.

    Further in the proof it is claimed[fn::In the original paper a stronger
    property is claimed, but the property highlighted here is the only piece
    missing.] that the following holds: \[‚ü®w,v‚ÇÄ‚ü©‚ààB.\]
    We find ourselves again in a situation which we have not been able to justify.

    As a closing remark, we want to emphasize that we do not deem this proof as
    definitely flawed since we have not found a counterexample to the theorem.
    However, the fact that we were unable to fill the presented gaps in
    this section hints that the at least the definitions involved in the proof
    should be tweaked.

* Frame conditions
  <<sec:frame-condition>>
** Introduction to principles and frame conditions
  An interpretability principle is a schema of modal formulas that carries some
  special significance. The relevance of a principle mainly stems from two
  factors. On the one hand we have principles, such as the principle \prin{M},
  that give rise to interpretability logics for certain theories. For instance,
  \prin{ILM} is the interpretability logic of \pa{}: $\prin{ILM}=\prin{IL(PA)}$
  (cite:shavrukov1988logic,berarducci1990interpretability). On the other hand we
  have principles which are valid in all reasonable arithmetical theories and
  thus are interesting in the search of an axiomatization for the logic
  \ilall{}. For instance, the series of principles \prin{R^n} and \prin{R_n}
  (cite:two-new-series), which we will present in this part, are central to the
  best known lower bound for \ilall{}.

  Regardless of the area of interest, finding the frame condition for a
  principle is always the first step towards studying the nature of the
  principle. Once we have established a frame condition for a principle, say
  \prin{X}, one has more tools when studying, for instance, modal soundness and
  completeness of the logic \prin{ILX}. Soundness in itself is already an
  interesting result, but the usefulness of a soundness theorem grows when it is
  applied to prove independence results between principles. To prove that two
  principles \prin{X} and \prin{Y} are independent means to show
  $\prin{ILX}‚ä¨\prin{Y}$ and $\prin{ILY}‚ä¨\prin{X}$, which is done by building
  countermodels (for instance, see cite:joosten-master), as usual in modal
  logics. To prove that a principle does not entail another principle is a
  necessary step in order to improve the lower bound of \ilall{} since we need to
  show that the new lower bound does indeed not follow from the previous lower
  bound. In this thesis however, we are not concerned with independence results
  and we will only focus on the frame conditions.

  As we have briefly mentioned in the overview at the beginning of this thesis,
  a frame condition captures the relational semantic nature of the
  principle. To be more precise, assume that we have a
  principle \prin{X} which is not necessarily valid in an arbitrary ordinary
  Veltman frame. A frame condition is a first (or higher) order formula
  $\kord{X}$ such that for any ordinary Veltman frame $F$ we have: \[F ‚ä®
  \kord{X} ‚áî F ‚ä© \prin{X}.\] In the expression above, $F ‚ä® \kord{M}$ denotes
  that $F$ models the condition $\kord{M}$ in the sense of a first (or higher)
  order structure. The $F ‚ä© \prin{X}$ part means that we have $‚ü®F,V‚ü©‚ä©\prin{X}$
  for any valuation $V$ and any particular instance of \prin{X}. We define frame
  conditions for generalized Veltman frames in an analogous way. As a
  convention, for a principle \prin{X} we will write \kord{X} and \kgen{X} to
  denote the frame conditions with respect to ordinary and generalized
  semantics, respectively.

  In cref:sec:generic-cond we will verify in Agda that there is a mechanical
  procedure to obtain frame conditions for any axiom schema. However, the
  generated condition encodes a quantification over valuations in the frame
  condition and thus it is usually not suitable as an /adequate/ frame
  condition. There is no precise definition on what constitutes an adequate
  frame condition. Usually one considers a frame condition to be adequate if it
  is relatively elegant and succinct. Let us continue the discussion by using an
  example. Consider L√∂b's axiom given in modal form: \[\prin{L}=‚ñ°(‚ñ°A‚ÜíA)‚Üí‚ñ°A.\] We
  know from the characterization of \(\text{\gl-frames}\) that the frame
  condition for \prin{L} is the following:
  #+begin_center
  The $R$ relation must be transitive and Noetherian.
  #+end_center
  The same condition expressed in formulas reads as follows (we refer to these
  formulation as the /original/): \[‚àÄx.‚àÄy.‚àÄz.xRyRz‚áíxRz\ ;\] \[‚àÄùïä.ùïä‚â†‚àÖ‚áí‚àÉs‚ààùïä‚àÄs'
  (s\cancel{R}s').\] And now observe the generic frame condition that arises
  from a mechanical procedure[fn::The mechanical procedure for Veltman semantics
  is presented in detail in cref:sec:generic-cond. Basically, the procedure
  consists in writing the definition of a frame condition as a second order
  formula.](we will refer to this formulation as the /generic/):
  \[‚àÄùî∏.‚àÄu(wRu‚áí(‚àÄu'(uRu'‚áíu'‚ààùî∏))‚áíu‚ààùî∏)‚áí‚àÄu(wRu‚áíu‚ààùî∏).\] If we compare the original
  and the generic conditions we see that they are both second order formulas as
  they quantify over sets: We have $‚àÄùïä$ in the original and $‚àÄùî∏$ in the generic.
  If we do the mental exercise to forget for a moment that we have the concepts
  of /transitivity/ and /Noetherian relation/ in our mathematical metalanguage,
  it is not completely obvious how to objectively justify why the original
  formulation is preferred in the literature over the generic formulation.
  However, the case is that we /do/ have the concepts of transitivity and
  Noetherian relations in our commonly used metalanguage and moreover we are
  used to operating with them. Furthermore, it is easy for us to imagine a
  transitive relation that has no infinite ascending chains. On the contrary the
  picture that is described by the generic condition is rather blurry for us.
  All in all, we see that we can precisely define the minimal requirement (frame
  validity) for a frame condition, but comparing the usefulness of a frame
  condition remains open to interpretation. However, we will lean towards
  conditions which are easy to visualize.

  In this part we present a number of principles in conjunction with their
  respective frame conditions for ordinary semantics as well as generalized
  semantics. We will prove that all the given conditions satisfy the minimal
  requirement to be considered frame conditions. Moreover, we attach a diagram
  representation of most of the presented frame conditions in an attempt to
  convey their visual value.
** The principle \prin{M}

   The \prin{M} principle reads as follows: \[A ‚ñ∑ B ‚Üí (A ‚àß ‚ñ° C) ‚ñ∑ (B ‚àß ‚ñ° C).\]

   The \prin{M} principle is named after Franco Montagna because the principle
   appeared during discussions between Franco Montagna and Albert Visser about
   interpretability logic (cite:bilkova2009interpretability).

   The theorems of $\prin{ILM}$ are the set of interpretability principles that
   are always provable in theories which are {{{latex($Œ£_1$-sound)}}} and have
   full induction.
   (cite:berarducci1990interpretability,visser1997overview,joosten2020overview).
   An example of such a theory is \pa{}.
*** Ordinary semantics
   The frame condition for \prin{M} for ordinary semantics, which we write as $\kord{M}$,
   reads as follows:
   \[‚àÄw,x,y,z(xS_w yRz ‚áí xRz).\]

   #+caption: Ordinary frame condition for \prin{M}.
   #+name: fig:ord-M-condition
   #+attr_latex: :float t :width 0.20\textwidth :placement [H]
   [[file:img/M-ord.pdf]]

   {{{begintheorem}}} {{{agda}}} For any ordinary frame $F$, we have that $F$
   satisfies the $\kord{M}$ condition iff any model based on $F$ forces every
   instantiation of the \prin{M} principle. In symbols:

   \[F ‚ä® \kord{M} ‚áî F ‚ä© \prin{M}.\]
   {{{endtheorem}}}

   {{{beginproof}}}
   - \boxed{‚áí} Let $M$ be a model based on $F$ and let $w$ be any world. Assume
     that $w‚ä©A‚ñ∑B$ and that there is a world $x$ such that $wRx$ and $x‚ä©A‚àß‚ñ°C$.
     Our aim is to find a world $z$ such that $xS_wz‚ä©B‚àß‚ñ°C$. Since $wRx‚ä©A$ and
     $w‚ä©A‚ñ∑B$ there is a world $z$ such that $xS_wz‚ä©B$. We now show that $z‚ä©‚ñ°C$.
     Consider an arbitrary $u$ such that $zRu$. By the frame condition it
     follows that $xRu$ and we know $x‚ä©‚ñ°C$ hence $u‚ä©C$ and thus $z‚ä©‚ñ°C$. Hence
     $z$ is the desired world.

   - \boxed{‚áê} Let $a,b,c‚àà\var{}$, assume $F‚ä©a‚ñ∑b‚Üí(a‚àß‚ñ°c)‚ñ∑(b‚àß‚ñ°c)$. Assume also that
     for some $x,w,u$ we have $xS_wzRu$. Our goal is to prove $xRu$. Consider a
     model such that the following holds.
     \begin{flalign*}
     ‚ü¶a‚üß &= \{x\}; \\
     ‚ü¶b‚üß &= \{z\}; \\
     ‚ü¶c‚üß &= \{v:xRv\}.
     \end{flalign*}
     We observe that $w‚ä©a‚ñ∑b$ because $a$ is only forced in $x$ and we have
     $xS_wz‚ä©b$. Then it follows that $w‚ä©(a‚àß‚ñ°c)‚ñ∑(b‚àß‚ñ°c)$. It is easy to observe
     that $x‚ä©a‚àß‚ñ°c$, furthermore we have that by the definition of an ordinary frame
     $xS_wz‚áíwRx$, hence $wRx$ and thus there must exist some $v$ such that
     $xS_wv‚ä©b‚àß‚ñ°c$. Since $b$ is only true in $z$ it must be $z‚ä©b‚àß‚ñ°c$. Then,
     because $zRu$ we have $u‚ä©c$, therefore $xRu$.

   The Agda proof can be found in cref:src:ordinaryveltmansemantics.properties.msub0.
   {{{endproof}}}

*** Generalized semantics
   The frame condition for \prin{M} for generalized semantics, which we write as
   $\kgen{M}$, reads as follows:

   \[ ‚àÄw,x,V(xS_wV‚áí ‚àÉV'‚äÜV(xS_wV',‚àÄv'‚ààV'‚àÄz(v'Rz‚áíxRz))).\]

   #+caption: Generalized frame condition for \prin{M}.
   #+name: fig:gen-M-condition
   #+attr_latex: :float t :width 0.35\textwidth :placement [H]
   [[file:img/M-gen.pdf]]

   {{{begintheorem}}} {{{agda}}} For any generalized frame $F$, we have that $F$ satisfies the
   $\kgen{M}$ condition iff any model based on $F$ forces every instantiation of
   the \prin{M} principle. In symbols:

   \[F ‚ä® \kgen{M} ‚áî F ‚ä© M.\] {{{endtheorem}}}

   {{{beginproof}}}
   - \boxed{‚áí} Let $M$ be a model based on $F$ and let $w$ be any world. Assume
     that $w‚ä©A‚ñ∑B$ and that there is a world $x$ such that $wRx$ and $x‚ä©A‚àß‚ñ°C$.
     Our aim is to find a set $Z$ such that $xS_wZ‚ä©B‚àß‚ñ°C$. Since $wRx‚ä©A$ and
     $w‚ä©A‚ñ∑B$ there is set $Z$ such that $xS_wZ‚ä©B$. Then by the $\kgen{M}$
     condition it follows that there is a set $Z'‚äÜZ$ such that $xS_wZ'$ and
     $‚àÄv‚ààZ'‚àÄz(vRz‚áíxRz)$. Now we show $Z'‚ä©‚ñ°C$. Let $v‚ààZ'$ and $u$ such that
     $vRu$, by the condition above it follows $xRu$ and since $x‚ä©‚ñ°C$ we have
     $u‚ä©C$. Hence $Z'$ is the desired set.
   - \boxed{‚áê} Let $a,b,c‚àà\var{}$ and assume $F‚ä©a ‚ñ∑ b ‚Üí (a ‚àß ‚ñ° c) ‚ñ∑ (b ‚àß ‚ñ° c)$ and
     $uS_wV$. Consider a model satisfying the following
     \begin{flalign*}
     ‚ü¶a‚üß &= \{u\}; \\
     ‚ü¶b‚üß &= V; \\
     ‚ü¶c‚üß &= \{v:uRv\}.
     \end{flalign*}
     We see that $w‚ä©a‚ñ∑b$ since $a$ is only true in $u$ and we have $uS_wV‚ä©b$. It
     follows that ${w‚ä©(a ‚àß ‚ñ° c)‚ñ∑(b‚àß‚ñ°c)}$. It is easy to see that $u‚ä©a‚àß‚ñ°c$, hence
     there must exist $V'$ such that $uS_wV'‚ä©b‚àß‚ñ°c$. Clearly $V'‚äÜV$ since $b$ is
     forced exactly in $V$. Now let $v',z$ such that $v'‚ààV'$ and $v'Rz$. Since
     $v'‚ä©‚ñ°c$, then $z‚ä©c$ and thus $uRz$. Therefore $V'$ is the desired set.

   The Agda proof can be found in
   cref:src:generalizedveltmansemantics.properties.m. {{{endproof}}}
** The principle \prin{M‚ÇÄ}

   The \prin{M‚ÇÄ} principle reads as follows:
   \[A ‚ñ∑ B ‚Üí ‚ô¢ A ‚àß ‚ñ° C ‚ñ∑ B ‚àß ‚ñ° C.\]

   The \prin{M‚ÇÄ} principle first appears in
   cite:Visser:1991:FormalizationOfInterpretability, where it is proved that
   \prin{M_0} is arithmetically sound. Moreover it is claimed that Dick de Jongh
   showed that $\prin{ILM_0W}=\prin{ILW^*}$. During a short period of time,
   \prin{ILM‚ÇÄ} was a candidate to be \ilall{}, however, such possibility was ruled
   out with the discovery of the principle \prin{P‚ÇÄ}. The logic \prin{ILM_0} is
   complete with respect to ordinary and generalized semantics
   (cite:modal-matters).

*** Ordinary semantics

    The $\kord{M‚ÇÄ}$ condition reads as follows:
    \[‚àÄw,x,y,z(wRxRyS_wz‚áí‚àÄu(zRu‚áíxRu)).\]

   #+caption: Ordinary frame condition for \prin{M‚ÇÄ}.
   #+name: fig:M_0-ord
   #+attr_latex: :float t :width 0.25\textwidth :placement [H]
   [[file:img/M_0-ord.pdf]]

    {{{begintheorem}}} {{{agda}}} For any ordinary frame $F$, we have that $F$
    satisfies the $\kord{M‚ÇÄ}$ condition iff any model based on $F$ forces every
    instantiation of the \prin{M‚ÇÄ} principle. In symbols:

    \[F ‚ä® \kord{M‚ÇÄ} ‚áî F ‚ä© \prin{M‚ÇÄ}.\]
    {{{endtheorem}}}

    {{{beginproof}}}
    - \boxed{‚áí} Let $M$ be a model based on $F$ and let $w$ be any world. Assume
      that $w‚ä©A‚ñ∑B$ and that there exists some $x$ such that $wRx‚ä© ‚ô¢ A ‚àß ‚ñ° C$. It
      follows that there exists some world $y$ such that $xRy‚ä©A$, then since
      $wRy$ and $w‚ä©A‚ñ∑B$ there exists a world $z$ such that $yS_wz‚ä©B$. Observe
      that from $wRxRy$ it follows that $xS_wy$ and by transitivity of $S_w$ and
      $yS_wz$ we get $xS_wz$. It remains to show $z‚ä©‚ñ°C$. Consider some world $u$
      such that $zRu$, then by the $\kord{M‚ÇÄ}$ condition we have that
      $‚àÄu(zRu‚áíxRu)$ and thus it follows that $xRu$ and since $x‚ä©‚ñ°C$ we also have
      $u‚ä©C$.
    - \boxed{‚áê} Let $a,b,c‚àà\var{}$ and assume $F‚ä©a ‚ñ∑ b ‚Üí (‚ô¢ a ‚àß ‚ñ° c) ‚ñ∑ (b ‚àß ‚ñ° c)$ and
      assume that for some $w,x,y,z$ we have $wRxRyS_wz$. Consider a model based
      on $F$ such that the following holds:
      \begin{flalign*}
      ‚ü¶a‚üß &= \{y\}; \\
      ‚ü¶b‚üß &= \{z\}; \\
      ‚ü¶c‚üß &= \{v:xRv\}.
      \end{flalign*}
      Observe that $w‚ä©a‚ñ∑b$ since $a$ is forced only in $y$ and we have $yS_wz‚ä©b$.
      It follows that $w‚ä©(‚ô¢ a ‚àß ‚ñ° c) ‚ñ∑ (b ‚àß ‚ñ° c)$. Clearly $x‚ä©‚ô¢a‚àß‚ñ°c$, hence there
      must exist some world $v$ such that $xS_wv‚ä©b‚àß‚ñ°c$ but since $b$ is only
      forced in $z$ we have $z=v$ and thus $xS_wz$. To prove the remaining
      implication let $u$ such that $zRu$, then $u‚ä©c$ and thus $xRu$.

    The Agda proof can be found in
    cref:src:ordinaryveltmansemantics.properties.msub0. {{{endproof}}}
*** Generalized semantics
    The $\kgen{M‚ÇÄ}$ condition reads as follows:
    \[‚àÄw,x,y,Y(wRxRyS_wY‚áí‚àÉY'‚äÜY(xS_wY',‚àÄy'‚ààY'‚àÄz(y'Rz‚áíxRz))).\]

   #+caption: Generalized frame condition for \prin{M‚ÇÄ}.
   #+name: fig:M_0-gen
   #+attr_latex: :float t :width 0.30\textwidth :placement [H]
   [[file:img/M_0-gen.pdf]]

    {{{begintheorem}}} For any ordinary frame $F$, we have that $F$ satisfies the
    $\kgen{M‚ÇÄ}$ condition iff any model based on $F$ forces every instantiation of
    the \prin{M‚ÇÄ} principle. In symbols:

    \[F ‚ä® \kgen{M‚ÇÄ} ‚áî F ‚ä© \prin{M‚ÇÄ}.\] {{{endtheorem}}}

    {{{beginproof}}}
    {{{agda}}}
    - \boxed{‚áí} Let $M$ be a model based on $F$ and let $w$ be any world. Assume
      that $w‚ä©A‚ñ∑B$ and that there is a world $x$ such that $wRx‚ä©‚ô¢A‚àß‚ñ°C$. Then
      there must exist some world $y$ such that $xRy‚ä©A$. Since $wRy$ and $w‚ä©A‚ñ∑B$
      there exists some set $Y$ such that $yS_wY‚ä©B$. Then by the $\kgen{M‚ÇÄ}$
      condition we have that there exists some $Y'‚äÜY$ such that $xS_wY'$ and
      $(‚ãÜ)\ ‚àÄy'‚ààY'‚àÄz(y'Rz‚áíxRz)$. Clearly $Y'‚ä©B$ since $Y'‚äÜY$. To show that
      $Y'‚ä©‚ñ°C$ consider some $y'‚ààY'$ and some $z$ such that $y'Rz$. Then, by
      $(‚ãÜ)$ it follows that $xRz$ and since $x‚ä©‚ñ°C$ we also have $x‚ä©C$.
    - \boxed{‚áê} Let $a,b,c‚àà\var{}$ and assume $F‚ä©a ‚ñ∑ b ‚Üí (‚ô¢ a ‚àß ‚ñ° c) ‚ñ∑ (b ‚àß ‚ñ° c)$
      and assume that for some $w,x,y,Y$ we have $wRxRyS_wY$. Then consider a
      model based on $F$ such that.
      \begin{flalign*}
      ‚ü¶a‚üß &= \{y\}; \\
      ‚ü¶b‚üß &= Y; \\
      ‚ü¶c‚üß &= \{v:xRv\}.
      \end{flalign*}
      Observe that $w‚ä©a‚ñ∑b$ as $a$ is only forced in $y$ and we have $yS_wY‚ä©b$.
      Consequently it holds that $w‚ä©(‚ô¢ a ‚àß ‚ñ° c) ‚ñ∑ (b ‚àß ‚ñ° c)$. See also that
      $x‚ä©‚ô¢a$ since $xRy‚ä©a$ and also $x‚ä©‚ñ°c$ by definition of the model. Then
      there must exist some set $Y'$ such that $xS_wY'‚ä©b‚àß‚ñ°c$. Clearly $Y'‚äÜY$ since
      $Y'‚ä©b$. To show the remaining condition pick some $y'‚ààY'$ and some $z$
      such that $y'Rz$. Since $Y'‚ä©‚ñ°c$ then $z‚ä©c$ and thus $xRz$.

    The Agda proof can be found in
    cref:src:generalizedveltmansemantics.properties.msub0. {{{endproof}}}

** The principle \prin{P‚ÇÄ}
   <<sec:prin-p0>>

 # - not super important, but you could make parentheses straight in math-mode (I
 #   think the command is \textup{...}), e.g. in this formula and similar formulas
 #   elsewhere: F |= (P_0) <=> F ||- P_0


   The \prin{P‚ÇÄ} principle reads as follows:
   \[A ‚ñ∑ ‚ô¢ B ‚Üí ‚ñ° (A ‚ñ∑ B).\]

   We give some context to the principle \prin{P‚ÇÄ}, borrowed from
   cite:joosten2020interpretability. The principle \prin{P‚ÇÄ} was discovered in
   1998 by Albert Visser. This principle appeared while trying to develop the
   completeness proof of \prin{ILM_0}. In an attempt to strengthen the logic,
   Visser modified the frame condition of \prin{ILM_0} to make it stronger and
   arrived at a stronger principle, which was given the name $\prin{P_0}$. The
   frame condition with respect to ordinary semantics of \prin{P_0} implies the
   frame condition (with respect to ordinary semantics) of $\prin{M_0}$. In
   cite:joosten-master it is proven that $\prin{ILP_0}‚ä¨\prin{ILM_0}$ using
   ordinary Veltman semantics. Thus we have that \prin{ILP_0} is modally
   incomplete with respect to ordinary semantics. However, it was shown recently
   in cite:mikec-vukovic20 that \prin{P_0} is in fact complete with respect to
   generalized Veltman semantics.

   The principle \prin{P_0} is valid in all reasonable arithmetical theories and
   thus it is in \ilall{}.

*** Ordinary semantics
    The $\kord{P‚ÇÄ}$ condition reads as follows:

    \[‚àÄw,x,y,z,u(wRxRyS_wzRu‚áíyS_xu).\]

   #+caption: Ordinary frame condition for \prin{P‚ÇÄ}.
   #+name: fig:P_0-ord
   #+attr_latex: :float t :width 0.15\textwidth :placement [H]
   [[file:img/P_0-ord.pdf]]

   {{{begintheorem}}} For any ordinary frame $F$, we have that $F$ satisfies the
   $\kord{P‚ÇÄ}$ condition iff any model based on $F$ forces every instantiation of
   the \prin{P‚ÇÄ} principle. In symbols:

   \[F ‚ä® \kord{P‚ÇÄ} ‚áî F ‚ä© \prin{P‚ÇÄ}.\] {{{endtheorem}}}

   {{{beginproof}}}
   {{{agda}}}
   - \boxed{‚áí} Let $M$ be a model based on $F$ and let $w$ be any world. Assume
     that $w‚ä©A‚ñ∑‚ô¢B$ and that there is a world $x$ such that $wRx$. Our goal is to
     show that $x‚ä©A‚ñ∑B$. Consider a world $y$ such that $xRy‚ä©A$. As $wRy$ and
     $w‚ä©A‚ñ∑‚ô¢B$ then there exist some worlds $z,u$ such that $yS_wzRu‚ä©B$. By the
     $\kord{P‚ÇÄ}$ condition it follows that $yS_xu$ and thus $x‚ä©A‚ñ∑B$.
   - \boxed{‚áê} Let $a,b‚àà\var{}$ and assume $F‚ä©a ‚ñ∑ ‚ô¢ b ‚Üí ‚ñ° (a ‚ñ∑ b)$ and assume that
     $wRxRyS_wzRu$. We want to show $yS_xu$. Consider a model based on $F$ such
     that:
     \begin{flalign*}
     ‚ü¶a‚üß = \{y \}; \\
     ‚ü¶b‚üß = \{u \}.
     \end{flalign*}
     Observe that $w‚ä©a‚ñ∑‚ô¢b$ as the only world that forces $a$ is $y$ and we have
     $yS_wz‚ä©‚ô¢b$, because $zRu‚ä©b$. Consequently we have $w‚ä©‚ñ°(a‚ñ∑b)$ and therefore
     $x‚ä©a‚ñ∑b$. Then, since $xRy‚ä©a$ it follows that there exist some $v$ such that
     $yS_xv‚ä©b$, but since $b$ is only forced in $u$, it must be $u=v$ and so
     $yS_xu$.

   The Agda proof can be found in
   cref:src:ordinaryveltmansemantics.properties.psub0.
   {{{endproof}}}

*** Generalized semantics
    The $\kgen{P_0}$ condition reads as follows:
    \[‚àÄw,x,y,V,Z((wRxRyS_wV,‚àÄv‚ààY‚àÉz‚ààZ(vRz))‚áí‚àÉZ'‚äÜZ(yS_xZ')).\]

   #+caption: Generalized frame condition for \prin{P‚ÇÄ}.
   #+name: fig:P_0-gen
   #+attr_latex: :float t :width 0.31\textwidth :placement [H]
   [[file:img/P_0-gen.pdf]]


   {{{begintheorem}}} For any generalized frame $F$, we have that $F$ satisfies the
   $\kgen{P‚ÇÄ}$ condition iff any model based on $F$ forces every instantiation of
   the \prin{P‚ÇÄ} principle. In symbols:

   \[F ‚ä® \kgen{P‚ÇÄ} ‚áî F ‚ä© \prin{P‚ÇÄ}.\] {{{endtheorem}}}

   {{{beginproof}}}
   {{{agda}}}
   - \boxed{‚áí} Let $M$ be a model based on $F$ and let $w$ be any world. Assume
     that $w‚ä©A‚ñ∑‚ô¢B$ and that there is a world $x$ such that $wRx$. We aim to show
     that $x‚ä©A‚ñ∑B$. Assume there is a world $u$ such that $xRu‚ä©A$ and as $wRu$
     and $w‚ä©A‚ñ∑‚ô¢B$ then there exists a set $V$ $uS_xV‚ä©‚ô¢B$. Let $ùîπ=\{v:v‚ä©B\}$.
     Then observe that because $V‚ä©‚ô¢B$ we have that for all $v$ in $V$ there
     exists some $z‚ààùîπ$ such that $vRz$. Hence by the $\kgen{P‚ÇÄ}$ condition
     there exists some $ùîπ'‚äÜùîπ$ such that $yS_xùîπ'$. Clearly $ùîπ'‚ä©B$, therefore
     $x‚ä©A‚ñ∑B$.
   - \boxed{‚áê} Let $a,b‚àà\var{}$ and assume $F‚ä©a ‚ñ∑ ‚ô¢ b ‚Üí ‚ñ° (a ‚ñ∑ b)$ and assume
     that for some $w,x,y,V,Z$ we have $wRxRyS_wY$ and $(‚ãÜ)\ ‚àÄv‚ààV‚àÉz‚ààZ(vRz)$.
     Consider a model based on $F$ such that:
     \begin{flalign*}
    ‚ü¶a‚üß &= \{y\}; \\
    ‚ü¶b‚üß &= Z.
     \end{flalign*}
     See that $w‚ä©a‚ñ∑‚ô¢b$ as the only world that forces $a$ is $y$ and we have
     $yS_wV$ and by $(‚ãÜ)$ it follows that $V‚ä©‚ô¢b$. Consequently it holds that
     $w‚ä©‚ñ°(a‚ñ∑b)$ and since $wRx$ then $x‚ä©a‚ñ∑b$. Also, since $xRy‚ä©a$ then there
     exists $Z'$ such that $yS_xZ'‚ä©b$. Clearly $Z'‚ä©b$ implies $Z'‚äÜZ$ so we are
     done.

   The Agda proof can be found in
   cref:src:generalizedveltmansemantics.properties.psub0.
   {{{endproof}}}

** The principle \prin{R}
   <<sec:prin-r>>

   The \prin{R} principle reads as follows:

   \[A ‚ñ∑ B ‚Üí ¬¨ (A ‚ñ∑ ¬¨C) ‚ñ∑ (B ‚àß ‚ñ° C)\ .\]

   The principle \prin{R} was introduced by Goris and Joosten in
   cite:a-new-principle. The authors show that \prin{R} does follow semantically
   but not syntactically from \prin{ILP_0W^*}, which was the best known lower
   bound for \ilall{} in at a time. Goris and Joosten also show that \prin{R} is
   valid in all reasonable arithmetical theories and thus giving a strictly
   better lower bound for \ilall{}.

   The principle \prin{R} is the same as \prin{R_0} and \prin{R^0}. The
   \prin{R^n} and \prin{R_n} series of principles, which generalize \prin{R},
   will be discussed in cref:sec:Rsub1,sec:Rsupn.
*** Ordinary semantics
    The $\kord{R}$ condition reads as follows:

    \[‚àÄw,x,y,z,u(wRxRyS_wzRu‚áíyS_xu).\]

   #+caption: Ordinary frame condition for \prin{R}.
   #+name: fig:ord-R-condition
   #+attr_latex: :float t :width 0.15\textwidth :placement [H]
   [[file:img/R-ord.pdf]]

   {{{begintheorem}}} {{{agda}}}
   For any ordinary frame $F$, we have that $F$ satisfies the
   $\kord{R}$ condition iff any model based on $F$ forces every instantiation of
   the \prin{R} principle. In symbols:

   \[F ‚ä® \kord{R} ‚áî F ‚ä© \prin{R}\ .\]
   {{{endtheorem}}}

   {{{beginproof}}}
   - \boxed{‚áí} Let $M$ be a model based on $F$ and let $w$ be any world. Assume
     that $w‚ä©A‚ñ∑B$ and that there is a world $x$ such that $wRx‚ä©¬¨(A‚ñ∑¬¨C)$. We need
     to see that there is some world $z$ such that $xS_wz‚ä©B‚àß‚ñ°C$. From
     $x‚ä©¬¨(A‚ñ∑¬¨C)$ we get a world $y$ such that $xRy‚ä©A$ and $(‚ãÜ)\ ‚àÄv(yS_xv‚áív‚ä©C)$.
     Since $w‚ä©A‚ñ∑B$, and by transitivity we have $wRy$, it follows that there
     exists a world $z$ such that $yS_wz‚ä©B$. To see that $z$ is the desired
     world we first see that $z‚ä©‚ñ°C$. Let $u$ be such that $zRu$, then by
     $\kord{R}$ it follows that $yS_xu$ and by $(‚ãÜ)$ we get $u‚ä©C$. Finally, we
     have to see that $xS_wz$. Since $wRxRy$ we have that $xS_wy$ and we have
     $yS_wz$ from before, hence by transitivity of $S_w$ we get $xS_wz$.

   # To see that \(z\) is the desired world.

   # {{{joost(I WOULD SAY HERE: "WE HAVE TO VERIFY
   # TWO THINGS". THEN YOU MENTION THE TWO THINGS AND THEN YOU PROVE THEM ONE BY ONE.
   # LIKE THIS\, YOU HELP THE NON-EXPERIENCED READER REMIND WHAT IS IT THAT YOU ARE
   # AFTER)}}}


   - \boxed{‚áê} Let $a,b,c‚àà\var{}$ and assume that for some $w,x,y,z$ we have
     $wRxRyS_wz$ . Consider a model
     based on $F$ that satisfies the following.
    \begin{flalign*}
     ‚ü¶a‚üß &= \{y\}; \\
     ‚ü¶b‚üß &= \{z\}; \\
     ‚ü¶c‚üß &= \{u:yS_xu\}.
    \end{flalign*}
     By assumption we have that $w‚ä©a ‚ñ∑ b ‚Üí (¬¨ (a ‚ñ∑ ¬¨c) ‚ñ∑ (b ‚àß ‚ñ° c))$. Clearly
     $w‚ä©a‚ñ∑b$ as we have $yS_wz‚ä©b$. Consequently it holds that $w‚ä©¬¨ (a ‚ñ∑ ¬¨c) ‚ñ∑ (b
     ‚àß ‚ñ° c)$. In order to show that $x‚ä©¬¨ (a ‚ñ∑ ¬¨c)$, considering that $a$ is only
     forced in $y$, it suffices to observe that $‚àÄz(yS_xz‚áíz‚ä©c)$, which clearly
     holds. Then there must exist some world $v$ such that $xS_wv‚ä©b‚àß‚ñ°c$ but
     $v=z$ since $z$ is the only world that forces $b$, hence $xS_wz‚ä©‚ñ°c$. Now to
     show $‚àÄv(zRv‚áíyS_xv)$ consider some $v$ such that $zRv$. From $z‚ä©‚ñ°c$ we get
     $v‚ä©c$ and thus $yS_xv$.

   The Agda proof can be found in
   cref:src:ordinaryveltmansemantics.properties.r.
   {{{endproof}}}

*** Generalized semantics
   In order to define the frame condition for the \sf{R} principle we first need
   to introduce the concept of choice set.

   {{{begindef}}} If $xRy$ we say that a set of worlds $K$ is a \gls{choice-set}
   for $‚ü®x,y‚ü©$ iff for any $V$ such that $yS_xV$ we have $V‚à©K‚â†‚àÖ$. We denote the
   family of choice sets for $‚ü®x,y‚ü©$ by $ùíû(x,y)$. Note that this definition
   depends on the frame, but it should always be clear from context.
   {{{enddef}}}

    The $\kgen{R}$ condition reads as follows:
    \begin{flalign*}
    &‚àÄw,x,y,Y,K(wRxRyS_wY,K‚ààùíû(x,y)   \\
    ‚áí& ‚àÉY'‚äÜY(xS_wY',‚àÄy'‚ààY'‚àÄz(y'Rz‚áíz‚ààK))).
    \end{flalign*}

   #+caption: Generalized frame condition for \prin{R}.
   #+name: fig:gen-R-condition
   #+attr_latex: :float t :width 0.36\textwidth :placement [H]
   [[file:img/R-gen.pdf]]

   {{{begintheorem}}} {{{agda}}}
   <<theorem:R^0>>
   For any generalized frame $F$, we have that $F$ satisfies the
   $\kgen{R}$ condition iff any model based on $F$ forces every instantiation of
   the \prin{R} principle. In symbols:

   \[F ‚ä® \kgen{R} ‚áî F ‚ä© \prin{R}.\]
   {{{endtheorem}}}

   {{{beginproof}}}
   - \boxed{‚áí} Let $M$ be a model based on $F$ and assume there is a world $w$ such
     that $w‚ä©A‚ñ∑B$ and a world $x$ such that $wRx$ and $x‚ä©¬¨(A‚ñ∑¬¨C)$. We need to
     show that there is a set $Z$ such that $xS_wZ‚ä©B‚àß‚ñ°C$. From $x‚ä©¬¨(A‚ñ∑¬¨C)$ it
     follows that there is a world $y$ such that $xRy‚ä©A$ and $(‚ãÜ)\
     ‚àÄV(yS_xV‚áí‚àÉc‚ààV(c‚ä©C))$. Consider the set $K‚âî\{c:c‚ä©C,‚àÉV(c‚ààV,yS_xV)\}$. Clearly
     by $(‚ãÜ)$ it follows that $K$ is a choice set for $‚ü®x,y‚ü©$. By transitivity
     of $R$ we get $wRy$ and since $w‚ä©A‚ñ∑B$ then there must exist some $Y$ such
     that $yS_wY‚ä©B$. We can now apply the $\kgen{R}$ condition and get a $Y'‚äÜY$
     such that $xS_wY'$ and $(‚Ä†)\ ‚àÄy'‚ààY'‚àÄz(y'Rz‚áíz‚ààK)$. To show that $Y'$ is the
     desired set it remains to see that $Y'‚ä©B‚àß‚ñ°C$. From the fact that $Y'‚äÜY‚ä©B$
     it easily follows that $Y'‚ä©B$. Now, let $y'‚ààY'$ and $u$ such that $y'Ru$,
     from $(‚Ä†)$ we get $u‚ààK$ and by definition of $K$ we have $u‚ä©C$.
   - \boxed{‚áê} Let $a,b,c‚àà\var{}$ and assume $F‚ä© a ‚ñ∑ b ‚Üí ¬¨ (a ‚ñ∑ ¬¨c) ‚ñ∑ (b ‚àß ‚ñ° c)$.
     Assume also that for some $w,x,y,Y,K$ we have $wRxRyS_wY,K‚ààùíû(x,y)$. Now
     consider a model based on $F$ that satisfies the following:
    \begin{flalign*}
    ‚ü¶a‚üß &=\{y\}; \\
    ‚ü¶b‚üß &=Y; \\
    ‚ü¶c‚üß &= K. \\
    \end{flalign*}
    By assumption we have $w‚ä©a ‚ñ∑ b ‚Üí ¬¨ (a ‚ñ∑ ¬¨c) ‚ñ∑ (b ‚àß ‚ñ° c)$. Observe that that
     $w‚ä©a‚ñ∑b$ since $yS_wY‚ä©b$. Thus $w‚ä©¬¨ (a ‚ñ∑ ¬¨c) ‚ñ∑ (b ‚àß ‚ñ° c)$. As $y$ is the
     only world that forces $a$, in order to show $x‚ä©¬¨(a‚ñ∑¬¨c)$ we need to see
     that $‚àÄV(yS_xV‚áí‚àÉz‚ààV(z‚ä©c))$, which is equivalent to $‚àÄV(yS_xV‚áí‚àÉz‚ààV‚à©K)$ and
     this holds since $K‚ààùíû(x,y)$. As a consequence of $x‚ä©¬¨(a‚ñ∑¬¨c)$ we have that
     there exists a set $Y'$ such that $xS_wY'‚ä©b‚àß‚ñ°c$. From $Y'‚ä©b$ we get $Y'‚äÜY$ and
     from $Y'‚ä©‚ñ°c$ we get $‚àÄy'‚ààY'(‚àÄz(y'Rz‚Üíz‚ààK))$, hence $Y'$ is the desired set.

   The Agda proof can be found in
   cref:src:generalizedveltmansemantics.properties.r.
   {{{endproof}}}

** The principle \prin{R‚ÇÅ}
   <<sec:Rsub1>>

   The $R_1$ principle reads as follows:
   \[A ‚ñ∑ B ‚Üí (¬¨(A ‚ñ∑ ¬¨C)‚àß (D‚ñ∑‚ô¢E))‚ñ∑(B‚àß‚ñ°C‚àß(D‚ñ∑E)).\]

   It is the second principle of the \prin{R_n} series. The series of principles
   \prin{R_n} is defined in cite:two-new-series and it has been named /the slim
   series/.
*** Ordinary semantics

    The $\kord{R_1}$ frame condition reads as follows:
    \[‚àÄw,x,y,z(wRxRyS_wz‚áí‚àÄu(zRu‚áíyS_xu,‚àÄv(uS_xv‚áí‚àÄm(vRm‚áíuS_zm))))\]

    {{{begintheorem}}}
    For any ordinary frame $F$, we have that $F$ satisfies the
    $\kord{R_1}$ condition iff any model based on $F$ forces every instantiation of
    the \prin{R‚ÇÅ} principle. In symbols:

    \[F ‚ä® \kord{R_1} ‚áî F ‚ä© \prin{R‚ÇÅ}.\]
    {{{endtheorem}}}

    {{{beginproof}}}
    The details of the proof can be found in cite:two-new-series.
    # - \boxed{‚áê} Let $a,b,c,d,e‚àà\var{}$ and assume $F‚ä© a ‚ñ∑ b ‚Üí ((¬¨ (a ‚ñ∑ ¬¨c) ‚àß(d‚ñ∑‚ô¢e))
    #   ‚ñ∑ (b ‚àß ‚ñ° c ‚àß (d‚ñ∑e)))$. Consider some worlds $w,x,y,z,u,v,m$ and assume for
    #   a contradiction that $wRxRyS_wzRu,yS_xu‚áí(uS_xv,vRm,u\cancel{S}_zm)$. Now
    #   consider a model based on $F$ that satisfies the following:
    #   \begin{flalign*}
    #   ‚ü¶a‚üß &= \{y\} \\
    #   ‚ü¶b‚üß &= \{z\} \\
    #   ‚ü¶c‚üß &= \{w:yS_xw\} \\
    #   ‚ü¶d‚üß &= \{?\} \\
    #   ‚ü¶e‚üß &= \{?\} \\
    #   \end{flalign*}
    #   First observe that $w‚ä©a‚ñ∑b$ since $a$ is only forced in $y$ and we have
    #   $yS_wz‚ä©b$. Therefore $w‚ä©¬¨ (a ‚ñ∑ ¬¨c) ‚àß(d‚ñ∑‚ô¢e) ‚ñ∑ (b ‚àß ‚ñ° c ‚àß (d‚ñ∑e))$. Now we
    #   show that $x‚ä©¬¨ (a ‚ñ∑ ¬¨c)$. Since $a$ is only forced in $y$ and $xRy$, we
    #   need to show that $‚àÄu(yS_xu‚áíu‚ä©c)$, which clearly holds. We proceed by
    #   showing $x‚ä©d‚ñ∑‚ô¢e$ (????).
    # - \boxed{‚áí} Let $M$ be a model based on $F$ assume there is a world $w$ such
    #   that $w‚ä©A‚ñ∑B$ and a world $x$ such that $wRx$ and $x‚ä©¬¨(A‚ñ∑¬¨C)‚àß(D‚ñ∑‚ô¢E)$. Then
    #   there exists world $y$ such that $xRy‚ä©A$ and $(‚ãÜ)\ ‚àÄv(yS_xv‚áív‚ä©C)$. As
    #   $wRy‚ä©A$ and $w‚ä©A‚ñ∑B$ there exists a world $z$ such that $yS_wz‚ä©B$. It
    #   remains to show that $z‚ä©‚ñ°C‚àß(D‚ñ∑E)$. We first see that $z‚ä©‚ñ°C$. Consider
    #   $v$ such that $zRv$, by $\kord{R_1}$ it follows that $yS_xv$ and by $(‚ãÜ)$
    #   we get $v‚ä©C$. Now we show $z‚ä©D‚ñ∑E$. Let $u$ be such that $zRu‚ä©D$, we need
    #   to find some $m$ such that $uS_zm‚ä©E$. By $\kord{R_1}$ we get $yS_xu$ and
    #   $(‚Ä†)\ ‚àÄv,m((uS_xv,vRm)‚áíuS_zm)$. See that $yS_xu$ implies $xRu$ and since
    #   $x‚ä©D‚ñ∑‚ô¢E$ and $u‚ä©D$ we get that there is some $n$ such that $uS_xn‚ä©‚ô¢E$.
    #   Hence there is a world $m$ such that $nRm‚ä©E$. Finally by $(‚Ä†)$ and $uS_xn$
    #   and $nRm$ we get $uS_zm$ and thus we have the desired $m$ and we conclude
    #   $z‚ä©D‚ñ∑E$.
    {{{endproof}}}

*** Generalized semantics
    The results presented in this section are a joint work with Luka Mikec.

    We start by giving some definitions:
    1. $R^{-1}[E] ‚âî \{x : ‚àÉy‚ààE. xRy\}$. $E$ denotes a set.
    2. $R‚Çì^{-1}[E]‚âîR^{-1}[E]‚à©R[x]$. $E$ denotes a set.

    The $\kgen{R_1}$ condition reads as follows:
    \begin{flalign*}
    ‚àÄw,&x,u,ùîπ,‚ÑÇ,ùîº.\\
    &wRxRuS_wùîπ, ‚ÑÇ‚ààùíû(x,u) \\
    ‚áí\ & ‚àÉùîπ'‚äÜùîπ.xS_wùîπ',R[ùîπ']‚äÜ‚ÑÇ,‚àÄv‚ààùîπ'.‚àÄc‚àà‚ÑÇ.(‚àÉU‚äÜR‚Çì^{-1}[ùîº],vRcS‚ÇìU)‚áí‚àÉùîº'‚äÜùîº.cS_vùîº'\Big)
    \end{flalign*}

    {{{begintheorem}}} {{{agda}}}
    <<theorem:R_1>>
    For any generalized frame $F$, we have that $F$ satisfies the
    $\kgen{R_1}$ condition iff any model based on $F$ forces every instantiation of
    the \prin{R‚ÇÅ} principle. In symbols:

    \[F‚ä®\kgen{R‚ÇÅ}‚áîF‚ä©\prin{R‚ÇÅ}.\]
    {{{endtheorem}}}

    {{{beginproof}}}
    - \boxed{‚áí} Let's fix the model and let $w ‚àà W$ be arbitrary. Suppose $w‚ä© A
      ‚ñ∑B$, and let $x$ be such that $wRx$ and $x‚ä© ¬¨(A ‚ñ∑ ¬¨C) ‚àß (D ‚ñ∑ ‚ô¢E)$. It
      follows from $x ‚ä©¬¨(A ‚ñ∑¬¨C)$ that there exists $u$ such that $xRu$, such
      that $u‚ä©A$, and for every $Z$ such that $uS_x Z$ there is some $c_Z ‚àà Z$
      such that $c_Z ‚ä©C$. From $wRu$, $w‚ä© A‚ñ∑ B$ and $u‚ä© A$ follows in particular
      that there is a $ùîπ$, $uS_w ùîπ ‚ä©B$. Let $‚ÑÇ ‚âî \{c_Z: uS_x Z\}$. It is easy to
      check that $‚ÑÇ ‚àà ùíû(x, u)$. Let $ùîº ‚âî ‚ü¶E‚üß$. For the selected $w, x, u, ùîπ, ‚ÑÇ,
      ùîº$ the property $\kgen{R_1}$ implies that there exists $ùîπ' ‚äÜ ùîπ$ such that:

      \[ xS_wùîπ',R[ùîπ']‚äÜ‚ÑÇ,‚àÄv‚ààùîπ'.‚àÄc‚àà‚ÑÇ.(‚àÉU‚äÜR‚Çì^{-1}[ùîº],vRcS‚ÇìU)‚áí‚àÉùîº'‚äÜùîº.cS_vùîº'\]
      # \[xS_wùîπ',R[ùîπ']‚äÜ‚ÑÇ ,(‚àÄv‚ààùîπ')(‚àÄc‚àà‚ÑÇ)(vRcS_xR_x^{-1}[ùîº]‚áí(‚àÉùîº'‚äÜùîº)cS_vùîº').\]

      We have that $ùîπ' ‚ä©B$ since $ùîπ'‚äÜùîπ$ and $ùîπ'‚ä©‚ñ° C$ since $R[ùîπ']‚äÜ‚ÑÇ$. We now
      show that $ùîπ'‚ä© D‚ñ∑ E$. Let $v‚ààB'$ and assume that for some $c$ such that
      $vRc$ we have $c‚ä© D$. From earlier we have $x‚ä© D ‚ñ∑ ‚ô¢E$. Since $c ‚àà R [ùîπ']
      ‚äÜ C ‚äÜ R [x]$, then $xRc$ so it follows that there exists $U$ such that
      $cS_x U$ and $U‚ä©‚ô¢E$. Clearly $U‚äÜR_x^{-1}[ùîº]$ so by the above property
      there exists $ùîº'‚äÜùîº$ such that $cS_v ùîº'$. Because $ùîº'‚äÜùîº$ we have $ùîº'‚ä©E$.
    - \boxed{‚áê} Assume for a contradiction that $F‚ä≠\kgen{R_1}$. It follows that
      there exist $w,x,u,ùîπ,‚ÑÇ,ùîº$ such that $wRxRuS_wùîπ$, $‚ÑÇ‚ààùíû(x,u)$ and:
      \[‚àÄùîπ'‚äÜùîπ.xS_wùîπ', R[ùîπ']‚äÜ‚ÑÇ‚áí ‚àÉv‚ààùîπ'.‚àÉc‚àà‚ÑÇ.‚àÉZ‚äÜR_x^{-1}[ùîº].vRcS_xZ,‚àÄùîº'‚äÜùîº.
      c\cancel{S}_v ùîº'.\]

      Let $ùí±$ be a family of sets defined thus:
      \[ùí±‚âî \{U : U‚äÜùîπ, xS_wU,R[U]‚äÜ‚ÑÇ\}.\]

      From the condition it follows that for every $U‚ààùí±$ the following is valid:
      \[‚àÉv_U‚ààU.‚àÉc_U‚àà‚ÑÇ.
      (‚àÉZ_U‚äÜR_x^{-1}[ùîº](v_URc_US_xZ_U,‚àÄùîº'‚äÜùîº.
      c_U\cancel{S}_{v_U} ùîº')).\]

      Let us fix such $v_U$ and $c_U$ and $Z_U$ for all $U‚ààùí±$.

      Define a valuation such that the following applies:
      \begin{flalign*}
      ‚ü¶a‚üß &= \{u\}; \\
      ‚ü¶b‚üß &= ùîπ; \\
      ‚ü¶c‚üß &= ‚ÑÇ; \\
      ‚ü¶d‚üß &= \{c_U:U‚ààùí±\}; \\
      ‚ü¶e‚üß &= ùîº.
      \end{flalign*}

      By assumption we have $w ‚ä© a ‚ñ∑ b ‚Üí (¬¨(a‚ñ∑¬¨c)‚àß(d‚ñ∑‚ô¢e))‚ñ∑(b‚àß‚ñ°c‚àß(d‚ñ∑e))$.

      It is easy to see that $w ‚ä© a ‚ñ∑ b$ and $x ‚ä© ¬¨(a ‚ñ∑ ¬¨c)$.

      Let us prove $x ‚ä© d‚ñ∑‚ô¢e$. Let $xRc‚ä© D$. Then $c = c_U$ for some $U ‚àà ùí±$.
      From the definition of $c_U$ we have that $c_U S_x Z_U$. The valuation is
      defined such that $e$ is true exactly on the set $ùîº$. Hence
      $R_x^{-1}[ùîº]‚ä©‚ô¢e$ and since $Z_U‚äÜR_x^{-1}[ùîº]$ it follows that $x ‚ä© d‚ñ∑‚ô¢e$.

      We can also check that for every $U ‚àà ùí±$ we have $U‚ä© b ‚àß ‚ñ°c$. Furthermore,
      for any set $U$ we have
      \begin{flalign*}
        (‚ãÜ)\ xS_wU ‚ä© b ‚àß ‚ñ°c‚áíU‚àà ùí±.
      \end{flalign*}
      Since $w‚ä©a‚ñ∑b$ and $wRx‚ä©¬¨(a‚ñ∑¬¨c)‚àß(d‚ñ∑‚ô¢e)$ there must exist some set $U$
      such that $xS_wU‚ä©b‚àß‚ñ°c‚àß(d‚ñ∑e)$. From $(‚ãÜ)$ follows that $U‚ààùí±$ hence
      there exist $v_U,c_U,Z_U$ such that $Z_U‚äÜR_x^{-1}[ùîº]$ and
      $v_URc_US_xZ_U,(‚àÄùîº'‚äÜùîº) c_U\cancel{S}_{v_U} ùîº'$. Since $c_U‚ä©d$ there must
      exist some $Y$ such that $c_US_{v_U}Y‚ä©e$, however, by the definition of
      the valuation it follows that $Y‚äÜùîº$ and thus $c_U\cancel{S}_{v_U} Y$,
      which is a contradiction.

   The Agda proof can be found in
   cref:src:generalizedveltmansemantics.properties.rsub1.
    {{{endproof}}}

** The principle \prin{R¬π}
   <<sec:prin-rsup1>>

   The \prin{R¬π} principle reads as follows:
   \[A ‚ñ∑ B ‚Üí (‚ô¢¬¨(D ‚ñ∑ ¬¨C)‚àß (D‚ñ∑A))‚ñ∑(B‚àß‚ñ°C).\]

   \prin{R¬π} is the second principle of the series \prin{R^n}. The series of
   principles \prin{R_n} is defined in cite:two-new-series and it has been named
   /the broad series/. In cref:sec:Rsupn we comment on the series \prin{R^n} and
   present the frame condition with respect to generalized semantics.

*** Generalized semantics
    The $\kgen{R¬π}$ condition reads as follows:
    \begin{flalign*}
    ‚àÄw&,x,y,z,ùî∏,ùîπ,‚ÑÇ,ùîª. \\
    &wRxRyRz, \\
    & (‚àÄu.wRu,u‚ààùî∏‚áí‚àÉV.uS_wV,V‚äÜùîπ), \\
    & (‚àÄu.xRu,u‚ààùîª‚áí‚àÉV.uS_xV,V‚äÜùî∏), \\
    & (‚àÄV.zS_yV‚áí‚àÉv‚ààV.v‚àà‚ÑÇ),      \\
    & z‚ààùîª \\
    ‚áí\ & ‚àÉV‚äÜùîπ(xS_wV,R[V]‚äÜ‚ÑÇ).
    \end{flalign*}

    {{{begintheorem}}} {{{agda}}}
    For any generalized frame $F$, we have that $F$ satisfies the
    $\kgen{R¬π}$ condition iff any model based on $F$ forces every instantiation of
    the \prin{R¬π} principle. In symbols:

    \[F‚ä®\kgen{R¬π}‚áîF‚ä©\prin{R¬π}.\]
    {{{endtheorem}}}


    {{{beginproof}}}
    - \boxed{‚áí} Fix a model $M$ and a world $w$, we are to prove that $w‚ä©A ‚ñ∑ B ‚Üí
      (‚ô¢¬¨(D ‚ñ∑ ¬¨C)‚àß (D‚ñ∑A))‚ñ∑(B‚àß‚ñ°C)$. For that assume that $w‚ä©A‚ñ∑B$ and that for
      some $x,y,z$ we have $wRxRyRz$ and satisfy the conditions on the left hand
      side of the implication in the $\kgen{R^1}$ condition. From that we derive that
      $x‚ä©D‚ñ∑A$, $y‚ä©¬¨(D‚ñ∑¬¨C)$ and $z‚ä©D$. Now let $ùî∏‚âî\{w:w‚ä©A\}$. We define $ùîπ,‚ÑÇ,ùîª$
      likewise for formulas $B,C,D$ respectively. It is routine to check that
      the left part of the implication of $\kgen{R¬π}$ is met. Hence there exist
      a set $V‚äÜùîπ$ such that $xS_wV$ and $R[V]‚äÜ‚ÑÇ$. By the definition of the sets
      $ùîπ$ and $‚ÑÇ$ it follows that $V‚ä©B‚àß‚ñ°C$.
    - \boxed{‚áê} Fix a frame $F$ and let $a,b,c,d$ be propositional variables and
      assume $F‚ä©a ‚ñ∑ b ‚Üí (‚ô¢¬¨(d ‚ñ∑ ¬¨c)‚àß (d‚ñ∑a))‚ñ∑(b‚àß‚ñ°c)$. Assume that the left part
      of the implication of $\kgen{R¬π}$ holds. Now consider a model extending
      $F$ such that:
      \begin{flalign*}
       ‚ü¶a‚üß &= ùî∏, \\
       ‚ü¶b‚üß &= ùîπ, \\
       ‚ü¶c‚üß &= ‚ÑÇ, \\
       ‚ü¶d‚üß &= ùîª.
      \end{flalign*}
      Now one can easily check that $w‚ä©A‚ñ∑B$, $x‚ä©‚ô¢¬¨(D‚ñ∑¬¨C)‚àß(D‚ñ∑A)$, hence there exists $U$
      such that $xS_wU$ and $U‚ä©B‚àß‚ñ°C$. From that we derive that $U‚äÜùîπ$ and $R[U]‚äÜ‚ÑÇ$.

   The Agda proof can be found in
   cref:src:generalizedveltmansemantics.properties.rsup1.
    {{{endproof}}}

** The series of principles \prin{R‚Åø}
   <<sec:Rsupn>>

   The series of principles \prin{R^n} principle is defined thus:
   \begin{flalign*}
   U_0 &‚âî ‚ô¢¬¨(D_0‚ñ∑¬¨C) \\
   U_{r+1} &‚âî ‚ô¢((D·µ£‚ñ∑D_{r+1}) ‚àß U·µ£) \\
   \\
   R‚Å∞& ‚âî A ‚ñ∑ B ‚Üí ¬¨ (A ‚ñ∑ ¬¨ C) ‚ñ∑ B ‚àß ‚ñ° C \\
   R^{n+1}& ‚âî A ‚ñ∑ B ‚Üí ((D_{n}‚ñ∑A) ‚àß U_{n}) ‚ñ∑ B ‚àß ‚ñ° C
   \end{flalign*}

   The principle \prin{R^0} is equivalent to \prin{R}, which we already
   discussed in cref:sec:prin-r and we already discussed the principle
   \prin{R^1} in cref:sec:prin-rsup1. In this chapter we deal with these and
   other principles from the series at once.

   The \prin{R^n} series is also referred to as /the broad series/.
*** Ordinary semantics
    The frame condition for ordinary semantics $\kord{R^n}$ can be found in
    cite:two-new-series.

*** Generalized semantics

    The $\kgen{R‚Åø}$ condition reads as follows:
    \begin{flalign*}
    ‚àÄw,&x‚ÇÄ,‚Ä¶,x_{n-1},y,z,ùî∏,ùîπ,‚ÑÇ,ùîª‚ÇÄ,‚Ä¶,ùîª_{n-1}.\\
    &wRx_{n-1}R‚Ä¶Rx_0RyRz, \\
    & (‚àÄu.wRu,u‚ààùî∏‚áí‚àÉV.uS_wV‚äÜùîπ), \\
    & (‚àÄu.x_{n-1}Ru‚ààùîª_{n-1}‚áí‚àÉV.uS_{x_{n-1}}V‚äÜùî∏), \\
    & (‚àÄi‚àà\{1,‚Ä¶,n-2\}‚àÄu.x·µ¢Ru‚ààùîª_i‚áí‚àÉV.uS_{x_i}V‚äÜùîª_{i+1}), \\
    & (‚àÄV.zS_yV‚áíV‚à©‚ÑÇ‚â†0),      \\
    & z‚ààùîª‚ÇÄ \\
    ‚áí\ & ‚àÉV‚äÜùîπ.x_{n-1}S_wV,R[V]‚äÜ‚ÑÇ.
    \end{flalign*}
    {{{beginlemma}}} {{{agda}}}
    <<lemma:R^n>>
    Let $M$ be a model, let $x$ be a world of $M$ and let $n‚àà‚Ñï$. For any $i‚â§n$ we have
    that if $M , x ‚ä© U_i$ then there exist some worlds $y,z,x‚ÇÄ,‚Ä¶,x_{i}$ such that:
    1. $x·µ¢=x$;
    2. $x_iR‚Ä¶Rx‚ÇÄRyRz$;
    3. for all $j‚â§i$ we have that $M,x_j‚ä©U_j$;
    4. for all $j<i$ we have that $M,x_j‚ä©D_j‚ñ∑D_{j+1}$;
    5. for all $V$ we have that if $zS_yV$ then $V‚à©\{w:M,w‚ä©C\}‚â†‚àÖ$;
    6. $M,z‚ä©D‚ÇÄ$.

    {{{beginproof}}}
    By induction on $i$.
    - For $i=0$ we have that $x‚ä©‚ô¢¬¨(D‚ÇÄ‚ñ∑¬¨C)$. It follows that there exists some
      $y$ such that $xRy‚ä©¬¨(D‚ÇÄ‚ñ∑¬¨C)$ and therefore there exists some $z$ such that
      $yRz‚ä©D‚ÇÄ$ and for any $V$, if $zS_yV$, then $V‚à©\{w:M,w‚ä©C\}‚â†‚àÖ$. It is clear
      that all claims are met.
    - For $i+1$ we have that $x‚ä©‚ô¢((D_i‚ñ∑D_{i+1})‚àßU_i)$. It follows that there
      exists some $x_{i}$ such that $x_i‚ä©D_i‚ñ∑D_{i+1}‚àßU_i$. By IH there exist
      $y,z,x‚ÇÄ,‚Ä¶,x_{i}$ such that they satisfy claims $1,‚Ä¶,6$. We set
      $x_{i+1}‚âîx$. It is trivial to observe that by using the IH all conditions
      are met for $i+1$.
    {{{endproof}}}
    {{{endlemma}}}

    {{{begintheorem}}} {{{agda}}}
    <<theorem:R^n>>
    For any generalized frame $F$, we have that $F$ satisfies
    the $\kgen{R‚Åø}$ condition iff any model based on $F$ forces every
    instantiation of the \prin{R‚Åø} principle. In symbols:

    \[F‚ä®\kgen{R‚Åø}‚áîF‚ä©\prin{R‚Åø}.\]
    {{{endtheorem}}}

    {{{beginproof}}}
    If $n=0$ we refer to cref:theorem:R^0. For $n+1$ proceed as follows.
    - \boxed{‚áí} Fix a model and assume that for some world $w$ we have $w‚ä©A‚ñ∑B$.
      Then assume also that $wRx‚ä©((D‚Çô‚ñ∑A)‚àßU_n)$. Our goal is to find a set $V$
      such that $xS_wV‚ä©B‚àß‚ñ°C$. By cref:lemma:R^n it follows that there exist
      $y,z,x‚ÇÄ,‚Ä¶,x_{n}$ satisfying $1,‚Ä¶,6$. Then let $ùî∏‚âî‚ü¶A‚üß$, $ùîπ‚âî‚ü¶B‚üß$, $‚ÑÇ‚âî‚ü¶C‚üß$
      and for $i‚â§n$ let $ùîª·µ¢‚âî‚ü¶D·µ¢‚üß$.

      It is routine to check that the left part of the $\kgen{R^{n+1}}$ holds
      and thus we get that there exists some $V‚äÜùîπ$ such that $x_nS_wV$ and
      $R[V]‚äÜ‚ÑÇ$. Since $V‚äÜùîπ$ we have that $V‚ä©B$ and since $R[V]‚äÜ‚ÑÇ$ we have
      $V‚ä©‚ñ°C$. Finally, since $x_{n}=x$ we conclude $xS_wV‚ä©B‚àß‚ñ°C$.
    - \boxed{‚áê} Fix a frame $F$ and let $a,b,c,d‚ÇÄ,‚Ä¶,d‚Çô$ be propositional
      variables and assume $F‚ä©R^{n+1}$. Assume that the left part of the
      implication of $\kgen{R^{n+1}}$ holds. Now consider a model based on $F$
      that satisfies the following:
      \begin{flalign*}
       ‚ü¶a‚üß &= ùî∏; \\
       ‚ü¶b‚üß &= ùîπ; \\
       ‚ü¶c‚üß &= ‚ÑÇ; \\
       ‚ü¶d·µ¢‚üß &= ùîª·µ¢, \text{ for all } i‚àà\{0‚Ä¶n\}.
      \end{flalign*}
      Now one can routinely check that $w‚ä©A‚ñ∑B$ and $x‚ä©((D_n‚ñ∑A)‚àßU_n)$, hence there
      exists $U$ such that $xS_wU$ and $U‚ä©B‚àß‚ñ°C$. From that we derive that $U‚äÜùîπ$
      and $R[U]‚äÜ‚ÑÇ$.

    The Agda proof can be found in
    cref:src:generalizedveltmansemantics.properties.rsupn.
    {{{endproof}}}

** Generic frame condition
   <<sec:generic-cond>> In this chapter we present a method that given a formula
   $A$, builds a second order formula that is a generalized frame condition for
   $A$.

   {{{begindef}}} *Generic frame condition* {{{agda}}} Given a generalized frame
   $F=‚ü®W,R,S‚ü©$ and a formula $A$ with $\sf{Var}(A)=\{x‚ÇÅ,‚Ä¶,x‚Çô\}$. Consider $n$
   second order variables $ùïè‚ÇÅ,‚Ä¶,ùïè‚Çô$ which range over sets of worlds. We write
   $ùïè_*$ instead of $ùïè‚ÇÅ,‚Ä¶,ùïè‚Çô$. Let $‚Ñ±$ be defined by:
 \begin{flalign*}
   ‚Ñ±&:\underbrace{ùí´(W)√ó‚ãØ√óùí´(W)}_n√ó\fm{}‚Üíùí´(W) \\
   ‚Ñ±(ùïè_*,x·µ¢) &‚âî  ùïè·µ¢;\\
   ‚Ñ±(ùïè_*,‚ä•) &‚âî ‚àÖ; \\
   ‚Ñ±(ùïè_*,A‚ÜíB) &‚âî \{w:w ‚àà ‚Ñ±(ùïè_*,A) ‚áí w ‚àà ‚Ñ±(ùïè_*,B)\}; \\
   ‚Ñ±(ùïè_*,A‚ñ∑B) &‚âî \{w:‚àÄ u.(wRu,u‚àà‚Ñ±(ùïè_*,A))‚áí‚àÉY.uS_wY‚äÜ‚Ñ±(ùïè_*,B))\}.
 \end{flalign*}

   Finally we define the condition $\kgen{A^*}$ thus:
   # \[(A)^*_{gen}‚âî‚àÄùïè_*‚àÄw‚ààW.w‚àà‚Ñ±(ùïè_*,A). \]
   \[\kgen{A^*}‚âî‚àÄùïè_*‚àÄw.w‚àà‚Ñ±(ùïè_*,A). \]
   {{{enddef}}}

   The following theorem shows that the previous definition gives a valid frame
   condition. {{{begintheorem}}} {{{agda}}} Let $A$ be a formula. For any
   generalized frame $F$, we have that $F$ satisfies the $\kgen{A^*}$ condition
   iff any model based on $F$ forces $A$. In symbols:

     \[F‚ä®\kgen{A^*}‚áîF‚ä©A.\]
   {{{endtheorem}}}

   {{{beginproof}}}
   The proof goes by an easy induction on the formula.

   The Agda proof can be found in
   cref:src:generalizedveltmansemantics.properties.genericframecond.
   {{{endproof}}}

   {{{beginremark}}} For instance, if we want the frame condition for \prin{P‚ÇÄ}
   we would look at \[\kgen{(a ‚ñ∑ ‚ô¢ b ‚Üí ‚ñ° (a ‚ñ∑ b))^*}.\] Where $a,b$ are
   different propositional variables. {{{endremark}}}

   It is easy to see that the presented method can be adapted to generate a
   frame condition for ordinary semantics.

   We suggest a future systematic study that lays down the relations between
   generic frame conditions and the ones used in practice.
* The logic of Agda
  <<sec:logic-agda>>

  The purpose of this part is to give a gradual introduction to Agda.

  In cref:sec:intro-types we will give a short introduction to untyped lambda
  calculus. Then we will proceed with simply typed lambda calculus. The
  important takeaway of this chapter is to observe how we can use types to rule
  out bogus terms.

  In cref:sec:martin-lof we will explain Martin L√∂f's logical framework. This
  system features dependent types and thus is a suitable system to formalize
  propositions and proofs. This system is especially important because it is the
  basis of Agda's type theory. We will see how we can embed intuitionistic
  propositional logic into the system and how we can prove some simple
  properties about natural numbers.

  In cref:sec:basic-agda we give an approximated specification of the Agda
  language. We must emphasize that it is an /approximation/ because there is no
  formal specification of Agda. The one we present has been built from the
  official documentation (cite:agda-doc), Ulf Norell's[fn::Original author of
  Agda.] PhD thesis (cite:norell:thesis) and personal experience.
  Furthermore, by no means we attempt to describe all the language. Rather, we
  focus on the parts which are more important to understand our implementation,
  which we will present in cref:sec:agda-thesis.

  In cref:sec:agda-tutorial we present an introductory tutorial to Agda. The
  spirit of this tutorial is to prioritize intuition over formalization and
  precision. The informal format is the one in which Agda is presented to the
  public in its official documentation (cite:agda-doc) and some of the most
  popular learning resources
  (cite:plfa2019,norell2008dependently,bove2009brief).

** Introduction to types
   <<sec:intro-types>> Type theory is a branch of mathematical symbolic logic.
   It formalizes mathematical concepts through terms, types and a typing
   relation between them. One could think of types as predicates on terms. We
   write $T:A$ to say that term $T$ satisfies predicate $A$, or synonymously,
   that term $T$ has type $A$. Later in this chapter we will see that types in
   /simply typed lambda calculus/ provide a basic classification of lambda
   terms. For instance, a term representing a natural number will have a
   different type from a lambda term representing a Boolean value. In more
   expressive type theories which feature dependent types, such as
   /intuitionistic type theory/, we can express complex mathematical properties
   such as ``$2*n$ is always even'' or that ``any finite sequence of numbers can
   be sorted in lexicographical order''.

   Type theory has become especially relevant in the following areas.
   - *Programming languages and proof assistants*. Simple (non-dependent) types
     are present in almost every modern programming language. Programming
     languages use types to classify its objects and functions with the goal of
     minimizing the amount of errors caused by misusing them. For instance, the
     term $1 + true$ does not make sense and types are used to rule out the
     validity of such term.

     Furthermore, the expressiveness of type theories with dependent types make
     them an adequate basis for modern proof assistants. Due to the constructive
     nature of the theory the proof assistants can be used as programming
     languages too. Agda and Coq are examples of that.
   - *Foundations of mathematics*. (This paragraph is a paraphrase from
     cite:sep-type-theory-intuitionistic) A sufficiently expressive type theory
     such as Martin-L√∂f type theory is a formal logical system and philosophical
     foundation for constructive mathematics. It is a full-scale system which is
     based on the /propositions-as-types/ principle and aims to play a similar
     role for constructive mathematics as Zermelo-Fraenkel set theory does for
     classical mathematics.

     (This paragraph is a quote from cite:hottbook) /Univalent Foundations
     of Mathematics/ is Vladimir Voevodsky‚Äôs new program for a comprehensive,
     computational foundation for mathematics based on the homotopical
     interpretation of type theory. The type theoretic univalence axiom relates
     propositional equality on the universe with homotopy equivalence of small
     types. The program is currently being implemented with the help of the
     automated proof assistant Coq. The Univalent Foundations program is closely
     tied to homotopy type theory.
*** The origins of types
      (cite:sep-type-theory) Types were first introduced by Russel in 1903 in
     ``Apendix B: The Doctrine of Types, from Principia Mathematica'' while
     trying to avoid a contradiction in set theory, namely Russel's paradox. In
     Principia Mathematica types are defined as follows.
      1. $i$ is the type of individuals (elements of some fixed domain);
      2. if $A_1,‚Ä¶,A_n$ (for $n‚â•0$) are types then $(A_1,‚Ä¶,A_n)$ is the type of
         n-ary relations over objects of respective types $A_1,‚Ä¶,A_n$. Note that
         for $n=0$ we have that $()$ is the type of propositions.
      For instance, the type of binary relations over individuals is $(i,i)$,
      the type of binary propositional connectives is $((),())$. Observe that
      this formulation prevents a proposition of the form $R(R)$. Assume for a
      contradiction that $R(R)$ is a proposition, then we have that (by looking
      at the outer occurrence) $R$ has type $(A)$ for some type $A$ and thus
      (by looking at the inner occurrence) $R$ has type $A$ but $A‚â†(A)$. This
      observation is the key for avoiding Russel's paradox using types.

      The more habitual definition of types is the one that stems from Church's
      formalization of lambda calculus which includes functions as primitive
      objects.
      1. $i$ is the type of individuals;
      2. $o$ is the type of propositions;
      3. if $A$ and $B$ are types then $A‚ÜíB$ is the type of functions from $A$ to $B$.
      We may observe that $i‚Üío$ is the type of predicates on individuals, $i‚Üíi$ is
      the type of functions on individuals and $\underbrace{i‚Üí(i‚Üí‚Ä¶‚Üí(i}_{n}‚Üío))$ is
      an \text{$n$-ary} relation. Although this definition of types is relevant
      for historical reasons, it has become obsolete and we proceed by giving a
      short introduction to three (out of many) versions of lambda calculus
      available today.

*** Untyped lambda calculus
     For the language of terms we present a refinement of Church's version due to
     Curry:
     1. /variable/: every variable is a term;
     2. /function application/: If $A$ and $B$ are terms then $A\ B$ is a term.
        Note that application associates to the left, thus $A\ B\ C=(A\ B)\ C$.
     3. /lambda abstraction/: If $x$ is a variable and $A$ is a term then $Œªx.A$
        is a term. The body of a lambda abstraction (the expression after the
        .) extends to the rightmost part. Thus $Œªx.Œªy.x\ y=Œªx.(Œªy.x\ y)$.
     This can be more succinctly expressed in the so-called Backus-Naur form
     (BNF for short): \[T‚âîx\ |\ T\ T\ |\ Œªx.T\] In lambda calculus we have the
     following equation known as \text{$Œ≤$-reduction}. \[(Œªx.T)\ A=T[x‚Ü¶A]\]
     This equation is often given as a reduction rule from left to right,
     giving computational value to lambda terms. In other words,
     \text{$Œ≤$-reduction} gives an algorithm based on a rewrite rule that
     /reduces/, /evaluates/ or /computes/ a lambda term until it can no longer
     be reduced. When a term cannot be reduced we say that it is in /normal
     form/. Note that not every term can be reduced to a normal form term as
     showcased by the following term, which reduces to itself: \[(Œªx.x\ x)\
     (Œªx.x\ x) \] Notice how this term is of the form $R(R)$ (or $R\ R$, in the
     new syntax), which we were able to rule out before by using types. In
     fact, in the next section we will see how this term cannot be assigned a
     type.

     Turing showed that untyped lambda calculus is equivalent in terms of
     computability to Turing machines (cite:turing1937computability), therefore
     any computable function has a lambda term that computes it.

     It might be difficult to imagine how we could express every computable
     function in a lambda term. We believe that showing some practical examples
     will be enlightening, thus we will briefly introduce the /Church
     encoding/ for Booleans and natural numbers.
     - *Booleans*. We define /true/ and /false/ thus: \[true:=Œªa.Œªb.a;\ \ \
       false‚âîŒªa.Œªb.b\] As we can see, both /true/ and /false/ are defined as a
       function that takes two arguments. The former returns the first argument
       while the latter returns the second. Thus, this encoding of Booleans
       conveniently allows us to define an /if then else/ expression.
       \[ite‚âîŒªb.Œªx.Œªy.b\ x\ y\] It is immediate to see by means of
       \text{$Œ≤$-reduction} that \[ite\ b\ x\ y=b\ x\ y\] hence, we will
       usually prefer to write $b\ x\ y$ instead of $ite\ b\ x\ y$. We can use
       the /if then else/ concept to encode the /and/ and /or/ operators. It
       may help to read the /and/ as ``if the first argument is true return the
       second argument else return false''. Likewise for the /or/.
       \[and:=Œªa.Œªb.a\ b\ false;\ \ \ or‚âîŒªa.Œªb. a\ true\ b\]
     - *Natural numbers*. The natural number $n$ is encoded as a lambda term
       that applies $n$ times some parameter function $f$.
       \[0:=Œªf.Œªa.a;\ \ \ 1‚âîŒªf.Œªa.f\ a;\ \ \ 2‚âîŒªf.Œªa.f\ (f\ a); \ \ \ ‚Ä¶\]
       Then we can define the successor function:
       \[suc‚âîŒªn.Œªf.Œªa.f\ (n\ f\ a)\]
       Let us show that the successor of 1 is indeed 2.
       \begin{flalign*}
       suc\ 1 &= (Œªn.Œªf.Œªa.f\ (n\ f\ a))\ (Œªf.Œªa.f\ a) & \text{Def}\\
        &= Œªf.Œªa.f\ ((Œªf.Œªa.f\ a)\ f\ a)  & \text{$Œ≤$-reduction for $n$}\\
        &= Œªf.Œªa.f\ (Œªa.f\ a)\ a  & \text{$Œ≤$-reduction for $f$}\\
        &= Œªf.Œªa.f\ (f\ a)  & \text{$Œ≤$-reduction for $a$}\\
        &= 2 & \text{Def}
       \end{flalign*}
       It is also easy to define addition and multiplication. It may help to
       read /add n m/ as ``apply $m$ times $f$, then apply $n$ times $f$'' and
       /mul n m/ as ``apply $n$ times (apply $m$ times)''. \[add‚âîŒªn.Œªm.Œªf.Œªa.n\ f\ (m\ f\
       a);\ \ \ mul‚âîŒªn.Œªm.Œªf.Œªa.n\ (m\ f)\ a \]

*** Simply typed lambda calculus
     Let us introduce the idea of types in lambda calculus due to Curry. We
     view types as predicates on lambda terms. We write $T:A$ to say that the
     term $T$ has type $A$.

     We fix a set of base types $ùêÅ$ and a set of term constants
     \[Œì=\{‚ü®c‚ÇÄ^0:B‚ÇÄ‚ü©,‚ü®c‚ÇÄ^1:B‚ÇÄ‚ü©,‚Ä¶,‚ü®c‚ÇÅ^0:B‚ÇÅ‚ü©,‚ü®c‚ÇÅ^1:B‚ÇÅ‚ü©,‚Ä¶\},\] where each $B_i‚ààùêÅ$.

     The syntax of terms is defined thus. \[T‚âîx\ |\ T\ T\ |\ Œª(x:S).T\ |\ c\]
     Where $S$ is a type, $c$ a term constant and $x$ a variable.

     The syntax of types is defined thus. \[S‚âîB\ |\ S‚ÜíS\] With $B‚ààùêÅ$. The $‚Üí$
     symbol has right associativity, so $A‚ÜíB‚ÜíC=A‚Üí(B‚ÜíC)$.

     Then we define typing rules to assign a type to suitable terms. We define
     a context to be a set of tuples $‚ü®x:A‚ü©$ where $x$ is either a variable or
     a constant and $A$ is a type. If $Œì$ is a context write $Œì‚ä¢t:A$ to mean
     that $y$ has type $A$ in context $Œì$. When a term can be assigned a type
     in a context we say that it is well-typed in that context. Only well-typed
     terms are considered valid in simply typed lambda calculus.
     #+caption: Typing rules for simply typed lambda calculus.
     #+name: fig:simply_typed
     #+attr_latex: :float
     \begin{figure}[H]
     \begin{mathpar}
     \inferrule[Id]{c : A ‚àà Œì}{Œì ‚ä¢ c : A}
     \and
     \inferrule[App]{Œì ‚ä¢ f : A ‚Üí B \\ Œì ‚ä¢ t : A}{Œì‚ä¢f\ t : B}
     \and
     \inferrule[Abstraction]{Œì‚à™\{‚ü®x:A‚ü©\} ‚ä¢ t : B}{Œì‚ä¢Œª(x:S).t :A ‚Üí B}
     \end{mathpar}
     \end{figure}

     Let us now see how we can give types to Booleans and natural numbers
     following the encoding given in the previous section. For that, we
     consider a singleton set of base types $B‚âî\{Œ±\}$.
     - *Booleans*. We define the type of Booleans thus: \[ùîπ‚âîŒ±‚ÜíŒ±‚ÜíŒ±\]
       \[true:=Œª(a:Œ±).Œª(b:Œ±).a;\ \ \ false‚âîŒª(a:Œ±).Œª(b:Œ±).b\]
       We proceed by showing that $‚àÖ‚ä¢true:ùîπ$.
       \begin{figure}[H]
       \begin{mathpar}
       \inferrule*[Left=Def]{
       \inferrule*[Left=Abs]{
       \inferrule*[Left=Abs]{
       \inferrule*[Left=Id]
       {\ }
       {\{‚ü®a:Œ±‚ü©,‚ü®b:Œ±‚ü©\} ‚ä¢a:Œ±}}
       {\{‚ü®a:Œ±‚ü©\} ‚ä¢Œª(b:Œ±).a:Œ±‚ÜíŒ±}}
       {‚àÖ ‚ä¢Œª(a:Œ±).Œª(b:Œ±).a:Œ±‚ÜíŒ±‚ÜíŒ±}}{‚àÖ ‚ä¢ true : ùîπ}
       \end{mathpar}
       \end{figure}
       Likewise we can show that $‚àÖ‚ä¢false:ùîπ$. It is routine to check that
       $‚àÖ‚ä¢and:ùîπ‚Üíùîπ‚Üíùîπ$ and that $‚àÖ‚ä¢or:ùîπ‚Üíùîπ‚Üíùîπ$. As we can see, types give us
       information about the nature of the term. For instance, $and:ùîπ‚Üíùîπ‚Üíùîπ$ tells
       us that $and$ is a lambda term that expects two Booleans as arguments and
       returns a Boolean.

     - *Natural numbers*. We define the type of natural numbers thus:
       \[‚Ñï‚âî(Œ±‚ÜíŒ±)‚ÜíŒ±‚ÜíŒ±\] \[0:=Œª(f:Œ±‚ÜíŒ±).Œª(a:Œ±).a;\ \ \ 1‚âîŒª(f:Œ±‚ÜíŒ±).Œª(a:Œ±).f\ a; \ \
       \ ‚Ä¶\] We can routinely check that for any natural number $n$ we have
       $‚àÖ‚ä¢n:‚Ñï$ and $‚àÖ‚ä¢add:‚Ñï‚Üí‚Ñï‚Üí‚Ñï$ and $‚àÖ‚ä¢mul:‚Ñï‚Üí‚Ñï‚Üí‚Ñï$.

     It is a well known property that simply typed lambda calculus is /strongly
     normalizing/, which means that every well-typed term can be reduced to a
     normal form. Thus it must be the case, and it is easy to observe, that
     the non-normalizing term we presented before cannot be typed for any
     choice of $A$. \[(Œª(x:A).x\ x)\ (Œª(x:A).x\ x)\]

     Strong normalization is a desirable property, but it comes at the price of
     losing equivalence to Turing machines as there are many computable
     functions that cannot be expressed in simply typed lambda calculus.
     To circumvent this, some extensions of simply typed lambda calculus are
     extended with Curry's $Y$ combinator defined below. The $Y$ combinator, also
     known as the fixed-point combinator, is a primitive lambda term that can
     be added to the language and be assigned the type $(A ‚ÜíA)‚ÜíA$ for any type
     $A$. \[Y‚âîŒªg.(Œªx.g\ (x\ x))\ (Œªx.g\ (x\ x))\] The $Y$ combinator gives general
     recursion and thus the strong normalization property no longer holds.

*** Dependently typed lambda calculus
    There is no way to briefly present a description of a type system with
    dependent types in an analogous form to untyped and simply typed lambda
    calculus. For this reason, we prefer to dedicate a longer section to it. In
    the upcoming cref:sec:martin-lof we present a full description of a theory
    which is based on dependent types and is the logical basis of Agda.
** Martin L√∂f's logical framework
   <<sec:martin-lof>> In this chapter we will present the intuitionistic type
   theory presented in cite:nordstrom1990programming. We will refer to this
   system as /Martin L√∂f's logical framework/ or LF for short. Even though Agda
   lacks a well defined specification, LF is considered the basis of Agda's type
   system (cite:sep-type-theory-intuitionistic). Furthermore, Peter Dybjer, who
   is a professor at the Chalmers University of Technology[fn::Where most of the
   development of Agda takes place.], suggested[fn::via email correspondence.]
   the specific version of LF that we will present in this chapter. However,
   there are important differences between LF and Agda's theory that we will
   comment in cref:sec:lof-agda.

   System LF is complex and has a lot of cyclic dependencies in the definitions.
   As such, it is impossible to give a linear presentation. For that, we ask the
   reader to have some patience when following this chapter. It may be a good
   idea to skim through the chapter and then read it more thoroughly for a
   second time. Additionally, it is likely, specially for someone new to type
   theory, that everything will remain very abstract until we start introducing
   sets in cref:sec:def-new-types.

*** Basic definitions
   The system LF has four kinds of judgment. Each kind of judgment is bound to
   a /context/. We postpone momentarily the definition of context.
   1. ``$a$ has type $A$ in context $Œì$''. We write $Œì‚ä¢a:A$. Crucially, in a type
      theory that follows the paradigm of /propositions as types/ we may
      interpret the statement $a:A$ in several ways, all of them equivalent in
      such a paradigm:
      - The term $a$ has type $A$;
      - the term $a$ satisfies the proposition $A$;
      - the term $a$ is a proof of the proposition $A$;
      - the term $a$ is a program that satisfies the specification $A$.
   2. ``$A$ is a type in context $Œì$''. We write $Œì‚ä¢A:\mathsf{Type}$.
   3. ``$A_1$ and $A_2$ are equal types in context $Œì$''. We write
      $Œì‚ä¢A_1=A_2:\mathsf{Type}$. It is important to remark that the $=$ sign is
      part of the judgment and is not part of the syntax of types and terms.
   4. ``$a_1$ and $a_2$ are equal elements of the type $A$ in context $Œì$''. We
      write $Œì‚ä¢a_1=a_2:A$. As before, the $=$ sign is part of the judgment.

   Notice that we have not yet defined what is the syntax of terms nor types. We
   need to postpone the definition because in order to describe how we can build
   types and terms we first need to define several basic concepts. We will
   define the syntax of types and terms in cref:sec:rules-types-terms.

   The following definition characterizes what we consider propositions in the
   LF system.
   #+begin_definition
   *Proposition*.
   We say that $A$ is a proposition (or a type) when we have:
   \[‚àÖ‚ä¢A:\type\]

   The above is the formal definition of a type within the system. However, it
   might be helpful for the reader to consider a meta definition of what we
   understand as type in the system. For that, we quote the description given in
   cite:nordstrom1990programming:
   #+begin_quote
   What does it mean that something is a type? To know that $A$ is a type is to
   know what it means to be an object of the type, as well as what it means for two
   objects to be the same. The identity between objects must be an equivalence
   relation and it must be decidable.
   #+end_quote
   #+end_definition

   Since types are proposition in LF, we need a way to discern which
   propositions hold the status of theorem. Such a notion is given by the
   following definition.
   #+begin_definition
   *Theorem*. We say that some proposition (or type) $A$ is true in LF if there exists some
   $t$ such that: \[‚àÖ‚ä¢t:A\]
   #+end_definition

   The following definition gives a precise statement on what it means for
   two terms to be indiscernible in LF.
   #+begin_definition
   *Equality of terms*. We say that two terms $t$ and $t'$ of type $A$
   are equal in LF if we have:
   \[‚àÖ‚ä¢t=t':A\]
   #+end_definition

   Similarly we define when two types are considered to be the same in LF.
   #+begin_definition
   *Equality of types*. We say that two types $T$ and $T'$
   are equal in LF if we have:
   \[‚àÖ‚ä¢T=T':\type\]
   #+end_definition

   We proceed by defining the concept of /context/.
   #+begin_definition
   *Context*. Intuitively, a context, is a sequence of typed variables, where
   each type may depend on the preceding variables in the sequence.

   More precisely, a context is a finite sequence of the form \[x‚ÇÅ:S‚ÇÅ,‚Ä¶,x‚Çô:S‚Çô\]
   Where each $x·µ¢$ denotes a variable[fn::Every variable must be different than
   the rest, that is, for every $i,j$ such that $i‚â†j$ we have $x·µ¢‚â†x‚±º$.].
   Furthermore, given arbitrary terms $a‚ÇÅ,‚Ä¶,a_n$ it must hold that:
   \begin{flalign*}
   \label{context-cond}
   ‚àÖ‚ä¢S‚ÇÅ:\type{} &\text{ and } ‚àÖ‚ä¢a‚ÇÅ:S‚ÇÅ; \\
   ‚àÖ‚ä¢S‚ÇÇ[x‚ÇÅ‚Ü¶a‚ÇÅ]:\type{} &\text{ and } ‚àÖ‚ä¢a‚ÇÇ:S‚ÇÇ[x‚ÇÅ‚Ü¶a‚ÇÅ]; \\
   & ‚ãÆ \\
   ‚àÖ‚ä¢S_n[x‚ÇÅ‚Ü¶a‚ÇÅ,‚Ä¶,x_{n-1}‚Ü¶a_{n-1}]:\type{} &\text{ and } ‚àÖ‚ä¢a_n:S_n[x‚ÇÅ‚Ü¶a‚ÇÅ,‚Ä¶,x_{n-1}‚Üía_{n-1}].
   \end{flalign*}
   #+end_definition

   We will now introduce a type for the first time. We introduce the type
   \set{}[fn::The concept of /set/ used here differs from the one in set
   theory.].
   \begin{mathpar}
   \inferrule[Set]{\ }{Œì‚ä¢\mathsf{Set}:\mathsf{Type}}
   \end{mathpar}
   As we see the previous rule has no assumptions, hence we have that
   $‚àÖ‚ä¢\set:\type$ is valid in LF.

   \pagebreak[4]
   The nature of the type \set{} is given by the following meta definition.
   #+begin_definition
   *Set*. A /set/ is an inductive description of how its
   /canonical elements/ are built, plus a decidable equality relation between
   them. Two sets are equal if any canonical element of one set is a canonical
   element of the other set and moreover, if any two equal canonical elements in
   one set also are equal in the other set.

   For instance, if we want to define the set of natural numbers, we have two
   canonical elements: /zero/ and the /successor/ of a natural number. The
   equality relation can be defined as expected. In cref:sec:def-new-types we
   will see how we can define the natural numbers, among other sets, in more
   detail.

   If $A$ is a set, then the elements of $A$, denoted with \el{A}, in
   conjunction with their equivalence relation form a type. As such, we add the
   following rules:
   \begin{mathpar}
   \inferrule[El]{Œì‚ä¢A:\set{} }{Œì‚ä¢\el{A}:\type{}}
   \and
   \inferrule[El=]{Œì‚ä¢A=B:\set{} }{Œì‚ä¢\el{A}=\el{B}:\type{}}
   \end{mathpar}
   Note that \el{.} is a primitive which takes a \set{} as an argument and
   returns a \type{}, which represents the elements of the set.

   Later in the chapter (cref:sec:family-types) we will define the concept of
   /family of types/ and we will see (in cref:example:el-family) that \el{.} is
   family of types over \set{}.
   #+end_definition

   We are now ready to introduce the first structural rule. The following rule
   allows us to use assumptions in the context:
   \begin{mathpar}
   \inferrule[Assum]{Œì‚ä¢A:\type{}}
   {Œì,x:A, Œì'‚ä¢x:A}
   \end{mathpar}

   Finally we can build our first derivation:
   #+begin_example2
   The derivation below shows that we can fully formalize in the system that we
   have an arbitrary set $P$ as an assumption and show that $\el{P}$ is a type.
   \begin{mathpar}
   \inferrule*[Left=El]
   {\inferrule*[Left=Assum]
   {\inferrule*[Left=Set]
   {\ }
   {Œì‚ä¢\set{}:\type{}}}
   {Œì,P:\set{},Œì'‚ä¢P:\set{}}}
   {Œì,P:\set{},Œì'‚ä¢\sf{El}(P):\type{}}
   \end{mathpar}
   #+end_example2

   It turns out that this is a common pattern that we will use in the examples
   later in the chapter. Thus, it is convenient to define a shortcut rule:
   \begin{mathpar}
   \inferrule[VarType]
   {\ }
   {Œì,P:\set{},Œì'‚ä¢\sf{El}(P):\type{}}
   \end{mathpar}

   We proceed by giving some rules that express that equality, both for types
   and terms, is indeed an equivalence relation.

   For equality on terms we have:
   \begin{mathpar}
   \inferrule[Refl]{Œì‚ä¢a:A}{Œì‚ä¢a=a:A} \and
   \inferrule[Sym]{Œì‚ä¢a=b:A}{Œì‚ä¢b=a:A} \and
   \inferrule[Trans]{Œì‚ä¢a=b:A \\ Œì‚ä¢b=c:A}{Œì‚ä¢a=c:A}
   \end{mathpar}
   Analogously, for equality on types we have:
   \begin{mathpar}
   \inferrule[ReflTy]{Œì‚ä¢A:\type{}}{Œì‚ä¢A=A:\type{}} \and
   \inferrule[SymTy]{ Œì‚ä¢A=B:\type{} }{Œì‚ä¢B=A:\type{}} \and
   \inferrule[TransTy]{Œì‚ä¢A=B:\type{} \\ Œì‚ä¢B=C:\type{}}{Œì‚ä¢A=C:\type{}}
   \end{mathpar}

   Furthermore we can substitute equal types.
   \begin{mathpar}
   \inferrule[SubsTy1]{Œì‚ä¢A=B:\type{}\\Œì‚ä¢a:A }{Œì‚ä¢a:B} \and
   \inferrule[SubsTy2]{Œì‚ä¢A=B:\type{} \\Œì‚ä¢a=b:A}{Œì‚ä¢a=b:B}
   \end{mathpar}

   #+begin_example2
   Let us show a trivial example. By using the shortcut rule \textsc{VarType}
   that we defined before we can show that type of the elements of an arbitrary
   set $S$ is indeed equal to itself:
   \begin{mathpar}
   \inferrule*[Left=ReflTy]  {
   \inferrule*[Left=VarType]{\ }
   {P:\set‚ä¢\el{P}:\type}
   }{P:\set‚ä¢\el{P}=\el{P}:\type{}}
   \end{mathpar}
   #+end_example2

   With the rules that we have given so far it is not possible to prove a
   judgment of the kind $Œì‚ä¢a:A$ nor $Œì‚ä¢a=b:A$. We will be able to do so in the
   next section.

*** Syntax of types and terms :noexport:
    In a theory that features dependent types, presenting types and terms
    separately is not possible as they are tightly intertwined. In fact, terms
    may appear inside types and vice versa. We will first give a short intuitive
    presentation of the syntax that will give an overall idea and hopefully make
    the rest of the section easier to follow.

    The syntax of terms is the same as the one presented in simply typed
    lambda calculus:
    \[T‚âîx\ |\ T\ T\ |\ Œª(x:A).T\ |\ c\]

    Recall the syntax of types in simply typed lambda calculus:
    \[S‚âîB\ |\ S‚ÜíS\]

    In this theory we expand the syntax of types in a way that resembles the
    syntax of terms: \[S‚âîx\ |\ (x:S)‚Ü†S\ |\ S\ S\ |\ c\] We want to highlight the
    construction $(x:S)‚Ü†S$. This is the type of dependent functions. If we have
    $(a:A)‚Ü†B$ then this is the type of functions from $A$ to $B$. However, in
    this case the type $B$ may depend on $a$ (we will also say that $B$ is
    indexed by a term of type $A$). As we will see, this is the cornerstone of
    and gives the name to /dependent types/.

    In any case, in order to avoid cluttered rules, if the context is the same
    for all the parts of a rule, we will not mention it explicitly. For
    instance, we will prefer to use the notation of the right rule over the
    notation used in the left rule when possible:
    \begin{mathpar}
    \inferrule[Refl]{Œì‚ä¢A:\type{} \\ Œì‚ä¢a:A}{Œì‚ä¢a=a:A} \and
    \inferrule[Refl]{A:\type{} \\ a:A}{a=a:A}
    \end{mathpar}
    Additionally, when the judgment does not depend on the context (\ie{} the
    context is allowed to be empty), we will drop the ``$Œì‚ä¢$'' part.

*** Rules for types and terms
    <<sec:rules-types-terms>>

    We are finally ready to introduce the syntax of terms and types. The syntax
    is introduced by means of typing rules.

    We first introduce the syntax of the dependent function type. The dependent
    function type is the type of functions from a type $A$ to a type $B$, where
    $B$ is a type that may depend on an arbitrary term of type $A$.
    \begin{mathpar}
    \inferrule[Fun]{Œì‚ä¢A:\type{}\\Œì,x:A‚ä¢B:\type{}}{Œì‚ä¢(x:A)‚Ü†B:\type{}}
    \end{mathpar}
    The subtle generalization to allow $B$ to depend on a term of type $A$ has
    incredible consequences for the system. So much so that it gives name the
    paradigm of /dependent types/.

    When we have $(x:A)‚Ü†B$ we say that $A$ is the type of the argument and that
    $B$ is the /return type/. Also, we set $‚Ü†$ to have right associativity.

    When $B$ does not depend on a term of type $A$, or in other words, when $x$
    does not appear free in $B$, we will simply write $A‚Ü†B$ instead of
    $(x:A)‚Ü†B$. This notation convention motivates the following simplified rule
    which corresponds to the function type in simply typed lambda calculus:
    \begin{mathpar}
    \inferrule[Fun']{Œì‚ä¢A:\type{}\\Œì‚ä¢B:\type{}}{Œì‚ä¢A‚Ü†B:\type{}}
    \end{mathpar}

    #+begin_example2
    <<example:id-type>>
    As an easy example, we show how for arbitrary set $P$ we can build the
    function type from elements of $P$ to elements of $P$.
    \begin{mathpar}
    \inferrule*[Left=Fun]
     {\inferrule*[Left=VarType]
     {\ }
     {P:\set‚ä¢\el{P}:\type}\\ \hspace{3em}
     \inferrule*[Left=VarType]{\ }
     {P:\set,x:\el{P}‚ä¢\el{P}:\type}}
     {P:\set‚ä¢(x:\el{P})‚Ü†\el{P}:\type}
    \end{mathpar}
    #+end_example2

    We have seen how we can build the dependent function type so the natural
    question is to ask how we can build terms of that type. The answer lies in
    the simple construction of a lambda abstraction, which is very reminiscent
    of the lambda abstraction of simply typed lambda calculus.
    \begin{mathpar}
    \inferrule[Abs]{Œì,x:A‚ä¢b:B}{Œì‚ä¢Œªx‚Üíb:(x:A)‚Ü†B}
    \end{mathpar}
    As a notational convention we have that expression on the right of the $‚Üí$
    extends to the rightmost part, without escaping parenthesis.

    #+begin_example2
    To follow up on cref:example:id-type we show how we can build a term that
    has the type $\el{P}‚Ü†\el{P}$ presented in that example. Unsirprisingly, the
    term that we are after is the lambda term $Œª(x:\el{P})‚Üíx$. For the
    experienced reader it should be obvious that term represents the identity
    function. For the novel reader we will see it in cref:example:id-fun.
    We will often refer to terms of a type of the form $(x:A)‚Ü†B$ as functions.
    Without further ado we show that $P:\set‚ä¢Œªx‚Üíx:(x:\el{P})‚Ü†\el{P}$.
    \begin{mathpar}
    \inferrule*[Left=Abs]
     {\inferrule*[Left=Assum]
     {\inferrule*[Left=VarType]{\ }
     {P:\set‚ä¢\el{P}:\type} }
     {P:\set,x:\el{P}‚ä¢x:\el{P}}}
     {P:\set‚ä¢Œªx‚Üíx:(x:\el{P})‚Ü†\el{P}}
    \end{mathpar}
    #+end_example2

    In order for a function to be useful we need to be able to apply it to an
    argument. The following rule allows us to do precisely that. More precisely,
    if we have a term $f$ of type $(x:A)‚Ü†B$ and a term $a$ of type $A$, then we
    can build a term $f\ a$ of type $B[x‚Ü¶a]$.
    \begin{mathpar}
    \inferrule[App]{Œì‚ä¢f:(x:A)‚Ü†B \\ Œì‚ä¢a:A}{Œì‚ä¢f\ a:B[x‚Ü¶a]}
    \end{mathpar}
    The most important detail to notice is that in the consequence we have $f\
    a:B[x‚Ü¶a]$. Thus, exhibiting the fact that indeed the type of an application
    depends not only on the type of the function but also on the argument itself.

    Application has left associativity. Thus, $f\ a\ b=(f\ a)\ b$. Also,
    application binds stronger that abstraction, thus $Œª x‚Üí f\ b\ x$ is equivalent
    to $Œª x‚Üí (f\ b\ x)$.


    In mathematics, when we have $f(x)‚âî2+x$ we expect that $f(3)=2+3$. The rule
    of \text{$Œ≤$-reduction} or simply \textsc{$Œ≤$-=} tells us exactly that.
    More precisely, the \textsc{$Œ≤$-=} rule tells us that if we have $(Œªx‚Üíb)\
    a$, then we can substitute the variable $x$ in the body $b$ by the term $a$.
    It is important to notice that the term $a$ is also substituted in the type
    $B$:
    \begin{mathpar}
    \inferrule[$Œ≤$-$=$]{Œì‚ä¢a:A \\ Œì,x:A‚ä¢b:B}{Œì‚ä¢(Œªx‚Üíb)\ a=b[x‚Ü¶a]:B[x‚Ü¶a]}
    \end{mathpar}

    #+begin_example2
    <<example:id-fun>> Let us now argue why we identify the term $Œªx‚Üíx$ with the
    identity function. For that, we will show that $P:\set,a:\el{P}‚ä¢(Œªx‚Üíx)\
    a=a:\el{P}$.
    \begin{mathpar}
    \inferrule*[Left=\textsc{$Œ≤$-$=$}]
    {
     \inferrule*[Left=Assum]{‚Ä¶}
     {P:\set,a:\el{P}‚ä¢a:\el{P}}
     \\ \hspace{2em}
     \inferrule*[Left=Assum]{‚Ä¶}
     {P:\set,a:\el{P},x:\el{P}‚ä¢x:\el{P}}
    }
    {P:\set,a:\el{P}‚ä¢(Œªx‚Üíx)\ a=a:\el{P}}
    \end{mathpar}
    At this point the reader should be able to fill in the $‚Ä¶$ gaps.
    #+end_example2

    In mathematics, we are used to renaming variables without affecting, if we
    are careful, the meaning of the expression that we are operating on. For
    instance the definitions $f(x)‚âî2+x$ and $f(y)‚âî2+y$ are essentially the same
    in any conceivable practical system. This equivalence is usually known as
    \(Œ±\text{-equivalence}\). In the LF system, \(Œ±\text{-equivalence}\) given
    by the \text{$Œ±$-$=$} rule which we define below. Such rule tells us that we
    can rename the abstracted variable of lambda abstraction terms.
    \begin{mathpar}
    \inferrule[$Œ±$-$=$]
     {Œì,x:A‚ä¢b:B}
     {Œì‚ä¢Œªx‚Üíb=Œªy‚Üí(b[x‚Ü¶y]):(z:A)‚Ü†B}
    \end{mathpar}
    It is important to remark that $y$ must not occur free in $b$.

    In mathematics, if we have $f(x)‚âîg(x)$ we expect that $f=g$. The
    \text{$Œ∑$-$=$} rule expresses such equivalence. In other words, the rule
    tells us that abstraction and application cancel each other out.
    \begin{mathpar}
    \inferrule[$Œ∑$-$=$]{Œì‚ä¢g:(x:A)‚Ü†B}
    {Œì‚ä¢Œªx‚Üíg\ x=g:(x:A)‚Ü†B}
    \end{mathpar}

    The following allows us to replace equal terms and types inside other terms
    and types.

    The \text{$Œæ$-$=$} rule tells us that we can replace equal bodies of lambda
    terms.
    \begin{mathpar}
    \inferrule[$Œæ$-$=$]{Œì,x:A‚ä¢b=b':B}{Œì‚ä¢Œªx‚Üíb=Œªx‚Üíb':(x:A)‚Ü†B}
    \end{mathpar}

    We can perform substitution in a function application.
    \begin{mathpar}
    \inferrule[SubsApp]{Œì‚ä¢f=f':(x:A)‚Ü†B \\ Œì‚ä¢a=a':A}{Œì‚ä¢f\ a=f'\ a':B[x‚Ü¶a]}
    \end{mathpar}

    Likewise, we can perform substitution in function types:
    \begin{mathpar}
    \inferrule[SubsFun]{Œì‚ä¢A=A':\type{}\\
     Œì,x:A‚ä¢B=B':\type{}}
     {Œì‚ä¢(x:A)‚Ü†B=(x:A')‚Ü†B'}
    \end{mathpar}

    At this point, we have introduced most of the system but still we cannot
    show any judgment of the form $‚àÖ‚ä¢a:A$. For that, we will need to wait until
    cref:sec:def-new-types, where we introduce concrete sets to the language.

*** Families of types
    <<sec:family-types>>
    In this section we present the concept of /family of types/. This is a
    technical concept that does not add much to the intuition of the system. As
    such, we suggest the reader to skip it on a first read and go back to
    it later.

    #+begin_definition
    *Family of types*. We say that $A$ is a family of types in the
    context $Œì$ iff $Œì‚ä¢A:\type{}$ and is extensional with respect to the
    context. To be extensional with respect to the context means the following.
    If $x‚ÇÅ:S‚ÇÅ,‚Ä¶,x‚Çô:S‚Çô‚ä¢A$ and the following holds:
    \begin{flalign*}
    ‚àÖ‚ä¢a‚ÇÅ&=b‚ÇÅ:S‚ÇÅ; \\
    ‚àÖ‚ä¢a‚ÇÇ&=b‚ÇÇ:S‚ÇÅ[x‚ÇÅ‚Ü¶a‚ÇÅ]; \\
    &‚ãÆ \\
    ‚àÖ‚ä¢a‚Çô&=b‚Çô:S‚Çô[x‚ÇÅ‚Ü¶a‚ÇÅ,‚Ä¶,x_{n-1}‚Ü¶a_{n-1}].
    \end{flalign*}
    Then it must be that:
    \[‚àÖ‚ä¢A[x‚ÇÅ‚Ü¶a‚ÇÅ,‚Ä¶,x_{n-1}‚Ü¶a_{n-1}]=A[x‚ÇÅ‚Ü¶b‚ÇÅ,‚Ä¶,x_{n-1}‚Ü¶b_{n-1}]. \]

    Note that in the case where $Œì=‚àÖ$, while $A$ is still a family of types by
    definition, we will usually simply say that $A$ is a type.

    If we have that $A$ is a family of types in the context $x:B$ we will say
    that $A$ is a family of types over $B$. Likewise, if $A$ is a family of
    types in the context $x:B,y:C$ we will say that is a family of types over
    $B$ and $C$. And so on.
    #+end_definition

    #+begin_example2
    <<example:el-family>>
    As we have previously commented, $\el{P}$ is a family of types over \set. To
    check that, we observe that $P:\set‚ä¢\el{P}$ follows from rule
    \textsc{VarType}. Moreover, extensionality is given by the \textsc{El-$=$}
    rule.
    #+end_example2

    We proceed by giving some rules for type families. Note that in the upcoming
    rules we have two assumptions, one on top the other. This is due to spacing
    and readability reasons. The intended meaning is the same as if the two
    hypotheses were side by side.

    Instantiation of a type family:
    \begin{mathpar}
    \inferrule[TF1]{x‚ÇÅ:A‚ÇÅ,‚Ä¶,x‚Çô:A‚Çô‚ä¢C:\type{}\\\\
    ‚àÖ‚ä¢a‚ÇÅ:A‚ÇÅ\\‚Ä¶\\‚àÖ‚ä¢a‚Çô:A‚Çô[x‚ÇÅ‚Ü¶a‚ÇÅ,‚Ä¶,x_{n-1}‚Ü¶a_{n-1}]}
    {‚àÖ‚ä¢C[x‚ÇÅ‚Ü¶a‚ÇÅ,‚Ä¶,x‚Çô‚Ü¶a‚Çô]:\type{}}
    \end{mathpar}

    Substitution in a type family:
    \begin{mathpar}
    \inferrule[TF2]{x‚ÇÅ:A‚ÇÅ,‚Ä¶,x‚Çô:A‚Çô‚ä¢C:\type{}\\\\
    ‚àÖ‚ä¢a‚ÇÅ=b‚ÇÅ:A‚ÇÅ\\‚Ä¶\\‚àÖ‚ä¢a‚Çô=b‚Çô:A‚Çô[x‚ÇÅ‚Ü¶a‚ÇÅ,‚Ä¶,x_{n-1}‚Ü¶a_{n-1}]}
    {‚àÖ‚ä¢C[x‚ÇÅ‚Ü¶a‚ÇÅ,‚Ä¶,x‚Çô‚Ü¶a‚Çô]=C[x‚ÇÅ‚Ü¶b‚ÇÅ,‚Ä¶,x‚Çô‚Ü¶b‚Çô]}
    \end{mathpar}

    Instantiation of a term of a type family:
    \begin{mathpar}
    \inferrule[TF3]{
    x‚ÇÅ:A‚ÇÅ,‚Ä¶,x‚Çô:A‚Çô‚ä¢c:C\\\\
     ‚àÖ‚ä¢a‚ÇÅ:A‚ÇÅ\\‚Ä¶\\‚àÖ‚ä¢a‚Çô:A‚Çô[x‚ÇÅ‚Ü¶a‚ÇÅ,‚Ä¶,x_{n-1}‚Ü¶a_{n-1}]}
    {‚àÖ‚ä¢c[x‚ÇÅ‚Ü¶a‚ÇÅ,‚Ä¶,x‚Çô‚Ü¶a‚Çô]:C[x‚ÇÅ‚Ü¶a‚ÇÅ,‚Ä¶,x‚Çô‚Ü¶a‚Çô]}
    \end{mathpar}

    Substitution in term of a type family:
    \begin{mathpar}
    \inferrule[TF4]{
    x‚ÇÅ:A‚ÇÅ,‚Ä¶,x‚Çô:A‚Çô‚ä¢c:C\\\\
    ‚àÖ‚ä¢a‚ÇÅ=b‚ÇÅ:A‚ÇÅ\\‚Ä¶\\‚àÖ‚ä¢a‚Çô=b‚Çô:A‚Çô[x‚ÇÅ‚Ü¶a‚ÇÅ,‚Ä¶,x_{n-1}‚Ü¶a_{n-1}]}
    {‚àÖ‚ä¢c[x‚ÇÅ‚Ü¶a‚ÇÅ,‚Ä¶,x‚Çô‚Ü¶a‚Çô]=c[x‚ÇÅ‚Ü¶b‚ÇÅ,‚Ä¶,x‚Çô‚Ü¶b‚Çô]:C[x‚ÇÅ‚Ü¶a‚ÇÅ,‚Ä¶,x‚Çô‚Ü¶a‚Çô]}
    \end{mathpar}

    Substitution of a type family.
    \begin{mathpar}
    \inferrule[TF5]{
    x‚ÇÅ:A‚ÇÅ,‚Ä¶,x‚Çô:A‚Çô‚ä¢B=C:\type{} \\\\
    ‚àÖ‚ä¢a‚ÇÅ:A‚ÇÅ\\‚Ä¶\\‚àÖ‚ä¢a‚Çô:A‚Çô[x‚ÇÅ‚Ü¶a‚ÇÅ,‚Ä¶,x_{n-1}‚Ü¶a_{n-1}]}
    {‚àÖ‚ä¢B[x‚ÇÅ‚Ü¶a‚ÇÅ,‚Ä¶,x‚Çô‚Ü¶a‚Çô]=C[x‚ÇÅ‚Ü¶a‚ÇÅ,‚Ä¶,x‚Çô‚Ü¶a‚Çô]:B[x‚ÇÅ‚Ü¶a‚ÇÅ,‚Ä¶,x‚Çô‚Ü¶a‚Çô]}
    \end{mathpar}

    Substitution of a type family term.
    \begin{mathpar}
    \inferrule[TF6]{
    x‚ÇÅ:A‚ÇÅ,‚Ä¶,x‚Çô:A‚Çô‚ä¢b=c:C\\\\
     ‚àÖ‚ä¢a‚ÇÅ:A‚ÇÅ\\‚Ä¶\\‚àÖ‚ä¢a‚Çô:A‚Çô[x‚ÇÅ‚Ü¶a‚ÇÅ,‚Ä¶,x_{n-1}‚Ü¶a_{n-1}]}
    {‚àÖ‚ä¢b[x‚ÇÅ‚Ü¶a‚ÇÅ,‚Ä¶,x‚Çô‚Ü¶a‚Çô]=c[x‚ÇÅ‚Ü¶a‚ÇÅ,‚Ä¶,x‚Çô‚Ü¶a‚Çô]:C[x‚ÇÅ‚Ü¶a‚ÇÅ,‚Ä¶,x‚Çô‚Ü¶a‚Çô]}
    \end{mathpar}

*** Introducing sets
    <<sec:def-new-types>> In this section we will define some sets that will
    allow us to represent different mathematical objects, such as pairs or
    natural numbers, in the system LF.

    For each set we will introduce the following (we will be purposely vague in
    this summary. A more precise list is given a few lines below).
    1. A constant that denotes the set.
    2. Some (zero or more) constants to build elements in the set.
    3. A way to interact with the elements of the set.

    The subsequent sections are going to be structured as follows: We define a
    new set, including all the parts mentioned before. then we give some
    examples. During the introduction of the first few sets we show how we can
    embed propositional intuitionistic logic into LF. After defining the natural
    numbers and the identity set we show how we can prove a property on addition
    by (formalized) induction.

    We believe that the summary above is enough to continue to cref:sec:fun-set.
    In fact, we recommend the reader to continue to cref:sec:fun-set and come
    back to read the remainder of this section once they have seen some examples
    of sets.

    We proceed by repeating the summary above with more precision. We want to
    stress that the following details do not add much to the intuition of the
    system and we add them just for reference.

    For each set we will introduce the following:
    1. A typed constant $\sf{T}:S$ that represents the set. By that we mean that
       we add a rule of the form $‚àÖ‚ä¢\sf{T}:S$ to the system. Moreover the
       following must hold:
       - \sf{T} is a fresh constant;
       - $S$ is of the form $(x‚ÇÅ:A‚ÇÅ)‚Ü†‚Ä¶‚Ü†(x‚Çô:A‚Çô)‚Ü†\set{}$;
       - we have $‚àÖ‚ä¢S:\type$.
    2. Zero or more[fn::The empty set is the only set which has no constants to
       introduce new elements.] typed constants \(\sf{c‚ÇÅ}:C‚ÇÅ,‚Ä¶,\sf{c‚Çô}:C‚Çô\) to
       introduce elements of the set. We call these constants /constructors/ of
       the set. Furthermore each $C_i$ must be of the form
       \[(y‚ÇÅ:A‚ÇÅ)‚Ü†‚Ä¶‚Ü†(y‚Çô:A‚Çô)‚Ü†(z‚ÇÅ:B‚ÇÅ)‚Ü†‚Ä¶‚Ü†(z‚Çò:B‚Çò)‚Ü†\sf{T}\ y‚ÇÅ\ ‚Ä¶\ y‚Çô\]

       The reader should notice the following:
       - The types of the first $n$ arguments of each constructor must coincide
         with the types of the arguments of $S$.
       - Furthermore, the return type of the constructor (the type after the
         rightmost arrow) must be $T$ applied to the first $n$ arguments of the
         constructor. In this case $\sf{T}\ y‚ÇÅ\ ‚Ä¶\ y‚Çô$.
    3. A way to interact with the elements of the set. This is done via an
       induction principle. The induction principle is defined by giving a typed
       constant to represent it. Then for each of the constructors we add an
       equality that describes the behavior of the induction principle with that
       constructor.

       The concept of /principle of induction/ that we use here should be taken
       in the wide sense of /structural induction/ since every set is defined in
       an inductive way. Of course, not every set that we will define has a
       recursive nature and thus the introduced induction principle for those
       sets is not going to be reminiscent of a principle of induction in the
       traditional sense.

       We use the following notational convention: If \sf{X} is the constant
       that denotes the set, then we will define the constant that represents
       the induction principle as \sf{case_X}.

    The rest of this chapter is going to be structured as follows: We define a
    new set, including all the parts mentioned before. then we give some
    examples. During the introduction of the first few sets we show how we can
    embed propositional intuitionistic logic into LF. After defining the natural
    numbers and the identity set we show how we can prove a property on addition
    by (formalized) induction.

**** Function set
     <<sec:fun-set>>

     We introduce the typed constant that denotes the set of functions from
     elements of a set $A$ to elements of a set $B$: \[‚Ü£:\set‚Ü†\set‚Ü†\set\] When
     we say that we introduce a typed constant to the language is shorthand for
     saying that we introduce a rule to assert that the new constant can be
     proven to have the given type from the empty set. In our case, it
     corresponds to the following rule:
     \begin{mathpar}
      \inferrule[]{\ }{‚àÖ‚ä¢\ ‚Ü£:\set‚Ü†\set‚Ü†\set}
     \end{mathpar}

     *Notation*: We will use infix notation and write $A\ ‚Ü£\ B$ instead of $‚Ü£\
     A\ B$. Also, $‚Ü£$ has right associativity.

     We add a constructor to introduce elements in this set: \[Œõ :
     (A:\set)‚Ü†(B:\set)‚Ü†(\el{A}‚Ü†\el{B})‚Ü† \el{A\ ‚Ü£\ B} \] As we can see, the
     return type of $Œõ$ is $\el{A\ ‚Ü£\ B}$. As such, if we apply $Œõ$ to a set
     $A$, a set $B$ and a function from elements of $A$ to elements of $B$ we
     get an element of the set $A\ ‚Ü£\ B$. In this case we will not introduce
     more constructors, thus, applying $Œõ$ to the corresponding arguments will
     be the only way to build an element of the function set.

     We proceed by adding an induction principle: \[\sf{case_Œõ} :
     (A:\set)‚Ü†(B:\set)‚Ü†(\el{A‚Ü£B})‚Ü† \el{A}‚Ü†\el{B} \] Let us clarify why we use
     the words /induction principle/ here. As already pointed out in the
     introduction of this section, every set must be defined in an inductive
     way. Some sets only have non-recursive constructors, like pairs or the
     function set being defined here. In the case of the function set we only
     have the $Œõ$ constructor. From the type of $Œõ$ we see that in order to
     build a term of type $\el{A‚Ü£B}$ we need to provide a term of type
     $\el{A}‚Ü†\el{B}$. We see that the inductive principle \sf{case_Œõ} does works
     in the opposite direction: from a term of type $\el{A‚Ü£B}$ returns a term of
     type $\el{A}‚Ü†\el{B}$. Because of this, the functionality of the \sf{case_Œõ}
     constant is often referred to as /inversion/, /deconstruction/ or
     /unwrapping/ principle. We believe that in this introduction to sets it
     helps to use a homogeneous language so we will always use the general term
     /induction principle/.

     And the equality:
     \begin{mathpar}
     \inferrule[case$Œõ$]{
     f:\el{A}‚Ü†\el{B} }{\sf{case_Œõ}\ A\ B\ (Œõ\ A\ B\ f)=f:\el{A}‚Ü†\el{B}}
     \end{mathpar}


     The following rules are redundant but they help keeping proofs shorter.
     \begin{mathpar}
     \inferrule[Intro$Œõ$]{f:\el{A}‚Ü†\el{B}}
     {Œõ\ A\ B\ f:\el{A‚Ü£B}}
     \and \inferrule[Abs$Œõ$]{Œì,x:A‚ä¢b:B}
     {Œõ\ A\ B\ (Œªx‚Üíb):\el{A‚Ü£B}}
     \and \inferrule[App$Œõ$]{f:\el{A‚Ü£B} \\ a:\el{A}}
     {\sf{case_Œõ}\ f\ a : \el{B}}
     \end{mathpar}
     *Notation*: When we have $f:\el{A‚Ü£B}$ and $a:\el{A}$ we will write $f\ a$
     instead of $\sf{case_Œõ}\ f\ a$. Note that this notational convention is
     very convenient and adds no ambiguity since $f\ a$ on its own would never
     be a valid term.

     In each of the sections where we define a set we will draw a horizontal
     line such as the one below to separate the definition of the set from the
     corresponding examples.
     -----

     Consider the fragment of intuitionistic logic with only implication. If $A$
     is a propositional formula then $A^*$ is the type that identifies the
     formula $A$ in LF, where $*$ is a map from propositional formulas to types
     as defined below.
     \begin{flalign*}
     A^*&‚âî\el{‚ü¶A‚üß} \\
     \\
     ‚ü¶p‚üß &‚âî P & \text{where } P:\set{} \\
     ‚ü¶A ‚Üí B‚üß&‚âî ‚ü¶A‚üß ‚Ü£ ‚ü¶B‚üß
     \end{flalign*}
     We map lowercase propositional variables to the same uppercase variable of
     type $\set$, that is, $‚ü¶p‚üß=P$ with $P:\set$, $‚ü¶q‚üß=Q$ with $Q:\set$, and so
     on.

     Let us now show that $(p‚Üíp)^*$ is a theorem in LF. In order to prove
     that, we need to give a term with type $\el{P‚Ü£P}$. This term is in fact the
     identity function wrapped in the function set, as shown below.
     \begin{mathpar}
     \inferrule*[Left=Abs$Œõ$]
     {\inferrule*[Left=Assum]
     {\inferrule*[Left=VarType]
     {\ }
     {P:\set{}‚ä¢\sf{El}(P):\type{}}}
     {P:\set{},x:\sf{El}(P)‚ä¢x:\sf{El}(P)}}
     {P:\set{}‚ä¢Œõ\ P\ P\ (Œªx‚Üíx):\el{P‚Ü£P}}
     \end{mathpar}

     As another example we show that $(p ‚Üí (q ‚Üí p))^*$ is a theorem in LF:
     \begin{mathpar}
     \inferrule*[Left=Abs$Œõ$]
     {\inferrule*[Left=Abs$Œõ$]
     {\inferrule*[Left=Assum]
     {\inferrule*[Left=VarType]
     {\ }
     {P:\set{}, Q:\set{},y:\sf{EL}(Q)‚ä¢\sf{El}(P):\type{}}}
     {P:\set{}, Q:\set{},x:\sf{EL}(P),y:\sf{EL}(Q)‚ä¢x:\sf{El}(P)}}
     {P:\set{}, Q:\set{},x:\sf{EL}(P)‚ä¢ Œõ\ Q\ P\ (Œª y‚Üí x):Q‚Ü£P}}
     {P:\set{}, Q:\set{}‚ä¢Œõ\ P\ (Q‚Ü£P)\ (Œªx‚ÜíŒõ\ Q\ P\ (Œª y‚Üí x)):\el{P‚Ü£Q‚Ü£P}}
     \end{mathpar}
     *Notation*. In order to improve readability, from now on, where we would
     have $Œõ\ A\ B\ (Œªx‚Üíb)$ and $A$ and $B$ are clear from the context, we will
     write $Œõx‚Üíb$ instead. For instance, the last step of the previous proof
     would be written as
     \begin{mathpar}
     \inferrule*[Left=Abs$Œõ$]
     {‚Ä¶}
     {P:\set{}, Q:\set{}‚ä¢Œõx‚ÜíŒõy‚Üí x:\el{P‚Ü£Q‚Ü£P}}
     \end{mathpar}

     We now show the last step of the proof for $((p‚Üí(q‚Üír)) ‚Üí ((p‚Üíq)‚Üí(p‚Üír))^*$.
     It should not be hard for the reader to see how the proof can be finished.
     \begin{mathpar}
     \inferrule*[Left=Abs$Œõ$]
     {‚Ä¶}
     {P:\set{}, Q:\set{}, R:\set{}‚ä¢Œõf‚Üí(Œõ g‚Üí (Œõx‚Üíf\ x\ (g\ x))):\\\\
       \el{(P‚Ü£Q‚Ü£R)‚Ü£(P‚Ü£Q)‚Ü£P‚Ü£R}}
     \end{mathpar}

     Observe now that the modus ponens rule is valid, that is, if $(p‚Üíq)^*$ and
     $p^*$ are theorems in LF, then $q^*$ is also a theorem. From the assumption
     it follows that there are terms $f:\el{P‚Ü£ Q}$ and $a:\sf{EL}(P)$. Then we
     have that $\sf{case_Œõ}\ f\ a$, which we write as $f\ a$, is the desired term.
     \begin{mathpar}
     \inferrule*[Left=App]
     {\inferrule*[]{\ }{P:\set{}, Q:\set{}‚ä¢f:\el{P‚Ü£ Q}}
     \\ \inferrule*[]{\ }{P:\set{}, Q:\set{}‚ä¢a:\sf{El}(P)}}
     {P:\set{}, Q:\set{}‚ä¢f\ a: \sf{El}(Q) }
     \end{mathpar}

     {{{begintheorem}}} {{{endtheorem}}} If $A$ is a theorem in the fragment of
     propositional intuitionistic logic with only implication, then
     $A^*$ is a theorem in LF.
     {{{beginproof}}} By induction on $A$ and using the previous facts. {{{endproof}}}

**** Top set
      We now define the singleton set. We name it $‚ä§$. We say that it
      is a singleton set because it only has one element, namely
      $\sf{tt}$. The $‚ä§$ set represents ``true'' in this logic.

      We add the constant that represents the set: \[‚ä§:\set{}\] We introduce the
      constant that is the only element in the set: \[\sf{tt}:\sf{El}(‚ä§)\] An
      induction principle: \[\sf{case}_{‚ä§}:(P : \sf{El}(‚ä§)‚Ü†\set{})‚Ü†\sf{El}(P\
      \sf{tt})‚Ü†(a:\sf{El}(‚ä§))‚Ü†\sf{El}(P\ a)\] The above type should read as
      follows. Given a predicate $P$, a proof that $P$ holds for the base case,
      that is, an element of the set $P\ \sf{tt}$, and an arbitrary element $a$
      in the set $‚ä§$, we build a term in the set $P\ a$, which is a proof that
      $a$ satisfies $P$.

      We also add the following equality.
      \begin{mathpar}
      \inferrule[case$‚ä§$]{P:\el{‚ä§}‚Ü†\set{} \\ p : \el{ P\ \sf{tt} }}
      {\sf{case}_{‚ä§}\ P\ p\ \sf{tt}=p\ \sf{tt}:\el{P\ \sf{tt}}}
      \end{mathpar}

      As expected from a set representing /true/, it is trivial to provide a term
      of type $\el{‚ä§}$.
      \begin{mathpar}
      \inferrule[]{\ }{\sf{tt}:\el{‚ä§} }
      \end{mathpar}
**** Bottom set
     We define the empty set, $‚ä•$, as we call it. We say that it is the empty
     set because there is no term $t$ such that $t:\el{‚ä•}$. The $‚ä•$ type
     represents ``false'' in this theory.

     We introduce the constant that represents the type: \[‚ä•:\set{}\] We do
     not introduce any constructors for this set. We introduce an
     induction principle: \[\sf{case_‚ä•}:(P : \el{‚ä•}‚Ü†\set{})‚Ü†(a:\el{‚ä•})‚Ü†\el{P\ a}\]

     The justification of this induction principle is that since it is
     impossible to build a term of type $‚ä•$ by definition, then from the
     assumption that we have a term of type $‚ä•$, follows anything.

     -----

     We add the following equation to the map $‚ü¶.‚üß$:
     \begin{flalign*}
     ‚ü¶‚ä•‚üß ‚âî ‚ä• &&
     \end{flalign*}
     The $‚ä•$ on the right of $‚âî$ is the constant introduced in this section.

     Let us now show that the principle $(‚ä•‚Üíp)^*$ known as /ex falso quodlibet/
     or /principle of explosion/ holds in LF. For that, we provide a term typed
     $(‚ä•‚Üíp)^*$.
     \begin{mathpar}
     \inferrule*[Left=Abs$Œõ$]
     {\inferrule*[Left=App, sep=2em]
     {\inferrule*[Left=App]
     {\inferrule*[]{\ }{\sf{case_‚ä•}:‚Ä¶}
        \\ \inferrule*[Left=Abs]
            {\inferrule*[Left=Assum]{\ }{P:\set, x:\el{‚ä•}‚ä¢P:\set}}
            {P:\set(Œªx‚ÜíP):\el{‚ä•}‚Ü†\set}}
     {P:\set,y:\el{‚ä•}‚ä¢\sf{case_‚ä•}\ (Œªx‚ÜíP):\el{‚ä•}‚Ü†\el{P}}
        \\\hspace{1.2em} \inferrule*[Left=Assum]{\ }{y:\el{‚ä•}‚ä¢y:\el{‚ä•}}}
     {P:\set,y:\el{‚ä•}‚ä¢\sf{case_‚ä•}\ (Œªx‚ÜíP)\ y:\el{P}}}
     {P:\set‚ä¢Œõy‚Üí\sf{case_‚ä•}\ (Œªx‚ÜíP)\ y:\el{‚ä•‚Ü£P}}
     \end{mathpar}
**** Disjoint unions set
     <<sec:disjoint-set>>
     We introduce the constant: \[‚äé : \set{}‚Ü†\set{}‚Ü†\set{}\] *Notation*.We will
     use infix notation for $‚äé$, hence we will write $A\ ‚äé\ B$ instead of $‚äé\ A\
     B$. The disjoint union set represents two options, hence, when we have a
     term of type $A\ ‚äé\ B$ it means that we either have a term of type $A$ or a
     term of type $B$ (and we know which of the two we have).

     Since we want to represent two options, we introduce two constructors:
     \begin{flalign*}
     \sf{inj}‚ÇÅ &: (A:\set{})‚Ü†(B:\set{})‚Ü†\el{A}‚Ü† \el{A\ ‚äé\ B}\\
     \sf{inj}‚ÇÇ &: (A:\set{})‚Ü†(B:\set{})‚Ü†\el{B}‚Ü† \el{A\ ‚äé\ B}
     \end{flalign*}

     We introduce the following induction principle:
     \begin{flalign*}
     \sf{case}_‚äé &: (A:\set{})‚Ü†(B:\set{})‚Ü†(P : \el{A\ ‚äé\ B} ‚Ü† \set{})\\
     &‚Ü† ((a:\el{A})‚Ü†\el{P\ (\sf{inj}‚ÇÅ\ A\ B\ a)}) & \text{case A}\\
     &‚Ü† ((b:\el{B})‚Ü†\el{P\ (\sf{inj}‚ÇÇ\ A\ B\ b)}) & \text{case B}\\
     &‚Ü† (u:\el{A\ ‚äé\ B}) \\
     &‚Ü† \el{P\ u}
     \end{flalign*}
     As we can easily identify from the type of $\sf{case}_‚äé$, this induction
     principle corresponds to a proof by cases. Note that we need to provide a
     proof for $P$ given an element of $A$ and also a proof of $P$ given an
     element of $B$.

     We also introduce the rules below. These rules tells us that when we apply
     the proof by cases to a disjoint set built with the \sf{inj‚ÇÅ} constructor
     we apply the proof which corresponds to the first case, whereas if we apply
     proof by cases to a disjoint set built with the \sf{inj‚ÇÇ} constructor we
     apply the proof which corresponds to the second case.
     \begin{mathpar}
     \inferrule[Case$‚äé‚ÇÅ$]{P:\el{A\ ‚äé\ B}‚Ü†\set{}\\\\
     p‚ÇÅ:(a:\el{A})‚Ü†\el{P\ (\sf{inj}‚ÇÅ\ A\ B\ a)} \\\\
     p‚ÇÇ:(b:\el{B})‚Ü†\el{P\ (\sf{inj}‚ÇÇ\ A\ B\ b)} \\\\
     a: \el{A}
     }{\sf{case}_‚äé\ A\ B\ P\ p‚ÇÅ\ p‚ÇÇ\ (\sf{inj}‚ÇÅ\ A\ B\ a)=
     p‚ÇÅ\ a:\el{P\ (\sf{inj}‚ÇÅ\ A\ B\ a)}}
     \and
     \inferrule[Case$‚äé‚ÇÇ$]{P:\el{A\ ‚äé\ B}‚Ü†\set{}\\\\
     p‚ÇÅ:(a:\el{A})‚Ü†\el{P\ (\sf{inj}‚ÇÅ\ A\ B\ a)} \\\\
     p‚ÇÇ:(b:\el{B})‚Ü†\el{P\ (\sf{inj}‚ÇÇ\ A\ B\ b)} \\\\
     b: \el{B} }{\sf{case}_‚äé\ A\ B\ P\ p‚ÇÅ\ p‚ÇÇ\ (\sf{inj}‚ÇÇ\ A\ B\ b)=
     p‚ÇÇ\ b:\el{P\ (\sf{inj}‚ÇÇ\ A\ B\ b)}}
     \end{mathpar}

     -----

     We extend the map $‚ü¶.‚üß$ we defined with the following equation:
     \begin{flalign*}
     ‚ü¶A‚à®B‚üß‚âî‚ü¶A‚üß‚äé‚ü¶B‚üß & &
     \end{flalign*}
     We show that $(p‚Üí(p‚à®q))^*$ is a theorem in LF.
     \begin{mathpar}
     \inferrule[]{‚Ä¶ }{P:\set,Q:\set‚ä¢Œõx‚Üí\sf{inj‚ÇÅ}\ P\ Q\ x:\el{P‚Ü£(P\ ‚äé\ Q)}}
     \end{mathpar}
     The proof of $(q‚Üí(p‚à®q))^*$ is analogous.
     \begin{mathpar}
     \inferrule[]{‚Ä¶ }{P:\set{},Q:\set‚ä¢Œõx‚Üí\sf{inj‚ÇÇ}\ P\ Q\ x:\el{Q‚Ü£(P\ ‚äé\ Q)}}
     \end{mathpar}
     Finally we have that $((p‚Üír)‚Üí((q‚Üír)‚Üí((p‚à®q)‚Üír)))^*$ is a theorem in LF.
     Finishing the proof is straightforward.
     \begin{mathpar}
     \inferrule[]{‚Ä¶ }{P:\set{},Q:\set{},R:\set{}‚ä¢
     Œõf‚ÜíŒõg‚ÜíŒõx‚Üí\sf{case}_‚äé\ P\ Q\ (Œª x‚Üí R)\ (\sf{case_Œõ}\ f)\ (\sf{case_Œõ}\ g)\ x:\\\\
     \el{(P‚Ü£R)‚Ü£(Q‚Ü£R)‚Ü£(P‚äéQ)‚Ü£R} }
     \end{mathpar}
**** Pairs set
     <<sec:pairs-set>>
     The following constant which represents the set of pairs:
     \[√ó:\set{}‚Ü†\set{}‚Ü†\set{}\]
     *Notation*. We will use infix notation for $√ó$, hence we will write $A\ √ó B$ instead
     of $√ó A\ B$.

     We introduce one constructor:
     \[\sf{pair} : (A:\set{})‚Ü†(B:\set{})‚Ü†\el{A}‚Ü† \el{B}‚Ü†\el{A\ √ó\ B}\]

     We introduce the following induction principle:
     \begin{flalign*}
     \sf{case}_√ó &: (A:\set{})‚Ü†(B:\set{})‚Ü†(P : \el{A\ √ó\ B} ‚Ü† \set{})\\
     &‚Ü† ((a:\el{A})‚Ü†(b:\el{B})‚Ü†\el{P\ (\sf{pair}\ A\ B\ a\ b)}) \\
     &‚Ü† (u:\el{A\ √ó B}) \\
     &‚Ü† \el{P\ u}
     \end{flalign*}
     The functionality of this induction principle is to unwrap a term of type
     $\el{A\ √ó\ B}$ to access its components.

     We add the following rule, which tells us that the constructor \sf{pair}
     and the induction principle $\sf{case}_√ó$ cancel each other.
     \begin{mathpar}
     \inferrule[case$√ó$]{P:\el{A\ √ó\ B}‚Ü†\sf{Set}\\\\
     p:(a':\el{A})‚Ü†(b':\el{B})‚Ü†\el{P\ (\sf{pair}\ A\ B\ a'\ b')}\\\\
     a : \el{A} \\ b : \el{B}
     }{
     \sf{case}_√ó\ A\ B\ P\ p\ (\sf{pair}\ A\ B\ a\ b)=
      p\ a\ b:P\ (\sf{pair}\ A\ B\ a\ b)}
     \end{mathpar}

     -----

     We extend the $‚ü¶.‚üß$ map with the following clause:
     \begin{flalign*}
     ‚ü¶A‚àßB‚üß‚âî‚ü¶A‚üß√ó‚ü¶B‚üß&&
     \end{flalign*}
     We show that $(p‚àßq‚Üíp)^*$ is a theorem in LF.
     \begin{mathpar}
     \inferrule[]{‚Ä¶ }{P:\set,Q:\set‚ä¢Œõx‚Üí\sf{case}_√ó\ P\ Q\ (Œª v‚Üí P)\ (Œªy‚ÜíŒªz‚Üíy)\ x:\el{(P√óQ)‚Ü£P}}
     \end{mathpar}
     Analogously, the proof for $(p‚àßq‚Üíq)^*$.
     \begin{mathpar}
     \inferrule[]{‚Ä¶ }{P:\set,Q:\set‚ä¢Œõx‚Üí\sf{case}_√ó\ P\ Q\ (Œª v‚Üí Q)\ (Œªy‚ÜíŒªz‚Üíz)\ x:\el{(P√óQ)‚Ü£Q}}
     \end{mathpar}
     Finally we show that $p‚Üí(q‚Üí(p‚àßq))^*$ is a theorem in LF.
     \begin{mathpar}
     \inferrule[]{‚Ä¶ }{P:\set,Q:\set‚ä¢Œõx‚ÜíÃãŒõy ‚Üí\sf{pair}\ P\ Q\ x\ y: \el{P‚Ü£Q‚Ü£(P√óQ)}}
     \end{mathpar}

**** Dependent functions set
     Dependent functions generalize regular functions in the way that the type
     of the return type depends on the argument value. More precisely, a
     dependent function is a map from elements of a set $A$ to elements of a set
     $B$ indexed by elements of $A$. Thus we introduce the following constant:
     \[‚áù:(A:\set)‚Ü†(B:\el{A}‚Ü†\set)‚Ü†\set\] *Notation*: We will use infix notation
     and write $A\ ‚áù\ B$ instead of $‚áù\ A\ B$. Also, $‚áù$ has right
     associativity.

     We add a constant to introduce elements in this set:
     \[Œõ' : (A:\set)‚Ü†(B:\el{A}‚Ü†\set)‚Ü†((a:\el{A})‚Ü†\el{B\ a})‚Ü† \el{A\ ‚áù\ B} \]

     We add an induction principle:
     \[\sf{case_Œõ}' : (A:\set)‚Ü†(B:\el{A}‚Ü†\set)‚Ü†(\el{A‚áùB})‚Ü† (a:\el{A})‚Ü†\el{B\ a} \]
     And the equality:
     \begin{mathpar}
     \inferrule[case$Œõ$']{
     f:\el{A}‚Ü†\el{B} }{\sf{case_Œõ}'\ A\ B\ (Œõ\ A\ B\ f)=f:(a:\el{A})‚Ü†\el{B\ a}}
     \end{mathpar}

     The following rules are redundant but they help keeping proofs shorter.
     \begin{mathpar}
     \inferrule[Intro$Œõ$']{f:(a:\el{A})‚Ü†\el{B\ a}}
     {Œõ\ A\ B\ f:\el{A‚áùB}}
     \and \inferrule[Abs$Œõ$']{x:A‚ä¢b:B\ x}
     {Œõ\ A\ B\ (Œªx‚Üíb):\el{A‚áùB}}
     \and \inferrule[App$Œõ$']{f:\el{A‚áùB} \\ a:\el{A}}
     {\sf{case_Œõ}\ f\ a : \el{B\ a}}
     \end{mathpar}
     *Notation*: When we have $f:\el{A‚áùB}$ and $a:\el{A}$ we will write $f\ a$
     instead of $\sf{case_Œõ'}\ f\ a$.

**** Œ£ Pairs set
      A $Œ£$ /pair/ generalizes the concept of a regular pair. In a $Œ£$ pair the type
      of the second component depends on the value of the first component.

      We introduce the constant for the set: \[Œ£ : (A : \set)‚Ü†(B : \el{A} ‚Ü†
      \set)‚Ü†\set\] We introduce a constant to build dependent pairs:
      \[\sf{pair}_Œ£ : (A : \set)‚Ü†(B : A ‚Ü† \set) ‚Ü† (a : \el{A})‚Ü†(b :
      \el{B\ a})‚Ü† Œ£\ A\ B\] The above constructor takes four arguments: The type
      of the first component, the type of the second component, the term for the
      first component, and the term for the second component. We add the
      following induction principle:
      \begin{flalign*}
      \sf{case}_Œ£:&(A:\set) ‚Ü† (B : \el{A}‚Ü†\set)‚Ü† (P : Œ£\ A\ B‚Ü†\set) \\
        &‚Ü† ((a:\el{A}) ‚Ü† (b:\el{B\ a})‚Ü†P\ (\sf{pair}_Œ£\ A\ B\ a\ b)) \\
        &‚Ü† (u : \el{Œ£\ A\ B})\\
        &‚Ü† \el{P\ u}
      \end{flalign*}
      We also add this equality.
      \begin{mathpar}
      \inferrule[]{P:\el{Œ£\ A\ B}‚Ü†\set\\\\
      p:(a':\el{A})‚Ü†(b':\el{B\ a'})‚Ü†\el{P\ (\sf{pair}_Œ£\ A\ B\ a'\ b')}\\\\
      a : \el{A} \\ b : \el{B\ a}
      }{
      \sf{case}_Œ£\ A\ B\ P\ p\ (\sf{pair}_Œ£\ A\ B\ a\ b)=
       p\ a\ b:P\ (\sf{pair}_Œ£\ A\ B\ a\ b)}
      \end{mathpar}

**** Natural numbers set
     We represent the set of natural numbers with the constant $‚Ñï$:
     \[‚Ñï:\set\]
     We add two constants to build elements in $‚Ñï$.
     \begin{flalign*}
     ùü¨ &: ‚Ñï\\
     \sf{suc}&: ‚Ñï‚Ü†‚Ñï
     \end{flalign*}
     We add an induction principle:
     \begin{flalign*}
     \sf{case}_‚Ñï:\ &(P:\el{‚Ñï}‚Ü†\set)\\
     ‚Ü†\ & \el{P\ ùü¨} \\
     ‚Ü†\ & ((n:\el{‚Ñï})‚Ü† \el{P\ n} ‚Ü† \el{P\ (\sf{suc}\ n)}) \\
     ‚Ü†\ & (a:\el{‚Ñï}) \\
     ‚Ü†\ & \el{P\ a}
     \end{flalign*}
     We add two equalities for the induction principle:
     \begin{mathpar}
     \inferrule[case 0]{P:\el{‚Ñï}‚Ü†\set \\ B:\el{P\ ùü¨}
     \\\\R:(n:\el{‚Ñï})‚Ü† \el{P\ n} ‚Ü† \el{P\ (\sf{suc}\ n)}}
     {\sf{case}_‚Ñï\ P\ B\ R\ ùü¨ =B:\el{P\ ùü¨}}
     \and \inferrule[case suc]{P:\el{‚Ñï}‚Ü†\set \\ B:\el{P\ ùü¨} \\ n:\el{‚Ñï}
     \\\\R:(n:\el{‚Ñï})‚Ü† \el{P\ n} ‚Ü† \el{P\ (\sf{suc}\ n)}}{\sf{case}_‚Ñï\ P\ B\ R\ (\sf{suc}\ n) =
      R\ n\ (\sf{case}_‚Ñï\ P\ B\ R\ n):\el{P\ (\sf{suc}\ n)}}
     \end{mathpar}

     -----

     Let us see how we can define addition:
     \[\sf{add}‚âîŒªn‚ÜíŒªm‚Üí\sf{case}_‚Ñï\ (Œªx‚Üí‚Ñï)\ m\ (Œªx‚ÜíŒªy‚Üí\sf{suc}\ y)\ n\]
     It is easy to show that indeed
     \[\sf{add}:\el{‚Ñï}‚Ü†\el{‚Ñï}‚Ü†\el{‚Ñï}\]
     Let us sketch the proof of $\sf{add}\ 1\ 2=3$.
     \begin{flalign*}
     \sf{add}\ 1\ 2 &= (Œªn‚ÜíŒªm‚Üí\sf{case}_‚Ñï\ (Œªx‚Üí‚Ñï)\ m\ (Œªx‚ÜíŒªy‚Üí\sf{suc}\ y)\ m)\ (\sf{suc}\ ùü¨)\ (\sf{suc}\ (\sf{suc}\ ùü¨)) &\\
     &= \sf{case}_‚Ñï\ (Œªx‚Üí‚Ñï)\ (\sf{suc}\ (\sf{suc}\ ùü¨))\ (Œªx‚ÜíŒªy‚Üí\sf{suc}\ y)\ (\sf{suc}\ ùü¨)&\textsc{Case suc} \\
     &= (Œªx‚ÜíŒªy‚Üí\sf{suc}\ y)\ ùü¨\ (\sf{case}_‚Ñï\ (Œªx‚Üí‚Ñï)\ (\sf{suc}\ (\sf{suc}\ ùü¨))\ (Œªx‚ÜíŒªy‚Üí\sf{suc}\ y)\ ùü¨)& Œ≤\text{-=} \\
     &= \sf{suc}\ (\sf{case}_‚Ñï\ (Œªx‚Üí‚Ñï)\ (\sf{suc}\ (\sf{suc}\ ùü¨))\ (Œªx‚ÜíŒªy‚Üí\sf{suc}\ y)\ ùü¨) &\textsc{Case }ùü¨\\
     &=\sf{suc}\ (\sf{suc}\ (\sf{suc}\ ùü¨)) &\\
     &=3
     \end{flalign*}

     In the next section we will see how we can use induction on the natural
     numbers to prove properties of addition.
**** Identity set
     <<sec:identity-set>>
     We denote the identity set (or equality set) with the $‚â°$ constant:
     \[‚â°\ : (S:\set)‚Ü†(x:\el{S})‚Ü†\el{S}‚Ü†\set\]
     *Notation*. We will write $A\ ‚â°_S\ B$ instead of $‚â°\ S\ A\ B$.

     We add the constant $\sf{refl}$ to build elements of this set.
     \[\sf{refl}\ : (S:\set)‚Ü†(x:\el{S})‚Ü†x‚â°_Sx\]

     We add an induction principle:
     \begin{flalign*}
     \sf{case_‚â°} :\ & (S:\set)‚Ü†(x:S)‚Ü† (y:\el{S})\\
       ‚Ü†\ &(P:(x':\el{S})‚Ü†(y':\el{S})‚Ü†\el{x'‚â°_Sy'}‚Ü†\set) \\
       ‚Ü†\ &((z:\el{S})‚Ü†\el{P\ z\ z\ (\sf{refl}\ S\ z)}) \\
       ‚Ü†\ & (e:\el{x‚â°_Sy}) \\
       ‚Ü†\ & \el{P\ x\ y\ e}
     \end{flalign*}
     We add one equality:
     \begin{mathpar}
     \inferrule[Case$‚â°$]{S:\set\\ a:\el{S} \\ y:\el{S} \\\\
     P:(x':\el{S})‚Ü†(y':\el{S})‚Ü†\el{x‚â°_Sy}‚Ü†\set
     \\\\ i:(z:\el{S})‚Ü†\el{P\ z\ z\ (\sf{refl}\ S\ z)} }
     {\sf{case_‚â°}\ S\ x\ y\ P\ i\ (\sf{refl}\ S\ x)=i\ a:\el{P\ x\ x\ (\sf{refl}\ S\ x)} }
     \end{mathpar}

     -----

     With this set we can build a type which states ``for every natural $n$, we
     have $n+0=n$''. Such type is as follows: \[(n:\el{‚Ñï})‚Ü† \el{\sf{add}\ n\ ùü¨
     ‚â°_‚Ñï n}\] If we were to prove this informally we would proceed as follows.
     Perform induction on $n$, for the base case is trivial, for the successor
     case $n=\sf{suc}m$ we have by IH that $\sf{add}\ m\ ùü¨=m$, then we apply
     $\sf{suc}$ on both sides of the IH, so we have $\sf{suc}\ (\sf{add}\ m\ ùü¨)=\sf{suc}\ m$
     which is equivalent to $(\sf{add}\ (\sf{suc}\ m)\ ùü¨)=\sf{suc}\ m$.

     In order to formalize the previous proof we will first show this lemma:
     \[(n:\el{‚Ñï})‚Ü†(m:\el{‚Ñï})‚Ü† \el{n‚â°_‚Ñïm}‚Ü†\el{\sf{suc}\ n‚â°_‚Ñï\sf{suc}\ m}\]
     In order to show that we build a term of the above type:
     \begin{flalign*}
     \sf{lemma} ‚âî Œªn‚ÜíŒªm‚ÜíŒªe‚Üí \sf{case_‚â°}\ &‚Ñï\ n\ m \\
           &(Œªn'‚ÜíŒªm'‚ÜíŒªe'‚Üí\sf{suc}\ n'‚â°_‚Ñï\sf{suc}\ m') \\
           & (Œªz‚Üí\sf{refl}\ ‚Ñï\ (\sf{suc}\ z))\\
           & e
     \end{flalign*}
     Let us explain the proof step by step. We start with three lambda
     abstractions as we have three arguments: two natural numbers and a proof of
     equality between them. Then we use the \sf{case_‚â°} primitive to build the
     desired proof. We now inspect each of the applied arguments. First we have
     $‚Ñï$ because the equalities in the proof are between naturals. Second and
     third we have $n$ and $m$ because they are the two involved naturals. Then
     we have the property that we want to show, namely $(Œªn'‚ÜíŒªm'‚ÜíŒªe'‚Üí\sf{suc}\
     n'‚â°_‚Ñï\sf{suc}\ m')$, we will refer to this term as $P$. After that we need
     to provide a term typed $(z:\el{S})‚Ü†\el{P\ z\ z\ (\sf{refl}\ S\ z)}$. In
     our case we need to replace $S$ by $‚Ñï$ and $P$ by the fourth argument.
     After simplifying with the \(\text{$Œ≤$-reduction}\) rule we get
     $(z:\el{‚Ñï})‚Ü†\el{\sf{suc}\ z‚â°_‚Ñï\sf{suc}\ z}$. We can easily see that
     $(Œªz‚Üí\sf{refl}\ ‚Ñï\ (\sf{suc}\ z))$ has the desired type. The last argument,
     $e$, which has type $\el{n‚â°_‚Ñïm}$ is the equality that we will use. Finally
     we see that the return type is $\el{P\ x\ y\ e}$. After replacing $P$ with
     its definition, $x$ by and $n$ and $y$ by $m$ and simplifying via the
     \(\text{$Œ≤$-reduction}\) rule we get $\el{\sf{suc}\ n‚â°_‚Ñï\sf{suc}\ m}$,
     which is what we wanted.

     We are now ready to prove the theorem. The term that serves as a proof of
     the theorem, or in other words the term that has the specified type, is
     provided below.
     \begin{flalign*}
     \sf{thm} ‚âî Œªn‚Üí \sf{case}_‚Ñï\ &(Œªn'‚Üí \sf{add}\ n'\ ùü¨ ‚â°_‚Ñïn')\\
                & (\sf{refl}\ ‚Ñï\ ùü¨) &\text{base case} \\
                & (Œªm‚Üí Œªp‚Üí \sf{lemma}\ (\sf{add}\ m\ ùü¨)\ m\ p) &\text{inductive case} \\
                & n
     \end{flalign*}
     Let us break the term \sf{thm} into smaller pieces and analyze them. Since
     we are proving that a property holds for any natural number, we start with
     a lambda abstraction $Œª n‚Üí ‚Ä¶$ and then we proceed by induction on $n$ by
     using the $\sf{case}_‚Ñï$ constant.

     The first argument of $\sf{case}_‚Ñï$, namely $(Œªn'‚Üí \sf{add}\ n'\ ùü¨ ‚â°_‚Ñïn')$,
     expresses the property that we want to prove abstracted over the term on
     which we perform the induction, in our case we abstract $n$ with the
     variable $n'$. We will refer to this argument as $P$. It is easy to observe
     that $P$ has type $\el{‚Ñï}‚Ü†\set$ as required by the type of $\sf{case}_‚Ñï$.

     Then, the second argument, which corresponds to the proof for the base case
     has type $\el{P\ ùü¨}$, which in our case translates into $(Œªn'‚Üí \sf{add}\
     n'\ ùü¨ ‚â°_‚Ñïn')\ ùü¨$ which is the same (by \(\text{$Œ≤$-reduction}\)) as
     $\el{\sf{add}\ ùü¨\ ùü¨ ‚â°_‚Ñïùü¨}$ which is the same (by \textsc{case 0}) as $\el{ùü¨
     ‚â°_‚Ñïùü¨}$. Thus it suffices to provide the term $\sf{refl}\ ‚Ñï\ ùü¨$, which has the desired
     type.

     The third argument corresponds to the proof of the inductive case. The type
     for this argument is[fn::We renamed the variable $n$ in this argument to
     $m$ to avoid confusion with the previously bound variable $n$. Recall that
     this can be done thanks to the \(\text{$Œ±$-$=$}\) rule.] $((m:\el{‚Ñï})‚Ü†
     \el{P\ m} ‚Ü† \el{P\ (\sf{suc}\ m)})$ which in our case translates into
     $((m:\el{‚Ñï})‚Ü† \el{\sf{add}\ m\ ùü¨ ‚â°_‚Ñïn} ‚Ü† \el{\sf{add}\ (\sf{suc}\ m)\ ùü¨
     ‚â°_‚Ñï\sf{suc}\ m})$. It is easy to see that the lemma we proved before will
     come in handy. In fact, it suffices to observe that the term $(Œªm‚Üí Œªp‚Üí
     \sf{lemma}\ (\sf{add}\ m\ ùü¨)\ m\ p)$ has the desired type. This concludes
     the proof of the inductive case.

     Finally, the fourth argument is the specific natural number for which we
     want to perform the induction and prove the property. We just give it $n$,
     which is bound by the initial $Œªn‚Üí‚Ä¶$. This concludes our proof.

*** Main differences with Agda's type system
    <<sec:lof-agda>> In this section we briefly highlight some of the
    differences between LF and Agda.

    *Hierarchy of sets*. The most important difference between LF and Agda is
    that Agda does not has the concepts of \type{} and \set{}, where
    $\set{}:\type$. For instance, in LF we do not have an answer to ``what is
    the type of \type{}?''. Agda solves this problem an infinite hierarchy of
    sets $\set‚ÇÄ:\set‚ÇÅ:‚Ä¶$. It is important to note that the word $\type$ does not
    exist in Agda, instead, there is only the hierarchy of sets. For instance,
    small types such as the type of natural numbers reside in $\set‚ÇÄ$.
    Predicates on natural numbers reside in $\set‚ÇÅ$, and so on. For a more
    detailed description we refer the reader to
    cref:sec:universe-hierarchy,sec:agda-doc-universes.

    *Extensible language*. Agda allows the introduction of new types within the
    language. Of course, in order to avoid bogus types that could cause the
    soundness of the system to be compromised, the types defined by the user are
    subject to some restrictions. For instance, positivity checking
    (cref:sec:positivity).

    *Pattern matching*. Agda has a generic way, called pattern matching, to
    deconstruct terms and do case splits based on the constructors of the
    corresponding type. We refer the reader to cref:sec:basic-agda for more
    information.

    *Induction by proof of termination*. Agda does not have explicit induction
    principles. In Agda, recursive calls and induction hypotheses are the same.
    In order to ensure that the system remains sound Agda checks for termination
    on the recursive calls, which is the same as saying that we use the
    induction hypotheses on something provably smaller.

*** Towards Agda :noexport:
    We have seen a formal definition of a system based on dependent types. But
    how do we go from LF to Agda? That is an answer that we cannot fully answer
    here, but we will give some pointers in that direction.

    *Type checking algorithm*. Of course, we want the proof assistant to tell us
    if a proof we wrote is indeed correct (according to the system). For that,
    we need to provide an algorithm that checks if a term has a given type.


    With this we conclude the presentation of Martin's L√∂f logical framework.
    Talk about operational semantics.

** Basic Agda
   <<sec:basic-agda>>

   This part of the thesis is not meant to be an exhaustive analysis of the inner
   workings of Agda, as this falls out of the scope of this thesis. The original
   author of Agda, Ulf Norell, has suggested[fn::In correspondence via email.]
   cite:cockx2018elaborating as a good reference for that purpose.

   In this chapter we precisely define a moderate subset of Agda. We have tried
   to remain faithful to the semantics of the real Agda language, however, this
   is an incomplete simplification and thus is not meant to be a reference for
   the real Agda language.
   # We comment on some of the
   # simplifications in cref:sec:agda-limitations.

   We introduce several concepts that have cyclic dependencies and thus a linear
   presentation is not possible.

   {{{begindef}}} *Identifier*. An identifier is a sequence of characters which
   do not contain any white space or parentheses (normal =()= or curly ={}=) and
   furthermore it is different than all reserved keywords. Some identifier
   examples are =a=, =x=, =¬¨¬¨x=, =A‚ñ∑B=, =A‚ÜíB=, =Some-Long-Word=. For all
   practical purposes, we can assume we have an infinite set of identifiers.

   Some of the Agda reserved keywords are =Œª=, =‚àÄ=, =‚Üí=, ===,
   =data=, =where=, =:=.

   It is worth noting that syntactically constructors and identifiers are
   subject to the same rules. Agda detects constructors by using the datatype
   definitions in scope. For more information on constructors see the definition
   of a datatype in cref:def:agda-datatype.
   {{{enddef}}}

   {{{begindef}}} <<def:agda-term>> *Term/Type*. An Agda term is recursively
   defined as shown in the figure below.

   We use =x= to denote an arbitrary identifier, we use =p‚ÇÅ=, ‚Ä¶, =p‚Çô= to denote
   arbitrary patterns (see cref:def:agda-pattern), we use =A,=, =B=, =A‚ÇÅ=,
   =‚Ä¶=, =A‚Çô= to denote arbitrary terms and we use =c= to denote an arbitrary
   constructor (see cref:def:agda-constructor).

   # #+caption: The syntax of terms (and types).
   #+name: fig:agda-term
   #+attr_latex: :align llll :float t :center t :placement [H]
    | $term$ | $‚âî$   | =x=                        | identifier;                               |
    |        | \vert | =(x : A) ‚Üí B=              | function type;                            |
    |        | \vert | =Œª x ‚Üí A=                  | lambda abstraction;                       |
    |        | \vert | =Œª {p‚ÇÅ ‚Üí A‚ÇÅ; ‚Ä¶ ; p‚Çô ‚Üí A‚Çô}= | lambda abstraction with pattern matching; |
    |        | \vert | =A B=                      | function application;                     |
    |        | \vert | =Set ‚Ñì=                    | universe $(‚Ñì‚ààœâ)$.                         |
   We say that an Agda term =A= is a *type* if we have =A : Set ‚Ñì= for some =‚Ñì=.
   In cref:def:agda-well-typed we give a description of the typing relation =:=.
   We want to emphasize, and it is clear from the definition, that all types
   are also terms.

   The =‚Üí= in the function type has right associativity, hence =(a : A) ‚Üí (b :
   B) ‚Üí C= is the same as =(a : A) ‚Üí ((b : B) ‚Üí C)=. The =‚Üí= in the lambda
   abstraction extends to the rightmost part, hence =Œª x ‚Üí Œª y ‚Üí A B= is the
   same as =(Œª x ‚Üí (Œª y ‚Üí A B))=. Function application has left associativity,
   hence =a b c= is the same as =(a b) c=. Also note that the =i= in =Set i= can
   be an identifier but for simplicity in this chapter we restrict the =i= to be
   an arbitrary constant natural number.

   An example term:
   #+begin_example
   Œª (A : Set 0) ‚Üí Œª (B : Set 0) ‚Üí (f : A ‚Üí B) ‚Üí (a : A) ‚Üí B
   #+end_example
   {{{enddef}}}

  {{{begindef}}} *Function definition*. A function definition is used to bind a
  new[fn::By new we mean that is has not yet been bound by another definition.]
  identifier to a term.

  /Note/: Maybe the name ``term definition'' or ``term binding'' would be more
  appropriate for the concept defined here. We have decided to use the name
  ``Function definition'' since it is widely used in the field of computer
  science.

  # #+name: fig:agda-fundef
  # #+attr_latex: :align llll :float t :center t :placement [H]
  # | $fundef$ | $‚âî$ | =x : term= | function def; |
  # |          |     | =x = term= |               |

  Below we present two schemas of function definitions:
  #+begin_example
  x : T
  x = A

  y : T'
  y = A'
  #+end_example
  The above code should read as: The identifier =x= is bound to =A=, which is a
  term of type =T=. Likewise, the identifier =y= is bound to =A'= which is a
  term of type =T'=.

  Note that =A : T= and =A' : T'= must be valid according to the typing rules
  (see cref:sec:typing-rules).

  Function definitions are evaluated in order, thus, in =T'= and in =A'= we can
  refer to =x=. However, neither in =A= or =T= we can refer to =y=.

  Recursive references are allowed in the term, thus we can refer to =x= in =A=.
  Likewise we can refer to =y= in =A'=.

  Also note that we cannot bind the same identifier twice.
  {{{enddef}}}

  {{{begindef}}} <<def:agda-constructor>> <<def:agda-datatype>> *Datatype
  definition*. Datatype definitions are used to introduce new terms/types to the
  language. We call datatypes the types which have been defined using a datatype
  definition. For instance, we would use a datatype definition to define a type
  representing the natural numbers.

  The general form of the definition of a datatype =D= is the following:
  #+begin_example
    data D (x‚ÇÅ : P‚ÇÅ) ‚Ä¶ (x‚Çñ : P‚Çñ) : (y‚ÇÅ : Q‚ÇÅ) ‚Üí ‚Ä¶ ‚Üí (y‚Çó : Q‚Çó) ‚Üí Set ‚Ñì where
      c‚ÇÅ : T‚ÇÅ
      ‚Ä¶
      c‚Çô : T‚Çô
    #+end_example
  Note that $k‚â•0$, $l‚â•0$ and $n‚â•0$.
  We distinguish the following parts of the declaration:
  1. /Name/. =D= is an identifier, which is the name of the newly introduced
     datatype. =D= is assigned the following type and is brought into scope:
     #+begin_example
     (x‚ÇÅ : P‚ÇÅ) ‚Üí ‚Ä¶ ‚Üí (x‚Çñ : P‚Çñ) ‚Üí (y‚ÇÅ : Q‚ÇÅ) ‚Üí ‚Ä¶ ‚Üí (y‚Çó : Q‚Çó) ‚Üí Set ‚Ñì
     #+end_example
     By bringing =D= into scope we mean that =D= can be referenced in the
     constructor types =T‚ÇÅ=, ‚Ä¶, =T‚Çô=, also in subsequent datatypes definitions
     and in terms defined after the definition of the datatype =D=.
  2. /Indices/. =(y‚ÇÅ : Q‚ÇÅ) ‚Ä¶ (y‚Çó : Q‚Çó)= are the indices of the datatype. For any
     $i‚àà\{1,‚Ä¶,l\}$ we have that:
     1. =y·µ¢= is an identifier with associated type =Q·µ¢=;
     2. the type =Q·µ¢= can reference =x‚±º= for any $j‚àà\{1,‚Ä¶,k\}$;
     3. if $i>1$ we have that the type =Q·µ¢= can reference any =y‚±º= for $j<i$.
  3. /Parameters/. =(x‚ÇÅ : P‚ÇÅ) ‚Ä¶ (x‚Çñ : P‚Çñ)= are the parameters of the datatype.
     For every $i‚àà\{1,‚Ä¶,k\}$ we have that:
     1. =x·µ¢= is an identifier with associated
        type =P·µ¢=;
     2. if $i>1$ we have that the type =P·µ¢= can reference any =x‚±º= for $j<i$.
  4. /Constructors/. =c‚ÇÅ ‚Ä¶ c‚Çô= are identifiers, which we call the constructors
     of the datatype. For every $i‚àà\{1,‚Ä¶,n\}$ we have that:
     1. =T·µ¢= is the type of the constructor =c·µ¢=.
     2. =T·µ¢= has to be of the form
       #+begin_example
       (z‚ÇÅ : B‚ÇÅ) ‚Üí ... ‚Üí (z‚Çò : B‚Çò) ‚Üí D x‚ÇÅ ‚Ä¶ x‚Çñ t‚ÇÅ ‚Ä¶ t‚Çó
     #+end_example
        Where for every $i‚àà\{1,‚Ä¶,l\}$ we have that =t·µ¢ : Q·µ¢=, furthermore =t·µ¢=
        can refer to =z‚±º= for any $j‚àà\{1,‚Ä¶,m\}$.

        If we focus on the return type[fn::The rightmost term which is not a
        function type.] of =c·µ¢=, namely =D x‚ÇÅ ‚Ä¶ x‚Çñ t‚ÇÅ ‚Ä¶ t‚Çó=, we see that the
        first $k$ arguments to =D= are required to be precisely the parameters
        of =D=, while the remaining $l$ arguments, the indices, can be any terms
        =t‚ÇÅ=, ‚Ä¶, =t‚Çó= of type =Q‚ÇÅ=, ‚Ä¶, =Q‚Çó= respectively and may vary for each
        constructor. For that reason, we say that parameters are shared among
        all constructors, while indices are specified on a constructor basis.
        Refer to cref:sec:agda-ref-datatype for a meaningful example.

     The following is fundamental: the only way to build a term of type =D x‚ÇÅ ‚Ä¶
     x‚Çñ t‚ÇÅ ‚Ä¶ t‚Çó= is to build a term of the form =c·µ¢ w‚ÇÅ ... w‚Çò=, for some
     $i‚àà\{1,‚Ä¶,n\}$, assuming =c·µ¢= is declared to have the type =(z‚ÇÅ : B‚ÇÅ) ‚Üí ...
     ‚Üí (z‚Çò : B‚Çò) ‚Üí D x‚ÇÅ ‚Ä¶ x‚Çñ t‚ÇÅ ‚Ä¶ t‚Çó= and =w‚ÇÅ=, ... =w‚Çò= are terms of type =B‚ÇÅ=,
     ... =B‚Çò= respectively.

     There are no datatypes or constructors which are inherent to the language,
     thus, every datatype and constructor will be defined by the user in a
     datatype definition.
  {{{enddef}}}

  {{{begindef}}} <<def:agda-pattern>> *Pattern*. A pattern is recursively
  defined as follows. We use =p‚ÇÅ,= ‚Ä¶, =p‚Çô= to denote patterns.
  #+name: fig:agda-pattern
  #+attr_latex: :align llll :float t :center t :placement [H]
  | $pattern$ | $‚âî$   | =c p‚ÇÅ ‚Ä¶ p‚Çô= | constructor of arity =n ‚â• 0=; |
  |           | \vert | =x=         | identifier.                   |
  A pattern cannot contain repeated identifiers. We define $ids(p)$ to be the
  set of identifiers that appear in a pattern.

  Note that patterns of the form =c p‚ÇÅ ‚Ä¶ p‚Çô= for $n‚â•1$ must be surrounded by
  parentheses. {{{enddef}}}

  {{{begindef}}} *Module*. A module is a sequence of function definitions and
  datatype definitions. Each function definition exposes the bound identifier to
  the subsequent definitions. Each datatype definition exposes the name of the
  datatype and its constructors to the subsequent definitions.

  #+name: fig:agda-module
  #+attr_latex: :align llll :float t :center t :placement [H]
  | $module$ | $‚âî$   | =fundef ‚Üµ module=  | function definition; |
  |          | \vert | =datadef ‚Üµ module= | datatype definition; |
  |          | \vert |                    | empty.               |
  The =‚Üµ= symbol represents a line break.


  An example module which contains a definition of the =Bool=
  datatype and the =not= function:
  #+begin_example
    data Bool : Set 0 where
      true : Bool
      false : Bool

    not : (b : Bool) ‚Üí Bool
    not = Œª { false ‚Üí true; true ‚Üí false}
  #+end_example
  {{{enddef}}}

  # {{{begindef}}} *Well-scoped term*. A well-scoped term is a term where every
  # identifier in it is bound. In other words, there are no free identifiers.

  # The set of free identifiers is defined as usual (following the syntax defined
  # in cref:def:agda-term):
  # \begin{flalign*}
  # &free(x) ‚âî ‚àÖ  &\text{if identifier $x$ is bound.} \\
  # &free(x) ‚âî \{x\} &\text{otherwise.}  \\
  # &free(Œªx‚ÜíA) ‚âî free(A)‚àñ\{x\}  \\
  # &free(Œª\ \{\ p‚ÇÅ‚ÜíA‚ÇÅ;\ ‚Ä¶;\ p‚Çô‚ÜíA‚Çô\}) ‚âî ‚ãÉ_{i}\Big(free(A·µ¢)‚àñids(p·µ¢)\Big)  \\
  # &free(A\ B) ‚âî free(A)‚à™free(B)  \\
  # &free(Set\ i) ‚âî ‚àÖ  \\
  # \end{flalign*}

  # We always assume terms to be well-scoped.
  # {{{enddef}}}

*** Contexts, and typing rules
    <<sec:typing-rules>>

    {{{begindef}}} *Context*. A context is a pair of (finite) sets $‚ü®Œ§,Œî‚ü©$. The
    set $Œ§$ consists of pairs $‚ü®identifier:type‚ü©$. It is used to keep track of
    what identifiers are bound and what is their type. The set $Œî$ consists of
    pairs $‚ü®identifier=term‚ü©$ which are the identifiers which have been assigned
    a term through a function definition.

    In order to simplify things we assume that there is no /shadowing/, which
    means that an identifier which is already bound in the current context
    cannot be bound again. Thus, the term =Œª x ‚Üí Œª x ‚Üí x= would be invalidated
    by this assumption since the identifier =x= is rebound by the second lambda
    function. This restriction is not a limiting as we can always rename our
    identifiers to De Bruijn indices (cite:de1972lambda), which guarantee this
    assumption.

    *Notation*. We refer to contexts by a single letter, thus if $Œì=‚ü®Œ§,Œî‚ü©$ we
    abuse notation and write $a:t‚ààŒì$ instead of $‚ü®a:t‚ü©‚ààŒ§$ and $a=t‚ààŒì$ instead of
    $‚ü®a=t‚ü©‚ààŒî$. Also, we use $Œì;t:A$ as short for $‚ü®Œ§ ‚à™\{‚ü®t:A‚ü©\},Œî‚ü©$.
    {{{enddef}}}

    {{{begindef}}} <<def:agda-well-typed>> *Well-typed term (and patterns)*. We
    say that a term $t$ is well-typed in context $Œì$ if $Œì‚ä¢t:A$ for some type
    $A$. The rules for $‚ä¢$ are presented below. We also define the relation
    $‚ä¢_{Œ°}$, which is for typing patterns. For that purpose we need an auxiliary
    function definition, $œÑ$, which is defined afterwards.

    The structure of a module implicitly assigns a context to each term in it.
    We usually use the concept of well-typed term in the context of a module, in
    that case, we implicitly refer to the context assigned by the structure of
    the module. See cref:def:agda-check-module for a thorough explanation.
    {{{enddef}}}

   #+caption: Typing rules for terms.
   #+name: fig:type
   #+attr_latex: :float
   \begin{figure}[H]
   \begin{mathpar}
   \inferrule[Id]{t : A ‚àà Œì}{Œì ‚ä¢ t : A}
   \and
   \inferrule[Level]{\ }{Œì‚ä¢Set\ i : Set\ (i+1)}
   \and
   \inferrule[Arrow]{Œì ‚ä¢ A:Set\ i \\ Œì; x:A ‚ä¢ B : Set\ j}{Œì ‚ä¢ (x:A)‚ÜíB:Set\ (i‚äîj)}
   \\
   \inferrule[Abstraction]{x:A; Œì ‚ä¢ t:B }{Œì‚ä¢Œªx‚Üít:(x:A)‚ÜíB}
   \and
   \inferrule[Application]{Œì‚ä¢f:(x:A)‚ÜíB \\ Œì‚ä¢a:A }{Œì‚ä¢f\ a : B[x‚Ü¶t]}
   \\
   \inferrule[Pattern abstraction]{\text{Let } \overline{D}‚âîD\ x‚ÇÅ\ ‚Ä¶\ x‚Çô\ t‚ÇÅ\ ‚Ä¶\ t‚Çô \\\\
     Œì‚ä¢_{Œ°}p‚ÇÅ:\overline{D} \\ ‚Ä¶ \\  Œì‚ä¢_{Œ°}p‚Çô:\overline{D} \\\\
     Œì‚à™œÑ(Œì,\overline{D},p‚ÇÅ)‚ä¢ s‚ÇÅ:B[x‚Ü¶p‚ÇÅ] \\ ‚Ä¶ \\ Œì‚à™œÑ(Œì,\overline{D},p‚Çô)‚ä¢ s‚Çô:B[x‚Ü¶p‚Çô]}
     {Œì‚ä¢Œª\ \{p‚ÇÅ ‚Üís‚ÇÅ;\ ‚Ä¶\ ;\ p‚Çô‚Üís‚Çô\}:(x:\overline{D})‚ÜíB}
   \end{mathpar}
   \end{figure}

   #+caption: Typing rules for patterns.
   #+name: fig:pat-type-rules
   #+attr_latex: :float
   \begin{figure}[H]
   \begin{mathpar}
   \inferrule[Identifier]{\ }{Œì‚ä¢_{Œ°}x : A}
   \\
   \inferrule[Constructor]{c:(b‚ÇÅ:B‚ÇÅ)‚Üí‚Ä¶‚Üí(b‚Çô:B‚Çô)‚ÜíD\ x‚ÇÅ\ ‚Ä¶\ x‚Çô\ t‚ÇÅ\ ‚Ä¶\ t‚Çô ‚ààŒì \\\\
     ‚àÄi‚àà\{1,‚Ä¶,n-1\}.\ Œì‚ä¢_Œ°p·µ¢:B·µ¢[b‚ÇÅ‚Ü¶p‚ÇÅ, ‚Ä¶,b_{i-1}‚Ü¶p_{i-1}]   }{Œì‚ä¢_Œ°c\ p‚ÇÅ\ ‚Ä¶\ p‚Çô : D\ x‚ÇÅ\ ‚Ä¶\ x‚Çô\ t‚ÇÅ\ ‚Ä¶\ t‚Çô}
   \end{mathpar}
   \end{figure}

   Let $\overline{D}‚âîD\ x‚ÇÅ\ ‚Ä¶\ x‚Çô\ t‚ÇÅ\ ‚Ä¶\ t‚Çô$. We now define
   $œÑ(Œì,\overline{D},p)$, which is the set of identifiers bound by pattern $p$
   paired with their respective types. Assume that $Œì‚ä¢_{Œ°}p:\overline{D}$.
   Finally, let $œÑ$ be defined as follows:
  \begin{flalign*}
  &œÑ(Œì,\overline{D},x)‚âî \{x:\overline{D}\} & \text{Identifier} \\
  &œÑ(Œì,\overline{D},c\ p‚ÇÅ\ ‚Ä¶\ p‚Çô)‚âî œÑ(Œì,p‚ÇÅ,B‚ÇÅ)‚à™‚Ä¶‚à™œÑ(Œì,p‚Çô,B‚Çô) & \text{Constructor} \\
  &\hspace{3.5cm} \text{assuming } c:(b‚ÇÅ:B‚ÇÅ)‚Üí‚Ä¶‚Üí(b‚Çô:B‚Çô)‚Üí\overline{D}‚ààŒì
  \end{flalign*}

  # The precise typing rule for the lambda abstraction with patterns falls out
  # of the scope of this thesis. We ask the reader to refer to Chapter 2 of
  # cite:norell:thesis for that purpose. Here we present a simplification.
  # {{{jan(pending.)}}}

  {{{begindef}}} <<def:agda-check-module>> *Scoping and type checking a module*.
  We understand by /scoping/ the process of implicitly assigning a context to
  each part of the module. We understand by /type checking/ the process of
  checking that all terms in a module are well-typed (in their corresponding
  context) and respect the typing annotations. These processes are tightly tied
  and thus we describe them together.

    # By respecting the
    # typing annotations we mean that if we have the following definition:
    # #+begin_example
    # x : A
    # x = t
    # #+end_example
    # Then we need check that =t= is well-typed and furthermore has type =A=.

    It may be worth noticing that sometimes the annotation =x : A= may be
    redundant since the type of =t= can be automatically inferred to be =A= from
    the rules. Type inference is widely used in the real Agda language, however,
    in this presentation we skip it for simplicity.

    However, for simplicity we do not differentiate between type inference
    and type checking. assume that the annotation is always required.

    The process of type-checking a module is as follows:
    1. At the beginning of a module we start with an empty context $Œì ‚âî ‚àÖ$.
    2. We look at the next definition.
       - If it is a *function definition*, it is of the form
         #+begin_example
         x : A
         x = t
         #+end_example
         Check there is some $‚Ñì$ such that $Œì‚ä¢A:Set\ ‚Ñì$. Then let $Œì'‚âîŒì;x:A$
         and check $Œì'‚ä¢t:A$.

         We repeat step 2 with context $Œì'$.
       - If it is a *datatype definition*, it is the form
           #+begin_example
       data D (x‚ÇÅ : P‚ÇÅ) ‚Ä¶ (x‚Çñ : P‚Çñ) : (y‚ÇÅ : Q‚ÇÅ) ‚Üí ‚Ä¶ ‚Üí (y‚Çó : Q‚Çó) ‚Üí Set ‚Ñì where
         c‚ÇÅ : T‚ÇÅ
         ‚Ä¶
         c‚Çô : T‚Çô
           #+end_example
           where each =T·µ¢= is of the form
           #+begin_example
           (z‚ÇÅ : B‚ÇÅ) ‚Üí ‚Ä¶ ‚Üí (z‚Çò : B‚Çò) ‚Üí D x‚ÇÅ ‚Ä¶ x‚Çñ t‚ÇÅ ‚Ä¶ t‚Çó
         #+end_example

         We check that:
         1. For each parameter =x·µ¢ : P·µ¢= check that for some $Œµ‚â§‚Ñì$ we have
            \[Œì;x‚ÇÅ:P‚ÇÅ;‚Ä¶;x_{i-1}:P_{i-1}‚ä¢P·µ¢:Set\ Œµ.\]
         2. Then let
            \begin{flalign*}
             Œì'‚âî&Œì;x‚ÇÅ : P‚ÇÅ; ‚Ä¶; x‚Çñ : P‚Çñ; \\
               &D : (x‚ÇÅ : P‚ÇÅ) ‚Üí ‚Ä¶ ‚Üí (x‚Çñ : P‚Çñ) ‚Üí (y‚ÇÅ : Q‚ÇÅ) ‚Üí ‚Ä¶ ‚Üí (y‚Çó :
              Q‚Çó) ‚Üí Set\ ‚Ñì.
            \end{flalign*}
             # \[Œì'‚âîŒì;x‚ÇÅ : P‚ÇÅ; ‚Ä¶; x‚Çñ : P‚Çñ;D : (x‚ÇÅ : P‚ÇÅ) ‚Üí ‚Ä¶ ‚Üí (x‚Çñ : P‚Çñ) ‚Üí (y‚ÇÅ : Q‚ÇÅ) ‚Üí ‚Ä¶ ‚Üí (y‚Çó :
             #  Q‚Çó) ‚Üí Set\ ‚Ñì. \]
            For each $i‚àà\{1,‚Ä¶,n\}$ check that
            \[Œì'‚ä¢ (z‚ÇÅ : B‚ÇÅ) ‚Üí ‚Ä¶ ‚Üí (z‚Çò : B‚Çò) ‚Üí D\ x‚ÇÅ\ ‚Ä¶\ x‚Çñ\ t‚ÇÅ\ ‚Ä¶\ t‚Çó : Set\ ‚Ñì.\]
            # #+begin_example
            # c·µ¢ : (z‚ÇÅ : B‚ÇÅ) ‚Üí ‚Ä¶ ‚Üí (z‚Çò : B‚Çò) ‚Üí D x‚ÇÅ ‚Ä¶ x‚Çñ t‚ÇÅ ‚Ä¶ t‚Çó
            # #+end_example
            #  We check that for all
            # $j‚àà\{1,‚Ä¶,m\}$ there is some $Œµ‚â§‚Ñì$ such that
            # \[Œì';x‚ÇÅ:P‚ÇÅ;‚Ä¶;x_{k}:P_{k}‚ä¢B_j :Set\ Œµ.\] Furthermore, for all
            # $j‚àà\{1,‚Ä¶,l\}$ we check that
            # \[Œì';x‚ÇÅ:P‚ÇÅ;‚Ä¶;x_{k}:P_{k};z‚ÇÅ:B‚ÇÅ;‚Ä¶;z‚Çò:B‚Çò;t‚ÇÅ:Q‚ÇÅ;‚Ä¶;t_{j-1}:Q_{j-1}‚ä¢
            # t‚±º:Q‚±º. \]
            Then let
            \begin{flalign*}
             Œì''‚âî&Œì;\\
              &D : (x‚ÇÅ : P‚ÇÅ) ‚Üí ‚Ä¶ ‚Üí (x‚Çñ : P‚Çñ) ‚Üí (y‚ÇÅ : Q‚ÇÅ) ‚Üí ‚Ä¶ ‚Üí (y‚Çó :
              Q‚Çó) ‚Üí Set\ ‚Ñì; \\
              &c‚ÇÅ : (z^1‚ÇÅ : B^1‚ÇÅ) ‚Üí ‚Ä¶ ‚Üí (z^1‚Çò : B^1‚Çò) ‚Üí D\ x‚ÇÅ\ ‚Ä¶\ x‚Çñ\ t^1‚ÇÅ\ ‚Ä¶\ t^1‚Çó; \\
              & ‚ãÆ \\
              &c‚Çô : (z^n‚ÇÅ : B^n‚ÇÅ) ‚Üí ‚Ä¶ ‚Üí (z^n‚Çò : B^n‚Çò) ‚Üí D\ x‚ÇÅ\ ‚Ä¶\ x‚Çñ\ t^n‚ÇÅ\ ‚Ä¶\ t^n‚Çó
            \end{flalign*}
            and continue to step 2 with context $Œì''$.
    {{{enddef}}}
*** Normalization
    <<sec:agda-normalization>> Normalization is refers to the process of
    simplifying or evaluating a term via rewrite rules.

    In real Agda normalization is done at the same time as type-checking via an
    involved algorithm (see Section 3.3.2 of cite:norell:thesis). Here we
    present a collection normalization rules which are detached from the
    type-checking process. Our aim is to provide an intuition of how well-typed
    terms are simplified automatically in Agda rather than giving details of the
    algorithm.

    The reader may be already acquainted with the \textsc{$Œ≤$-reduction} rule,
    which is present in untyped lambda calculus, the most basic form of lambda
    calculus. Here we present the mentioned rule among others. We use the
    notation $Œî‚ä¢_Nt‚Üìt'$ to say that term $t$ normalizes to term $t'$ in context
    $Œî$. We extend the definition of context to also contain all the pairs
    $‚ü®identifier=term‚ü©$ which are defined in a function definition above in the
    module. To be more precise, now a context consists of two sets: One contains
    the typing relations $‚ü®identifier:term‚ü©$ and the other contains the binding
    relations $‚ü®identifier=term‚ü©$.

    Normalization can happen in nested terms. For instance, if we have that
    $t‚Üìt'$ then $Œª x‚Üí t‚ÜìŒªx‚Üít'$. Likewise for the other kinds of terms.

    In the rule \textsc{Match} we use the notation $‚àÉ^{min}i$ to mean that in
    case there exist multiple values for $i$ such that the function
    $match(p·µ¢,b)$ succeeds and returns a substitution $œÉ$, then we must take the
    minimum of such \text{$i$s}. In other words, we check patterns in order and
    we use the first that succeeds.

    We use $a,b,c,t$ to denote arbitrary terms and $x,f$ to denote arbitrary
    identifiers.
   #+caption: Normalization rules for terms.
   #+name: fig:normalization
   #+attr_latex: :float
    \begin{figure}[H]
    \begin{mathpar}
    \inferrule[$Œ≤$-reduction]{\ }{Œî‚ä¢_N(Œª x ‚Üí t)\ a‚Üìt[x‚Ü¶a] } \and
    \inferrule[Transitivity]{Œî‚ä¢_Na‚Üìb \\ Œî‚ä¢_Nb‚Üìc }{Œî‚ä¢_Na‚Üìc} \and
    \inferrule[Definition]{f=t‚ààŒî  }{Œî‚ä¢_Nf‚Üìt}
    \\
    \inferrule[Match]{Œî‚ä¢_Na‚Üìb \\ ‚àÉ^{min}i.match(p·µ¢,b)=œÉ  }{Œî‚ä¢_NŒª\ \{p‚ÇÅ‚Üít‚ÇÅ;‚Ä¶;p‚Çô‚Üít‚Çô\}\ a‚ÜìœÉ(t·µ¢)}
    \end{mathpar}
    \end{figure}

    Here we define the partial function $match$, which takes a pattern and a
    term, then either fails or returns a substitution. We represent a substitution
    by a set of pairs of the form $‚ü®x‚Ü¶t‚ü©$, which means ``replace identifier $x$
    by term $t$''. Keep in mind that a pattern does not contain repeated
    identifiers, so the result (if it succeeds) of $match$ is a proper function.
    \begin{flalign*}
    &match(x, t)‚âî \{‚ü®x‚Ü¶t‚ü©\} \\
    &match(c\ p‚ÇÅ\ ‚Ä¶\ p‚Çô, c'\ t‚ÇÅ\ ‚Ä¶\ t‚Çô)‚âî \begin{cases}
             ‚ãÉ_i(match(p·µ¢,t·µ¢)) & \text{if $c=c'$ and all recursive calls succed;}  \\
             \text{fail} & \text{otherwise.}\end{cases}
    \end{flalign*}

    Some examples for the \textsc{$Œ≤$-reduction} rule:
    \begin{flalign*}
    &Œª y ‚Üí (Œªx‚Üíx)\ y ‚Üì Œª y ‚Üí y & \\
    &(Œªx‚Üíx)\ a ‚Üì a &
    \end{flalign*}
    To see examples for the \textsc{Match} rule assume we have the following
    definition in scope:
    #+begin_example
    data Nat : Set 0 where
      zero : Nat
      suc : Nat ‚Üí Nat

    plus : Nat ‚Üí Nat ‚Üí Nat
    plus = Œª { zero ‚Üí (Œª b ‚Üí b); (suc a) ‚Üí (Œª b ‚Üí suc (plus a b) ) }
    #+end_example
    Then see that the term =plus zero= normalizes to the identity function:
    \begin{flalign*}
    &plus\ zero‚ÜìŒª b ‚Üí b &
    \end{flalign*}

    As another example, see that the term =plus (suc zero)= normalizes to =Œª b ‚Üí
    suc b=. We present this example step by step.
    \begin{flalign*}
    plus\ (suc\ zero)&‚Üì &\textsc{Def}
    \\ Œª\ \{ zero ‚Üí (Œª b ‚Üí b);\ (suc\ a) ‚Üí (Œª b ‚Üí suc\ (plus\ a\ b) )\}\ (suc\ zero)& ‚Üì & \textsc{Match}
    \\ Œª b ‚Üí suc\ (plus\ zero\ b) &‚Üì & \textsc{Def}
    \\ Œª b ‚Üí suc\ ((Œª b' ‚Üí b')\ b) &‚Üì &\textsc{$Œ≤$-reduction}
    \\ Œª b ‚Üí suc\ b
    \end{flalign*}


    {{{begintheorem}}}
    Normalization is type-preserving.
    \begin{figure}[H]
    \begin{mathpar}
    \inferrule[]{Œì‚ä¢_N t‚Üìt' \\ Œì‚ä¢t:A }{Œì‚ä¢t':A }
    \end{mathpar}
    \end{figure}
    {{{endtheorem}}}
    {{{beginproof}}}
    By an easy proof by induction.
    {{{endproof}}}

*** Totality
    <<sec:agda-totality>>
    In order to be a sound system, Agda requires all of its terms to be
    total. Thus, it needs to assure that:
    1. Every lambda abstraction with pattern matching of the form =Œª {p‚ÇÅ ‚Üí A‚ÇÅ; ‚Ä¶
       ; p‚Çô ‚Üí A‚Çô}= must have a set of exhaustive patterns =p‚ÇÅ=, ‚Ä¶, =p‚Çô=. For
       instance if we have the following:
       #+begin_example
       data Bool : Set 0 where
         true : Bool
         false : Bool

       wrong : (b : Bool) ‚Üí Bool
       wrong = Œª { true ‚Üí true }
       #+end_example
       Then the definition of =wrong= is rejected since it does not have the
       =false= pattern. The coverage algorithm (the algorithm which checks
       the exhaustivity of patterns) is described in
       cite:norell:thesis.
    2. There are no infinite loops. For instance, the following definition is
       rejected.
       #+begin_example
       loop : (A : Set 0) ‚Üí A
       loop = Œª A ‚Üí loop A
       #+end_example
       In order to do so Agda analyses every recursive call and tries to find a
       well-founded order on its arguments. If it succeeds the recursive call is
       considered save, otherwise it is rejected. The Agda online documentation
       (cite:agda-doc) references cite:abel1998foetus as the basis of the
       termination checker implemented in Agda. For instance, the checker is
       sophisticated enough to accept the definition of the Ackermann function
       (cite:agda-doc), which is non-primitive recursive.

*** Limitations :noexport:
    <<sec:agda-limitations>>
    As mentioned at the beginning of this section we did not give a complete
    presentation of the language due to its complexity. Moreover, we had to
    simplify some of the concepts presented. Here we comment on those
    simplifications.

**** Pattern matching on indexed datatypes
     The typing rules given in cref:sec:typing-rules are not enough to
     sensibly deal with datatypes which have indices.

     Consider the following example:
     #+begin_example
     data Bool : Set 0 where
       true : Bool
       false : Bool

     data IsTrue : (b : Bool) ‚Üí Set 0 where
       is-true : IsTrue true

     data IsFalse : (b : Bool) ‚Üí Set 0 where
       is-false : IsFalse false

     not : (b : Bool) ‚Üí Bool
     not = Œª {true ‚Üí false; false ‚Üí true}
     #+end_example
     We see that we have the usual definition of =Bool=. We also an indexed
     datatype called =IsTrue=. Observe that it has a single constructor called
     =is-true= which gives a term of type =IsTrue true=. Since =is-true= is
     the only constructor it is impossible to build a term of type =IsTrue
     false=. After this we have a dual definition called =IsFalse=. Then we have
     the definition of the =not= function with the expected definition.

     We expect that we should be able to prove that if have a term =b : Bool=
     and a term of type =IsTrue b= we should be able to give a term of type
     =IsFalse (not b)=. We represent this property with the following type:
     #+begin_example
     property : (b : Bool) ‚Üí (p : IsTrue b) ‚Üí IsFalse (not b)
     #+end_example
     Providing a term of this type can be done in real Agda as follows:
     #+begin_example
     property : (b : Bool) ‚Üí (p : IsTrue b) ‚Üí IsFalse (not b)
     property = Œª b ‚Üí Œª { is-true ‚Üí is-false }
     #+end_example
     Unfortunately, giving a term of this type is not possible with the typing
     rules that we gave. To see this, consider the context $Œì$ at the =?= site
     below.
     #+begin_example
     property : (b : Bool) ‚Üí (p : IsTrue b) ‚Üí IsFalse (not b)
     property = Œª b ‚Üí Œª p ‚Üí ?
     #+end_example
     We have $b:Bool‚ààŒì$ and $p : IsTrue\ b ‚ààŒì$. We can try to pattern match on
     =b=.
     #+begin_example
     property : (b : Bool) ‚Üí (p : IsTrue b) ‚Üí IsFalse (not b)
     property = Œª {true ‚Üí Œª pt ‚Üí is-false; false ‚Üí Œª pf ‚Üí ? }
     #+end_example
     Filling in the case where =b= is equal to =true= is straightforward because
     here the goal is to provide a term of type =IsFalse (not true)=, which
     normalizes to =IsFalse false=, therefore we can use the term =is-false=.
     The conflicting case is when =b= is equal to false. See that in this case
     we have that =pf= has type =IsTrue false=. Clearly we should be able to
     somehow derive a contradiction from this, because it is impossible that a
     term of this type exists. Agda deals with contradictions with absurd
     patterns, which are discussed in the next section.

     Another possibility to tackle the previous problem is to pattern match on
     =p= as we did in real Agda:
     #+begin_example
     property : (b : Bool) ‚Üí (p : IsTrue b) ‚Üí IsFalse (not b)
     property = Œª b ‚Üí Œª { is-true ‚Üí ? }
     #+end_example

**** Absurd patterns :noexport:
**** Unreachable patterns :noexport:
**** Universes :noexport:
*** Syntax sugar :noexport:

** Agda tutorial
   <<sec:agda-tutorial>>
*** BHK interpretation of propositional logic

   In this section we present an informal tutorial of Agda. We introduce new
   syntax by means of example and we introduce new concepts appealing to the
   reader intuition. We guide the reader to cref:sec:basic-agda for a more
   precise definition of the language. In the official Agda reference
   (cite:agda-doc), the informal approach is always preferred.

   # {{{jan(this should probably be in the Basic Agda section)}}}
   # We believe[fn::This is an opinion by the author of this thesis which has not
   # been contrasted with the Agda developers.] that such an approach is chosen
   # for mainly two reasons. First, Agda is a remarkably extensive software which
   # is rapidly evolving, thus, the lack of a formal specification facilitates the
   # incorporation of new features to the language. Second, Agda itself is not
   # verified and thus any attempt of a formal specification would still be
   # suspect of not being completely faithful to the implementation.

   As we have already mentioned, Agda is based on an intuitionistic type theory
   with dependent types that extends Per Martin-L√∂f's type theory
   (cite:martin1984intuitionistic). Agda's constructive nature suggests that a
   fitting way to start the introduction is through the BHK interpretation of
   intuitionistic logic (cite:sep-intuitionistic-logic-development). We start
   with propositional logic. During this part, the reader will notice that the
   first steps in this tutorial are going to be reminiscent of the embedding of
   propositional logic into LF we presented in cref:sec:def-new-types. Later in
   the chapter (cref:sec:bhk-fol) we will continue with first-order logic and
   explain how to represent relations and quantifiers in Agda.

   The BHK interpretation states that:
   1. A proof of $A‚ÜíB$ is an algorithm that transforms an arbitrary proof of $A$
      into a proof of $B$;
   2. A proof of $A‚àßB$ is a proof of $A$ and a proof of $B$;
   3. A proof of $A‚à®B$ is an algorithm telling to which of $A$ or $B$ we commit to
      and according to that, a proof of $A$ or a proof of $B$;
   4. Nothing is a proof of $‚ä•$;
   5. $‚ä§$ is always true and provable.

   According to the BHK interpretation a proof of $A‚ÜíA$ is an algorithm
   implementing the identity function. We can implement this algorithm in Agda by
   writing the identity lambda term:
   #+begin_src text
           Œª a ‚Üí a
   #+end_src
   More generally, in order to build lambda terms we will use the syntax =Œª arg‚ÇÅ
   arg‚ÇÇ ‚Ä¶ ‚Üí term=. The term =Œª a ‚Üí a= is well-formed. However, in Agda we must
   give a name to all the terms that we define so we can refer to them in other
   parts of our code. We give a name to a term by prepending =name == to the
   term. We name our term =id=:
   #+begin_src text
   id = Œª a ‚Üí a
   #+end_src
   When the term that we are defining is a lambda term, we are allowed to move
   the arguments to the left of the === sign. Furthermore, we should write the
   type of the function using the =:= symbol. The =:= symbol denotes the typing
   relation between terms and types, hence =a : A= reads as ``term
   =a= has type =A=''. Sometimes we also say that ``the term =a= is a proof of
   =A=''.
   #+begin_src text
   id : (A : Set) ‚Üí A ‚Üí A
   id A a = a
   #+end_src
   The definition =id A a = a= should be read as $\sf{id}(A)(a)‚âîa$. The
   definition =id : (A : Set) ‚Üí A ‚Üí A= should be read as follows: Given an
   arbitrary type =A= and a term of type =A=, it returns a term of type =A=. It
   may be helpful to the reader to identify the Agda type =(A : Set) ‚Üí A ‚Üí A=
   with the LF type $(A:\set)‚Ü†\el{A}‚Ü†\el{A}$. The Agda type checking algorithm
   is in charge of checking the implementation of =id= matches the specified
   type. For instance, if we wrote the following:
   #+begin_src text
   id-bad : (A : Set) ‚Üí A ‚Üí A
   id-bad A a = A
   #+end_src
   Agda would complain that =A= is of type =Set= and not of type =A=.

   Since the argument named =A= will always be exactly the type of the second
   argument of =id=, Agda can infer it and thus it is recommended to use an
   implicit argument (see cref:sec:agda-implicit-args).
   #+begin_src text
   id2 : {A : Set} ‚Üí A ‚Üí A
   id2 a = a
   #+end_src
   For instance, assume we have a term =t= of type =B= and we want to apply the
   identity function to it. If we use =id= we would write =id B t=. On the other
   hand, using =id2= we would write =id2 t=. We observe that the argument ={A :
   Set}= is inferred from =t= and is not needed to be explicitly given.

   Let us identify propositional formulas which contain only the implication
   connective with Agda types. We define the map $*$ as follows:
   - If $p$ is a variable, then $p^*‚âî\texttt{P}$, where =P : Set=.
   - $(A‚ÜíB)^*‚âîA^* \texttt{ ‚Üí }B^*$. Note that the =‚Üí= on the right of the symbol
     $‚âî$ is Agda's arrow type.
   Then, if $F$ is a propositional formula with variables $p‚ÇÅ,‚Ä¶,p‚Çô$ we define
   \[
   ‚ü¶F‚üß‚âî \texttt{\{P‚ÇÅ : Set\} ‚Üí ‚Ä¶ ‚Üí \{P‚Çô : Set\} ‚Üí F*}\] Note that in Agda we can
   write ={P‚ÇÅ ‚Ä¶ P‚Çô : Set} ‚Üí F*= instead of ={P‚ÇÅ : Set} ‚Üí ‚Ä¶ ‚Üí {P‚Çô : Set} ‚Üí F*=.

   We will say that an Agda type =T= is a theorem if we can provide a function
   definition of type =T=. In the simplest form, the definition will be of the
   following form:
   #+begin_src text
   thm : T
   thm = proof
   #+end_src
   Where =thm= is the name of the theorem. For the general form we refer the
   reader to the Agda documentation in cref:sec:agda-doc-fun-defs.

   Let us now see that $‚ü¶A‚ÜíA‚üß$ is a theorem in Agda. It suffices to observe that
   $‚ü¶A‚ÜíA‚üß$ is equal to ={A : Set} ‚Üí A ‚Üí A=, which is the type of =id2=. Hence
   =id2= is indeed a proof that $‚ü¶A‚ÜíA‚üß$ is an Agda theorem. However, it is more
   than that. Agda is a programming language, so the programs that we define in
   Agda are executable. For instance, we can ask the system to evaluate the
   expression =id2 t=, which evaluates to =t=, as expected. The capability of
   evaluating expressions reflects the fact that the =id2= function we defined
   is a perfect candidate to be a proof of $A‚ÜíA$ according to the BHK
   interpretation. How the evaluation of expression works falls out of the scope
   of this tutorial. We refer the reader to the Agda documentation
   (cite:agda-doc) for that.

   \pagebreak[4]
   Let us see another example involving functions. The following Agda definition
   shows that $‚ü¶(A‚Üí(B‚ÜíC))‚Üí(B‚Üí(A‚ÜíC))‚üß$ is an Agda theorem.
   #+begin_src text
   commute : {A B C : Set} ‚Üí (A ‚Üí B ‚Üí C) ‚Üí B ‚Üí A ‚Üí C
   commute f b a = f a b
   #+end_src
   We see that =commute= has three explicit arguments, namely =f : A ‚Üí B ‚Üí C=,
   =b : B= and =a : A=. Then in the right hand side of the === sign we have =f a
   b=, which should read as ``term =f= applied to =a= and =b=''. Notice how
   function application is denoted by juxtaposition and has left associativity.

   Let us now put our attention on proofs that revolve around conjunction.
   First, we need to define a new type. In Agda we can introduce new
   types by means of a datatype definition (we refer the reader to
   cref:def:agda-datatype for a precise definition). Recall from
   cref:sec:basic-agda that we call datatypes the types which have been defined
   by the user by means of a datatype definition.

   The definition below defines the pair datatype (the semantics of this datatype
   are analogous to the pair set we defined for LF in cref:sec:pairs-set).
   #+begin_src text
 data _√ó_ (A B : Set) : Set where
   _,_ : A ‚Üí B ‚Üí A √ó B
   #+end_src
   A pair type is in rough terms the type of a tuple. More precisely, the
   definition defines a new datatype called =_√ó_=. It has two parameters: =(A
   B : Set)=. These parameters are the types of the components of the pair. It
   has a single constructor named =_,_=. Underscores are used to denote infix
   operators. Thus we have that =_,_ A B= is the same as =A , B=. We observe
   that the type of the constructor =_,_= is =A ‚Üí B ‚Üí A √ó B=. This tells us that
   =_,_= is a constructor that takes an argument of type =A=, an argument of
   type =B=, and then returns a term of type =A √ó B=. Recall that when we
   /pattern match/ (or deconstruct) a term we will have a case for each possible
   constructor of the type of that term.

   We proceed by extending the map $*$ with the following clause:
   \begin{flalign*}
   (A‚àßB)^*‚âîA^*\texttt{ √ó }B^*
   \end{flalign*}

   We can show that $‚ü¶A‚Üí(B‚ÜíA‚àßB)‚üß$ is a theorem in Agda by simply applying the
   constructor =_,_=:
   #+begin_src text
   p1 : {A B : Set} ‚Üí A ‚Üí B ‚Üí A √ó B
   p1 a b = a , b
   #+end_src

   In order to show that $‚ü¶A‚àßB‚ÜíB‚àßA‚üß$ is a theorem we need to access to
   components of the argument. We can do so by deconstructing the argument with
   pattern matching as shown below. Note that when we use pattern matching on an
   argument we need to put parentheses around it.
   #+begin_src text
   swap : {A B : Set} ‚Üí A √ó B ‚Üí B √ó A
   swap (a , b) = b , a
   #+end_src

   We proceed by giving some more examples involving conjunction.

   We show that we can prove $‚ü¶A‚àßB‚ÜíA‚üß$ and $‚ü¶A‚àßB‚ÜíB‚üß$. It suffices to pattern
   match on the argument to access to corresponding component and return it.
   #+begin_src text
     proj‚ÇÅ : {A B : Set} ‚Üí A √ó B ‚Üí A
     proj‚ÇÅ (a , b) = a

     proj‚ÇÇ : {A B : Set} ‚Üí A √ó B ‚Üí B
     proj‚ÇÇ (a , b) = b
   #+end_src
   If we ask Agda to evaluate an expression of the form =proj‚ÇÅ (a , b)= the
   result will be =a=.

   Observe how we can use =proj‚ÇÅ= and =proj‚ÇÇ= to provide an alternative proof of
   $‚ü¶A‚àßB‚ÜíB‚àßA‚üß$:
   #+begin_src text
   swap' : {A B : Set} ‚Üí A √ó B ‚Üí B √ó A
   swap' ab = (proj‚ÇÅ ab) , (proj‚ÇÇ ab)
   #+end_src

   We show that we can prove $‚ü¶(A ‚Üí B ‚Üí C) ‚Üí ((A ‚àß B) ‚Üí C)‚üß$.
   #+begin_src text
   p3 : {A B C : Set} ‚Üí (A ‚Üí B ‚Üí C) ‚Üí (A √ó B) ‚Üí C
   p3 f (a , b) = f a b
   #+end_src
   As we can see, we use pattern matching to extract the components of the pair
   and then apply =f= to them.


   Now that we are familiarized with the pair type we can proceed by exploring
   disjunction.

   In order to express options we can define a new datatype called sum type thus
   (the semantics of this datatype are analogous to the disjoint union set we
   defined for LF in cref:sec:disjoint-set):
   #+begin_src text
 data _‚äé_ (A B : Set) : Set where
   inj‚ÇÅ : A ‚Üí A ‚äé B
   inj‚ÇÇ : B ‚Üí A ‚äé B
   #+end_src
   We see that the main difference with respect to the pair type is that now we
   have two constructors which we named =inj‚ÇÅ= and =inj‚ÇÇ=. The constructor
   =inj‚ÇÅ= is used to build a term of type =A ‚äé B= by providing a term with type
   =A=. The constructor =inj‚ÇÇ= builds a term of type =A ‚äé B= given a term of
   type =B=.

   We extend the $*$ map with the following clause:
   \begin{flalign*}
   (A ‚à® B)^* ‚âî A^* \texttt{ ‚äé } B^*
   \end{flalign*}

   We show how we can prove $‚ü¶A‚à®B‚ÜíB‚à®A‚üß$.
   #+begin_src text
   p4: {A B : Set} ‚Üí A ‚äé B ‚Üí B ‚äé A
   p4 (inj‚ÇÅ a) = inj‚ÇÇ a
   p4 (inj‚ÇÇ b) = inj‚ÇÅ b
   #+end_src
   We observe that since we have the =‚äé= type has two constructors, when pattern
   matching against an argument of type =A ‚äé B= we need to define two cases, one
   for each constructor. In the first case, when we have =inj‚ÇÅ a= on the left of
   the equal sign we know that =a= is of type =A= by the definition of the
   =inj‚ÇÅ= constructor. Hence, we can build a term of type =B ‚äé A= by applying
   =inj‚ÇÇ= to =a=. The second case is symmetric to the first case.

   Let us see another example, we show $‚ü¶(A‚à®B)‚Üí(A‚ÜíC)‚Üí(B‚ÜíC)‚ÜíC‚üß$.
   #+begin_src text
   p5 : {A B : Set} ‚Üí A ‚äé B ‚Üí (A ‚Üí C) ‚Üí (B ‚Üí C) ‚Üí C
   p5 (inj‚ÇÅ a) f g = f a
   p5 (inj‚ÇÇ b) f g = g b
   #+end_src

   The reader may have raised the following question in their mind: when we
   pattern match an argument of type =A ‚äé B=, what if we do not include one
   of the cases? In other words, what happens if we try to prove $‚ü¶A‚à®B‚ÜíA‚üß$?
   #+begin_src text
   wrong : {A B : Set} ‚Üí A ‚äé B ‚Üí A
   wrong : (inj‚ÇÅ a) = a
   #+end_src
   The answer is that Agda rejects the above definition. As explained in
   cref:sec:agda-totality Agda requires all the definitions to be total. As
   such, when we split an argument into cases using pattern matching, it checks
   that the cases are exhaustive.

   We proceed with $‚ä•$. We can define a datatype which we call /bottom type/ or
   /empty type/.
   #+begin_src text
   data ‚ä• : Set where
   #+end_src
   Notice that =‚ä•= has no constructors and hence it is impossible to construct a
   term with type =‚ä•=. The bottom type is specially useful to define negation,
   which we define in the following way:
   #+begin_src text
   ¬¨ : Set ‚Üí Set
   ¬¨ A = A ‚Üí ‚ä•
   #+end_src

   We extend the $*$ map with the following clauses (note that the =‚ä•= and =¬¨=
   on the left of the symbol $‚âî$ refer to the Agda symbols):
   \begin{flalign*}
   ‚ä•^*&‚âî\texttt{‚ä•} \\
   (¬¨A)^*&‚âî\texttt{¬¨}(A^*)
   \end{flalign*}

   The principle of explosion (/ex falso quodlibet/) $‚ü¶‚ä•‚ÜíA‚üß$ can be proved as
   shown below:
   #+begin_src text
   explosion : {A : Set} ‚Üí ‚ä• ‚Üí A
   explosion ()
   #+end_src
   We see that we have a new pattern: =()=. Agda uses the pattern =()= to denote
   the impossible pattern. When one of the arguments matches the impossible
   pattern then there is no need to provide a definition of the function. In
   this case we match the impossible pattern because the type =‚ä•= has not
   constructors. For more information on the absurd pattern we refer the reader
   to cref:sec:agda-doc-absurd.

   As we are in an intuitionistic logic then we cannot show $‚ü¶¬¨¬¨A‚ÜíA‚üß$ nor
   $‚ü¶A‚à®¬¨A‚üß$[fn::Observe that in the Agda code we use the symbol =¬¨= in the name
   of the term =¬¨¬¨elim=. Here the =¬¨= symbol is just part of the name and serves
   the same purpose of any other character. Hence it is important to note that
   =¬¨a= (just a name with the =¬¨= character) is different from =¬¨ a= (the
   negation of =a=).]:
   #+begin_src text
   ¬¨¬¨elim : {A : Set} ‚Üí ¬¨ (¬¨ A) ‚Üí A
   ¬¨¬¨elim = ?             -- not provable

   excluded-middle : {A : Set} ‚Üí A ‚äé (¬¨ A)
   excluded-middle = ?    -- not provable
   #+end_src
   However, we can show that $‚ü¶A‚Üí¬¨¬¨A‚üß$ and $‚ü¶¬¨¬¨¬¨A‚Üí¬¨A‚üß$:
   #+begin_src text
     ¬¨¬¨intro : {A : Set} ‚Üí A ‚Üí ¬¨ (¬¨ A)
     ¬¨¬¨intro a ¬¨a = ¬¨a a

     ¬¨¬¨¬¨elim : {A : Set} ‚Üí ¬¨ (¬¨ (¬¨ A)) ‚Üí ¬¨ A
     ¬¨¬¨¬¨elim ¬¨¬¨¬¨a a = ¬¨¬¨¬¨a (¬¨¬¨intro a)
   #+end_src

   We can build an alternative proof of $‚ü¶¬¨¬¨¬¨A‚Üí¬¨A‚üß$ that does not use =¬¨¬¨intro=
   by replacing it with a lambda term:
   #+begin_src text
   ¬¨¬¨¬¨elim' : {A : Set} ‚Üí ¬¨ (¬¨ (¬¨ A)) ‚Üí ¬¨ A
   ¬¨¬¨¬¨elim' ¬¨¬¨¬¨a a = ¬¨¬¨¬¨a (Œª ¬¨a ‚Üí ¬¨a a)
   #+end_src

   Consider the proof of $‚ü¶A‚Üí¬¨A‚ÜíB‚üß$.
   #+begin_src text
   p6 : {A B : Set} A ‚Üí ¬¨ A ‚Üí B
   p6 a ¬¨a = explosion (¬¨a a)
   #+end_src
   We have two arguments, =a : A= and =¬¨a : ¬¨ A=. It is easy to see that the
   type of =¬¨a a= is =‚ä•=. Also, recall that the type of =explosion= is[fn::we
   have renamed the bound variable =A= to =C= to avoid confusion with the =A= in
   =A ‚Üí ¬¨ B ‚Üí B=.] ={C : Set} ‚Üí ‚ä• ‚Üí C=. Then, in the definition above, since we
   expect a term of type =B=, Agda can infer that implicit argument ={C : Set}=
   is equal to =B= and thus =explosion (¬¨a a)= has type =B=. For illustrative
   purposes, let us rewrite the same proof but with the implicit arguments made
   explicit. We can make implicit arguments explicit by surrounding them with
   ={}= as shown below:
   #+begin_src text
   p6' : {A B : Set} A ‚Üí ¬¨ A ‚Üí B
   p6' {A} {B} a ¬¨a = explosion {B} (¬¨a a)
   #+end_src

   This concludes the first part of the introduction.

*** Booleans and case analysis
    <<sec:agda-bool>> The /true or false/ concept is ubiquitous in computer
    science and in logic. In this section we show how we can define a datatype
    that represents this dichotomy and we give a small introduction to
    case analysis through pattern matching.

    In Agda we can define the =Bool= type in a similar fashion to the
    disjunction type we defined before.
    #+begin_src text
    data Bool : Set where
      true : Bool
      false : Bool
    #+end_src
    As a simple example, see how we can define the =not= and =and= Boolean
    operators using pattern matching:
    #+begin_src text
    not : Bool ‚Üí Bool
    not false = true
    not true = false

    and : Bool ‚Üí Bool ‚Üí Bool
    and false b = false
    and true b = b
    #+end_src
    We proceed by defining equality for the =Bool= type[fn::This definition is
    just for illustrative purposes. It is possible to define generic equality
    as described in cref:sec:agda-equality.]. We use the symbol
    =‚â°= because === is reserved for Agda.
    #+begin_src text
 data _‚â°_ : Bool ‚Üí Bool ‚Üí Set where
   t‚â°t : true ‚â° true
   f‚â°f : false ‚â° false
    #+end_src
    We see that the type of =_‚â°_= is =Bool ‚Üí Bool ‚Üí Set=. We say that =_‚â°_= is an
    /indexed datatype/, in this case with two =Bool= indices. In contrast to
    parameters (recall the definitions of =_√ó_= and =_‚äé_=) which are shared among
    all constructors, indices are specified on a constructor basis.

    Let us prove the following property:
    #+begin_src text
    notnot : (b : Bool) ‚Üí not (not b) ‚â° b
    notnot true = t‚â°t
    notnot false = f‚â°f
    #+end_src
    There are a number of things that are worth mentioning. First, we see that we
    refer to =b= on the returning result =not (not b) ‚â° b=, which is possible in
    virtue of dependent types. Then we see that we pattern match on =b= and thus
    we need to fill out two cases. We could make an analogy with a hand written
    proof by cases. The case split with pattern matching allows Agda to know via
    /normalization/ that in the =true= case we must provide a term (proof) of
    type =true ‚â° true=, which we can provide using the =t‚â°t= constructor. We
    proceed analogously in the =false= case. Agda normalizes the terms when
    possible, for instance the term =not (not b)= is already normalized because
    we cannot apply any rule. On the other hand the term =not (not true)= can be
    normalized to =not false= and further normalized to =true= by using the
    definition of =not=. For further information on normalization refer to
    cite:norell:thesis. Another thing to notice is that we use the same
    construction (i.e. an Agda function definition) to provide function definitions,
    like =not=, and theorems, like =notnot=.

    Pattern matching (case analysis) is ubiquitous in Agda, be it in definitions
    or in proofs. We show some more examples below:
    #+begin_src text
    p1 : (b : Bool) ‚Üí and false b ‚â° false
    p1 b = f‚â°f

    p2 : (b : Bool) ‚Üí and b false ‚â° false
    p2 true = f‚â°f
    p2 false = f‚â°f
    #+end_src
    See that in the first case we did not need to do pattern matching while in
    the second we had to. This is due to how the definition of =and= is written
    which in our case performs pattern matching on the first argument.
*** Naturals and induction
    <<sec:agda-nat>>
    In this section we will have a look at the simplest possible recursive
    structure, the natural numbers. In Agda natural numbers can be defined in the
    following way:
    #+begin_src
    data Nat : Set where
      zero : Nat
      suc : Nat ‚Üí Nat
    #+end_src
    The definition should be intuitive enough for the reader at this point. We
    can represent the number $1$ with the term =suc zero=, the number $2$ with
    =suc (suc zero)= and so on.

    Let us continue by defining the equality relation for natural
    numbers[fn::Agda does not allow overloading of symbols so we would need to
    use a different name other than =_‚â°_= to avoid the clash with the equality relation
    of Booleans that we defined before.].
    #+begin_src text
    data _‚â°_ : Nat ‚Üí Nat ‚Üí Set where
      z‚â°z : zero ‚â° zero
      s‚â°s : {a b : Nat} ‚Üí a ‚â° b ‚Üí suc a ‚â° suc b
    #+end_src
    We see that it has a similar structure to the datatype for Boolean equality.
    The only difference is that the =s‚â°s= constructor requires a proof of =a ‚â° b=
    as an argument. Let us show that every natural number is equal to itself.
    #+begin_src text
    refl : (n : Nat) ‚Üí n ‚â° n
    refl zero = z‚â°z
    refl (suc n) = s‚â°s (refl n)
    #+end_src
    We see that we pattern match on =n=, for the =zero= case we give the =z‚â°z=
    constructor. For the =suc= case we need to provide a proof of =suc n ‚â° suc
    n=. By performing a recursive call with =n= as argument we get a proof of =n
    ‚â° n=, then we can use the constructor =s‚â°s= to build a term of type =suc n ‚â°
    suc n=. It can be enlightening to observe that in a proof by induction, such
    as the previous one, a recursive call plays the role of an induction
    hypothesis.

    An inexperienced Agda user might try the following:
    #+begin_src text
    refl' : (n : Nat) ‚Üí n ‚â° n
    refl' zero = z‚â°z
    refl' (suc n) = refl' (suc n)
    #+end_src
    While the types match we see that in the inductive case we perform a
    recursive call on the same argument and thus we get an infinite loop. Agda
    has a termination checker that rejects proofs where termination cannot be
    assured and thus rejects the previous definition. We know that termination is
    an undecidable problem hence it is inevitable that Agda will reject some
    programs that in fact would always terminate. For more information on Agda's
    termination checker refer to cite:norell:thesis,agda-doc.

    We now define addition on natural numbers:
    #+begin_src text
    _+_ : Nat ‚Üí Nat ‚Üí Nat
    zero + b = b
    (suc a) + b = suc (a + b)
    #+end_src

    Proving associativity can be achieved by means of an inductive proof
    following a similar structure as before. For the base case we use the =refl=
    property proved above.
    #+begin_src text
 assoc : (a b c : Nat) ‚Üí (a + b) + c ‚â° a + (b + c)
 assoc zero b c = refl (b + c)
 assoc (suc a) b c = s‚â°s (assoc a b c)
    #+end_src

    Consider the following example involving negation. Keep in mind that =¬¨ (n ‚â°
    suc n) = n ‚â° suc n ‚Üí ‚ä•=.
    #+begin_src text
    p1 : (n : Nat) ‚Üí ¬¨ (n ‚â° suc n)
    p1 zero ()
    p1 (suc n) (s‚â°s x) = p1 n x
    #+end_src
    For the base case we have the impossible pattern because when =n = zero= the
    second argument is supposed to have the type =zero ‚â° suc zero= which is not
    unifiable with any type of a constructor and thus we get the empty pattern.
    For more information on Agda unification refer to cite:norell:thesis.

    Finally, let us focus on proving commutativity of addition, which is a more
    involved example. We first prove transitivity of equality, which is proved by
    an easy induction.
    #+begin_src text
 trans : {a b c : Nat} ‚Üí a ‚â° b ‚Üí b ‚â° c ‚Üí a ‚â° c
 trans z‚â°z z‚â°z = z‚â°z
 trans (s‚â°s x) (s‚â°s y) = s‚â°s (trans x y)
    #+end_src
    Notice how there are two missing cases, that is, =z‚â°z= with =s‚â°s= and vice
    versa. We are allowed to do that because Agda was able to
    detect the empty pattern. We could have also omitted the =p1 zero ()= case in
    the theorem above.

    We proceed by proving two lemmas by an easy induction:
    #+begin_src text
 zero-r : (a : Nat) ‚Üí a ‚â° (a + zero)
 zero-r zero = z‚â°z
 zero-r (suc a) = s‚â°s (zero-r a)

 suc-r : (a b : Nat) ‚Üí suc (a + b) ‚â° (a + suc b)
 suc-r zero b = refl (suc b)
 suc-r (suc a) b = s‚â°s (suc-r a  b)
    #+end_src

    At last, we put all the pieces together to prove our theorem:
    #+begin_src text
 +commut : (a b : Nat) ‚Üí (a + b) ‚â° (b + a)
 +commut zero b = zero-r b
 +commut (suc a) b = trans (s‚â°s (+commut a b)) (suc-r b a)
    #+end_src
    For the base case we must prove =0 + b ‚â° b + 0= which normalizes to =b ‚â° b +
    0= and then we can use our =zero-r= lemma. For the inductive case we must
    prove =suc a + b ‚â° b + suc a= which normalizes to =suc (a + b) ‚â° b + suc a=.
    By IH we know that =a + b ‚â° b + a= so by =s‚â°s= we get =suc (a + b) ‚â° suc (b +
    a)=. Then by our lemma =suc-r= we get =suc (b + a) ‚â° b + suc a=. Finally by
    transitivity we get the desired =suc (a + b) ‚â° b + suc a=.

    We hope that at this point the user has a grasp of how properties can be
    proved in Agda.

    # To summarize, we outline the usual course of action when we
    # want to prove a theorem.
    # 1. We define the datatypes and functions that represent our relations,
    #    operators, assumptions and so on. Usually there are multiple
    #    routes that we can take, and it is important to implement definitions in a
    #    way that they are easy to work with.
    # 2. We prove intermediary lemmas...
    # 3. The type of a function can represent a mathematical proposition.
    # 4. The term
*** Universe hierarchy
    <<sec:universe-hierarchy>> In Agda every well-typed term is assigned a type.
    For instance, the type of =true= is =Bool= and the type of =0= is =Nat=. As
    we have seen before, in a dependent type theory we are allowed to mix types
    and terms, hence =Nat= is a term in itself and must be assigned a type. Agda
    calls the type of (small) types =Set=, hence we have that =Nat= has type
    =Set=. But then =Set= is also a term an must be assigned a type as well.
    Could we have that the type of =Set= is =Set=? No. The first version of
    Martin-L√∂f‚Äôs type theory (cite:martin-lof-1971a) had an axiom stating that
    there is a type of all types and thus we would have that the type of =Set= is
    =Set=. However Girard showed (cite:sep-type-theory-intuitionistic) that
    having =Set : Set= allowed the Burali-Forti paradox[fn::The assumption that
    there is a set of all ordinal numbers leads to a contradiction.] to be
    encoded in the theory, and thus the relation =Set : Set= needs to be
    rejected. In order to avoid such inconsistency Agda builds a hierarchy of
    universes where small types such as =Nat= and =Bool= are assigned the type
    =Set 0= and then for every $i‚ààœâ$ we have that =Set i : Set i+1=. Notice
    however, that =Set i : Set i+1= is true while =Set i : Set i+n= does not hold
    for $n>1$. In Agda we write =Set= instead of =Set 0=. When the level is a
    constant natural number we can also write =Set‚ÇÅ=, =Set‚ÇÇ=, etc. instead of
    =Set 1=, =Set 2=, etc.

    It is possible to combine types of different universe levels. The biggest type
    is the one that counts. For instance:
    #+begin_src text
    function : Set‚ÇÉ ‚Üí Set‚ÇÅ ‚Üí Set‚ÇÉ
    function A B = A ‚Üí B
    #+end_src
    The typing rule is analogous for product and sum types.

    Agda provides a primitive[fn::/primitive/ means that it is built in the
    language and it cannot be defined by the user.] type for universe levels called
    =Level=. Essentially it is the same as =Nat= (we have =lzero= for the base
    level and =lsuc= for the successor level), but it is designed to work as a universe
    index. Having the =Level= type allows us to write universe polymorphic
    functions. See the same function as before, but now with universe
    polymorphism.
    #+begin_src text
    function' : {a b : Level} ‚Üí Set a ‚Üí Set b ‚Üí Set (a ‚äî b)
    function' A B = A ‚Üí B
    #+end_src
    The =_‚äî_= operator is a primitive operator of type =Level ‚Üí Level ‚Üí Level=
    that normalizes to the the maximum of its two operands.

    Most of the functions that we have defined before should be rewritten to be
    universe polymorphic if possible. For instance, we can now rewrite the
    identity function thus:
    #+begin_src text
    id : {a : Level} {A : Set a} ‚Üí A ‚Üí A
    id a = a
    #+end_src

    In the most recent version of Agda (2.6.1) there is an option to enable
    /universe cumulativity/ (cite:agda-doc). This extension adds the typing rule
    $Set·µ¢:Set‚±º$ for $i<j$. Hence it allows us to write the following:
    #+begin_src text
    a : Set              -- always allowed
    a = Nat
    b : Set‚ÇÅ             -- only with cumulativity
    b = Nat
    c : {i : Level} ‚Üí Set i    -- only with cumulativity
    c = Nat
    #+end_src
    In our thesis we have not used this extension.

*** BHK interpretation of first order logic
    <<sec:bhk-fol>>
    <<sec:predicates>>

    We extend the interpretation that we gave before to include the universal and
    existential quantifiers (cite:sep-intuitionistic-logic-development):
    1. A proof of $‚àÄx.P(x)$ is a function that given an arbitrary element $c$ in
       the domain, builds a proof that $c$ satisfies $P$.
    2. A proof of $‚àÉx.P(x)$ is a witness $c$ in the domain and a proof that $c$
      satisfies $P$.
    Before diving into quantifiers we first discuss how to represent relations in
    Agda. Recall the equality relation for natural numbers =_‚â°_= that we defined
    before. Its type is =Nat ‚Üí Nat ‚Üí Set=. Let us say that we want to define a
    generic type =REL= for relations on any type. A first attempt could be:

    #+begin_src text
 REL : Set ‚Üí Set ‚Üí Set‚ÇÅ
 REL A B = A ‚Üí B ‚Üí Set
    #+end_src

    This first definition is somewhat limited. Recall that =Set = Set 0=, thus we
    restrict =A= and =B= to be small types, furthermore, we require the relation
    to be a small type as well. If we make our =REL= definition universe
    polymorphic it turns out like this.\glsadd{REL}
    #+begin_src text
 REL : {a b : Level} ‚Üí Set a ‚Üí Set b ‚Üí (‚Ñì : Level) ‚Üí Set (a ‚äî b ‚äî lsuc ‚Ñì)
 REL A B ‚Ñì = A ‚Üí B ‚Üí Set ‚Ñì
    #+end_src
    This is the definition used in the Agda standard library (cite:agda-stdlib)
    and is the one that we use in our thesis.

    For homogeneous relations we use the name =Rel=:\glsadd{Rel}
    #+begin_src text
 Rel : {a : Level} ‚Üí Set a ‚Üí (‚Ñì : Level) ‚Üí Set (a ‚äî lsuc ‚Ñì)
 Rel A ‚Ñì = REL A A ‚Ñì
    #+end_src

    By using these new definitions we could have defined the type of =_‚â°_= thus
    (observe that =Rel Nat lzero= normalizes to =Nat ‚Üí Nat ‚Üí Set=):
    #+begin_src text
    data _‚â°_ : Rel Nat lzero where
      ... -- same as before
    #+end_src

    \glsadd{Pred}
    In a similar way we can define predicates:
    #+begin_src text
    Pred : {a : Level} ‚Üí Set a ‚Üí (‚Ñì : Level) ‚Üí Set (a ‚äî lsuc ‚Ñì)
    Pred A ‚Ñì = A ‚Üí Set ‚Ñì
    #+end_src

    We proceed by giving a representation of the universal quantifier. In the
    following definition the parameter =D= represents the domain and =P= the
    predicate.
    #+begin_src text
 data ‚àÄ[_] {a ‚Ñì : Level} (D : Set a) (P : Pred D ‚Ñì) : Set (a ‚äî ‚Ñì) where
   proof‚àÄ : ((e : D) ‚Üí P e) ‚Üí ‚àÄ[ D ] P
    #+end_src
    In fact this datatype is just a wrapper for a function of type =(e : D) ‚Üí P
    e=.

    For instance, let us prove that every successor of a natural number is
    different than zero:
    #+begin_src text
 aux : (n : Nat) ‚Üí ¬¨ (suc n ‚â° zero)
 aux n ()

 s‚â†z : ‚àÄ[ Nat ] (Œª n ‚Üí ¬¨ (suc n ‚â° zero))
 s‚â†z = proof‚àÄ aux
    #+end_src
    Alternatively we could have written a shorter version that does not use an
    auxiliary lemma.
    #+begin_src text
 s‚â†z : ‚àÄ[ Nat ] (Œª n ‚Üí ¬¨ (suc n ‚â° zero))
 s‚â†z = proof‚àÄ Œª {n ()}
    #+end_src
    Proving \text{$‚àÄ$-elimination} (if $‚àÄx.P(x)$ and $c$ is in the domain then
    $P(c)$) is straightforward:
    #+begin_src text
    ‚àÄ-elim : {a ‚Ñì : Level} {A : Set a} {P : Pred A ‚Ñì} ‚Üí ‚àÄ[ A ] P ‚Üí (a : A) ‚Üí P a
    ‚àÄ-elim (proof‚àÄ f) a = f a
    #+end_src

    We now continue with the existential quantifier. Recall that according to
    the BHK interpretation a proof $‚àÉx.P(x)$ is an element $c$ of the domain and
    a proof that $P(c)$. The first plan could be to use the pair type we defined
    before to contain the needed elements. We repeat the definition here:
    #+begin_src text
 data _√ó_ (A B : Set) : Set where
   _,_ : A ‚Üí B ‚Üí A √ó B
    #+end_src
    The problem is that the type of the second component, =B=, is independent of
    the first component and thus we cannot express what we need. Here is where
    the $Œ£$ type (or \gls*{dependent-pair}) comes into play. A
    dependent pair is a structure where the type of the second component depends
    on the value of the first component. This concept is defined by the following
    datatype.
    #+begin_src text
 data Œ£ {‚Ñì ‚Ñì' : Level} (A : Set ‚Ñì) (B : A ‚Üí Set ‚Ñì') : Set (‚Ñì ‚äî ‚Ñì') where
   _,_ : (a : A) ‚Üí B a ‚Üí Œ£ A B
    #+end_src
    Proving \text{$‚àÉ$-introduction} is trivial:
    #+begin_src
    ‚àÉ-intro : {‚Ñì ‚Ñì' : Level} {A : Set ‚Ñì} {P : A ‚Üí Set ‚Ñì'}
      ‚Üí (a : A) ‚Üí P a ‚Üí Œ£ A P
    ‚àÉ-intro a p = a , p
    #+end_src
    We now show that $‚àÄx(P(x))‚áí¬¨‚àÉx(¬¨P(x))$.
    #+begin_src text
    p1 : {‚Ñì ‚Ñì' : Level} {A : Set ‚Ñì} {P : A ‚Üí Set ‚Ñì'}
      ‚Üí ‚àÄ[ A ] P ‚Üí ¬¨ (Œ£ A (Œª x ‚Üí ¬¨ (P x)))
    p1 (proof‚àÄ f) (c , b) = b (f c)
    #+end_src
    Our goal is to give a term of type =‚ä•=. We have that =f= has type =(a : A) ‚Üí
    P a= so =f c= has type =P c=, then =b= has type =¬¨ (P c)= which is the same
    as =P c ‚Üí ‚ä•=, thus by applying =b= to =(f c)= we get a term of type =‚ä•=.

    Of course, as we are in an intuitionistic logic we cannot show
    the other direction, namely $¬¨‚àÉx(¬¨P(x))‚áí‚àÄx(P(x))$.

    *A note on syntax*. The reader may find the $Œ£$ syntax a bit too different
    from the usual existential notation: $‚àÉx(Px)$. We can fix that thanks to
    Agda's syntax versatility. Agda provides a tool to define custom syntax.
    Below we show how we can use that tool to improve the syntax of $Œ£$ pairs. We
    will not go into more detail since this feature is of shallow mathematical
    interest.
    #+begin_src text
 Œ£-syntax : {‚Ñì ‚Ñì' : Level} ‚Üí (A : Set ‚Ñì) ‚Üí (A ‚Üí Set ‚Ñì') ‚Üí Set (‚Ñì ‚äî ‚Ñì')
 Œ£-syntax = Œ£
 syntax Œ£-syntax A (Œª x ‚Üí B) = Œ£[ x ‚àà A ] B
    #+end_src
    With this syntax enhancement we can replace =Œ£ A (Œª c ‚Üí P c)= by =Œ£[ c ‚àà A ] (P c)=.
    The previous theorem becomes:
    #+begin_src text
    ‚àÉ-intro : {‚Ñì ‚Ñì' : Level} {A : Set ‚Ñì} {P : A ‚Üí Set ‚Ñì'}
      ‚Üí (a : A) ‚Üí P a ‚Üí Œ£[ c ‚àà A ] (P c)
    #+end_src
    There is a variation of this notation which omits the type of the variable as
    it can be inferred in many cases. That is, instead of =Œ£[ c ‚àà A ] (P c)= we
    would have =‚àÉ[ c ] (P c)=. We prefer this notation when possible in the
    thesis[fn::For instance, in the definition of Veltman semantics in cref:sec:agda-ord-semantics.]. See again the =‚àÉ-intro= theorem type using this
    notation:
    #+begin_src text
    ‚àÉ-intro : {‚Ñì ‚Ñì' : Level} {A : Set ‚Ñì} {P : A ‚Üí Set ‚Ñì'}
      ‚Üí (a : A) ‚Üí P a ‚Üí ‚àÉ[ c ] (P c)
    #+end_src

*** Equality
    <<sec:agda-equality>>

    In cref:sec:agda-nat,sec:agda-bool we have seen how we can define
    equality for Booleans and naturals. In this section we explore a generic
    equality and some of its properties and limitations. Of course, the main
    advantage of generic equality is that we can use it for every type and
    thus there is no need to redefine it for every new datatype that we
    define.

    Below we present a slight simplification of generic equality as defined in
    cite:agda-stdlib. The semantics of this generic equality type defined in
    this section are analogous to the identity set for the system LF presented
    in cref:sec:identity-set.
    #+begin_example
 data _‚â°_ {a : Level} {A : Set a} (x : A) : A ‚Üí Set a where
   refl : x ‚â° x
    #+end_example

    It may help the reader to read the following description of the generic
    equality datatype defined above taken from cite:plfa2019:
    #+begin_quote
    For any type =A= and for any =x= of type =A=, the constructor =refl=
    provides evidence that =x ‚â° x=. Hence, every value is equal to itself, and
    we have no other way of showing values equal. The definition features an
    asymmetry, in that the first argument to =_‚â°_= is given by the parameter
    =x : A=, while the second is given by an index in =A ‚Üí Set a=. The first
    argument to =_‚â°_= can be a parameter because it does not vary, while the
    second must be an index, so it can be required to be equal to the first.
    #+end_quote

    It is easy to see that equality is a reflexive relation.
    #+begin_src text
 reflexive : {‚Ñì : Level} {A : Set ‚Ñì} {a : A} ‚Üí a ‚â° a
 reflexive = refl
    #+end_src
    We can also show that it is symmetric.
    #+begin_src text
 symmetric : {‚Ñì : Level} {A : Set ‚Ñì} {a b : A} ‚Üí a ‚â° b ‚Üí b ‚â° a
 symmetric a‚â°b = ?
    #+end_src
    The argument =a‚â°b= has type =a ‚â° b= and our goal is to give a term of type =b
    ‚â° a=. However, the only way to give a term of type =b ‚â° a= is by unifying =a=
    and =b= since we only have the =refl= constructor. We achieve that by pattern
    matching against the argument =a‚â°b=. Then the goal becomes =a ‚â° a= and we can
    use the =refl= constructor.
    #+begin_src text
 symmetric : {‚Ñì : Level} {A : Set ‚Ñì} {a b : A} ‚Üí a ‚â° b ‚Üí b ‚â° a
 symmetric refl = refl
    #+end_src
    We can prove transitivity in an analogous way.
    #+begin_src text
 transitivity : {‚Ñì : Level} {A : Set ‚Ñì} {a b c : A} ‚Üí a ‚â° b ‚Üí b ‚â° c ‚Üí a ‚â° c
 transitivity refl refl = refl
    #+end_src
    We can also show that if =x ‚â° y= then for any =f= we have =f x ‚â° f y=.
    #+begin_src text
 cong : {‚ÑìA ‚ÑìB : Level} {A : Set ‚ÑìA} {B : Set ‚ÑìB} {x y : A}
   ‚Üí (f : A ‚Üí B) ‚Üí x ‚â° y ‚Üí f x ‚â° f y
 cong f refl = refl
    #+end_src

    We now see that this new equality datatype is equivalent to the previously
    defined equality for naturals. To avoid a name clash, we redefine equality
    for naturals with the =_‚Ñï‚â°_= symbol. We also rename reflexivity for =_‚Ñï‚â°_=
    as =‚Ñïrefl=.
    #+begin_src text
    data _‚Ñï‚â°_ : Nat ‚Üí Nat ‚Üí Set where
      z‚â°z : zero ‚Ñï‚â° zero
      s‚â°s : {a b : Nat} ‚Üí a ‚Ñï‚â° b ‚Üí suc a ‚Ñï‚â° suc b

    ‚Ñïrefl : (n : Nat) ‚Üí n ‚Ñï‚â° n
    ‚Ñïrefl zero = z‚â°z
    ‚Ñïrefl (suc n) = s‚â°s (‚Ñïrefl n)
    #+end_src
    We show that the new equality implies the old equality.
    #+begin_example
    ‚â°‚Üí‚Ñï‚â° : {a b : Nat} ‚Üí a ‚â° b ‚Üí a ‚Ñï‚â° b
    ‚â°‚Üí‚Ñï‚â° {a} refl = ‚Ñïrefl a
    #+end_example
    We see that the old equality implies the new equality.
    #+begin_example
    ‚Ñï‚â°‚Üí‚â° : {a b : Nat} ‚Üí a ‚Ñï‚â° b ‚Üí a ‚â° b
    ‚Ñï‚â°‚Üí‚â° z=z = refl
    ‚Ñï‚â°‚Üí‚â° (s=s a‚Ñï‚â°b) = cong suc (‚Ñï‚â°‚Üí‚â° a‚Ñï‚â°b)
    #+end_example

    See cref:sec:agda-ext for a note on extensionality.
*** Predicates as mathematical sets
    <<sec:sets>>
    In this section when we say /set/ we refer to a subset of an Agda type. The
    most natural way to represent subsets in Agda is to use predicates. See
    [[sec:predicates]] for an introduction. A predicate represents the characteristic
    function of the associated subset. For instance consider the predicate:
    #+begin_src text
    Pos : Pred Nat lzero
    Pos n = ¬¨ (n ‚â° 0)
    #+end_src
    It represents the subset of strictly positive natural numbers.

    We proceed by defining the usual concepts related to mathematical sets. In
    order to make the types less verbose we assume that we already have =A : Set
    ‚Ñì= in scope.
     1. \boxed{‚àà} A proof of membership is a simple function application.
        #+begin_src text
        _‚àà_ : REL A (Pred A)
        a ‚àà X = X a
        #+end_src
        This definition is mostly superfluous but it helps to have a syntax closer
        to regular mathematics.
     2. \boxed{‚àâ} A proof of non membership is function from a proof of membership to =‚ä•=.
        #+begin_src text
        _‚àâ_ : REL A (Pred A)
        a ‚àâ X = ¬¨ (a ‚àà X)
        #+end_src
     3. \boxed{‚äÜ} A proof of inclusion =X ‚äÜ Y= is a function that maps a proof of
        membership to =X= to a proof of membership to =Y=.
        #+begin_example
        _‚äÜ_ : Rel (Pred A)
        X ‚äÜ Y = ‚àÄ {x} ‚Üí x ‚àà X ‚Üí x ‚àà Y
        #+end_example
     4. \boxed{‚à©} We use pairs to represent the intersection. Each component is a
        proof of membership to =X= and =Y= respectively.
        #+begin_src text
        _‚à©_ : Pred A ‚Üí Pred A ‚Üí Pred A
        X ‚à© Y = Œª x ‚Üí x ‚àà X √ó x ‚àà Y
        #+end_src
     5. \boxed{‚à™} We use a sum type to represent the union.
        #+begin_src text
        _‚à™_ : Pred A ‚Üí Pred A ‚Üí Pred A
        X ‚à™ Y = Œª x ‚Üí x ‚àà X ‚äé x ‚àà Y
        #+end_src
     6. \boxed{‚àÖ}
        The empty set is represented by a characteristic constant function to =‚ä•=.
        #+begin_src text
        ‚àÖ : Pred A
        ‚àÖ = Œª x ‚Üí ‚ä•
        #+end_src
     7. \boxed{ùüè}
        Similarly, the universe set is represented by a characteristic constant function to =‚ä§=.
        #+begin_src text
        U : Pred A
        U = Œª x ‚Üí ‚ä§
        #+end_src
     8. \(\boxed{\{x\}}\) A singleton set is defined using equality (assuming we
        have equality defined for that type).
        #+begin_example
        ÔΩõ_ÔΩù : A ‚Üí Pred A
        ÔΩõ x ÔΩù = Œª y ‚Üí x ‚â° y
        #+end_example

*** Extensionality
    <<sec:agda-ext>> In Set theory we call axiom of extensionality the property
    that if two sets have the same elements, then they are equal. As in Agda we
    represent sets as functions we reword extensionality for functions: if two
    functions have the same domain and coincide for every element in their domain then
    they are equal. In symbols: \[‚àÄf‚àÄg.(‚àÄx.f(x)=g(x))‚áíf=g.\]

    In Agda we can represent this concept thus (cite:agda-stdlib):
    #+begin_src text
Extensionality : (a b : Level) ‚Üí Set _
Extensionality a b =
  {A : Set a} {B : A ‚Üí Set b} {f g : (x : A) ‚Üí B x} ‚Üí
  ((x : A) ‚Üí f x ‚â° g x) ‚Üí f ‚â° g
    #+end_src

    It is usually the case that we accept the axiom of extensionality as part of
    our metalogic as it is part of the most popular logical framework
    $\textsf{ZF}$, however, in Agda the property of extensionality is not an
    axiom nor a provable theorem.

    An direct consequence of the lack of extensionality is that we cannot show
    equality of sets by double inclusion.
    #+begin_src text
    ‚äÜ‚äá‚Üí‚â° : {‚ÑìS ‚ÑìA : Level} {A : Set ‚ÑìA} {X Y : Pred A ‚ÑìS} ‚Üí X ‚äÜ Y ‚Üí Y ‚äÜ X ‚Üí X ‚â° Y
    ‚äÜ‚äá‚Üí‚â° = ? -- not provable
    #+end_src

    We will see that this has a small effect on
    the definition of generalized Veltman frames in cref:sec:agda-gen-semantics.

*** Positivity
    <<sec:positivity>>

    In this section we present a technicality as described in the Agda
    documentation (cite:agda-doc) regarding datatype definitions that will become
    relevant in cref:sec:agda-ord-semantics where we define ordinary Veltman
    semantics.

    When defining a datatype =D=, Agda poses an additional requirement on the types
    of the constructors of =D=, namely that =D= may only occur strictly positively in
    the types of their arguments. Concretely, for a datatype with constructors
    =c‚ÇÅ : A‚ÇÅ, ‚Ä¶, c‚Çô : A‚Çô=, Agda checks that each =A·µ¢= has the form
    #+begin_src text
    (y‚ÇÅ : B‚ÇÅ) ‚Üí ... ‚Üí (y‚Çó : B‚Çó) ‚Üí D
    #+end_src
    where an argument of type =B·µ¢= of the constructors does not mention =D= or has
    the form
    #+begin_example
    (z‚ÇÅ : C‚ÇÅ) ‚Üí ... ‚Üí (z‚Çñ : C‚Çñ) ‚Üí D
    #+end_example

    The following example showcases the possibility to build a term of type =‚ä•=
    by defining a non strictly positive type =Bad=. As mentioned above, Agda
    rejects the definition of =Bad=.
    #+begin_src text
 data ‚ä• : Set where

 data Bad : Set where
   bad : (Bad ‚Üí ‚ä•) ‚Üí Bad

 self-app : Bad ‚Üí ‚ä•
 self-app (bad f) = f (bad f)

 absurd : ‚ä•
 absurd = self-app (bad self-app)
    #+end_src
* Agda in the thesis
  <<sec:agda-thesis>>
  The goal of this part is to guide the reader through some key parts of the
  code that we have implemented. It is worth noting that we have started from
  scratch as we believe that no other previous work in interpretability logics
  has been done in Agda.

  The implementation relies on the Agda standard library (cite:agda-stdlib).

** Naming conventions :noexport:
   1. If we have =f : T= we say that =f= has type =T= or that =f= is a proof of =T=.
   2. If we have =f : A ‚Üí B ‚Üí C= we say =f= has arguments =A= and =B= and it has
      return type =C=.
** Modal formulas
   Here we present the Agda type that represents a formula as defined in cref:sec:language.

   First we define variables to be natural numbers:
   #+begin_src text
Var : Set
Var = Nat
   #+end_src

   We proceed by inductively defining the formula type: =Fm=. We add a
   constructor for variables and one for each primitive operator.
   #+begin_src text
data Fm : Set where
  var : Var ‚Üí Fm
  ‚ä•' : Fm
  _‚Üù_ : Fm ‚Üí Fm ‚Üí Fm
  _‚ñ∑_ : Fm ‚Üí Fm ‚Üí Fm
   #+end_src
   We have named the bottom constructor =‚ä•'= since the symbol =‚ä•= is commonly
   used in Agda as the empty type. We have used the =‚Üù= to denote a implication
   since =‚Üí= is a reserved symbol for the Agda function type.

   We finally add definable operators as Agda functions. For instance, we define
   $¬¨$ and $‚ñ°$ thus:
  #+begin_src text
infix 60 ¬¨'_
¬¨'_ : Fm ‚Üí Fm
¬¨' a = a ‚Üù ‚ä•'

infix 70 ‚ñ°_
‚ñ°_ : Fm ‚Üí Fm
‚ñ°_ a = ¬¨' a ‚ñ∑ ‚ä•'
  #+end_src
  We use the symbol =¬¨'= instead of =¬¨= for the same reason we used =‚ä•'= instead
  of =‚ä•=.

  It is often the case that we define priority and associativity for our infix
  operators in order to minimize the amount of needed parentheses. The following
  code defines the /infixity/ (level or priority) of =_‚Üù_= and =_‚ñ∑_=.
    #+begin_src text
  infixr 20 _‚Üù_
  infixr 50 _‚ñ∑_
    #+end_src
  A greater number means higher priority. Then we can drop the parentheses
  from the previous formula =var 1 ‚ñ∑ var 0 ‚Üù ‚ä•'=. The $r$ in =infixr= stands
  for right associativity.

** Noetherian relations
   <<sec:agda-noetherian>> We say that a relation is \gls*{noetherian} if it is
    conversely well-founded. We begin by formalizing the concept of infinite
    ascending chain in Agda. In order to do that, we define a coinductive record
    datatype (cite:agda-doc,norell:thesis). A coinductive record is allowed to
    be infinite. In other words, it does not need to have a non-recursive
    constructor.
    #+begin_src text
record InfiniteChain {‚ÑìW ‚ÑìR} {W : Set ‚ÑìW} (_<_ : Rel W ‚ÑìR) (a : W)
  : Set (‚ÑìR ‚äî ‚ÑìW)where
  coinductive
  constructor infiniteChain
  field
    b : W
    a<b : a < b
    tail : InfiniteChain _<_ b
    #+end_src
    We see that the previous record datatype represents an infinite ascending
    chain starting at =a= of some relation =_<_=. It has three fields. =b=: The
    next element in the chain. =a<b=: A proof that $a < b$ and =tail=: an
    infinite chain starting at =b=.

    Then we can define being Noetherian as the negation of the existence of an
    infinite chain:
    #+begin_src text
Noetherian : ‚àÄ {‚ÑìR ‚ÑìW} {W : Set ‚ÑìW} ‚Üí Rel W ‚ÑìR ‚Üí Set (‚ÑìR ‚äî ‚ÑìW)
Noetherian _<_ = ‚àÄ {a} ‚Üí ¬¨ (InfiniteChain _<_ a)
    #+end_src

    For instance, we can prove that a Noetherian relation is irreflexive. First
    we show that from a proof that $xRx$ we can build an infinite chain:
    #+begin_src text
infiniteRefl : ‚àÄ {‚Ñì} {R : Rel A ‚Ñì} {x} ‚Üí R x x ‚Üí InfiniteChain R x
InfiniteChain.b (infiniteRefl {x = x} Rxx) = x
InfiniteChain.a<b (infiniteRefl {x = x} Rxx) = Rxx
InfiniteChain.tail (infiniteRefl {x = x} Rxx) = infiniteRefl Rxx
    #+end_src
    We see that each equation corresponds to a different field in the record
    datatype. This construction is known as /copattern/. Coinductive
    datatypes must be constructed in this way. Copatterns are for
    coinductive types what patterns are for inductive (finite) types. In
    cite:abel2013programming copatterns are described in detail.

    And then we can apply the Noetherian definition.
    #+begin_src text
Noetherian‚áíIrreflexive : ‚àÄ {‚ÑìR ‚ÑìW} {W : Set ‚ÑìW} {R : Rel W ‚ÑìR}
     ‚Üí Noetherian R ‚Üí ‚àÄ {x} ‚Üí ¬¨ R x x
Noetherian‚áíIrreflexive noetherian Rxx = noetherian (infiniteRefl Rxx)
    #+end_src

    To see another example we refer the reader to cref:sec:agda-L.
** Ordinary semantics
   <<sec:agda-ord-semantics>>
   In this chapter we explain how we have represented ordinary Veltman semantics
   in Agda.

   To represent ordinary Veltman semantics in Agda, the first step is to
   define the type of an ordinary Veltman frame:
   #+begin_src text
record Frame {‚ÑìW ‚ÑìR ‚ÑìS : Level} (W : Set ‚ÑìW) (R : Rel W ‚ÑìR) (S : Rel‚ÇÉ W ‚ÑìS)
  : Set (‚ÑìW ‚äî ‚ÑìR ‚äî ‚ÑìS) where
  constructor frame
  field
    witness : W
    R-trans : Transitive R
    R-noetherian : Noetherian R
    Sw‚äÜR[w]¬≤ : ‚àÄ {w u v} ‚Üí S w u v ‚Üí R w u √ó R w v
    Sw-refl : ‚àÄ {w u} ‚Üí R w u ‚Üí S w u u
    Sw-trans : ‚àÄ {w} ‚Üí Transitive (S w)
    R-Sw-trans : ‚àÄ {w u v} ‚Üí R w u ‚Üí R u v ‚Üí S w u v
   #+end_src
   The keyword =record= is used to define a new product type (a tuple) in which
   each component (or field) has a name that we can use to access it.

   We see that the datatype is parameterized by the universe =W=, the =R=
   relation, the =S= relation and their respective universe levels =‚ÑìW, ‚ÑìR, ‚ÑìS=.

   The first component, =witness=, is required to make sure that the set of worlds is
   not empty. The remaining components are the properties that must be satisfied
   according to cref:def:ordinary-frames.

   We define a valuation on a frame thus:
   #+begin_src text
Valuation : Frame {‚ÑìW} {‚ÑìR} {‚ÑìS} W R S ‚Üí Set (lsuc lzero ‚äî ‚ÑìW)
Valuation {W = W} F = REL W Var lzero
   #+end_src

   And then we define a model to be a frame parameterized with a valuation on that
   frame.
   #+begin_src text
record Model (W : Set ‚ÑìW) (R : Rel W ‚ÑìR) (S : Rel‚ÇÉ W ‚ÑìS) (V : REL W Var lzero)
  : Set (‚ÑìW ‚äî ‚ÑìR ‚äî ‚ÑìS) where
  constructor model
  field
    F : Frame {‚ÑìW} {‚ÑìR} {‚ÑìS} W R S
   #+end_src

   Our next step is to define the forcing relation.
   #+begin_src text
data _,_‚ä©_ (M : Model {‚ÑìW} {‚ÑìR} {‚ÑìS} W R S V) (w : W)
  : Fm ‚Üí Set (‚ÑìW ‚äî ‚ÑìR ‚äî ‚ÑìS)
   #+end_src
   We set a model and a world of that model as parameters as they should be
   shared by all constructors. We leave the formula as an index as it may vary
   depending on the constructor. We should introduce a constructor for each case
   in cref:def:ord-forcing:
   1. We do not need a constructor for =‚ä•'= as its absence implicitly implies
      that we can never build an instance of =M , w ‚ä© ‚ä•'= regardless of =M= and
      =w=.
   2. If $x‚àà\var{}$, then $w‚ä©x$ iff $‚ü®w,x‚ü©‚ààV$:
      #+begin_src text
  var : {p : Var} ‚Üí p ‚àà V w ‚Üí M , w ‚ä© var p
      #+end_src
   3. If $A,B‚àà\fm{}$, then $w‚ä©A‚ÜíB$ iff if $w‚ä©A$ then $w‚ä©B$:
      #+begin_src text
  impl : {A B : Fm} ‚Üí ((M , w ‚ä© A) ‚Üí (M , w ‚ä© B)) ‚Üí M , w ‚ä© (A ‚Üù B)
      #+end_src
   4. If $A,B‚àà\fm{}$, then $w‚ä©A‚ñ∑B$ iff if $wRu$ and $u‚ä©A$ then there exists $v$ such
      that $v‚ä©B$ and $uS_wv$.
      #+begin_src text
   rhd : {A B : Fm} ‚Üí
     ({u : W} ‚Üí R w u ‚Üí M , u ‚ä© A ‚Üí (‚àÉ[ v ] (S w u v √ó (M , v ‚ä© B))))
     ‚Üí M , w ‚ä© A ‚ñ∑ B
      #+end_src

   Unfortunately the definition above is not accepted by Agda. The reason is that
   constructors =rhd= and =impl= both fail the positivity check (see
   cref:sec:positivity). For instance, observe that in the =impl= constructor type
   we have =(M , w ‚ä© A)= on the left of an arrow =‚Üí=.

   We have circumvented this problem by providing mutually recursive definitions
   for /forcing/ (=_,_‚ä©_=) and /not forcing/ (=_,_‚äÆ_=). Agda allows the
   definition of mutually recursive datatypes (and functions) by first providing
   the type of both[fn::Or more if it is the case.] definitions and after those
   giving the rest of the definition, that is, the constructors for datatypes
   and the equations for functions.

   The type of the two datatypes that we want to define are as follows.
   #+begin_src text
data _,_‚ä©_ (M : Model {‚ÑìW} {‚ÑìR} {‚ÑìS} W R S V) (w : W)
  : Fm ‚Üí Set (‚ÑìW ‚äî ‚ÑìR ‚äî ‚ÑìS) -- forcing relation

data _,_‚äÆ_ (M : Model {‚ÑìW} {‚ÑìR} {‚ÑìS} W R S V) (w : W)
  : Fm ‚Üí Set (‚ÑìW ‚äî ‚ÑìR ‚äî ‚ÑìS) -- not forcing relation
   #+end_src

   Next we provide the strictly positive types of each constructor of the
   =_,_‚ä©_= and =_,_‚äÆ_= relations.
   1. For the =‚ä•'= constant.
      1. Forcing (=_,_‚ä©_=). No constructor is required.
      2. Not forcing (=_,_‚äÆ_=).
        #+begin_example
        bot : M , w ‚äÆ ‚ä•'
        #+end_example
   2. For variables.
    1. Forcing (=_,_‚ä©_=).
       #+begin_src text
  var : {p : Var} ‚Üí p ‚àà V w ‚Üí M , w ‚ä© var p
       #+end_src
    2. Not forcing (=_,_‚äÆ_=).
       #+begin_example
  var : {p : Var} ‚Üí p ‚àâ V w ‚Üí M , w ‚äÆ var p
       #+end_example

   3. For implication (=‚Üù=).
    1. Forcing (=_,_‚ä©_=).
       #+begin_src text
  impl : {A B : Fm} ‚Üí M , w ‚äÆ A ‚äé M , w ‚ä© B ‚Üí M , w ‚ä© A ‚Üù B
       #+end_src
    2. Not forcing (=_,_‚äÆ_=).
       #+begin_src text
  impl : {A B : Fm} ‚Üí M , w ‚ä© A ‚Üí M , w ‚äÆ B ‚Üí M , w ‚äÆ A ‚Üù B
       #+end_src
       \pagebreak
   4. For interpretability (=‚ñ∑=).
    1. Forcing (=_,_‚ä©_=).
       #+begin_src text
  rhd : {A B : Fm} ‚Üí
    (‚àÄ {u} ‚Üí R w u ‚Üí M , u ‚äÆ A ‚äé (‚àÉ[ v ] (S w u v √ó M , v ‚ä© B)))
    ‚Üí M , w ‚ä© A ‚ñ∑ B
       #+end_src
    2. Not forcing (=_,_‚äÆ_=).
       #+begin_src text
  rhd : {A B : Fm} ‚Üí
    ‚àÉ[ u ] (R w u √ó M , u ‚ä© A √ó ((v : W) ‚Üí (¬¨ S w u v) ‚äé M , v ‚äÆ B))
    ‚Üí M , w ‚äÆ A ‚ñ∑ B
       #+end_src

   Putting it all together results in the following definitions:
   #+begin_src text
data _,_‚ä©_ M w where
  var : {x : Var} ‚Üí V w x ‚Üí M , w ‚ä© var x
  impl : {A B : Fm} ‚Üí M , w ‚äÆ A ‚äé M , w ‚ä© B ‚Üí M , w ‚ä© A ‚Üù B
  rhd : {A B : Fm} ‚Üí
    (‚àÄ {u} ‚Üí R w u ‚Üí M , u ‚äÆ A ‚äé (‚àÉ[ v ] (S w u v √ó M , v ‚ä© B)))
    ‚Üí M , w ‚ä© A ‚ñ∑ B
   #+end_src
   #+begin_src text
data _,_‚äÆ_ M w where
  var : {x : Var} ‚Üí ¬¨ (V w x) ‚Üí M , w ‚äÆ var a
  impl : {A B : Fm} ‚Üí M , w ‚ä© A ‚Üí M , w ‚äÆ B ‚Üí M , w ‚äÆ A ‚Üù B
  rhd : {A B : Fm} ‚Üí
    ‚àÉ[ u ] (R w u √ó M , u ‚ä© A √ó ((v : W) ‚Üí (¬¨ S w u v) ‚äé M , v ‚äÆ B))
    ‚Üí M , w ‚äÆ A ‚ñ∑ B
  bot : M , w ‚äÆ ‚ä•'
   #+end_src

   To prove that =_,_‚ä©= and =_,_‚äÆ= are indeed the negation of each other
   we should prove two lemmas. We define =A ‚áî B ‚âî A ‚Üí B √ó B ‚Üí A=. Then the lemma in
   Agda types is as follows.

   {{{beginlemma}}}
   {{{agda}}}
   <<lemma:forcing-neg>>
   \hfill
   1. =‚àÄ {M w A} ‚Üí M , w ‚ä© A ‚áî ¬¨ (M , w ‚äÆ A)=.
   2. =‚àÄ {M w A} ‚Üí ¬¨ (M , w ‚ä© A) ‚áî M , w ‚äÆ A=.
   {{{endlemma}}} For part 1 we can prove $‚áí$ and for part 2 we can prove $‚áê$
   (see cref:lemma:equiv). However, it is not possible to prove the remaining
   directions. In general terms, this is due to the fact that in Agda (and in
   intuitionistic logic in general) we can prove that =(¬¨ A ‚äé B) ‚Üí A ‚Üí B= but we
   cannot prove =A ‚Üí B ‚Üí (¬¨ A ‚äé B)=. The reason being that we lack the law of
   excluded middle, as it is a non-constructive axiom. In order to prove the
   remaining directions we need to assume that the forcing relation is
   decidable.

   {{{begindef}}} {{{agda}}} <<def:ord-decidable-model>>

   We say that =M= is \gls*{decidable model} if for any world =w= and formula
   =A= we have that either =M , w ‚ä© A= or =M , w ‚äÆ A=.

   In Agda terms:
   #+begin_src text
DecidableModel : Model ‚Üí Set
DecidableModel M = ‚àÄ w A ‚Üí M , w ‚ä© A ‚äé M , w ‚äÆ A
   #+end_src
   {{{enddef}}}

   {{{beginproof}}}
   Under the assumption that we restrict ourselves to decidable models we can
   prove cref:lemma:forcing-neg.
   {{{endproof}}}

   {{{beginlemma}}} {{{agda}}} {{{coq}}} <<lemma:equiv>> The following
   properties on the forcing relation are true:

   1. =‚ä©‚ä• : ‚àÄ {M w} ‚Üí ¬¨ (M , w ‚ä© ‚ä•')=;
   2. =‚äÆ‚Üí¬¨‚ä© : ‚àÄ {M w A} ‚Üí M , w ‚äÆ A ‚Üí ¬¨ (M , w ‚ä© A)=;
   3. =‚ä©‚Üí¬¨‚äÆ : ‚àÄ {M w A} ‚Üí M , w ‚ä© A ‚Üí ¬¨ (M , w ‚äÆ A)=;
   4. =‚ä©MP : ‚àÄ {M w A B} ‚Üí M , w ‚ä© A ‚Üù B ‚Üí M , w ‚ä© A ‚Üí M , w ‚ä© B=;
   5. =‚ä©¬¨ : ‚àÄ {M w A} ‚Üí (M , w ‚ä© ¬¨' A) ‚áî (M , w ‚äÆ A)=;
   6. =‚äÆ¬¨ : ‚àÄ {M w A} ‚Üí M , w ‚äÆ ¬¨' A ‚áî M , w ‚ä© A=;
   7. =‚ä©¬¨¬¨ : ‚àÄ {M w A} ‚Üí M , w ‚ä© ¬¨' ¬¨' A ‚áî M , w ‚ä© A=;
   8. =‚äÆ¬¨¬¨ : ‚àÄ {M w A} ‚Üí M , w ‚äÆ ¬¨' ¬¨' A ‚áî M , w ‚äÆ A=;
   9. =‚ä©‚àß : ‚àÄ {M w A B} ‚Üí M , w ‚ä© A ‚àß B ‚áî (M , w ‚ä© A √ó M , w ‚ä© B)=;
   10. =‚äÆ‚àß : ‚àÄ {M w A B} ‚Üí M , w ‚äÆ A ‚àß B ‚áî (M , w ‚äÆ A ‚äé M , w ‚äÆ B)=;
   11. =‚ä©‚à® : ‚àÄ {M w A B} ‚Üí M , w ‚ä© A ‚à® B ‚áî (M , w ‚ä© A ‚äé M , w ‚ä© B)=;
   12. =‚ä©‚ñ° : ‚àÄ {M w A} ‚Üí M , w ‚ä© ‚ñ° A ‚áî (‚àÄ {v} ‚Üí R w v ‚Üí M , v ‚ä© A)=;
   13. =‚äÆ‚ñ° : ‚àÄ {M w A} ‚Üí M , w ‚äÆ ‚ñ° A ‚áî (‚àÉ[ u ] (R w u √ó M , u ‚äÆ A))=;
   14. =‚ä©‚ô¢ : ‚àÄ {M w A} ‚Üí M , w ‚ä© ‚ô¢ A ‚áî (‚àÉ[ u ] (R w u √ó M , u ‚ä© A))=;
   15. =‚äÆ‚ô¢ : ‚àÄ {M w A} ‚Üí M , w ‚äÆ ‚ô¢ A ‚áî (‚àÄ {u} ‚Üí R w u ‚Üí M , u ‚äÆ A)=;
   16. =‚ä©‚Üù‚á® : ‚àÄ {M w A B} ‚Üí M , w ‚ä© A ‚Üù B ‚Üí M , w ‚ä© A ‚Üí M , w ‚ä© B=;
   17. =‚ä©‚ñ∑‚á® : ‚àÄ {M w A B} ‚Üí M , w ‚ä© A ‚ñ∑ B ‚Üí (‚àÄ {u} ‚Üí R w u ‚Üí M , u ‚ä© A ‚Üí ‚àÉ[ v ] (S w u v √ó M , v ‚ä© B)=.
   {{{endlemma}}}
   {{{beginproof}}} The above properties have been proven
   in Agda and Coq without assuming that the model is decidable. {{{endproof}}}


   {{{beginlemma}}} {{{agda}}} {{{coq}}} <<lemma:ord-equiv-dec>> The following
   series of equivalences can be proven for decidable models.

   1. =‚ä©‚Üù : ‚àÄ {w A B} ‚Üí M , w ‚ä© A ‚Üù B ‚áî (M , w ‚ä© A ‚Üí M , w ‚ä© B)=;
   2. =‚ä©‚ñ∑ : ‚àÄ {w A B} ‚Üí M , w ‚ä© A ‚ñ∑ B ‚áî
      (‚àÄ {u} ‚Üí R w u ‚Üí M , u ‚ä© A ‚Üí ‚àÉ[ v ] (S w u v √ó M , v ‚ä© B))=;
   3. =‚ä©‚áî¬¨‚äÆ : ‚àÄ {w A} ‚Üí M , w ‚ä© A ‚áî (¬¨ M , w ‚äÆ A)=;
   4. =‚äÆ‚áî¬¨‚ä© : ‚àÄ {w A} ‚Üí M , w ‚äÆ A ‚áî (¬¨ M , w ‚ä© A)=.
   {{{endlemma}}} {{{beginproof}}} Note that we only need the
   decidability assumption for 1 ($‚áê$), 2 ($‚áê$), 3 ($‚áê$) and 4 ($‚áê$). {{{endproof}}}

   From now on, we always restrict ourselves to decidable models as the usage of
   cref:lemma:ord-equiv-dec is ubiquitous. If we were to assume that we are
   outside of Agda and that we accept the law of excluded middle as part of our
   metalogic, the mentioned assumption could be dropped.

** Generalized semantics
   <<sec:agda-gen-semantics>> In this chapter we explain how we have represented
   generalized Veltman semantics in Agda. As explained in cref:sec:trans we
   consider eight different quasi-transitivity properties, thus, we need to
   define everything related to generalized Veltman semantics to be generic with
   respect to the quasi-transitivity condition used, which was certainly
   presented some challenges.

   Analogously to ordinary semantics we start by defining a frame. We begin by
   defining a datatype that represents a frame without the quasi-transitivity
   condition. See that we define the type =ùïé ‚âî Pred W ‚ÑìW=, which means that a
   term of type =ùïé= is a subset of =W= (see cref:sec:sets for details on how
   to represent mathematical sets in Agda). See that the =S-ext= field adds
   extensionality restricted to the third component of the =S= relation.
   #+begin_src text
record FrameNoTrans (W : Set ‚ÑìW) (R : Rel W ‚ÑìR) (S : REL‚ÇÉ W W (Pred W ‚ÑìW) ‚ÑìS)
  : Set (lsuc lzero ‚äî ‚ÑìR ‚äî ‚ÑìS ‚äî lsuc ‚ÑìW) where
  constructor frame
  ùïé : Set (lsuc ‚ÑìW)
  ùïé = Pred W ‚ÑìW
  field
    witness : W
    Swu-sat : ‚àÄ {w u Y} ‚Üí S w u Y ‚Üí Satisfiable Y
    R-trans : Transitive R
    R-noetherian : Noetherian R
    Sw‚äÜR[w] : ‚àÄ {w u Y} ‚Üí S w u Y ‚Üí R w u
    SwuY‚äÜRw : ‚àÄ {w u Y} ‚Üí S w u Y ‚Üí ‚àÄ {y} ‚Üí y ‚àà Y ‚Üí R w y
    S-quasirefl : ‚àÄ {w u} ‚Üí R w u ‚Üí S w u ÔΩõ u ÔΩù
    R-Sw-trans : ‚àÄ {w u v} ‚Üí R w u ‚Üí R u v ‚Üí S w u ÔΩõ v ÔΩù
    S-ext : ‚àÄ {w x V V'} ‚Üí S w x V ‚Üí V ‚äÜ V' ‚Üí V' ‚äÜ V ‚Üí S w x V'
   #+end_src

   Then we define a new datatype =Frame= which represents a non-transitive
   Generalized Veltman frame plus some quasi-transitivity condition, which is
   left as a parameter =T=.
   #+begin_example
record Frame (W : Set ‚ÑìW) (R : Rel W ‚ÑìR) (S : REL‚ÇÉ W W (Pred W ‚ÑìW) ‚ÑìS)
  (T : (W : Set ‚ÑìW) ‚Üí REL‚ÇÉ W W (Pred W ‚ÑìW) ‚ÑìS ‚Üí Set (lsuc ‚ÑìW ‚äî ‚ÑìS))
  : Set (lsuc ‚ÑìW ‚äî ‚ÑìR ‚äî ‚ÑìS) where
  constructor frame
  field
    frame-0 : FrameNoTrans {‚ÑìW} {‚ÑìR} {‚ÑìS} W R S
    quasitrans : T W S
   #+end_example

   We now define all the quasi-transitivity conditions. Here we only present
   {{{cond(4)}}}.
   #+begin_example
  Trans-4 : (W : Set ‚ÑìW) ‚Üí REL‚ÇÉ W W (Pred W ‚ÑìW) ‚ÑìS ‚Üí Set (lsuc ‚ÑìW ‚äî ‚ÑìS))
  Trans-4 W S = ‚àÄ {x u Y} ‚Üí S x u Y ‚Üí ‚àÉ[ y ] (y ‚àà Y √ó (‚àÄ {Y'} ‚Üí S x y Y' ‚Üí S x u Y'))
   #+end_example

   And finally we can define a datatype that represents a generalized Veltman
   frame for each of the quasi-transitivity conditions as a simple instantiation
   of the generic =Frame= defined before. Here we only present {{{cond(4)}}}.
   #+begin_example
Frame4 : (W : Set ‚ÑìW) (R : Rel W ‚ÑìR) (S : REL‚ÇÉ W W (Pred W ‚ÑìW) ‚ÑìS) ‚Üí Set _
Frame4 W R S = Frame W R S (Trans-4 W S)
   #+end_example


   In order to define the generalized Veltman semantics forcing relation, since
   we need to define it generically to work for any quasi-transitivity condition
   assume that we have some term =T= representing such condition of typed thus:
   #+begin_example
   (T : ‚àÄ {‚ÑìW ‚ÑìS} (W : Set ‚ÑìW) ‚Üí REL‚ÇÉ W W (Pred W ‚ÑìW) ‚ÑìS ‚Üí Set (lsuc ‚ÑìW ‚äî ‚ÑìS))
   #+end_example

   Then we define a generalized model in an analogous way to how we did it for
   ordinary semantics:
   #+begin_example
  record Model
    {‚ÑìW ‚ÑìR ‚ÑìS}
    (W : Set ‚ÑìW)
    (R : Rel W ‚ÑìR)
    (S : REL‚ÇÉ _ _ _ ‚ÑìS)
    (V : REL W Var lzero)
    : Set (lsuc ‚ÑìW ‚äî ‚ÑìR ‚äî ‚ÑìS) where
    constructor model
    field
      F : Frame {‚ÑìW} {‚ÑìR} {‚ÑìS} W R S T
   #+end_example

   And finally we define the forcing relation using mutually recursive datatypes
   as we did for ordinary semantics. The only difference is in the =rhd=
   constructor.
   #+begin_example
  data _,_‚äÆ_ {‚ÑìW ‚ÑìR ‚ÑìS W R S V} (M : Model {‚ÑìW} {‚ÑìR} {‚ÑìS} W R S V) (w : W)
    : Fm ‚Üí Set (lsuc ‚ÑìW ‚äî ‚ÑìR ‚äî ‚ÑìS)

  data _,_‚ä©_ {‚ÑìW ‚ÑìR ‚ÑìS W R S V} (M : Model {‚ÑìW} {‚ÑìR} {‚ÑìS} W R S V) (w : W)
    : Fm ‚Üí Set (lsuc ‚ÑìW ‚äî ‚ÑìR ‚äî ‚ÑìS)

  data _,_‚ä©_ {‚ÑìW} {‚ÑìR} {‚ÑìS} {W} {R} {S} {V} M w where
    var : ‚àÄ {a : Var} ‚Üí a ‚àà V w ‚Üí M , w ‚ä© var a
    impl : ‚àÄ {A B} ‚Üí M , w ‚äÆ A ‚äé M , w ‚ä© B ‚Üí M , w ‚ä© A ‚Üù B
    rhd : ‚àÄ {A B} ‚Üí
      (‚àÄ {u} ‚Üí R w u ‚Üí M , u ‚äÆ A ‚äé (‚àÉ[ Y ] (S w u Y √ó (Y ‚äÜ M ,_‚ä© B))))
      ‚Üí M , w ‚ä© A ‚ñ∑ B

  data _,_‚äÆ_ {‚ÑìW} {‚ÑìR} {‚ÑìS} {W} {R} {S} {V} M w where
    var : ‚àÄ {a : Var} ‚Üí a ‚àâ V w ‚Üí M , w ‚äÆ var a
    impl : ‚àÄ {A B} ‚Üí M , w ‚ä© A ‚Üí M , w ‚äÆ B ‚Üí M , w ‚äÆ A ‚Üù B
    rhd : ‚àÄ {A B} ‚Üí
      ‚àÉ[ u ] (R w u √ó M , u ‚ä© A
      √ó ‚àÄ Y ‚Üí Satisfiable Y ‚Üí (¬¨ S w u Y) ‚äé (Satisfiable (Y ‚à© (M ,_‚äÆ B))))
      ‚Üí M , w ‚äÆ A ‚ñ∑ B
    bot : M , w ‚äÆ ‚ä•'
   #+end_example

   Recall that in cref:sec:agda-ord-semantics in order to prove some
   properties we had to assume that the ordinary models were decidable in the
   sense of cref:def:ord-decidable-model. For generalized
   semantics we need to make a stronger assumption described in the next
   definition.

   {{{begindef}}} {{{agda}}} We say that =M= is \gls*{multi decidable model} if for any set
   of worlds =Y= and formula =A= we can decide whether
   1. for every element =y= in =Y= we have =M , y ‚äÆ A=; or
   2. there is an element =y= in =Y= such that =M , y ‚äÆ A=.

   In Agda terms:
   #+begin_src text
  MultiDecidableModel : ‚àÄ {‚ÑìW ‚ÑìR ‚ÑìS W R S V} ‚Üí Model {‚ÑìW} {‚ÑìR} {‚ÑìS} W R S V
    ‚Üí Set (lsuc ‚ÑìW ‚äî ‚ÑìR ‚äî ‚ÑìS ‚äî lsuc ‚ÑìW)
  MultiDecidableModel {‚ÑìW = ‚ÑìW} {W = W} M =
    ‚àÄ (Y : Pred W ‚ÑìW) A ‚Üí Y ‚äÜ M ,_‚ä© A ‚äé Satisfiable (Y ‚à© (M ,_‚äÆ A))
   #+end_src
   {{{enddef}}}

   {{{beginlemma}}} {{{agda}}}
   Every multi-decidable model is also decidable.
   {{{endlemma}}}

   {{{beginlemma}}} <<lemma:gen-lemmas>> {{{agda}}} Assuming that we restrict
   ourselves to multi-decidable models then properties in
   cref:lemma:forcing-neg,lemma:equiv,lemma:ord-equiv-dec also hold for
   generalized semantics. {{{endlemma}}}
*** A guided Agda proof
    <<sec:agda-L>> In this section we guide the user through a non-trivial Agda
    proof, which will hopefully give the reader a feel of how we can proof
    generalized Veltman semantic properties in Agda. We prove that for any
    generalized Veltman model $M$ and world $w$ we have that $w$ forces L√∂b's
    axiom. In symbols: \[‚àÄM‚àÄw‚àÄA.\ M , w ‚ä© ‚ñ° (‚ñ° A ‚Üí A) ‚Üí ‚ñ° A.\] Note that since
    L√∂b's axiom is in $\textsf{IL}$ we need to show this as part of the
    soundness proof.

    We begin by outlining the proof without Agda. Assume that for some world
    $w‚ÇÄ$ we have $w_0‚ä©‚ñ° (‚ñ° A ‚Üí A)$. Assume for a contradiction that $w‚äÆ‚ñ°A$, then
    there exists some $w‚ÇÅ$ such that $w‚ÇÄRw‚ÇÅ‚äÆA$. Since $w‚ÇÄRw‚ÇÅ$ it follows that
    $w‚ÇÅ‚ä©‚ñ°A‚ÜíA$. Then since $w‚ÇÅ‚äÆA$ we necessarily have that $w‚ÇÅ‚äÆ‚ñ°A$. Then there
    exists $w‚ÇÇ$ such that $w‚ÇÅRw‚ÇÇ‚äÆA$. Since $R$ is transitive we have that
    $w‚ÇÄRw‚ÇÇ$ and thus $w‚ÇÇ‚ä©‚ñ°A‚ÜíA$. We can repeat the previous argument indefinitely
    to build an infinite chain $w‚ÇÄRw‚ÇÅR‚Ä¶$, which is a contradiction since $R$ is
    Noetherian. This concludes the pen and paper proof.

    We proceed with the Agda proof. During the course of this example we use
    some lemmas listed below, which we have proved in Agda, however, we just
    display their type here and we omit their proof in order to save space. Also,
    assume that we have some model =M= in scope.
    #+begin_src text
    ‚ä©4' : ‚àÄ {w A} ‚Üí M , w ‚ä© ‚ñ° A ‚Üí M , w ‚ä© ‚ñ° ‚ñ° A
    ‚äÆ‚ñ° : ‚àÄ {w A} ‚Üí M , w ‚äÆ ‚ñ° A ‚áî (‚àÉ[ u ] (R w u √ó M , u ‚äÆ A))
    ‚ä©‚ñ° : ‚àÄ {w A} ‚Üí M , w ‚ä© ‚ñ° A ‚áî (‚àÄ {v} ‚Üí R w v ‚Üí M , v ‚ä© A)
    ‚ä©‚áî¬¨‚äÆ : ‚àÄ {w A} ‚Üí M , w ‚ä© A ‚áî ¬¨ (M , w ‚äÆ A)
    _‚áí_ : ‚àÄ {a b} {A : Set a} {B : Set b} ‚Üí A ‚áî B ‚Üí A ‚Üí B
    #+end_src

    *Naming convention*. In this proof we use the popular convention to name
    variables after their type, which greatly improves the readability of
    proofs. For instance, if we bind some variable of type =R w u= we will name
    it =Rwu=; if we bind a variable of type =M , w ‚ä© A= we will name it =w‚ä©A=;
    and so on.

    We begin by showing a useful lemma: for any $w,u,A$, if $wRu$ and $u‚äÆA$ and
    $w‚ä©‚ñ°(‚ñ°A‚ÜíA)$ then we can build an infinite \text{$R$-chain} starting at $w$.
    The following type expresses the aforementioned property.
    #+begin_src text
    R-chain : ‚àÄ {w u A} ‚Üí R w u ‚Üí M , u ‚äÆ A ‚Üí M , w ‚ä© ‚ñ° (‚ñ° A ‚Üù A) ‚Üí InfiniteChain R w
    #+end_src
    Recall that infinite chains are defined as coinductive datatypes in cref:sec:agda-noetherian. Hence we proceed by building the infinite chain using
    copatterns. The first two components are clear:
    #+begin_src text
  InfiniteChain.b (R-chain {w} {u} Rwu uA uF) = u
  InfiniteChain.a<b (R-chain {w} {u} Rwu uA uF) = Rwu
    #+end_src
    Then we must show that there is an infinite chain starting at $u$. The
    argument =w‚ä©‚ñ°‚ü®‚ñ°A‚ÜùA‚ü©= has type =M , w ‚ä© ‚ñ° (‚ñ° A ‚Üù A)=, hence by applying the
    lemma =‚ä©‚ñ°= in the right (=‚áí=) direction and using the fact that =Rwu= has type =R
    w u= we get a term of type =M , u ‚ä© ‚ñ° A ‚Üù A= which we pattern match using
    the =widh= construct[fn::The =width= construct allows us to pattern match
    on terms that can be build from the arguments of the function.]. By the
    definition of the constructor =impl= for the =_,_‚ä©_= datatype it follows
    that we have two cases: either =M , u ‚ä© A= or =M , u ‚äÆ ‚ñ° A=.

    If it is the case that =M , u ‚ä© A= we can build a term of type =‚ä•= by using
    the =‚ä©‚Üí¬¨‚äÆ= lemma and then we can use the principle of explosion to return
    anything.
    #+begin_src text
  InfiniteChain.tail (R-chain Rwu u‚äÆA w‚ä©‚ñ°‚ü®‚ñ°A‚ÜùA‚ü©) with (‚ä©‚ñ° ‚áí w‚ä©‚ñ°‚ü®‚ñ°A‚ÜùA‚ü©) Rwu
  ... | impl (inj‚ÇÇ u‚ä©A) = explosion (‚ä©‚Üí¬¨‚äÆ u‚ä©A u‚äÆA)
    #+end_src

    On the contrary, if we have that =M , u ‚äÆ ‚ñ° A= then by the =‚äÆ‚ñ°= lemma we get
    that there exists some =v= such that =R u v= and =M , v ‚ä© A=. Then we can
    use the =‚ä©4'= lemma to get a term of type =M , w ‚ä© ‚ñ° (‚ñ° (‚ñ° A ‚Üù A))=, then by
    lemma =‚ä©‚ñ°= and the fact we have a proof of =R w u= we can build a term of
    type =M , u ‚ä© ‚ñ° (‚ñ° A ‚Üù A)=. Finally by a recursive call (induction
    hypothesis) to =R-chain= with =R u v= and =v‚ä©A= and the term described above
    we get a term of the desired type.
    #+begin_src text
  ... | impl (inj‚ÇÅ x‚äÆ‚ñ°A) with ‚äÆ‚ñ° ‚áí x‚äÆ‚ñ°A
  ... | (v ‚∏¥ Ruv ‚∏¥ v‚ä©A) = R-chain Ruv v‚ä©A ((‚ä©‚ñ° ‚áí ‚ä©4' w‚ä©‚ñ°‚ü®‚ñ°A‚ÜùA‚ü©) Rwu)
    #+end_src
    This concludes the proof of the lemma. We now proceed to prove our theorem.
    The statement of the theorem is represented by the following type:
    #+begin_src text
  ‚ä©L : ‚àÄ {w A} ‚Üí M , w ‚ä© ‚ñ° (‚ñ° A ‚Üù A) ‚Üù ‚ñ° A
    #+end_src
    We use lemma =‚ä©‚Üù= to get a proof of =M , w ‚ä© ‚ñ° (‚ñ° A ‚Üù A)=. Then we use lemma
    =‚ä©‚ñ°= on the left direction, so we assume =R w u= and our goal is to show =M
    , u ‚ä© A=. By using lemma =‚ä©‚áî¬¨‚äÆ= on the left direction. Our goal is to show
    =¬¨ (M , w ‚äÆ A)= which normalizes to =M , w ‚äÆ A ‚Üí ‚ä•=, hence we assume =M , u
    ‚äÆ A= and we aim to build a proof of =‚ä•=. We can build an infinite chain with
    lemma =R-chain= proved above and the facts that =R w u=, =M , u ‚äÆ A= and =M
    , w ‚ä© ‚ñ° (‚ñ° A ‚Üù A)=. Before the final step it may be useful to recall the
    definition of a =Noetherian= relation (see cref:sec:agda-noetherian):
    #+begin_src text
Noetherian _<_ = ‚àÄ {a} ‚Üí ¬¨ (InfiniteChain _<_ a)
    #+end_src
    Finally we use the property that the =R= relation of the model is Noetherian
    to get a term of type =‚ä•= as desired.
    #+begin_example
  ‚ä©L : ‚àÄ {w A} ‚Üí M , w ‚ä© ‚ñ° (‚ñ° A ‚Üù A) ‚Üù ‚ñ° A
  ‚ä©L {w} {A} = ‚ä©‚Üù ‚áê Œª w‚ä©‚ñ°‚ü®‚ñ°A‚ÜíA‚ü© ‚Üí ‚ä©‚ñ° ‚áê Œª {u} Rwu ‚Üí ‚ä©‚áî¬¨‚äÆ ‚áê
    Œª {u‚äÆA ‚Üí R-noetherian (R-chain Rwu u‚äÆA w‚ä©‚ñ°‚ü®‚ñ°A‚ÜíA‚ü©)}
    #+end_example

    Putting it all together we have:
    #+begin_src text
  R-chain : ‚àÄ {w u A} ‚Üí R w u ‚Üí M , u ‚äÆ A ‚Üí M , w ‚ä© ‚ñ° (‚ñ° A ‚Üù A) ‚Üí InfiniteChain R w
  InfiniteChain.b (R-chain {w} {u} Rwu uA uF) = u
  InfiniteChain.a<b (R-chain {w} {u} Rwu uA uF) = Rwu
  InfiniteChain.tail (R-chain {w} {u} Rwu u‚äÆA w‚ä©‚ñ°‚ü®‚ñ°A‚ÜùA‚ü©)
     with (‚ä©‚ñ° ‚áí w‚ä©‚ñ°‚ü®‚ñ°A‚ÜùA‚ü©) Rwu
  ... | impl (inj‚ÇÇ u‚ä©A) = ‚ä•-elim (‚ä©‚Üí¬¨‚äÆ u‚ä©A u‚äÆA)
  ... | impl (inj‚ÇÅ x‚äÆ‚ñ°A) with ‚äÆ‚ñ° ‚áí x‚äÆ‚ñ°A
  ... | (v ‚∏¥ Ruv ‚∏¥ v‚ä©A) = R-chain Ruv v‚ä©A ((‚ä©‚ñ° ‚áí ‚ä©4' w‚ä©‚ñ°‚ü®‚ñ°A‚ÜùA‚ü©) Rwu)

  ‚ä©L : ‚àÄ {w A} ‚Üí M , w ‚ä© ‚ñ° (‚ñ° A ‚Üù A) ‚Üù ‚ñ° A
  ‚ä©L {w} {A} = ‚ä©‚Üù ‚áê Œª w‚ä©‚ñ°‚ü®‚ñ°A‚ÜíA‚ü© ‚Üí ‚ä©‚ñ° ‚áê Œª {u} Rwu ‚Üí ‚ä©‚áî¬¨‚äÆ ‚áê
    Œª {u‚äÆA ‚Üí R-noetherian (R-chain Rwu u‚äÆA w‚ä©‚ñ°‚ü®‚ñ°A‚ÜíA‚ü©)}
    #+end_src
** Logic \il{} and syntactic proofs
   Here we present our efforts on formalizing syntactic \il{} proofs in Agda. We
   restrict ourselves to finite sets of assumptions.

   We begin by defining the necessary type to represent a finite list:
   #+begin_src text
data List {a : Level} (A : Set a) : Set a where
  []  : List A
  _‚à∑_ : A ‚Üí List A ‚Üí List A
   #+end_src
   Then we can define a proof of membership inductively in the following way:
   #+begin_src text
data _‚àà_ {a : Level} {A : Set a} (a : A) : Pred (List A) a where
  here  : {x : A} {xs : List A} ‚Üí a ‚â° x ‚Üí a ‚àà (x ‚à∑ xs)
  there : {x : A} {xs : List A} ‚Üí a ‚àà xs ‚Üí a ‚àà (x ‚à∑ xs)
   #+end_src

   Now that we have all the necessary tools, we proceed to define the relation
   =_‚ä¢_=, which represents the \il{} logic in Agda.
   #+begin_src text
data _‚ä¢_ (Œ† : List Fm) : Fm ‚Üí Set where
  -- identity rule
  Ax : ‚àÄ {A} ‚Üí A ‚àà Œ† ‚Üí Œ† ‚ä¢ A
  -- classical axioms
  C1 : ‚àÄ {A B} ‚Üí Œ† ‚ä¢ A ‚Üù (B ‚Üù A)
  C2 : ‚àÄ {A B C} ‚Üí Œ† ‚ä¢ (A ‚Üù (B ‚Üù C)) ‚Üù ((A ‚Üù B) ‚Üù (A ‚Üù C))
  C3 : ‚àÄ {A B} ‚Üí Œ† ‚ä¢ (¬¨' A ‚Üù ¬¨' B) ‚Üù (B ‚Üù A)
  -- IL axioms
  K : ‚àÄ {A B} ‚Üí Œ† ‚ä¢ (‚ñ° (A ‚Üù B)) ‚Üù (‚ñ° A ‚Üù ‚ñ° B)
  L : ‚àÄ {A} ‚Üí Œ† ‚ä¢ ‚ñ° (‚ñ° A ‚Üù A) ‚Üù ‚ñ° A
  J1 : ‚àÄ {A B} ‚Üí Œ† ‚ä¢ ‚ñ° (A ‚Üù B) ‚Üù A ‚ñ∑ B
  J2 : ‚àÄ {A B C} ‚Üí Œ† ‚ä¢ A ‚ñ∑ B ‚àß B ‚ñ∑ C ‚Üù A ‚ñ∑ C
  J3 : ‚àÄ {A B C} ‚Üí Œ† ‚ä¢ (A ‚ñ∑ C ‚àß B ‚ñ∑ C) ‚Üù (A ‚à® B) ‚ñ∑ C
  J4 : ‚àÄ {A B} ‚Üí Œ† ‚ä¢ A ‚ñ∑ B ‚Üù ‚ô¢ A ‚Üù ‚ô¢ B
  J5 : ‚àÄ {A} ‚Üí Œ† ‚ä¢ ‚ô¢ A ‚ñ∑ A
  -- rules
  MP : ‚àÄ {A B} ‚Üí Œ† ‚ä¢ A ‚Üù B ‚Üí Œ† ‚ä¢ A ‚Üí Œ† ‚ä¢ B
  nec : ‚àÄ {A} ‚Üí [] ‚ä¢ A ‚Üí Œ† ‚ä¢ ‚ñ° A
   #+end_src
   We include constructor =Ax= so we can use assumptions. We include
   constructors =C1=, =C2= and =C3= so that every classical tautology in the
   language of \il{} can be proved. Then we add the axioms of \il{} and finally we add
   =MP= for modus ponens and =nec= for necessitation. Note that the
   necessitation rule only accepts \il{} theorems (empty set of assumptions) and
   thus this definition is fitting for local semantics.
   We have formalized several results about \il, which are presented in cref:sec:il.

   Consider the pen and paper syntactic proof of $A‚ÜíA$.
   \begin{flalign*}
   0.\ &(A ‚Üí ((A ‚Üí A) ‚Üí A)) ‚Üí ((A ‚Üí (A ‚Üí A)) ‚Üí (A ‚Üí A)) & \text{By } C2 \\
   1.\ &A ‚Üí ((A ‚Üí A) ‚Üí A) & \text{By } C1 \\
   2.\ &A ‚Üí (A ‚Üí A) & \text{By } C1 \\
   3.\ & (A ‚Üí (A ‚Üí A)) ‚Üí A ‚Üí A   &\text{By MP 0, 1} \\
   4.\ & A ‚Üí A   &\text{By MP 3, 2} \\
   ‚ñ†&
   \end{flalign*}
   Now see how we could replicate the proof in Agda using our definition of =_‚ä¢_=.
   #+begin_src text
‚ä¢A‚ÜùA : ‚àÄ {A Œ†} ‚Üí Œ† ‚ä¢ A ‚Üù A
‚ä¢A‚ÜùA {A} = MP (MP (C2 {Œ†} {A} {A ‚Üù A} {A}) (C1 {Œ†} {A} {A ‚Üù A})) (C1 {Œ†} {A} {A})
   #+end_src
   We see that it is extremely verbose and hard to read. We can substantially
   shorten it by relying on Agda's type inference to automatically infer the
   instantiation of almost all of the axiom schemas used. However, it is still
   far from being human friendly.
   #+begin_src text
‚ä¢A‚ÜùA : ‚àÄ {A Œ†} ‚Üí Œ† ‚ä¢ A ‚Üù A
‚ä¢A‚ÜùA {A} = MP (MP C2 C1) (C1 {B = A})
   #+end_src
   For now, we forget about the obscure syntax and we use the previous result to
   prove that $A‚ñ∑A$ is an \il{} theorem. First, the pen and paper proof:
   \begin{flalign*}
        0.\ &  A ‚Üí A                        &\text{By } ‚ä¢A‚ÜíA \\
        1.\ &  ‚ñ° (A ‚Üí A)                    &\text{By necessitation on 0} \\
        2.\ &  ‚ñ° (A ‚Üí A) ‚Üí (A ‚ñ∑ A)          &\text{By J1} \\
        3.\ &  A ‚ñ∑ A                        &\text{By MP 2, 1} \\
       ‚ñ†
   \end{flalign*}
   And now the same proof in Agda.
   #+begin_src text
‚ä¢A‚ñ∑A : ‚àÄ {A Œ†} ‚Üí Œ† ‚ä¢ A ‚ñ∑ A
‚ä¢A‚ñ∑A {A} = MP J1 (nec ‚ä¢A‚ÜùA)
   #+end_src
   Although the Agda proofs of $A‚ÜíA$ and $A‚ñ∑A$ are short, it is very hard for a
   human to fully understand them with the Agda syntax used above. This problem
   motivates our next chapter, in which we present a way to express syntactic
   proofs in Agda using paper-like syntax.

** An eDSL for syntactic proofs
    <<sec:edsl>> In this chapter we present a verified language for writing
    Hilbert style proofs for logic \il. The language has been designed and
    implemented by the author of this thesis. It was first presented in
    cite:slug for logic $K$.

    We begin by introducing the concept of eDSL. The acronym eDSL stands for
    /Embedded Domain Specific Language/. It refers to a small language (a set of
    functions and datatypes) embedded in another language (in this case Agda)
    that has been designed to solve a problem in a very specific domain, in this
    case, Hilbert style proofs.

    We begin by showing how we could write the two syntactic proofs presented
    in the previous section in our eDSL. Then we will present the language in
    detail.

    The first example shows how we can formalize the proof $‚ä¢_\il{}A‚ÜíA$ in the
    new language.
   #+begin_src text
‚ä¢A‚ÜùA : ‚àÄ {A} ‚Üí [] ‚ä¢ A ‚Üù A
‚ä¢A‚ÜùA {A} =
  begin[ 0 ] (A ‚Üù ((A ‚Üù A) ‚Üù A)) ‚Üù ((A ‚Üù (A ‚Üù A)) ‚Üù (A ‚Üù A)) By C2
       [ 1 ] A ‚Üù ((A ‚Üù A) ‚Üù A)                               By C1
       [ 2 ] A ‚Üù (A ‚Üù A)                                     By C1
       [ 3 ] (A ‚Üù (A ‚Üù A)) ‚Üù A ‚Üù A                           ByMP 0 , 1
       [ 4 ] A ‚Üù A                                           ByMP 3 , 2
       ‚ñ†
   #+end_src

   Second example:
   #+begin_src text
‚ä¢A‚ñ∑A : ‚àÄ {A} ‚Üí [] ‚ä¢ A ‚ñ∑ A
‚ä¢A‚ñ∑A {A} =
  begin[ 0 ] A ‚Üù A                        By ‚ä¢A‚ÜùA
       [ 1 ] ‚ñ° (A ‚Üù A)                    ByNec 0
       [ 2 ] ‚ñ° (A ‚Üù A) ‚Üù (A ‚ñ∑ A)          By J1
       [ 3 ] A ‚ñ∑ A                        ByMP 2 , 1
       ‚ñ†
   #+end_src

   We see that our eDSL allows us to write syntactic proofs in a very similar
   human-friendly syntax which is almost identical to the pen and paper usual
   syntax with the standout benefit that the proof is computer checked. In
   particular, it is checked by Agda's type checking algorithm.

   We want to emphasize, as it may be surprising to the reader, that the proofs
   shown above are actual Agda code. It is crucial to make clear that this eDSL
   is /not/ an alternative definition of the logic \il{} presented in different
   syntax. The eDSL is layer above the definition which allows us to use nice
   syntax while still relying on the simple definition of \il{} we provided in
   the previous chapter. Of course, the main challenge is to prove that we can
   transform proofs in the nice syntax to proofs in the original syntax. We will
   comment on it later on this section.

   We proceed by giving a short description of the language, which consists of
   four types of instructions:
   1. =[_]_By_=. This instruction is used to include a theorem in the proof. The
      theorem can be any axiom scheme of \il{} or anything proved to be a theorem.
      More precisely, the theorem can be any =A= if we have =Œ† ‚ä¢ A= for some =Œ†=.
      The first instruction must be of this kind and must be preceded with =begin=.
   2. =[_]_ByNec_=. This instruction applies the necessitation rule to a formula
      in a previous line referenced by its number. This rule can only be applied
      if we have an empty set of assumptions.
   3. =[_]_ByMP_=. This instruction applies the modus ponens rule to two
      formulas in previous lines referenced by their number.
   4. =‚ñ†=. The proof must be closed using this instruction.
   Every instruction must be numbered in increasing order starting at 0.

   Thanks to the design of the language, if the user mistakenly numbers one of
   the instructions Agda will report an error indicating where the error is. If
   the user improperly instantiates an axiom scheme or theorem or references an
   incorrect line, they will also be prompted with an error. Summarizing, an error
   will appear if the proof has any deficiency. This holds true as the eDSL is
   implemented in Agda and thus it is verified.

   We proceed by giving a rough approximation on how the language has been
   implemented. Details of the inner workings of the language are left out as
   they fall out of the scope of this paper, however, we encourage the reader to look
   for further information in cite:slug if they are interested.

   We begin by defining the datatype that represents our language.
   #+begin_src text
data HilbertProof : List Fm ‚Üí Fm ‚Üí Nat ‚Üí Set where
  begin : ‚àÄ {Œ£ A} ‚Üí Œ£ ‚ä¢ A ‚Üí HilbertProof Œ£ A 0
  by : ‚àÄ {Œ£ A B n} ‚Üí Œ£ ‚ä¢ B ‚Üí HilbertProof Œ£ A n ‚Üí HilbertProof Œ£ B (suc n)
   Ax : ‚àÄ {Œ£ B n} ‚Üí (A : Fm) ‚Üí HilbertProof Œ£ B n ‚Üí HilbertProof (A ‚à∑ Œ£) A (suc n)
  nec : ‚àÄ {Œ£ n ‚ñ°A C} (H : HilbertProof [] C n) (i : HilbertRef H (‚ñ°A) ‚ñ°_)
    ‚Üí HilbertProof Œ£ (‚ñ°A) (suc n)
  MP : ‚àÄ {n Œ£ A B C} (H : HilbertProof Œ£ C n) ‚Üí HilbertRef H (A ‚Üù B) id
    ‚Üí HilbertRef H A id ‚Üí HilbertProof Œ£ B (suc n)
   #+end_src
   Each instruction (except =‚ñ†=) has its corresponding constructor. We see that
   the datatype is indexed by a list of formulas and a formula. Those are the set of
   assumptions and the formula that is shown to be a theorem. The third index is
   a natural number. This number keeps track of the length of the proof and it
   is needed to ensure that references to previous lines are not out of bounds.
   The type =HilbertRef= represents a reference to a previous line in the proof.
   We omit its definition here as is not crucial for understanding the overall
   idea.

   Then we define the front end syntax for each of the constructors. For
   instance, the definition of the =[_]_By_= instruction is as follows (we omit
   the type for simplicity as it is the same as the type of the constructor =by=).
   #+begin_src text
infixl 10 _[_]_By_
_[_]_By_ : ...
H [ n ] B By p = by p H
   #+end_src
   Notice that we also declare the instruction to have left associativity
   (=infixl=), which will allow us to write each subsequent instruction below
   the other without need of parentheses.

   We skip how references work for simplicity, as they use advanced Agda
   features (type classes and instance arguments (cite:agda-doc)) in order to be
   automatically checked without an explicit proof.

   Observe now how we can build a proof in this language.
   #+begin_src text
‚ä¢A‚ñ∑A' : ‚àÄ {A} ‚Üí HilbertProof [] (A ‚ñ∑ A) 3
‚ä¢A‚ñ∑A' {A} =
  begin[ 0 ] A ‚Üù A                 By ‚ä¢A‚ÜùA
       [ 1 ] ‚ñ° (A ‚Üù A)             ByNec 0
       [ 2 ] ‚ñ° (A ‚Üù A) ‚Üù (A ‚ñ∑ A)   By J1
       [ 3 ] A ‚ñ∑ A                 ByMP 2 , 1
   #+end_src
   It is essentially the same as we showcased before but it is lacking the
   closing =‚ñ†= instruction. The type of such instruction is:
   #+begin_src text
_‚ñ† : ‚àÄ {n Œ£ A} ‚Üí HilbertProof Œ£ A n ‚Üí Œ£ ‚ä¢ A
   #+end_src
   We see that =‚ñ†= is defined as a postfix operator which translates a proof
   =HilbertProof Œ£ A n= into a proof =Œ£ ‚ä¢ A=. This translation step is where
   most of the complexity lays. Needless to say, as is implemented and verified
   in Agda it is guaranteed to be correct. To reiterate, by correct we mean that
   every proof in the new syntax can be transformed (and definition of the term
   =‚ñ†=, which can be found in cref:src:il.edsl, is actually the
   algorithm which performs the transformation) to a proof using only axioms and
   rules of \il{} as presented in the previous section. This ends the tour of
   the language.

   We strongly believe in the practical usefulness of this language as it can be
   used by logicians that are not Agda experts due to its simple and familiar
   syntax. We are all aware that long syntactic proofs are error prone. This
   language completely removes such problem. Of course, there is some room for
   improvement, for instance, the language does not include the deduction
   theorem rule, which is frequently used in practice. Note that this limitation
   can be ameliorated as we can use the deduction theorem outside of the eDSL
   and then include the result by using a =[_]_By_= instruction.

* Glossary and bibliography
\printglossary

\printbibliography[
 heading=bibintoc,
 title=Bibliography
 ]

 #+latex: \appendix
* Appendix
** Official Agda reference
   This appendix contains a thorough description of some of the Agda related
   topics that were discussed in the thesis. We believe that the intuition given
   in the introduction should be enough for the reader to be able to read
   cref:sec:agda-thesis, however, we encourage the reader to resort to the
   ensuing reference if they wish for more precise information on the language.
   The contents of this section have been merely copied from the online Agda
   documentation (cite:agda-doc).

*** Function definitions and pattern matching
    <<sec:agda-doc-fun-defs>>
    A function is defined by first declaring its type followed by a number of
    equations called clauses. Each clause consists of the function being defined
    applied to a number of patterns, followed by = and a term called the
    right-hand side. For example:
    #+begin_example
    not : Bool ‚Üí Bool
    not true  = false
    not false = true
    #+end_example
    Functions are allowed to call themselves recursively, for example:
    #+begin_example
    twice : Nat ‚Üí Nat
    twice zero    = zero
    twice (suc n) = suc (suc (twice n))
    #+end_example

    The general form for defining a function is
    #+begin_example
    f : (x‚ÇÅ : A‚ÇÅ) ‚Üí ‚Ä¶ ‚Üí (x‚Çô : A‚Çô) ‚Üí B
    f p‚ÇÅ ‚Ä¶ p‚Çô = d
    ‚Ä¶
    f q‚ÇÅ ‚Ä¶ q‚Çô = e
    #+end_example
    where =f= is a new identifier, =p·µ¢= and =q·µ¢= are patterns of type =A·µ¢=, and =d= and =e=
    are expressions.

    The declaration above gives the identifier =f= the type =(x‚ÇÅ : A‚ÇÅ) ‚Üí ‚Ä¶ ‚Üí (x‚Çô :
    A‚Çô) ‚Üí B= and =f= is defined by the defining equations. Patterns are matched
    from top to bottom, i.e., the first pattern that matches the actual
    parameters is the one that is used.

    By default, Agda checks the following properties of a function definition:
    1. The patterns in the left-hand side of each clause should consist only of
       constructors and variables.
    2. No variable should occur more than once on the left-hand side of a single
       clause.
    3. The patterns of all clauses should together cover all possible inputs of
       the function.
    4. The function should be terminating on all possible inputs.

*** Absurd patterns
    <<sec:agda-doc-absurd>>

    Absurd patterns can be used when none of the constructors for a particular
    argument would be valid. The syntax for an absurd pattern is =()=.

    As an example, if we have a datatype Even defined as follows:
    #+begin_src text
    data Even : Nat ‚Üí Set where
     even-zero  : Even zero
     even-plus2 : {n : Nat} ‚Üí Even n ‚Üí Even (suc (suc n))
    #+end_src text

    Then we can define a function =one-not-even : Even 1 ‚Üí ‚ä•= by using an absurd
    pattern:
    #+begin_src text
    one-not-even : Even 1 ‚Üí ‚ä•
    one-not-even ()
    #+end_src
    Note that if the left-hand side of a clause contains an absurd pattern, its
    right-hand side must be omitted.

    In general, when matching on an argument of type =D i‚ÇÅ ‚Ä¶ i‚Çô= with an absurd
    pattern, Agda will attempt for each constructor =c : (x‚ÇÅ : A‚ÇÅ) ‚Üí ‚Ä¶ ‚Üí (x‚Çò :
    A‚Çò) ‚Üí D j‚ÇÅ ‚Ä¶ j‚Çô= of the datatype =D= to unify =i‚ÇÅ ‚Ä¶ i‚Çô= with =j‚ÇÅ ‚Ä¶ j‚Çô=. The
    absurd pattern will only be accepted if all of these unifications end in a
    conflict.
*** Implicit arguments and automatic inference
    <<sec:agda-implicit-args>>

    It is possible to omit terms that the type checker can figure out for
    itself, replacing them by =_=. If the type checker cannot infer the value of
    an =_= it will report an error. For instance, for the polymorphic identity
    function
    #+begin_example
    id : (A : Set) ‚Üí A ‚Üí A
    #+end_example
    the first argument can be inferred from the type of the second argument, so
    we might write =id _ zero= for the application of the identity function to
    =zero=.

    We can even write this function application without the first argument. In
    that case we declare an implicit function space:
    #+begin_example
    id : {A : Set} ‚Üí A ‚Üí A
    #+end_example
    and then we can use the notation =id zero=.

    Another example:
    #+begin_example
    _==_  : {A : Set} ‚Üí A ‚Üí A ‚Üí Set
    subst : {A : Set} (C : A ‚Üí Set) {x y : A} ‚Üí x == y ‚Üí C x ‚Üí C y
    #+end_example
    Note how the first argument to =_==_= is left implicit. Similarly, we may
    leave out the implicit arguments =A=, =x=, and =y= in an application of
    =subst=. To give an implicit argument explicitly, enclose it in curly braces.
    The following two expressions are equivalent:
    #+begin_example
    x1 = subst C eq cx
    x2 = subst {_} C {_} {_} eq cx
    #+end_example
    It is worth noting that implicit arguments are also inserted at the end of
    an application, if it is required by the type. For example, in the
    following, =y1= and =y2= are equivalent.
    #+begin_example
    y1 : a == b ‚Üí C a ‚Üí C b
    y1 = subst C

    y2 : a == b ‚Üí C a ‚Üí C b
    y2 = subst C {_} {_}
    #+end_example
    Implicit arguments are inserted eagerly in left-hand sides so =y3= and =y4= are
    equivalent. An exception is when no type signature is given, in which case
    no implicit argument insertion takes place. Thus in the definition of =y5= the
    only implicit is the =A= argument of =subst=.
    #+begin_example
    y3 : {x y : A} ‚Üí x == y ‚Üí C x ‚Üí C y
    y3 = subst C

    y4 : {x y : A} ‚Üí x == y ‚Üí C x ‚Üí C y
    y4 {x} {y} = subst C {_} {_}

    y5 = subst C
    #+end_example
    It is also possible to write lambda abstractions with implicit arguments.
    For example, given =id : (A : Set) ‚Üí A ‚Üí A=, we can define the identity
    function with implicit type argument as
    #+begin_example
    id‚Äô = Œª {A} ‚Üí id A
    #+end_example
    Implicit arguments can also be referred to by name, so if we want to give
    the expression =e= explicitly for =y= without giving a value for =x= we can
    write
    #+begin_example
    subst C {y = e} eq cx
    #+end_example
    In rare circumstances it can be useful to separate the name used to give an
    argument by name from the name of the bound variable, for instance if the
    desired name shadows an existing name. To do this you write
    #+begin_example
    id‚ÇÇ : {A = X : Set} ‚Üí X ‚Üí X  -- name of bound variable is X
    id‚ÇÇ x = x

    use-id‚ÇÇ : (Y : Set) ‚Üí Y ‚Üí Y
    use-id‚ÇÇ Y = id‚ÇÇ {A = Y}      -- but the label is A
    #+end_example

    Labeled bindings must appear by themselves when typed, so the type =Set= needs
    to be repeated in this example:
    #+begin_example
    const : {A = X : Set} {B = Y : Set} ‚Üí A ‚Üí B ‚Üí A
    const x y = x
    #+end_example

    When constructing implicit function spaces the implicit argument can be
    omitted, so both expressions below are valid expressions of type ={A : Set}
    ‚Üí A ‚Üí A=:
    #+begin_example
    z1 = Œª {A} x ‚Üí x
    z2 = Œª x ‚Üí x
    #+end_example
    The =‚àÄ= (or =forall=) syntax for function types also has implicit variants:

    #+begin_example
    ‚ë† : (‚àÄ {x : A} ‚Üí B)    is-the-same-as  ({x : A} ‚Üí B)
    ‚ë° : (‚àÄ {x} ‚Üí B)        is-the-same-as  ({x : _} ‚Üí B)
    ‚ë¢ : (‚àÄ {x y} ‚Üí B)      is-the-same-as  (‚àÄ {x} ‚Üí ‚àÄ {y} ‚Üí B)
    #+end_example

    In very special situations it makes sense to declare unnamed hidden
    arguments ={A} ‚Üí B=. In the following =example=, the hidden argument to
    =scons= of type =zero ‚â§ zero= can be solved by \text{$Œ∑$-expansion}, since
    this type reduces to =‚ä§=.
    #+begin_example
    data ‚ä• : Set where

    _‚â§_ : Nat ‚Üí Nat ‚Üí Set
    zero ‚â§ _      = ‚ä§
    suc m ‚â§ zero  = ‚ä•
    suc m ‚â§ suc n = m ‚â§ n

    data SList (bound : Nat) : Set where
    []    : SList bound
    scons : (head : Nat) ‚Üí {head ‚â§ bound} ‚Üí (tail : SList head) ‚Üí SList bound

    example : SList zero
    example = scons zero []
    #+end_example
    There are no restrictions on when a function space can be implicit. Internally,
    explicit and implicit function spaces are treated in the same way. This means
    that there are no guarantees that implicit arguments will be solved. When there
    are unsolved implicit arguments the type checker will give an error message
    indicating which application contains the unsolved arguments. The reason for
    this liberal approach to implicit arguments is that limiting the use of implicit
    argument to the cases where we guarantee that they are solved rules out many
    useful cases in practice.
*** datatype definitions and constructors
    <<sec:agda-ref-datatype>>
    <<sec:agda-datatype>>

    The general form of the definition of a simple datatype =D= is the following
    #+begin_src text
  data D (x‚ÇÅ : P‚ÇÅ) ... (x‚Çñ : P‚Çñ) : (y‚ÇÅ : Q‚ÇÅ) ‚Üí ... ‚Üí (y‚Çó : Q‚Çó) ‚Üí Set ‚Ñì where
    c‚ÇÅ : A‚ÇÅ
    ...
    c‚Çô : A‚Çô
    #+end_src

    The name =D= of the data type and the names =c‚ÇÅ=, ‚Ä¶, =c‚Çô= of the
    constructors must be new w.r.t. the current signature and context, and the
    types =A‚ÇÅ=, ‚Ä¶, =A‚Çô= must be function types ending in =D=, i.e. they must be
    of the form
    #+begin_example
    (y‚ÇÅ : B‚ÇÅ) ‚Üí ... ‚Üí (y‚Çò : B‚Çò) ‚Üí D
    #+end_example

    Datatypes can have parameters. They are declared after the name of the
    datatype but before the colon, for example:
    #+begin_example
    data List (A : Set) : Set where
      []  : List A
      _‚à∑_ : A ‚Üí List A ‚Üí List A
    #+end_example

    In addition to parameters, datatypes can also have indices. In contrast to
    parameters which are required to be the same for all constructors, indices
    can vary from constructor to constructor. They are declared after the colon
    as function arguments to =Set=. For example, fixed-length vectors can be
    defined by indexing them over their length of type =Nat=:
    #+begin_example
    data Vector (A : Set) : Nat ‚Üí Set where
      []  : Vector A zero
      _‚à∑_ : {n : Nat} ‚Üí A ‚Üí Vector A n ‚Üí Vector A (suc n)
    #+end_example
    Notice that the parameter =A= is bound once for all constructors, while the
    index ={n : Nat}= must be bound locally in the constructor =_‚à∑_=.

    Indexed datatypes can also be used to describe predicates, for example the
    predicate =Even : Nat ‚Üí Set= can be defined as follows:
    #+begin_example
    data Even : Nat ‚Üí Set where
      even-zero  : Even zero
      even-plus2 : {n : Nat} ‚Üí Even n ‚Üí Even (suc (suc n))
    #+end_example

    The general form of the definition of a (parametrized, indexed) datatype =D=
    is the following
    #+begin_example
    data D (x‚ÇÅ : P‚ÇÅ) ... (x‚Çñ : P‚Çñ) : (y‚ÇÅ : Q‚ÇÅ) ‚Üí ... ‚Üí (y‚Çó : Q‚Çó) ‚Üí Set ‚Ñì where
      c‚ÇÅ : A‚ÇÅ
      ...
      c‚Çô : A‚Çô
    #+end_example

    where the types =A‚ÇÅ=, ‚Ä¶, =A‚Çô= are function types of the form
    #+begin_example
    (z‚ÇÅ : B‚ÇÅ) ‚Üí ... ‚Üí (z‚Çò : B‚Çò) ‚Üí D x‚ÇÅ ... x‚Çñ t‚ÇÅ ... t‚Çó
    #+end_example
*** Function types
    Function types are written =(x : A) ‚Üí B=, or in the case of non-dependent
    functions simply =A ‚Üí B=. For instance, the type of the addition function
    for natural numbers is:
    #+begin_example
    Nat ‚Üí Nat ‚Üí Nat
    #+end_example
    and the type of the addition function for vectors is:
    #+begin_example
    (A : Set) ‚Üí (n : Nat) ‚Üí (u : Vec A n) ‚Üí (v : Vec A n) ‚Üí Vec A n
    #+end_example

    where =Set= is the type of sets and =Vec A n= is the type of vectors with =n=
    elements of type =A=. Arrows between consecutive hypotheses of the form =(x :
    A)= may also be omitted, and =(x : A) (y : A)= may be shortened to =(x y : A)=:
    #+begin_example
    (A : Set) (n : Nat) (u v : Vec A n) ‚Üí Vec A n
    #+end_example

    Functions are constructed by lambda abstractions, which can be either typed
    or untyped. For instance, both expressions below have type =(A : Set) ‚Üí A ‚Üí A=
    (the second expression checks against other types as well):
    #+begin_example
    example‚ÇÅ = Œª (A : Set) (x : A) ‚Üí x
    example‚ÇÇ = Œª A x ‚Üí x
    #+end_example

    The application of a function =f : (x : A) ‚Üí B= to an argument =a : A= is
    written =f a= and the type of this is \texttt{B[x := a]}.

    Some notation conventions follow.
    - Function types:
      #+begin_example
      prop‚ÇÅ : ((x : A) (y : B) ‚Üí C) is-the-same-as   ((x : A) ‚Üí (y : B) ‚Üí C)
      prop‚ÇÇ : ((x y : A) ‚Üí C)      is-the-same-as   ((x : A)(y : A) ‚Üí C)
      prop‚ÇÉ : (‚àÄ (x : A) ‚Üí C)  is-the-same-as   ((x : A) ‚Üí C)
      prop‚ÇÑ : (‚àÄ x ‚Üí C)        is-the-same-as   ((x : _) ‚Üí C)
      prop‚ÇÖ : (‚àÄ x y ‚Üí C)      is-the-same-as   (‚àÄ x ‚Üí ‚àÄ y ‚Üí C)
      #+end_example

    - Functional abstraction:
      #+begin_example
      (Œª x y ‚Üí e)                    is-the-same-as   (Œª x ‚Üí (Œª y ‚Üí e))
      #+end_example

    - Functional application:
      #+begin_example
      (f a b)                       is-the-same-as    ((f a) b)
      #+end_example

*** Record types
    The general form of a record declaration is as follows:
    #+begin_example
    record <recordname> <parameters> : Set <level> where
      <directives>
      constructor <constructorname>
      field
        <fieldname1> : <type1>
        <fieldname2> : <type2>
        -- ...
      <declarations>
    #+end_example
    All the components are optional, and can be given in any order. In
    particular, fields can be given in more than one block, interspersed with
    other declarations. Each field is a component of the record. Types of later
    fields can depend on earlier fields.

    The directives available are eta-equality, no-eta-equality, inductive and
    co-inductive. For more information visit cite:agda-doc.
*** Universes
    <<sec:agda-doc-universes>>
    Russell‚Äôs paradox implies that the collection of all sets is not itself a
    set. Namely, if there were such a set =U=, then one could form the subset
    =A ‚äÜ U= of all sets that do not contain themselves. Then we would have =A ‚àà
    A= if and only if =A ‚àâ A=, a contradiction.

    For similar reasons, not every Agda type is a Set. For example, we have
    #+begin_example
    Bool : Set
    Nat : Set
    #+end_example
    but not =Set : Set=. However, it is often convenient for =Set= to have a type
    of its own, and so in Agda, it is given the type =Set‚ÇÅ=:
    #+begin_example
    Set : Set‚ÇÅ
    #+end_example

    In many ways, expressions of type =Set‚ÇÅ= behave just like expressions of
    type =Set=; for example, they can be used as types of other things. However,
    the elements of =Set‚ÇÅ= are potentially larger; when =A : Set‚ÇÅ=, then =A= is
    sometimes called a large set. In turn, we have:
    #+begin_example
    Set‚ÇÅ : Set‚ÇÇ
    Set‚ÇÇ : Set‚ÇÉ
    #+end_example
    and so on. A type whose elements are types is called a universe; Agda
    provides an infinite number of universes =Set=, =Set‚ÇÅ=, =Set‚ÇÇ=, =Set‚ÇÉ=, ‚Ä¶,
    each of which is an element of the next one. In fact, Set itself is just an
    abbreviation for =Set‚ÇÄ=. The subscript n is called the level of the universe
    =Set‚Çô=.

    A note on syntax: you can also write =Set1=, =Set2=, etc., instead of =Set‚ÇÅ=,
    =Set‚ÇÇ=. To enter a subscript in the Emacs mode, type =\_1=.

**** Universe example
     So why are universes useful? Because sometimes it is necessary to define,
     and prove theorems about, functions that operate not just on sets but on
     large sets. In fact, most Agda users sooner or later experience an error
     message where Agda complains that \texttt{Set‚ÇÅ != Set}. These errors usually
     mean that a small set was used where a large one was expected, or vice
     versa.

     For example, suppose you have defined the usual datatypes for lists and
     Cartesian products:
     #+begin_example
     data List (A : Set) : Set where
       [] : List A
       _::_ : A ‚Üí List A ‚Üí List A

     data _√ó_ (A B : Set) : Set where
      _,_ : A ‚Üí B ‚Üí A √ó B

     infixr 5 _::_
     infixr 4 _,_
     infixr 2 _√ó_
     #+end_example

     Now suppose you would like to define an operator =Prod= that inputs a list
     of =n= sets and takes their Cartesian product, like this:
     #+begin_example
     Prod (A :: B :: C :: []) = A √ó B √ó C
     #+end_example

     There is only one small problem with this definition. The type of =Prod=
     should be:
     #+begin_example
     Prod : List Set ‚Üí Set
     #+end_example

     However, the definition of =List A= specified that =A= had to be a =Set=.
     Therefore, =List Set= is not a valid type. The solution is to define a
     special version of the =List= operator that works for large sets:
     #+begin_example
     data List‚ÇÅ (A : Set‚ÇÅ) : Set‚ÇÅ where
       []   : List‚ÇÅ A
       _::_ : A ‚Üí List‚ÇÅ A ‚Üí List‚ÇÅ A

     With this, we can indeed define:

     Prod : List‚ÇÅ Set ‚Üí Set
     Prod []        = ‚ä§
     Prod (A :: As) = A √ó Prod As
     #+end_example

**** Universe polymorphism

     Although we were able to give a type to the =Prod= operator by defining a
     special notion of large list, this quickly gets tiresome. Sooner or later,
     we find that we require yet another list type =List‚ÇÇ=, and it doesn‚Äôt stop
     there. Also every function on lists (such as append) must be re-defined, and
     every theorem about such functions must be re-proved, for every possible
     level.

     The solution to this problem is universe polymorphism. Agda provides a
     special primitive type =Level=, whose elements are possible levels of
     universes. In fact, the notation for the =n= th universe, =Set‚Çô=, is just an
     abbreviation for =Set n=, where =n : Level= is a level. We can use this to
     write a polymorphic =List= operator that works at any level. The library
     =Agda.Primitive= must be imported to access the =Level= type. The definition
     then looks like this:
     #+begin_example
     open import Agda.Primitive

     data List {n : Level} (A : Set n) : Set n where
     []   : List A
     _::_ : A ‚Üí List A ‚Üí List A
     #+end_example

     This new operator works at all levels; for example, we have
     #+begin_example
     List Nat : Set
     List Set : Set‚ÇÅ
     List Set‚ÇÅ : Set‚ÇÇ
     #+end_example
**** Level arithmetic

   Even though we don‚Äôt have the number of levels specified, we know that there
   is a lowest level =lzero=, and for each level =n=, there exists some higher
   level =lsuc n=; therefore, the set of levels is infinite. In addition, we can
   also take the least upper bound =n ‚äî m= of two levels. In summary, the following
   (and only the following) operations on levels are provided:

   #+begin_src text
   lzero : Level
   lsuc  : (n : Level) ‚Üí Level
   _‚äî_   : (n m : Level) ‚Üí Level
   #+end_src
   This is sufficient for most purposes; for example, we can define the Cartesian
   product of two types of arbitrary (and not necessarily equal) levels like
   this:
   #+begin_example
   data _√ó_ {n m : Level} (A : Set n) (B : Set m) : Set (n ‚äî m) where
      _,_ : A ‚Üí B ‚Üí A √ó B
   #+end_example

   With this definition, we have, for example:
   #+begin_example
   Nat √ó Nat : Set
   Nat x Set : Set‚ÇÅ
   Set √ó Set : Set‚ÇÅ
   #+end_example

** Agda library code
    <<src:agda>>
*** All
    <<src:all>>
    This is a helper module which imports everything in the library. It is used
    to check all the library at once.

    #+include: "latex/All.tex" export latex
*** Base
    <<src:base>>
    This module contains some definitions and helper functions which are used
    throughout the thesis. It includes, for instance, the definition of a
    Noetherian relation.

  #+include: "latex/Base.tex" export latex
*** Classical
    <<src:classical>>
  #+include: "latex/Classical.tex" export latex
*** Formula
    <<src:formula>>
    The definition of formulas in the language of interpretability logics.

  #+include: "latex/Formula.tex" export latex
*** GeneralizedFrame/Properties
    <<src:generalizedframe.properties>>
    Properties of generalized Veltman frames.

  #+include: "latex/GeneralizedFrame/Properties.tex" export latex
*** GeneralizedFrame
    <<src:generalizedframe>>
  #+include: "latex/GeneralizedFrame.tex" export latex
*** GeneralizedVeltmanSemantics/Properties/GenericFrameCond
    <<src:generalizedveltmansemantics.properties.genericframecond>>
    It contains the proof that we can find a frame condition for any principle.
  #+include: "latex/GeneralizedVeltmanSemantics/Properties/GenericFrameCond.tex" export latex
*** GeneralizedVeltmanSemantics/Properties/Luka
    <<src:generalizedveltmansemantics.properties.luka>>
    It contains the proof that we build an ordinary frame from a generalized model.
  #+include: "latex/GeneralizedVeltmanSemantics/Properties/Luka.tex" export latex
*** GeneralizedVeltmanSemantics/Properties/M
    <<src:generalizedveltmansemantics.properties.m>>
    The frame condition for the \sf{M} principle.
  #+include: "latex/GeneralizedVeltmanSemantics/Properties/M.tex" export latex
*** GeneralizedVeltmanSemantics/Properties/M\sf{‚ÇÄ}
    <<src:generalizedveltmansemantics.properties.msub0>>
    The frame condition for the \sf{M‚ÇÄ} principle.
  #+include: "latex/GeneralizedVeltmanSemantics/Properties/M‚ÇÄ.tex" export latex
*** GeneralizedVeltmanSemantics/Properties/P\sf{‚ÇÄ}
    <<src:generalizedveltmansemantics.properties.psub0>>
    The frame condition for the \sf{P‚ÇÄ} principle.
  #+include: "latex/GeneralizedVeltmanSemantics/Properties/P‚ÇÄ.tex" export latex
*** GeneralizedVeltmanSemantics/Properties/R
    <<src:generalizedveltmansemantics.properties.r>>
    The frame condition for the \sf{R} principle.
  #+include: "latex/GeneralizedVeltmanSemantics/Properties/R.tex" export latex
*** GeneralizedVeltmanSemantics/Properties/R\sf{¬π}
    The frame condition for the \sf{R^1} principle.
    <<src:generalizedveltmansemantics.properties.rsup1>>
  #+include: "latex/GeneralizedVeltmanSemantics/Properties/R¬π.tex" export latex
*** GeneralizedVeltmanSemantics/Properties/R\sf{¬≤}
    <<src:generalizedveltmansemantics.properties.rsup2>>
    The frame condition for the \sf{R^2} principle.
  #+include: "latex/GeneralizedVeltmanSemantics/Properties/R¬≤.tex" export latex
*** GeneralizedVeltmanSemantics/Properties/R\sf{‚Åø}
    <<src:generalizedveltmansemantics.properties.rsupn>>
    The frame condition for the \sf{R^n} principle.
  #+include: "latex/GeneralizedVeltmanSemantics/Properties/R‚Åø.tex" export latex
*** GeneralizedVeltmanSemantics/Properties/R\sf{‚ÇÅ}
    The frame condition for the \sf{R^1} principle.
    <<src:generalizedveltmansemantics.properties.rsub1>>
  #+include: "latex/GeneralizedVeltmanSemantics/Properties/R‚ÇÅ.tex" export latex
*** GeneralizedVeltmanSemantics/Properties/R\sf{‚ÇÇ} :noexport:
    The frame condition for the \sf{R^2} principle.
    <<src:generalizedveltmansemantics.properties.rsub2>>
  #+include: "latex/GeneralizedVeltmanSemantics/Properties/R‚ÇÇ.tex" export latex
*** GeneralizedVeltmanSemantics/Properties/Verbrugge
    <<src:generalizedveltmansemantics.properties.verbrugge>>
  #+include: "latex/GeneralizedVeltmanSemantics/Properties/Verbrugge.tex" export latex
*** GeneralizedVeltmanSemantics/Properties/Vukovic
    <<src:generalizedveltmansemantics.properties.vukovic>> This file contains
    the unfinished proof of proposition 2.8 in cite:vukovic2008bisimulations.
  #+include: "latex/GeneralizedVeltmanSemantics/Properties/Vukovic.tex" export latex
*** GeneralizedVeltmanSemantics/Properties
    <<src:generalizedveltmansemantics.properties>>
  #+include: "latex/GeneralizedVeltmanSemantics/Properties.tex" export latex
*** GeneralizedVeltmanSemantics
    <<src:generalizedveltmansemantics>>
  #+include: "latex/GeneralizedVeltmanSemantics.tex" export latex
*** IL
    <<src:il>>
  #+include: "latex/IL.tex" export latex
*** IL/Edsl
    <<src:il.edsl>>
  #+include: "latex/IL/Edsl.tex" export latex
*** IL/Properties
    <<src:il.properties>>
  #+include: "latex/IL/Properties.tex" export latex
*** OrdinaryFrame
    <<src:ordinaryframe>>
  #+include: "latex/OrdinaryFrame.tex" export latex
*** OrdinaryVeltmanSemantics/Finite
    <<src:ordinaryveltmansemantics.finite>>
  #+include: "latex/OrdinaryVeltmanSemantics/Finite.tex" export latex
*** OrdinaryVeltmanSemantics/Properties/M
    <<src:ordinaryveltmansemantics.properties.m>>
  #+include: "latex/OrdinaryVeltmanSemantics/Properties/M.tex" export latex
*** OrdinaryVeltmanSemantics/Properties/M\sf{‚ÇÄ}
    <<src:ordinaryveltmansemantics.properties.msub0>>
  #+include: "latex/OrdinaryVeltmanSemantics/Properties/M‚ÇÄ.tex" export latex
*** OrdinaryVeltmanSemantics/Properties/P\sf{‚ÇÄ}
    <<src:ordinaryveltmansemantics.properties.psub0>>
  #+include: "latex/OrdinaryVeltmanSemantics/Properties/P‚ÇÄ.tex" export latex
*** OrdinaryVeltmanSemantics/Properties/R
    <<src:ordinaryveltmansemantics.properties.r>>
  #+include: "latex/OrdinaryVeltmanSemantics/Properties/R.tex" export latex
*** OrdinaryVeltmanSemantics/Properties
    <<src:ordinaryveltmansemantics.properties>>
  #+include: "latex/OrdinaryVeltmanSemantics/Properties.tex" export latex
*** OrdinaryVeltmanSemantics
    <<src:ordinaryveltmansemantics>>
  #+include: "latex/OrdinaryVeltmanSemantics.tex" export latex
*** Principles
    <<src:principles>>
  #+include: "latex/Principles.tex" export latex

** Coq library code
    <<src:coq>> Everything that is formalized and proved in Coq is in a single
    file:

    #+include: "latex/Coq.tex" export latex

** Manuscript by Verbrugge: Set Veltman frames and models
   <<pdf:Verbrugge>> In the following pages we copy a scan of a manuscript by
   Verbrugge (see notes below). It has not been processed or edited by us in any
   way. The original title, in Dutch, is /Verzamelingen-Veltman frames en
   modellen/.

   Annotations are probably from various authors, like Dick de Jongh and
   possibly others. Verbrugge commented in private correspondence that in
   particular the ‚ÄúEnglish translation on Page 1a‚Äù on the first typed page is
   from her own hand and likely the ‚Äú$‚àñ ‚àÖ$‚Äù and the two $x$‚Äôs on that same page
   too while the accolades on handwritten Page 1a are not her handwriting. These
   can most likely be attributed to Dick de Jongh together with the phrase $=
   KM_1$ on Page 2 of the handwritten part. The double exclamations marks have
   an uncertain author and they are possibly from somebody else altogether.
   Possibly the ‚ÄúRineke Verbrugge, manuscript, 1992‚Äù at the top of the first
   typed page is from Troelstra‚Äôs hand.

   \includepdf[pages=1-]{pdf/Verbrugge-manuscript-1992.pdf}
