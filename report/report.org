#+latex_compiler: xelatex
#+latex_class: scrreprt
#+options: H:4
#+options: toc:nil

#+latex_header: \usepackage{hyperref}
#+latex_header: \usepackage{mathpartir}
#+latex_header: \usepackage{graphicx}
#+latex_header: \usepackage{unicode-math}
#+latex_header: \usepackage{fontspec}
#+latex_header: \usepackage[x11names, table]{xcolor}
#+latex_header: \usepackage[margin=2.5cm]{geometry}
#+latex_header: \usepackage{lmodern}
#+latex_header: \setmonofont{FreeMono}
#+latex_header: \usepackage{cancel}
#+latex_header: \usepackage{amsthm}
#+latex_header: \usepackage{float}
#+latex_header: \usepackage{newunicodechar}
#+latex_header: \usepackage[toc,indexonlyfirst,docdef=restricted]{glossaries-extra}
#+latex_header: \usepackage[style=ieee]{biblatex}
#+latex_header: \usepackage{multicol}
#+latex_header: \usepackage{spverbatim}

#+latex_header: \bibliography{refs}
#+latex_header: \makeglossaries

#+latex_header: \hypersetup{colorlinks=true,urlcolor=DodgerBlue4,linkcolor=Firebrick4,citecolor=Green4}
#+latex_header: \newcommand{\ie}[0]{i.e.\ }
#+latex_header: \newcommand{\todo}[0]{\textcolor{red}{pending}}
#+latex_header: \newcommand{\pend}[0]{\textcolor{Tomato3}{pending }}
#+latex_header: \newcommand{\red}[1]{\textcolor{red}{#1 }}

#+macro: begindef @@latex:\begin{definition}@@
#+macro: enddef @@latex:\end{definition}@@

#+macro: begincoro @@latex:\begin{corollary}@@
#+macro: endcoro @@latex:\end{corollary}@@

#+macro: beginremark @@latex:\begin{remark}@@
#+macro: endremark @@latex:\end{remark}@@

#+macro: begintheorem @@latex:\begin{theorem}@@
#+macro: endtheorem @@latex:\end{theorem}@@

#+macro: beginlemma @@latex:\begin{lemma}@@
#+macro: endlemma @@latex:\end{lemma}@@

#+macro: beginproof @@latex:\begin{proof}@@
#+macro: endproof @@latex:\end{proof}@@


#+macro: defglossary @@latex:\newglossaryentry{$1}{name=$2,description={$3}}@@
#+macro: defacronym @@latex:\newacronym{$1}{$2}{$3}@@


#+latex_header: \newtheorem{theorem}{Theorem}
#+latex_header: \theoremstyle{definition}
#+latex_header: \newtheorem{corollary}[theorem]{Corollary}
#+latex_header: \theoremstyle{definition}
#+latex_header: \newtheorem{lemma}[theorem]{Lemma}
#+latex_header: \theoremstyle{definition}
#+latex_header: \newtheorem{definition}[theorem]{Definition}
#+latex_header: \theoremstyle{definition}
#+latex_header: \newtheorem{remark}[theorem]{Remark}

#+latex_header: \newglossaryentry{agdaprf}{name={\includegraphics[height=\baselineskip]{img/agda}},description={A proof formalized in Agda}}
#+latex_header: \newglossaryentry{coqprf}{name={\includegraphics[height=\baselineskip]{img/coq}},description={A proof formalized in Coq}}

#+macro: beginmulticols @@latex:\begin{multicols}{$1}@@
#+macro: endmulticols @@latex:\end{multicols}@@

#+latex_header: \newcommand{\joost}[1]{\textcolor{purple}{\textbf Joost: #1}}
#+latex_header: \newcommand{\jan}[1]{\textcolor{blue}{\textbf Jan: #1}}
#+latex_header: \newcommand{\luka}[1]{\textcolor{green}{\textbf Luka: #1}}
#+macro: joost @@latex:\joost{$1}@@
#+macro: jan @@latex:\jan{$1}@@
#+macro: luka @@latex:\luka{$1}@@

{{{defglossary(gvm,model,Generalized Veltman model)}}}
{{{defglossary(gvf,frame,Generalized Veltman frame)}}}
{{{defglossary(ovf,frame,Ordinary Veltman frame)}}}
{{{defglossary(ovm,model,Ordinary Veltman model)}}}
{{{defglossary(forcing-gen,{\ensuremath{âŠ©^{gen}_M}},Forcing relation for generalized semantics)}}}
{{{defglossary(forcing-ord,{\ensuremath{âŠ©^{ord}_M}},Forcing relation for ordinary semantics)}}}
{{{defglossary(choice-set,choice set,Choice set)}}}
{{{defglossary(noetherian,Noetherian,Conversely well-founded relation)}}}
#+latex_header: \newglossaryentry{dependent-pair}{name={dependent pair},description={A pair in which the type of the second component is indexed by the first component}}
#+latex_header: \newglossaryentry{sum type}{name={sum type},description={A disjunction of two ore more types}}
#+latex_header: \newglossaryentry{decidable model}{name={decidable model},description={A model whose forcing relation is decidable}}
#+latex_header: \newglossaryentry{multi decidable model}{name={multi-decidable model},description={A model whose forcing relation is decidable for sets}}
#+latex_header: \newglossaryentry{Rel}{name={\texttt{Rel}},description={Homogeneous relation}}
#+latex_header: \newglossaryentry{REL}{name={\texttt{REL}},description={Heterogeneous relation}}
#+latex_header: \newglossaryentry{Pred}{name={\texttt{Pred}},description={A predicate or a subset}}

#+macro: agda @@latex:\gls{agdaprf}\glsadd{agdaprf}@@
#+macro: coq @@latex:\gls{coqprf}\glsadd{coqprf}@@
#+latex_header: \newcommand{\prin}[1]{\ensuremath{\mathsf{#1}}}
#+latex_header: \newcommand{\il}[0]{\prin{IL}}
#+latex_header: \newcommand{\pa}[0]{\prin{PA}}
#+latex_header: \newcommand{\gl}[0]{\prin{GL}}
#+latex_header: \newcommand{\kgen}[1]{\text{($\mathsf{#1}$)\textsubscript{gen}}}
#+latex_header: \newcommand{\kord}[1]{\text{($\mathsf{#1}$)}}
#+latex_header: \newcommand{\ilall}[0]{\ensuremath{\mathsf{IL}}(All)}
#+latex_header: \newcommand{\rep}[1]{âŒœ#1âŒ}
#+latex_header: \newcommand{\prov}[1]{\prin{Prov}(#1)}


# remember to invoke with \ilall{} and not \ilall so that the space at the end
# is inserted if needed.


# Missing monospaced characters
#+latex_header: \setmathfont{XITS Math}
#+latex_header: \newfontfamily{\myfont}{XITS Math}
#+latex_header: \newunicodechar{ğ•}{\makebox[1em]{\myfontğ•}}
#+latex_header: \newunicodechar{áµ¢}{\makebox[0.5em]{\textsubscript{i}}}
#+latex_header: \newunicodechar{â±¼}{\makebox[0.5em]{\textsubscript{j}}}
#+latex_header: \newunicodechar{â‚–}{\makebox[0.5em]{\textsubscript{k}}}
#+latex_header: \newunicodechar{â‚™}{\makebox[0.5em]{\textsubscript{n}}}
#+latex_header: \newunicodechar{â‚˜}{\makebox[0.5em]{\textsubscript{m}}}
#+latex_header: \newunicodechar{â‚—}{\makebox[0.5em]{\textsubscript{l}}}
#+latex_header: \newunicodechar{â¸´}{\makebox[0.5em]{,}}
#+latex_header: \newunicodechar{ï½›}{\ensuremath{\{}}
#+latex_header: \newunicodechar{ï½}{\ensuremath{\}}}
#+latex_header: \setmathfont{Latin Modern Math}

#+latex_header: \newcommand{\horrule}[1]{\rule{\linewidth}{#1}}

\begin{titlepage}
  \begin{center}

    \textsc{\Large Master's thesis to obtain the degree\\ Master in pure and applied logic}
     \\[1.4cm]

    % \horrule{0.5pt} \\[0.4cm]
    { \huge \bfseries Interpretability logics and generalized Veltman semantics in Agda \\[0.01cm] }

    \horrule{0.7pt} \\[2cm]
    % \horrule{1.6pt}
    % \sectionlinetwo{black}{87}

    ~\textsc{\LARGE Jan Mas Rovira}

    ~\\[1.2cm]
    \begin{tabular}[!htb]{ll}
    \text{\large Supervised by } &\textsc{\Large Joost J. Joosten} \\
    \text{\large and } &\textsc{\Large Luka Mikec}
    \end{tabular}
    ~\\[6.2cm]

    \begin{figure}[H]
      \centering
      \includegraphics[width=9cm]{img/ub_logo}
    \end{figure}
    \vfill

    \text{\Large Facultat de Filosofia de Barcelona and}\\
    \text{\Large Facultat de MatemÃ tiques de Barcelona}\\
    {\Large July 2020}

  \end{center}
\end{titlepage}

#+BEGIN_abstract
abstract
#+END_abstract

\newpage

\renewcommand{\abstractname}{Acknowledgements}
#+BEGIN_abstract
thanks
#+END_abstract

\newpage
#+toc: headlines 2
\newpage
* [0/2] Pending                                                    :noexport:
** [0/2] Apply Luka's comments for review 1
   [[file:./jan_thesis_comments_16_06_20.pdf][pdf-link]].
*** TODO Fix drawings
** TODO Apply Luka's comments for review 2
   [[file:./jan_thesis_comments_07_07_2020.pdf][pdf-link]].
* Introduction
** Overview of interpretability logics
   We begin by giving a short introduction on provability logics. For more
   information refer to cite:sep-logic-provability. The reason to start here is
   that interpretability logics extend provability logics. Furthermore the
   ecosystem of interpretability logics is similar to the one of provability
   logics, albeit more complex, thus it will help establish an idea of the
   problems that we will tackle further in the report.

   Since GÃ¶del's incompleteness theorems, we have been interested in studying
   how much arithmetical theories like Peano Arithmetic can say about
   themselves, more precisely, about their provability capacity. As we know,
   sufficiently strong arithmetical theories like \pa{} can represent, by means
   of a clever syntactical encoding, their provability predicate, \prin{Prov},
   which states ``this formula is provable in $T$''. We call this predicate
   \prin{Prov}. A landmark result on this predicate is known as LÃ¶b's theorem,
   which states that \pa{} shows $\prov{\rep{A}}â†’A$ only if \pa{} shows $A$.
   LÃ¶b's theorem can be expressed in the language of \pa{} thus:
   \[\prov{\prov{\rep{A}} â†’A}â†’\prov{\rep{A}}.\] This result sparked an interest
   in studying provability logic from a modal centered point of view which
   birthed the axiomatization of the propositional provability logic \gl{},
   named after GÃ¶del and LÃ¶b. The logic \gl{} extends propositional classical
   logic and its language consists in the language of propositional logic
   $âŸ¨â†’,âŠ¥âŸ©$ plus the $â–¡$ modal operator, which stands for the provability
   predicate. In this language LÃ¶b's theorem reads as \[â–¡(â–¡Aâ†’A)â†’â–¡A.\] The above
   principle is in fact one of the axioms of \gl{}. The value of \gl{} directly
   depends on the arithmetical soundness and completeness theorems that we will
   present shortly, but first we need to introduce the concept of arithmetical
   realization. A realization $*$ is a map from modal formulas in the language
   of \gl{} to arithmetical sentences such that it satisfies the following:
   \begin{flalign*}
   âŠ¥^* &= âŠ¥; \\
   (A â†’ B)^* &= A^*â†’B^*; \\
   (â–¡A)^* &= \prov{\rep{A}}.
   \end{flalign*}
   The arithmetical soundness theorem states that if $\gl{}âŠ¢A$ then $\pa{}âŠ¢A^*$
   for any realization $*$. Solovay proved that arithmetical completeness, which
   is the converse of soundness, also holds.

   Provability logics have Kripke (relational) semantics. As a remainder a
   Kripke model is a tuple $âŸ¨W,R,VâŸ©$ where $W$ is a non-empty set of worlds, $R$
   is a binary relation on worlds and $VâŠ†WÃ—Var$ is a valuation. Then we define a
   forcing relation $âŠ©\ âŠ†WÃ—Fm$ thus:
   1. $wâŠ®âŠ¥$;
   2. if $pâˆˆVar$, then $wâŠ©p$ iff $âŸ¨w,pâŸ©âˆˆV$;
   3. if $A,BâˆˆFm$, then $wâŠ©Aâ†’B$ iff if $wâŠ©A$ then $wâŠ©B$;
   4. if $A,BâˆˆFm$, then $wâŠ©â–¡A$ iff if $wRu$ then $uâŠ©A$.
   In order to have modal soundness and completeness we ought to restrict the
   class of frames that we consider. We say that a frame $âŸ¨W,RâŸ©$ is a
   $\text{\gl{}-frame}$ if $R$ is transitive and conversely well-founded, that
   is, there are no infinite ascending chains $wâ‚€Rwâ‚â€¦$. Then we have that
   \[\gl{}âŠ¢Aâ‡”âŸ¨W,R,VâŸ©âŠ©A \text{ for any \gl{}-frame $âŸ¨W,RâŸ©$ and valuation $V$.} \]
   With this we conclude the introduction to provability logics and continue
   with interpretability logics.

   We introduce the concept of /interpretation/ as a first step towards
   understanding interpretability logics. Given two theories $V$ and $U$, an
   interpretation of $V$ into $U$ is a translation $f$ from \text{$V$-formulas}
   to \text{$U$-formulas} such that if $VâŠ¢A$ then $UâŠ¢f(A)$. In the history of
   mathematics we find numerous examples (cite:visser1997overview) of theorems
   that use interpretations as a cornerstone in their proofs. For instance,
   GÃ¶del's incompleteness theorems translate syntactical constructions into
   natural numbers. As another example we have that GÃ¶del's interpretation of
   \prin{ZF} plus the axiom of constructibility ($V=L$) serves as a proof of
   relative consistency of the continuum hypothesis with respect to \prin{ZF}.

   Interpretability logics logics study the behaviour

   mention $M$, $P$ and $R$.
** Original contributions
   This work includes the following original contributions:
   1. Generalized frame condition for $Râ‚$ (in collaboration with Luka). [[theorem:Râ‚][Link]];
   2. generalized frame condition for $Râ¿$. [[theorem:Râ¿][Link]];
   3. analysis of transitivity. [[theorem:trans][Link]];
   4. every Agda proof.

** Language
   <<sec:language>> The symbols of interpretability logics are $âŠ¥,â†’,â–·$.
   Formulas are defined recursively thus:
   \[Fmâ‰”Var\ |\ âŠ¥\ |\ Fmâ†’Fm \ |\  Fmâ–·Fm.\]

   We define $Varâ‰”â„•$. However, we use non-capital letters $a,b,c,x,y,zâ€¦$ to
   refer to variables.

   We define the usual operators and constants in the following way:
   1. $Â¬ A â‰” A â†’ âŠ¥$;
   2. $âŠ¤ â‰” Â¬ âŠ¥$;
   3. $A âˆ¨ B â‰” Â¬ A â†’ B$;
   4. $A âˆ§ B â‰” Â¬ (A â†’ Â¬ B)$;
   5. $A â†” B â‰” (A â†’ B) âˆ§ (B â†’ A)$;
   6. $â–¡ A â‰” Â¬ A â–· âŠ¥$;
   7. $â™¢ A â‰” Â¬ â–¡ Â¬ A$.

   The precedence (from higher to lower) of the operators is in the following
   order: $âˆ§,â–·,âˆ¨,â†’$.

   The scope of unary symbols ($â–¡,â™¢,Â¬$) is as small as possible. Thus $â–¡Aâˆ§Â¬Â¬B$ is
   the same as $(â–¡A)âˆ§(Â¬Â¬B)$.
** Notation
   Some notation that we use throughout the report:
   1. If $A$ and $B$ are binary relations, then $wAuBv$ means $wAu$ and $uBv$.
      For instance $wRuS_xv$ means $wRu$ and $uS_xv$. Another example: $wRuâŠ©A$
      means $wRu$ and $uâŠ©A$;
   2. $YâŠ©A$ iff for all $yâˆˆY$ we have $yâŠ©A$;
   3. $YâŠ®A$ iff there is some $yâˆˆY$ such that $yâŠ®A$;
   4. $âŸ¦AâŸ§â‰”\{w:wâŠ©A\}$;
   5. {{{agda}}} this is Agda's logo. Each proof that is formalized in Agda
      has been tagged with it;
   5. {{{coq}}} this is Coq's logo. Each proof that is formalized in Coq
      has been tagged with it;
   6. When we write a dot after the quantification of some variables, the scope of
      the variables extends to the rightmost part of what follows. Hence the
      formula  $âˆ€xâˆƒy.Pxyâˆ§âˆ€z.Pyz$ is equivalent to $âˆ€xâˆƒy(Pxyâˆ§âˆ€z(Pyz))$.


   In Section [[sec:trans]] and [[sec:frame-condition]] we present some diagrams. We use
   straight arrows to represent the $R$ relation and curvy arrows to represent
   some $S_w$ relation. We sometimes use red ink when an arrow is in a positive
   position in the formula to emphasize its role. We use discontinuous arrows
   when it is quantified universally.

   We believe that diagrams can help the reader have a better understanding of
   the underlying formula, however, they are not meant to be a replacement as
   they cannot unambiguously convey all the information in the formula.

** Logic \il
   <<sec:il>>
   The logic \il{} encompasses all classical tautologies in the new language plus
   the following axiom schemes:
   - K: $â–¡ (A â†’ B) â†’ â–¡ A â†’ â–¡ B$;
   - L: $â–¡ (â–¡ A â†’ A) â†’ â–¡ A$;
   - J1: $â–¡ (A â†’ B) â†’ A â–· B$;
   - J2: $A â–· B âˆ§ B â–· C â†’ A â–· C$;
   - J3: $(A â–· C âˆ§ B â–· C) â†’ (A âˆ¨ B) â–· C$;
   - J4: $A â–· B â†’ â™¢ A â†’ â™¢ B$;
   - J5: $â™¢ A â–· A$.
   If $A$ is an instantiation of any of the previous axiom schemes, then
   $âŠ¢_{\il}A$. Additionally it has the following rules:
   - Necessitation: if $âŠ¢_{\il}A$ then $âŠ¢_{\il}â–¡A$;
   - modus ponens: if $Î âŠ¢_{\il}Aâ†’B$ and $Î âŠ¢_{\il}A$ then $Î âŠ¢_{\il}B$;
   - identity: If $AâˆˆÎ $ then $Î âŠ¢_{\il}A$.

   {{{beginremark}}} While it is acceptable to have an infinite set of
   assumptions $Î $, when verifying properties in Agda we have restricted
   ourselves to finite sets and thus we assume that $Î $ is finite in the Agda
   proof. This restriction is not meaningful in the context of this project.
   {{{endremark}}}

   {{{begintheorem}}} *Local soundness for ordinary semantics*. That is, if
   $Î âŠ¢_{\il}A$ and $M$ is an ordinary model with a world $w$ such that $wâŠ©Î $,
   then $wâŠ©A$. {{{endtheorem}}} {{{beginproof}}} {{{agda}}} {{{coq}}} {{{endproof}}}

   {{{begintheorem}}} <<theorem:il-sound>> *Local soundness for generalized
   semantics*. That is, if $Î âŠ¢_{\il}A$ and $M$ is a generalized model with a world
   $w$ such that $wâŠ©Î $, then $wâŠ©A$. {{{endtheorem}}}

   {{{beginproof}}} {{{agda}}} We have verified this in Agda for all the presented
   quasi-transitivity conditions in Table [[fig:table-trans]]. {{{endproof}}}

   {{{begintheorem}}} *Weakening*. If
   $Î âŠ¢_{\il}A$ then $B,Î âŠ¢_{\il}A$. {{{endtheorem}}}
   {{{beginproof}}} {{{agda}}} {{{endproof}}}

   {{{begintheorem}}} *Deduction*.
   $Î âŠ¢_{\il}Aâ†’B$ iff $A,Î âŠ¢_{\il}B$. {{{endtheorem}}}
   {{{beginproof}}} {{{agda}}} {{{endproof}}}

   {{{begintheorem}}} *Cut*. If
   $Î âŠ¢_{\il}B$ and $B,Î âŠ¢_{\il}A$ then $Î âŠ¢_{\il}A$. {{{endtheorem}}}
   {{{beginproof}}} {{{agda}}} {{{endproof}}}

   {{{begintheorem}}} *Structurality*. If $Î âŠ¢_{\il}B$ and $Ïƒ$ is a
   substitution then $Ïƒ[Î ]âŠ¢_{\il}Ïƒ(A)$. {{{endtheorem}}} {{{beginproof}}}
   {{{agda}}} {{{endproof}}}

   {{{begintheorem}}} *Conjunction*. $Î âŠ¢_{\il}Aâˆ§B$ iff $Î âŠ¢_{\il}A$ and $Î âŠ¢_{\il}B$.
   {{{endtheorem}}} {{{beginproof}}} {{{agda}}} {{{endproof}}}

   {{{begintheorem}}} The following holds:
    1. $âŠ¢_{\il} A â†’ A$;
    2. $âŠ¢_{\il} A â–· A$;
    3. $âŠ¢_{\il} (A â†’ B) â†’ (B â†’ C) â†’ A â†’ C$;
    4. $âŠ¢_{\il} A â†’ Â¬ Â¬ A$;
    5. $âŠ¢_{\il} (Â¬ Â¬ A) â†’ A$;
    6. $âŠ¢_{\il} (A â†’ B) â†’ Â¬ B â†’ Â¬ A$;
    7. $âŠ¢_{\il} A â†’ âŠ¤$;
    8. $âŠ¢_{\il} âŠ¥ â†’ A$;
    9. $âŠ¢_{\il} Â¬ A â†’ A â†’ B$;
    10. $âŠ¢_{\il} A âˆ§ B â†’ A$;
    11. $âŠ¢_{\il} A âˆ§ B â†’ B$;
    12. $âŠ¢_{\il} (A â†’ B â†’ C) â†’ B â†’ A â†’ C$;
    13. $âŠ¢_{\il} A â†’ B â†’ A âˆ§ B$;
    14. $âŠ¢_{\il} A â†’ A âˆ¨ B$;
    15. $âŠ¢_{\il} B â†’ A âˆ¨ B$;
    16. $âŠ¢_{\il} A â–· (A âˆ¨ â™¢ A)$;
    17. $âŠ¢_{\il} (A âˆ¨ â™¢ A) â–· A$;
    18. $âŠ¢_{\il} A â†’ B â‡’ âŠ¢_{\il} â–¡ A â†’ â–¡ B$;
    19. $âŠ¢_{\il} A â†” B â‡’ âŠ¢_{\il} â–¡ A â†” â–¡ B$;
    20. $âŠ¢_{\il} â–¡ (A âˆ§ B) â†” (â–¡ A âˆ§ â–¡ B)$;
    21. $âŠ¢_{\il} A â†’ B â‡’ âŠ¢_{\il} â™¢ A â†’ â™¢ B$;
    22. $âŠ¢_{\il} A â†” B â‡’ âŠ¢_{\il} â™¢ A â†” â™¢ B$;
    23. $âŠ¢_{\il} Â¬ (A âˆ§ B) â†” Â¬ A âˆ¨ Â¬ B$;
    24. $âŠ¢_{\il} (A âˆ¨ Â¬ B) â†’ (A âˆ§ B âˆ¨ Â¬ B)$.
   {{{endtheorem}}}
   {{{beginproof}}} {{{agda}}}
   {{{endproof}}}

** Semantics
   In this document we consider two variants of relational semantics for
   interpretability logics similar to Kripke semantics for other modal logics.

*** Ordinary Veltman semantics
    {{{begindef}}} <<def:ordinary-frames>> cite:modal-matters An ordinary
    Veltman \gls{ovf} $F=âŸ¨W,R,SâŸ©$ is a structure constituted by a non-empty set
    of worlds $W$, a binary relation $RâŠ†WÂ²$ and a ternary relation $SâŠ†WÃ—WÃ—W$. We
    write $wRu$ instead of $âŸ¨w,uâŸ©âˆˆR$ and $uS_wv$ instead of $âŸ¨w,u,vâŸ©âˆˆS$. The
    structure must satisfy the following conditions:

    1. $R$ is transitive;
    2. $R$ is conversely well-founded. That is, there is no infinite ascending
       chain $wâ‚Rwâ‚‚Râ€¦$;
    3. if $uS_wv$ then $wRu$ and $wRv$;
    4. if $wRu$ then $uS_wu$;
    5. if $wRu$ and $uRv$ then $uS_wv$;
    6. for every $w$, $S_w$ is transitive.
    {{{enddef}}}


    {{{begindef}}} An ordinary Veltman \gls{ovm} $M=âŸ¨F,VâŸ©$ is a structure
    constituted by an ordinary Veltman frame $F$ and a valuation $VâŠ†WÃ—Var$. If
    $F=âŸ¨W,R,SâŸ©$ we will write $M=âŸ¨W,R,S,VâŸ©$ instead of $M=âŸ¨âŸ¨W,R,SâŸ©,VâŸ©$. {{{enddef}}}

    {{{begindef}}} <<def:ord-forcing>> Given a model $M$, we define a forcing
    relation $\gls{forcing-ord}âŠ†W Ã— Fm$. We write $M,wâŠ©A$ instead of
    $âŸ¨w,AâŸ©âˆˆ\gls*{forcing-ord}$ or simply $wâŠ©A$ when the model is clear from the
    context. We write $wâŠ®A$ when $âŸ¨w,AâŸ©âˆ‰âŠ©_M$.
    1. $wâŠ®âŠ¥$;
    2. if $pâˆˆVar$, then $wâŠ©p$ iff $âŸ¨w,pâŸ©âˆˆV$;
    3. if $A,BâˆˆFm$, then $wâŠ©Aâ†’B$ iff if $wâŠ©A$ then $wâŠ©B$;
    4. if $A,BâˆˆFm$, then $wâŠ©Aâ–·B$ iff if $wRu$ and $uâŠ©A$ then there exists some $v$ such
       that $vâŠ©B$ and $uS_wv$.
    {{{enddef}}}

    If $F$ is an ordinary Veltman frame and $A$ a formula, we write $FâŠ©A$ to
    denote that for every valuation we have $âŸ¨F,VâŸ©âŠ©A$.

    {{{begincoro}}}
    <<coro:ord-semantics>>
    It can be shown that:
    1. If $A,BâˆˆFm$, then $wâŠ©Aâˆ§B$ iff $wâŠ©A$ and $wâŠ©B$;
    1. If $A,BâˆˆFm$, then $wâŠ©Aâˆ¨B$ iff $wâŠ©A$ or $wâŠ©B$;
    2. if $AâˆˆFm$, then $wâŠ©Â¬A$ iff $wâŠ®A$;
    3. if $AâˆˆFm$, then $wâŠ©â™¢A$ iff there exists $u$ such that $wRu$ and $uâŠ©A$;
    4. if $AâˆˆFm$, then $wâŠ©â–¡A$ iff for every $u$ such that $wRu$ we have $uâŠ©A$.
    {{{endcoro}}}
    {{{beginproof}}}
    {{{agda}}}
    {{{coq}}}
    {{{endproof}}}

    {{{begintheorem}}} *Decidability* If $W$ is finite and $R,S,V$ are decidable relations,
    then the forcing relation associated to the model $Mâ‰”âŸ¨W,R,S,VâŸ©$ is decidable.
    {{{endtheorem}}} {{{beginproof}}} {{{agda}}} We have implemented a verified
    algorithm that given the mentioned conditions, a world $w$ and a formula
    $A$, constructs either a proof of $M,wâŠ©A$ or a proof of $M,wâŠ®A$. {{{endproof}}}

*** Generalized Veltman semantics
    {{{begindef}}} cite:mikec2019interpretability A generalized Veltman \gls{gvf}
    $F=âŸ¨W,R,SâŸ©$ is a structure constituted by a non-empty set of worlds $W$, a binary
    relation $RâŠ†WÂ²$ and a ternary relation $SâŠ†WÃ—WÃ—(ğ’«(W)âˆ–\{âˆ…\})$. We write $wRu$
    instead of $âŸ¨w,uâŸ©âˆˆR$ and $uS_wY$ instead of $âŸ¨w,u,YâŸ©âˆˆS$. The structure must
    satisfy the following conditions :

    1. $R$ is transitive; <<R-trans>>
    2. $R$ is conversely well-founded. That is, there is no infinite ascending
       chain $wâ‚Rwâ‚‚Râ€¦$;
    3. if $uS_wY$ then $wRu$ and for all $yâˆˆY$ we have $wRy$;
    4. /quasi-reflexivity/: if $wRu$ then $uS_w\{u\}$;
    5. if $wRu$ and $uRv$ then $uS_w\{v\}$;
    6. /quasi-transitivity/: if $uS_wY$ and $yS_wZ_y$ for all $yâˆˆY$, then
       $uS_w\left(â‹ƒ_{yâˆˆY}Z_y\right)$. This is a particular notion of
       quasi-transitivity, throughout this document we explore a total of eight
       notions, see Section [[sec:trans]].
    # 7. $S$ is monotone in the following sense: if $uS_wVâŠ†ZâŠ†\{u:wRu\}$ then
    #    $uS_wZ$.
    {{{enddef}}}

    {{{begindef}}}
    <<def:gen-frame>>
    A generalized Veltman \gls{gvm} $M=âŸ¨F,VâŸ©$ is a structure
    constituted by a generalized Veltman \gls{gvf} $F$ and a valuation $VâŠ†WÃ—Var$.
    {{{enddef}}}
    {{{begindef}}}
    Given a model $M$, we define a forcing relation $\gls{forcing-gen}âŠ†W Ã—
    Fm$. We use the same notational conventions as in the ordinary semantics.
    1. $wâŠ®âŠ¥$;
    2. if $pâˆˆVar$, then $wâŠ©p$ iff $âŸ¨w,pâŸ©âˆˆV$;
    3. if $A,BâˆˆFm$, then $wâŠ©Aâ†’B$ iff if $wâŠ©A$ then $wâŠ©B$;
    4. if $A,BâˆˆFm$, then $wâŠ©Aâ–·B$ iff if $wRu$ and $uâŠ©A$ then there exists some $Y$ such
       that $YâŠ©B$ and $uS_wY$. When we write $YâŠ©B$ we mean that for all $yâˆˆY$ we
       have $yâŠ©B$;
    {{{enddef}}}

    If $F$ is a generalized Veltman frame and $A$ a formula, we write $FâŠ©A$ to
    denote that for every valuation we have $âŸ¨F,VâŸ©âŠ©A$.

    {{{begincoro}}} We can show the same results in Corollary [[coro:ord-semantics]]
    for generalized semantics:
    1. If $A,BâˆˆFm$, then $wâŠ©Aâˆ§B$ iff $wâŠ©A$ and $wâŠ©B$;
    1. If $A,BâˆˆFm$, then $wâŠ©Aâˆ¨B$ iff $wâŠ©A$ or $wâŠ©B$;
    2. If $AâˆˆFm$, then $wâŠ©Â¬A$ iff $wâŠ®A$;
    3. If $AâˆˆFm$, then $wâŠ©â™¢A$ iff there exists $u$ such that $wRu$ and $uâŠ©A$;
    4. If $AâˆˆFm$, then $wâŠ©â–¡A$ iff for every $u$ such that $wRu$ we have $uâŠ©A$.
    {{{endcoro}}}
    {{{beginproof}}}
    {{{agda}}}
    {{{endproof}}}

** Transitivity
   <<sec:trans>> In the literature one can find several semantic requirements
   for the quasi-transitivity condition which we present in the table below. See
   that in definition [[def:gen-frame]] we used Condition (2). Theorem [[theorem:trans]] presents
   some direct implications between them. Theorems [[theorem:il-sound]] and
   [[theorem:trans-extend]] are sufficient to argue that all of them are appropriate
   for proving completeness of \il{}. It is worth mentioning however, that not
   all of them are sufficiently expressive to prove completeness for extensions
   of \il{}.

#+name: fig:table-trans
#+caption: Semantic requirements for quasi-transitivity mentioned in the literature.
#+attr_latex: :align c|l|l :float t :center t :placement [H] :font \small
| Nr. | Semantic requirement for transitivity                                                  | Mentioned in                                  |
|-----+----------------------------------------------------------------------------------------+-----------------------------------------------|
| (1) | $uS_xY â‡’ âˆ€ \, \{ Y_y\}_{yâˆˆ Y} \Big((âˆ€\, yâˆˆY\ yS_xY_y) â‡’ âˆƒ ZâŠ† â‹ƒ_{yâˆˆ Y}Y_y âˆ§ uS_xZ\Big)$ | Joosten et al. '20 \cite{joosten2020overview} |
| (2) | $uS_xY â‡’ âˆ€ \, \{ Y_y\}_{yâˆˆ Y} \Big((âˆ€\, yâˆˆY\ yS_xY_y) â‡’ uS_xâ‹ƒ_{yâˆˆ Y}Y_y\Big)$          | Verbrugge '92 '20 \cite{Verbrugge}            |
| (3) | $uS_xY â‡’ âˆƒ\, yâˆˆY\, âˆ€ Y'(yS_xY' â‡’ âˆƒ \, Y''{âŠ†}Y' âˆ§ uS_xY'')$                             | Joosten et al. \cite{joosten2020overview}     |
| (4) | $uS_xY â‡’ âˆƒ\, yâˆˆY\, âˆ€ Y'(yS_xY' â‡’ uS_xY')$                                              | Joosten '98 \cite{joosten-master}             |
| (5) | $uS_xY â‡’ âˆ€\, yâˆˆY\, âˆ€ Y'(yS_xY' â‡’ âˆƒ \, Y''{âŠ†}Y' âˆ§ uS_xY'')$                             | Joosten et al. '20 \cite{joosten2020overview} |
| (6) | $uS_xY â‡’ âˆ€\, yâˆˆY\, âˆ€ Y'(yS_xY' â‡’ uS_xY')$                                              | Verbrugge '92 \cite{Verbrugge}                |
| (7) | $uS_xY â‡’ âˆ€\, yâˆˆY\, âˆ€ Y'(yS_xY'\wedge yâˆ‰Y' â‡’ âˆƒ \, Y''{âŠ†}Y'\ uS_xY'')$                   | Joosten et al. '20 \cite{joosten2020overview} |
| (8) | $uS_xY â‡’ âˆ€\, yâˆˆY\, âˆ€ Y'(yS_xY'\wedge yâˆ‰Y' â‡’ uS_xY')$                                   | Goris, Joosten '09 \cite{a-new-principle}     |

   #+caption: Diagrams for conditions 2, 4 and 6.
   #+name: fig:diagrams-transitivity
   #+attr_latex: :float t :width 0.9\textwidth :placement [H]
   [[file:img/trans-2-4-6.pdf]]

# I NOW SEE THAT THE TABLE IN YOUR SECTION 1.6 HAS BEEN UPDATED IN OUR PAPER

# OF COURSE, YOU SHOULD ADAPT IT TO YOUR THESIS.
# SHORTLY WE WILL PUT IT ON THE ARXIV SO THAT YOU CAN INCLUDE A REFERENCE



 # All of the presented quasi-transitivity requirements are adequate for proving
 # IL soundness and completeness. For soundness it is routine to check that every
 # instantiation of $J2$ holds. For the completeness part it is enough to see that
 # any ordinary Veltman model $M=âŸ¨W,R,S,VâŸ©$ can be transformed into a generalized
 # Veltman model $M'=âŸ¨W,R,S',VâŸ©$ where $S'â‰”\{âŸ¨w,x,\{y\}âŸ©:âŸ¨w,x,yâŸ©âˆˆS\}$ and see that
 # $M'$ has the same truth value as $M$. This has been verified in Agda.

 {{{begintheorem}}} <<theorem:trans>> Let $F$ be a generalized Veltman frame. Let
 \[Mâ‰”âˆ€w,u,V,Z(uS_wVâŠ†ZâŠ†\{u:wRu\}â‡’uS_wZ)\] represent the monotonicity condition. The
 following implications hold.

 The first item should be read as $FâŠ¨Mâˆ§(1)â†’(2)$.

 {{{beginmulticols(3)}}}

   1. $M âˆ§ (1) â‡’ (2)$
   2. $(2) â‡’ (1)$
   3. $M âˆ§ (3) â‡’ (4)$
   4. $(4) â‡’ (3)$
   5. $(5) â‡’ (1)$
   6. $M âˆ§ (5) â‡’ (2)$
   7. $(5) â‡’ (3)$
   8. $M âˆ§ (5) â‡’ (4)$
   9. $M âˆ§ (5) â‡’ (6)$
   10. $(5) â‡’ (7)$
   11. $M âˆ§ (5) â‡’ (8)$
   12. $(6) â‡’ (1)$
   13. $M âˆ§ (6) â‡’ (2)$
   14. $(6) â‡’ (3)$
   15. $(6) â‡’ (4)$
   16. $(6) â‡’ (5)$
   17. $(6) â‡’ (7)$
   18. $(6) â‡’ (8)$
   19. $M âˆ§ (7) â‡’ (8)$
   20. $(8) â‡’ (7)$

 {{{endmulticols}}} {{{endtheorem}}}

 {{{beginproof}}}
 {{{agda}}}
 {{{endproof}}}

 {{{begintheorem}}} <<theorem:trans-extend>> Given an ordinary Veltman model
 $M=âŸ¨W,R,S,VâŸ©$ we can find some generalized Veltman model $M'=âŸ¨W,R,S',VâŸ©$, where
 we can replace our notion of quasi-transitivity by any of the Conditions
 $(i)âˆˆ\{1,â€¦,8\}$. Furthermore, for every world $w$ and formula $A$:
 \[M,wâŠ©Aâ‡”M',wâŠ©A.\] {{{endtheorem}}}

 {{{beginproof}}} We prove it for the quasi-transitivity Condition (2) (the rest
 can be proven in the same way). Let $M=âŸ¨W,R,S,VâŸ©$ be an ordinary model. Let
 $M'â‰”âŸ¨W,R,S',VâŸ©$ with $S'$ defined thus: \[S'â‰”\{âŸ¨w,x,\{y\}âŸ©:âŸ¨w,x,yâŸ©âˆˆS\}.\] It is
 easy to observe that $M'$ satisfies conditions 1--5 from definition
 [[def:gen-frame]]. It is also easy to see that it satisfies quasi-transitivity (2).
 We show that they force the same formulas by induction on the complexity of the
 formula. The only interesting case is $Aâ–·B$.
   - Assume $M,wâŠ©Aâ–·B$ and that for some $x$ we have $wRxâŠ©A$. It follows that
     there exists some $y$ such that $xS_wyâŠ©B$. By definition of $M'$ we have
     $xS'_w\{y\}$ and also $\{y\}âŠ©B$, therefore $M',wâŠ©Aâ–·B$.
   - Assume $M,wâŠ®Aâ–·B$, then there exists some $x$ such that $wRxâŠ©A$ and
     $âˆ€y(xS_wyâ‡’yâŠ®B)$. It is obvious that for $M'$ we have $âˆ€y(xS'_w\{y\}â‡’yâŠ®B)$
     and also $âˆ€Y(xS'_wYâ‡’YâŠ®B)$, which is the required property.
 {{{endproof}}}

** Monotonicity
   Consider the following monotonicity condition:

  #+begin_center
    if $uS_wVâŠ†ZâŠ†\{v:wRv\}$ then $uS_wZ$.
  #+end_center

  {{{begintheorem}}} <<theorem:mono>> Let $F=âŸ¨W,R,SâŸ©$ be a generalized Veltman
  frame with quasi-transitivity $(i)âˆˆ\{1,â€¦,8\}$. Let $F'=âŸ¨W,R,S'âŸ©$ where $S'$ is
  the monotone closure of $S$:

  \[S'â‰”\{âŸ¨w,x,Y'âŸ© : âŸ¨w,x,YâŸ©âˆˆS, YâŠ†Y'âŠ†\{u:wRu\}\}.\]

  Then $F'$ is a generalized Veltman frame satisfying quasi-transitivity
  Condition (2). Furthermore, let $V$ be an arbitrary valuation and $A$ an
  arbitrary formula. Let $Mâ‰”âŸ¨F,VâŸ©$ and $M'â‰”âŸ¨F',VâŸ©$. We have that for every world
  $w$: \[M,wâŠ©Aâ‡”M',wâŠ©A.\] {{{endtheorem}}}


  {{{beginproof}}} {{{agda}}}

  We check conditions listed in definition [[def:gen-frame]].
  - Conditions 1 and 2 are clear since $R$ is unchanged;
  - Condition 3 follows from the fact that in the definition of $S'$ we require
    $Y'âŠ†\{u:wRu\}$;
  - for Conditions 4 and 5 observe that $SâŠ†S'$. Then, since these conditions hold for
    $F$ they also hold for $F'$;
  - for quasi-transitivity Condition (2) assume that $uS'_xY'$ and that for
    every $y'âˆˆY'$ we have $y'S'_xÎ¥_{y'}$. We need to show that
    $uS'_xâ‹ƒ_{y'âˆˆY'}Î¥_{y'}$. By definition of $S'$ it follows that there exists
    $YâŠ†Y'$ such that $uS_xY$, furthermore, for every $y'âˆˆY'$ we have that there
    exists $f(Î¥_{y'})âŠ†Î¥_{y'}$ such that $y'S_xf(Î¥_{y'})$. From $YâŠ†Y'$ it follows
    that for all $yâˆˆY$ there exists $f(Î¥_{y})âŠ†Î¥_{y}$ such that $yS_xf(Î¥_{y})$.
    Then by (2) for $F$ it follows that $uS_xâ‹ƒ_{yâˆˆY}f(Î¥_{y})$. Then see that
    $â‹ƒ_{yâˆˆY}f(Î¥_{y})âŠ†â‹ƒ_{y'âˆˆY'}Î¥_{y'}$. It remains to show
    $â‹ƒ_{y'âˆˆY'}Î¥_{y'}âŠ†xR\{u:xRu\}$. Consider some $u$ such that there is some
    $y'âˆˆY'$ with $uâˆˆÎ¥_{y'}$. By assumption we have $y'S'_xÎ¥_{y'}$ and thus
    $xRu$.
  To show $M,wâŠ©Aâ‡”M',wâŠ©A$ we proceed by induction on $A$. The only
  interesting case is $Aâ–·B$.
  - Assume that $M,wâŠ©Aâ–·B$ and that there is some world $x$ such that $wRx$ and
    $M',xâŠ©A$. By IH we have $M,xâŠ©A$, so there exists some $Y$ such that $xS_wY$
    and $M,YâŠ©B$. By IH we have $M',YâŠ©B$ and by definition of $S'$ it follows
    that $xS'_wY$, therefore $M',wâŠ©Aâ–·B$.
  - Assume that $M,wâŠ®Aâ–·B$. It follows that there is some $x$ such that $wRx$,
    $M,xâŠ©A$ and $(â‹†)\ âˆ€Y(xS_wYâ‡’M,YâŠ®B)$. We want to prove that
    $âˆ€Y'(xS'_wY'â‡’M',Y'âŠ®B)$. Assume that for some $Y'$ we have $xS'_wY'$. By
    definition of $S'$ it follows there exists some $Y$ such that $YâŠ†Y'$ and
    $xS_wY$. Hence by $(â‹†)$ we have that $M,YâŠ®B$ and thus there exists $yâˆˆY$
    such that $M,yâŠ®B$. By IH we get that $M',yâŠ®B$ and since $yâˆˆYâŠ†Y'$ we have
    $Y'âŠ®B$, so $M',wâŠ®Aâ–·B$.
  {{{endproof}}}

  As we see in Theorem [[theorem:mono]] taking the monotone closure of each $S_w$ does not
  change the forcing relation and the resulting frame satisfies quasi-transitivity
  Condition (2).

  # The previous lemma allows us to safely assume that monotonicity is a condition
  # for a Veltman frame with quasi-transitivity (2).

  {{{beginremark}}} Taking the monotone closure of each $S_w$ is essentially
  different than assuming that each $S_w$ is monotone by definition of the
  frame, as then the forcing relation may change. In the following example we
  present a generalized Veltman model with Condition (8) that showcases such
  behaviour.

   #+caption: Example frame: $wRv_0,wRv_1,wRv_2,wRv_3$, $v_0S_w\{v_1\}$, $v_2S_w\{v_3\}$.
   #+name: fig:example-trans
   #+attr_latex: :float t :width 0.28\textwidth :placement [H]
   [[file:img/example.pdf]]

  Let $M$ be a model based on the frame displayed[fn::In the figure we do not
  show the $S_w$ relations required by quasi-reflexivity for clarity.] in figure
  [[fig:example-trans]] such that $âŸ¦pâŸ§ = \{v_0\}$, $âŸ¦qâŸ§ = \{v_2\}$. We see that
  $wâŠ©Â¬(p â–· q)$ as $p$ is only true in $v_0$ and we only have $v_0S_w\{v_1\}$ and
  $v_0S_w\{v_0\}$ (by quasi-reflexivity) with $v_0âŠ®q$ and $v_1âŠ®q$. If we take
  the monotonic closure of $S$ we have $v_0S_w \{v_1, v_2\}$ and by
  quasi-transitivity (8) we get $v_0S_w \{v_3\}$ and consequently $wâŠ©Â¬(p â–· q)$
  is no longer true.

  {{{endremark}}}

* Generalized vs ordinary models
  In this section we discuss how we can transform an ordinary model into a
  generalized model and vice versa. Of course, we want the transformation to
  maintain the forcing relation associated with the models.

  In Section [[sec:ord-to-gen]] we see a straightforward transformation from an
  ordinary Veltman model into a generalized Veltman model. In Section
  [[sec:verbrugge]] we see an involved transformation from a generalized model into
  an ordinary model. This transformation is due to Verbrugge and was described
  in cite:Verbrugge. The proof was originally described to work with
  quasi-transitivity Condition (6). We have slightly improved the result by
  showing that the same transformation also works for Conditions (3), (4) and
  (5). In Section [[sec:gen-to-ord-luka]] we show a transformation that achieves the
  same as Verbrugge's transformation but it is much simpler. This transformation
  was suggested by Luka Mikec during online correspondence.

** From ordinary to generalized
   <<sec:ord-to-gen>> The transformation from an ordinary to a generalized
   Veltman frame is immediate.

   {{{begintheorem}}} Let $M=âŸ¨W,R,S,VâŸ©$ be an ordinary Veltman model. We define
   $M'â‰”âŸ¨W,R,S',VâŸ©$ where $S'â‰”âŸ¨âŸ¨w,u,\{v\}:âŸ¨w,u,vâŸ©âˆˆSâŸ©âŸ©$. Then M' is a generalized
   Veltman frame. Furthermore, for any world $w$ and formula $A$ we have that
   \[M,wâŠ©Aâ‡”M',wâŠ©A.\]{{{endtheorem}}} {{{beginproof}}} We observe that the
   quasi-transitivity condition for ordinary models entails the
   quasi-transitivity Condition (6) for our $M'$ model. Keep in mind that by
   definition of $M'$ we only have singleton sets in the third component of
   $S'$. Now assume that $uS'_x\{y\}$ and $yS'_x\{y'\}$. By definition of $S'$
   it follows that $uS_xyS_xy'$ and by quasi-transitivity of $M$ we have
   $uS_xy'$ and thus $uS_x\{y'\}$. Then, by theorem [[theorem:trans]] we know that
   quasi-transitivity Condition (6) implies Conditions (1), (3)-(8), thus, the
   presented transformation works for any of those notions of
   quasi-transitivity. Moreover, if we wish to obtain a generalized Veltman
   frame with quasi-transitivity Condition (2) we take monotone closure of $S'$
   as described in theorem [[theorem:mono]]. We leave the rest of the details to be
   worked out by the reader. {{{endproof}}}

** From generalized to ordinary (Verbrugge)
   <<sec:verbrugge>>
   In this section we proof that given a generalized Veltman model that satisfies
   a certain property, we can build an ordinary Veltman model with the same
   associated forcing relation. For the rest of this section we fix a generalized
   Veltman model $Mâ‰”âŸ¨W, R, S, VâŸ©$.

   We define an ordinary Veltman model $M'â‰”âŸ¨W',R',S',V'âŸ©$ where
   \begin{flalign*}
   W'â‰”&\{âŸ¨x,AâŸ©:AâŠ†W^2, \\ &(W1)\ âˆ€âŸ¨u,vâŸ©âˆˆA\ âˆƒY(xS_uY,vâˆˆY), \\
   & (W2)\ âˆ€uV(xS_uVâ‡’âˆƒvâˆˆV(âŸ¨u,vâŸ©âˆˆA)\}; \\
   R'â‰”&\{âŸ¨âŸ¨x,AâŸ©,âŸ¨y,BâŸ©âŸ© : xRy,âˆ€wz(wRxâ‡’âŸ¨w,zâŸ©âˆˆBâ‡’âŸ¨w,zâŸ©âˆˆA)\}; \\
   S'â‰”&\{âŸ¨âŸ¨w,CâŸ©,âŸ¨x,AâŸ©,âŸ¨y,BâŸ©âŸ© : âŸ¨w,CâŸ©R'âŸ¨x,AâŸ©,âŸ¨w,CâŸ©R'âŸ¨y,BâŸ©, âˆ€v(âŸ¨w,vâŸ©âˆˆBâ‡’âŸ¨w,vâŸ©âˆˆA) \}; \\
   V'â‰”&\{âŸ¨âŸ¨x, AâŸ©,varâŸ©: âŸ¨x,varâŸ©âˆˆV, âŸ¨x,AâŸ©âˆˆW'\}.
   \end{flalign*}

   {{{beginlemma}}}
   The structure $âŸ¨W',R',S',V'âŸ©$ is an ordinary Veltman model.
   {{{endlemma}}}
   {{{beginproof}}}
   {{{agda}}} It is routine to check that all the requirement are satisfied.
   {{{endproof}}}

   Let the conditions $(C_0)$ and $(C_1)$ be defined thus:
   \begin{flalign*}
   (Câ‚€)&â‰”âˆ€wxV.xS_wVâ‡’âˆƒyâˆˆV.âˆ€bV'.yS_bV'â‡’âˆƒvâˆˆV'. (b=w â‡’ xS_b\{v\}), (bRw â‡’ wS_b\{v\}); \\
   (Câ‚)&â‰”âˆ€wbxV.wRxâ‡’xS_bVâ‡’âˆƒvâˆˆV.xS_b\{v\},(bRwâ‡’wS_b\{v\}).
   \end{flalign*}
   {{{begintheorem}}}
   If $M$ satisfies both conditions $(C_0)$ and $(C_1)$ then
   for any world $âŸ¨w,CâŸ©âˆˆW'$ and formula $D$:
   \[wâŠ©Dâ‡”âŸ¨w,CâŸ©âŠ©D\]
   {{{endtheorem}}}
   {{{beginproof}}} {{{agda}}}
   We proceed by induction on the formula. We only consider the
   case $Dâ–·E$ as the other cases are easy.
   - \boxed{â‡’} Assume $wâŠ©Dâ–·E$ and let $C$ be such that $âŸ¨w,CâŸ©âˆˆW'$. We
     want to prove $âŸ¨w,CâŸ©âŠ©Dâ–·E$. Assume that for some $âŸ¨x,AâŸ©âˆˆW'$ we have
     $âŸ¨w,CâŸ©R'âŸ¨x,AâŸ©âŠ©D$. By IH it follows that $xâŠ©D$ and hence there exists $V$
     such that $xS_wVâŠ©E$. By $(C_0)$ there is some $yâˆˆV$ such that

     #+name: eq:verb-y-cond
     \begin{equation}
     âˆ€bV'.yS_bV'â‡’âˆƒvâˆˆV'. (b=w â‡’ xS_b\{v\}), (bRw â‡’ wS_b\{v\})
     \end{equation}

     We proceed by showing that there is some $B$ such that
     $âŸ¨x,AâŸ©S'_{âŸ¨w,CâŸ©}âŸ¨y,BâŸ©$. Let $B$ be defined thus:
     \[Bâ‰”\{âŸ¨u,vâŸ©: âˆƒY.yS_uY,vâˆˆY,(u=wâ‡’âŸ¨w,vâŸ©âˆˆA),(uRwâ‡’âŸ¨u,vâŸ©âˆˆC)\}\]

     To show $âŸ¨y,BâŸ©âˆˆW'$ we need to prove that $(W1)$ and $(W2)$ hold. The
     condition $(W1)$ follows immediately from the definition of $B$. To show
     $(W2)$ assume that for some $b$ and $V$ we have $yS_bV$. We need to see that
     there exists $vâˆˆV$ such that $âŸ¨b,vâŸ©âˆˆB$. From $yS_bV$ and [[eq:verb-y-cond]] we
     get that there exists $vâˆˆV'$ such that
     \begin{flalign}
     b=w &â‡’ xS_b\{v\} \label{eq:verb-b=w}, \\
     bRw &â‡’ wS_b\{v\} \label{eq:verb-2}
     \end{flalign}
     To show that $âŸ¨b,vâŸ©âˆˆB$ we first see that $b=wâ‡’âŸ¨w,vâŸ©âˆˆA$. Assume $b=w$, then
     by \ref{eq:verb-b=w} it follows that $xS_b\{v\}$ and therefore by condition
     $(W2)$ for $A$ it follows $âŸ¨b,vâŸ©âˆˆA$. We proceed likewise and use
     \ref{eq:verb-2} to show $bRwâ‡’âŸ¨b,vâŸ©âˆˆC$. This concludes the proof that
     $âŸ¨y,BâŸ©âˆˆW'$.

     We now check the conditions for $âŸ¨x,AâŸ©S'_{âŸ¨w,CâŸ©}âŸ¨y,BâŸ©$. We already have
     $âŸ¨w,CâŸ©R'âŸ¨x,AâŸ©$ by assumption. To see that $âŸ¨w,CâŸ©R'âŸ¨y,BâŸ©$ we first observe
     that $wRy$ holds since $xS_wV$ and $yâˆˆV$. Then assume that for some $b,z$ we
     have $bRw$ and $âŸ¨b,zâŸ©âˆˆB$. Then from the definition of $B$ it follows that
     $âŸ¨b,zâŸ©âˆˆC$. The condition $âˆ€v(âŸ¨w,vâŸ©âˆˆBâ‡’âŸ¨w,vâŸ©âˆˆA)$ follows immediately from the
     definition of $B$.

     Finally, since $VâŠ©E$ and $yâˆˆV$ we have $yâŠ©E$ and thus by IH it follows that
     $âŸ¨y,BâŸ©âŠ©E$.

   - \boxed{â‡} We proceed by contraposition. Assume $wâŠ®Dâ–·E$, then there exists
     $x$ such that $wRx$ and
     #+name: eq:verb-neg
     \begin{equation}
     âˆ€Y(vS_wYâ‡’âˆƒyâˆˆY(yâŠ®E)).
     \end{equation}

     Let $A$ be defined thus:
     \[Aâ‰” \{âŸ¨b,vâŸ©:(âˆƒY.xS_bY,vâˆˆY),(b=wâ‡’M,vâŠ®E),(bRwâ‡’âŸ¨b,vâŸ©âˆˆC)\}.\]

     We first show that $âŸ¨x,AâŸ©âˆˆW'$. Condition $(W1)$ follows directly from the
     definition of $A$. To show that $(W2)$ holds assume that for some $b$ and
     $V$ we have $xS_bV$. We need to see that for some $vâˆˆV$ we have $âŸ¨b,vâŸ©âˆˆA$.
     Since $wRx$ and $xS_bV$ it follows from condition $(C_1)$ that there exists
     $vâˆˆV$ such that
     \begin{flalign}
     &xS_b\{v\}, \label{eq:verb-neg-b=w} \\
     bRwâ‡’&wS_b\{v\}. \label{eq:verb-neg-bRw}
     \end{flalign}
     The first condition to show $âŸ¨b,vâŸ©âˆˆA$, namely that $âˆƒY.xS_bY,vâˆˆY$, is met
     trivially. For the next condition assume $b=w$, then see that we have
     $xS_w\{v\}$ by \ref{eq:verb-neg-b=w} and thus by [[eq:verb-neg]] it follows that
     $vâŠ®E$. For the remaining condition assume $bRw$, then by \ref{eq:verb-neg-bRw} we
     have $wS_b\{v\}$ and thus by $(W2)$ for $C$ we have $âŸ¨b,vâŸ©âˆˆC$. Therefore we
     conclude $âŸ¨b,vâŸ©âˆˆA$ and thus $âŸ¨x,AâŸ©âˆˆW'$.

     To see that $âŸ¨w,CâŸ©R'âŸ¨x,AâŸ©$ we already have $wRx$ by assumption. The
     remaining condition, $âˆ€bz(bRxâ‡’âŸ¨b,zâŸ©âˆˆAâ‡’âŸ¨b,zâŸ©âˆˆC)$, follows directly from the
     definition of $A$.

     Since $xâŠ©D$, it follows from the IH that $âŸ¨x,AâŸ©âŠ©D$.

     Lastly, assume that for some $âŸ¨y,BâŸ©âˆˆW'$ we have $âŸ¨x,AâŸ©S'_{âŸ¨w,CâŸ©}âŸ¨y,BâŸ©$. By
     definition of $S'$ we have $xS_wy$ and thus $wRy$. By quasi-reflexivity of
     $S$ we then have $yS_w\{y\}$ and thus by $(W2)$ for $B$ we have $âŸ¨w,yâŸ©âˆˆB$.
     By definition of $S'$ we also have that $âˆ€v(âŸ¨w,vâŸ©âˆˆBâ‡’âŸ¨w,vâŸ©âˆˆA)$, hence
     $âŸ¨w,yâŸ©âˆˆA$. By definition of $A$ it follows that $yâŠ®E$ and by IH we have
     $âŸ¨y,BâŸ©âŠ®E$, which concludes the proof.
   {{{endproof}}}

   {{{begintheorem}}} If a generalized Veltman frame satisfies
   quasi-transitivity Condition 3, 4, 5 or 6, then it satisfies conditions
   $(C_0)$ and $(C_1)$. {{{endtheorem}}}

   {{{beginproof}}} {{{agda}}} Here we prove the property for a generalized
   Veltman frame satisfying quasi-transitivity Condition 3. Conditions 4, 5 and 6
   imply Condition 3 as shown in Theorem [[theorem:trans]].

   Assume $F$ is a generalized Veltman frame satisfying quasi-transitivity
   Condition 3.
   It is easy to observe that the following property holds:
   #+name: eq:verb-trans-prop
   \begin{equation}
   uS_xY â‡’ âˆƒ\, yâˆˆY\, âˆ€ z(yS_x\{z\} â‡’ uS_x\{z\}).
   \end{equation}
   - \boxed{(Câ‚€)} Assume that for some $w,x,V$ we have $xS_wV$. Then by
     [[eq:verb-trans-prop]] there is some $yâˆˆV$ such that
     #+name: eq:verb-trans-y
     \begin{equation}
      âˆ€ z(yS_w\{z\} â‡’ xS_w\{z\}).
     \end{equation}

     Now assume that for some $b,V'$ we have $yS_bV'$. It follows by
     [[eq:verb-trans-prop]] that there is some $vâˆˆV'$ such that
     #+name: eq:verb-trans-v
     \begin{equation}
      âˆ€ z(vS_b\{z\} â‡’ yS_b\{z\}).
     \end{equation}
     Assume that $b=w$, we need to see that $xS_b\{v\}$. From $xS_wV$ and $yâˆˆV$
     it follows that $wRy$. Then by quasi-reflexivity we have $yS_w\{y\}$ and by
     [[eq:verb-trans-y]] we get $xS_w\{v\}$ which is the same as $xS_b\{v\}$. Assume
     that $bRw$, we need to see that $wS_b\{v\}$. From $bRwRy$ we have
     $wS_b\{y\}$ and from property [[eq:verb-trans-prop]] we get
     #+name: eq:verb-trans-Sbyz
     \begin{equation}
     âˆ€z(yS_b\{z\}â‡’wS_b\{z\}).
     \end{equation}
     Then since $yS_bV'$ and $vâˆˆV'$ we have $bRv$ so by quasi-reflexivity we have
     $vS_b\{v\}$. Finally by [[eq:verb-trans-v]] we get $yS_b\{v\}$ and by
     [[eq:verb-trans-Sbyz]] we get $wS_b\{v\}$.
   - \boxed{(C_1)} Assume that for some $w,b,x,V$ we have $wRxS_bV$.
     By [[eq:verb-trans-prop]] it follows that there is some $vâˆˆV$ such that
     #+name: eq:verb-trans-SbxV
     \begin{equation}
      âˆ€z(vS_b\{z\} â‡’ xS_b\{z\}).
     \end{equation}
     We first see that $xS_b\{v\}$. From $xS_bV$ and $vâˆˆV$ we get $bRv$ and by
     quasi-reflexivity we get $vS_b\{v\}$. Then by [[eq:verb-trans-SbxV]] we have
     $xS_b\{v\}$. Assume $bRw$, we need to see $wS_b\{v\}$. By quasi-reflexivity
     we get $vS_b\{v\}$ and by [[eq:verb-trans-SbxV]] we get $xS_b\{v\}$. By $bRwRx$
     we get $wS_b\{x\}$ and thus by [[eq:verb-trans-prop]] we have
     #+name: eq:verb-Sbwx
     \begin{equation}
     âˆ€z(xS_b\{z\}â‡’wS_b\{z\}).
     \end{equation}
     Finally by $xS_b\{v\}$ and [[eq:verb-Sbwx]] we get $wS_b\{v\}$.
   {{{endproof}}}
** From generalized to ordinary (Luka)
   <<sec:gen-to-ord-luka>> In this section we present a transformation that
   achieves the same as the one presented in Section [[sec:verbrugge]], however, it
   is much simpler. This transformation was described by Mikec in an online
   conversation during the development of this project.

   {{{begintheorem}}} Let $M$ a generalized Veltman model with
   quasi-transitivity Condition 3, 4, 5 or 6. By theorem [[theorem:trans]] we shall
   assume without loss of generality that $M$ satisfies quasi-transitivity
   Condition 3. We remind the reader that the condition reads thus: \[uS_xY â‡’
   âˆƒ\, \textcolor{blue}{y}âˆˆY\, âˆ€ Y'(yS_xY' â‡’ âˆƒ \, Y''{âŠ†}Y' âˆ§ uS_xY'').\] For
   every $âŸ¨x,u,YâŸ©$ such that $uS_xY$ we fix the $y$ that is highlighted in blue
   and name it $y_{xuY}$.

   We define $M'â‰”âŸ¨W,R,S',VâŸ©$ with $S'â‰”\{âŸ¨w,x,vâŸ©:âˆƒV.wS_xVâˆ§ y_{xwV}=v\}$. Then
   $M'$ is an ordinary Veltman frame and it holds that for every $wâˆˆW$ and
   $AâˆˆFm$ we have \[M,wâŠ©Aâ‡”M',wâŠ©A.\]

   {{{endtheorem}}} {{{beginproof}}} {{{agda}}} It is not hard to check that all
   the conditions hold. {{{endproof}}}
   # I tried reconstructing the remainder of Mladen's proof and got stuck on
   # another issue. Instead of trying to fix it, I started playing with another
   # formulation of the same (or similar) construction which I think is much more
   # convenient:

   # For every $u S_w V$ and $v \in V$, put $u_{(w, v)} S_w \{v\}$,
   # where $u_{(w, v)}$ is a fresh world that inherits transitions that the world
   # $u$ was a part of. The construction should be performed recursively, starting
   # with R-leaves $w$, then proceeding with their direct R-ancestors etc. Finally,
   # remove all transition $u S_w V$ where $|V| > 1$.

   # Unless I'm missing something, it is almost obvious that this preserves truth
   # values. There are details to be spelled out though, for example what does
   # $u_{(w, v)}$ inherit exactly (it shouldn't be too hard, I actually did
   # something similar in the old version of the IL complexity paper).

** A false theorem in disguise

   In this section we give an example that shows the importance of verified proofs.

   The transformations from a generalized to an ordinary Veltman model given in
   Sections [[sec:verbrugge]] and [[sec:gen-to-ord-luka]] work for simple notions of
   quasi-transitivity but does not work for Condition (2), which is the one
   which we have picked as standard in this report. In
   cite:vukovic2008bisimulations a transformation which is supposed to work for
   Condition (2) is presented. We studied the transformation and started to
   formalize in Agda the proof of its correctness following the proof of
   Proposition 2.8 of cite:vukovic2008bisimulations. Despite of our best efforts
   we could not follow some steps which are claimed to be obvious in the
   original paper. After that, we decided to ask the original author for a
   clarification. He kindly replied but was unable to find a satisfying fix for
   the holes in the proof. After further investigation we realized that the
   proof had fundamental flaws which could not be fixed easily. Sadly, we have
   to conclude that Proposition 2.8 of cite:vukovic2008bisimulations is no
   longer a proven theorem. Thus, the problem of finding transformation from a
   generalized model (with Condition (2)) to an ordinary model such that it
   preserves some structure of the original model remains an open question. By
   ``preserves some structure'' we mean that we should have a property similar
   to \[M,wâŠ©Aâ‡”M',f(w)âŠ©A\ \ \ \text{for every }wâˆˆW,AâˆˆFm.\]

   We believe that this example should be taken as a humbling remainder that we
   are humans and we make mistakes. Even if a proof has been through skilled
   reviewers from a well established journal it is still suspect of being flawed
   in some subtle way. For this reason, we believe that computer checked proofs
   should gain relevance in all fields of logic. We know that nowadays proof
   assistants are far from perfect and usually require a lot of time investment
   both on learning and in formalizing big scale mathematical proofs. However,
   the confidence level that they offer certainly outweighs their negatives in
   some situations.
* Frame conditions
  <<sec:frame-condition>> An interpretability principle is a schema of modal
  formulas that carries some special significance.

  In this section we present a number of principles in conjunction with their
  respective frame conditions for ordinary semantics as well as generalized
  semantics.
** The principle \prin{M}
   The \prin{M} principle reads as follows:
   \[A â–· B â†’ (A âˆ§ â–¡ C) â–· (B âˆ§ â–¡ C).\]

   # {{{joost(AT SOME STAGE YOU SHOULD BE GIVING CONTEXT HERE. WHEN WAS THE
   # PRINCIPLE INTRODUCED AND BY WHOM. ALSO\, WHY IS IT IMPORTANT\, ETC.)}}}

   The \prin{M} principle is coined after Franco Montagna because the principle
   appeared during discussions between Franco Montagna and Albert Visser about
   interpretability logic (cite:bilkova2009interpretability).

   The theorems of $\textsf{ILM}$ are the set of interpretability principles
   that are always provable in theories which are $Î£_1$ sound, have full
   induction and prove consistency of any of its finite subsystems
   (cite:visser1997overview,joosten2020overview). An example of such theory is
   $\textsf{PA}$.
*** Ordinary semantics
   The frame condition for \prin{M} for ordinary semantics, which we write as $\kord{M}$,
   reads as follows:
   \[âˆ€w,x,y,z(xS_w yRz â‡’ xRz).\]

   #+caption: Ordinary frame condition for \prin{M}.
   #+name: fig:ord-M-condition
   #+attr_latex: :float t :width 0.20\textwidth :placement [H]
   [[file:img/M-ord.pdf]]

   {{{begintheorem}}} For any ordinary frame $F$, we have that $F$ satisfies the
   $\kord{M}$ condition iff any model based on $F$ forces every instantiation of the \prin{M}
   principle. In symbols:

   \[F âŠ¨ \kord{M} â‡” F âŠ© M.\] {{{endtheorem}}}

   {{{beginproof}}}
   {{{agda}}}
   - \boxed{â‡’} Let $M$ be a model based on $F$ and let $w$ be any world. Assume
     that $wâŠ©Aâ–·B$ and that there is a world $x$ such that $wRx$ and $xâŠ©Aâˆ§â–¡C$.
     Our aim is to find a world $z$ such that $xS_wzâŠ©Bâˆ§â–¡C$. Since $wRxâŠ©A$ and
     $wâŠ©Aâ–·B$ there is a world $z$ such that $xS_wzâŠ©B$. We now show that $zâŠ©â–¡C$.
     Consider an arbitrary $u$ such that $zRu$. By the frame condition it
     follows that $xRu$ and we know $xâŠ©â–¡C$ hence $uâŠ©C$ and thus $zâŠ©â–¡C$. Hence
     $z$ is the desired world.

   - \boxed{â‡} Let $a,b,câˆˆVar$, assume $FâŠ©aâ–·bâ†’(aâˆ§â–¡c)â–·(bâˆ§â–¡c)$. Assume also that
     for some $x,w,u$ we have $xS_wzRu$. Our goal is to prove $xRu$. Consider a
     model such that the following holds.
     \begin{flalign*}
     âŸ¦aâŸ§ &= \{x\}; \\
     âŸ¦bâŸ§ &= \{z\}; \\
     âŸ¦câŸ§ &= \{v:xRv\}.
     \end{flalign*}
     We observe that $wâŠ©aâ–·b$ because $a$ is only forced in $x$ and we have
     $xS_wzâŠ©b$. Then it follows that $wâŠ©(aâˆ§â–¡c)â–·(bâˆ§â–¡c)$. It is easy to observe
     that $xâŠ©aâˆ§â–¡c$, furthermore we have that by the definition of an ordinary frame
     $xS_wzâ‡’wRx$, hence $wRx$ and thus there must exist some $v$ such that
     $xS_wvâŠ©bâˆ§â–¡c$. Since $b$ is only true in $z$ it must be $zâŠ©bâˆ§â–¡c$. Then,
     because $zRu$ we have $uâŠ©c$, therefore $xRu$.
   {{{endproof}}}

*** Generalized semantics
   The frame condition for \prin{M} for generalized semantics, which we write as
   $\kgen{M}$, reads as follows:

   \[ âˆ€w,x,V(xS_wVâ‡’ âˆƒV'âŠ†V(xS_wV',âˆ€v'âˆˆV'âˆ€z(v'Rzâ‡’xRz))).\]


   #+caption: Generalized frame condition for \prin{M}.
   #+name: fig:gen-M-condition
   #+attr_latex: :float t :width 0.20\textwidth :placement [H]
   [[file:img/wip.png]]

   {{{begintheorem}}} For any generalized frame $F$, we have that $F$ satisfies the
   $\kgen{M}$ condition iff any model based on $F$ forces every instantiation of
   the \prin{M} principle. In symbols:

   \[F âŠ¨ \kgen{M} â‡” F âŠ© M.\] {{{endtheorem}}}

   {{{beginproof}}}
   {{{agda}}}
   - \boxed{â‡’} Let $M$ be a model based on $F$ and let $w$ be any world. Assume
     that $wâŠ©Aâ–·B$ and that there is a world $x$ such that $wRx$ and $xâŠ©Aâˆ§â–¡C$.
     Our aim is to find a set $Z$ such that $xS_wZâŠ©Bâˆ§â–¡C$. Since $wRxâŠ©A$ and
     $wâŠ©Aâ–·B$ there is set $Z$ such that $xS_wZâŠ©B$. Then by the $\kgen{M}$
     condition it follows that there is a set $Z'âŠ†Z$ such that $xS_wZ'$ and
     $âˆ€vâˆˆZ'âˆ€z(vRzâ‡’xRz)$. Now we show $Z'âŠ©â–¡C$. Let $vâˆˆZ'$ and $u$ such that
     $vRu$, by the condition above it follows $xRu$ and since $xâŠ©â–¡C$ we have
     $uâŠ©C$. Hence $Z'$ is the desired set.
   - \boxed{â‡} Let $a,b,câˆˆVar$ and assume $FâŠ©a â–· b â†’ (a âˆ§ â–¡ c) â–· (b âˆ§ â–¡ c)$ and
     $uS_wV$. Consider a model satisfying the following
     \begin{flalign*}
     âŸ¦aâŸ§ &= \{u\}; \\
     âŸ¦bâŸ§ &= V; \\
     âŸ¦câŸ§ &= \{v:uRv\}.
     \end{flalign*}
     We see that $wâŠ©aâ–·b$ since $a$ is only true in $u$ and we have $uS_wVâŠ©b$. It
     follows that ${wâŠ©(a âˆ§ â–¡ c)â–·(bâˆ§â–¡c)}$. It is easy to see that $uâŠ©aâˆ§â–¡c$, hence
     there must exist $V'$ such that $uS_wV'âŠ©bâˆ§â–¡c$. Clearly $V'âŠ†V$ since $b$ is
     forced exactly in $V$. Now let $v',z$ such that $v'âˆˆV'$ and $v'Rz$. Since
     $v'âŠ©â–¡c$, then $zâŠ©c$ and thus $uRz$. Therefore $V'$ is the desired set.
   {{{endproof}}}
** The principle \prin{Mâ‚€}
   The \prin{Mâ‚€} principle reads as follows:
   \[A â–· B â†’ â™¢ A âˆ§ â–¡ C â–· B âˆ§ â–¡ C.\]

   The logic \prin{ILM_0} is complete (cite:modal-matters).
*** TODO Ordinary semantics
    {{{jan(update drawing)}}}

    The $\kord{Mâ‚€}$ condition reads as follows:
    # \[âˆ€w,x,y,z(wRxRyS_wzâ‡’xS_wz,âˆ€u(zRuâ‡’xRu)).\]
    \[âˆ€w,x,y,z(wRxRyS_wzâ‡’âˆ€u(zRuâ‡’xRu)).\]

   #+caption: Ordinary frame condition for \prin{Mâ‚€}.
   #+name: fig:M_0-ord
   #+attr_latex: :float t :width 0.25\textwidth :placement [H]
   [[file:img/M_0-ord.pdf]]

    {{{begintheorem}}} For any ordinary frame $F$, we have that $F$ satisfies the
    $\kord{Mâ‚€}$ condition iff any model based on $F$ forces every instantiation of
    the \prin{Mâ‚€} principle. In symbols:

    \[F âŠ¨ \kord{Mâ‚€} â‡” F âŠ© Mâ‚€.\] {{{endtheorem}}}

    {{{beginproof}}}
    {{{agda}}}
    - \boxed{â‡’} Let $M$ be a model based on $F$ and let $w$ be any world. Assume
      that $wâŠ©Aâ–·B$ and that there exists some $x$ such that $wRxâŠ© â™¢ A âˆ§ â–¡ C$. It
      follows that there exists some world $y$ such that $xRyâŠ©A$, then since
      $wRy$ and $wâŠ©Aâ–·B$ there exists a world $z$ such that $yS_wzâŠ©B$. Observe
      that from $wRxRy$ it follows that $xS_wy$ and by transitivity of $S_w$ and
      $yS_wz$ we get $xS_wz$. It remains to show $zâŠ©â–¡C$. Consider some world $u$
      such that $zRu$, then by the $\kord{Mâ‚€}$ condition we have that
      $âˆ€u(zRuâ‡’xRu)$ and thus it follows that $xRu$ and since $xâŠ©â–¡C$ we also have
      $uâŠ©C$.
    - \boxed{â‡} Let $a,b,câˆˆVar$ and assume $FâŠ©a â–· b â†’ (â™¢ a âˆ§ â–¡ c) â–· (b âˆ§ â–¡ c)$ and
      assume that for some $w,x,y,z$ we have $wRxRyS_wz$. Consider a model based
      on $F$ such that the following holds:
      \begin{flalign*}
      âŸ¦aâŸ§ &= \{y\}; \\
      âŸ¦bâŸ§ &= \{z\}; \\
      âŸ¦câŸ§ &= \{v:xRv\}.
      \end{flalign*}
      Observe that $wâŠ©aâ–·b$ since $a$ is forced only in $y$ and we have $yS_wzâŠ©b$.
      It follows that $wâŠ©(â™¢ a âˆ§ â–¡ c) â–· (b âˆ§ â–¡ c)$. Clearly $xâŠ©â™¢aâˆ§â–¡c$, hence there
      must exist some world $v$ such that $xS_wvâŠ©bâˆ§â–¡c$ but since $b$ is only
      forced in $z$ we have $z=v$ and thus $xS_wz$. To prove the remaining
      implication let $u$ such that $zRu$, then $uâŠ©c$ and thus $xRu$.
    {{{endproof}}}

*** Generalized semantics
    The $\kgen{Mâ‚€}$ condition reads as follows:
    \[âˆ€w,x,y,Y(wRxRyS_wYâ‡’âˆƒY'âŠ†Y(xS_wY',âˆ€y'âˆˆY'âˆ€z(y'Rzâ‡’xRz))).\]

   #+caption: Generalized frame condition for \prin{Mâ‚€}.
   #+name: fig:M_0-gen
   #+attr_latex: :float t :width 0.30\textwidth :placement [H]
   [[file:img/M_0-gen.pdf]]


    {{{begintheorem}}} For any ordinary frame $F$, we have that $F$ satisfies the
    $\kgen{Mâ‚€}$ condition iff any model based on $F$ forces every instantiation of
    the \prin{Mâ‚€} principle. In symbols:

    \[F âŠ¨ \kgen{Mâ‚€} â‡” F âŠ© Mâ‚€.\] {{{endtheorem}}}

    {{{beginproof}}}
    {{{agda}}}
    - \boxed{â‡’} Let $M$ be a model based on $F$ and let $w$ be any world. Assume
      that $wâŠ©Aâ–·B$ and that there is a world $x$ such that $wRxâŠ©â™¢Aâˆ§â–¡C$. Then
      there must exist some world $y$ such that $xRyâŠ©A$. Since $wRy$ and $wâŠ©Aâ–·B$
      there exists some set $Y$ such that $yS_wYâŠ©B$. Then by the $\kgen{Mâ‚€}$
      condition we have that there exists some $Y'âŠ†Y$ such that $xS_wY'$ and
      $(â‹†)\ âˆ€y'âˆˆY'âˆ€z(y'Rzâ‡’xRz)$. Clearly $Y'âŠ©B$ since $Y'âŠ†Y$. To show that
      $Y'âŠ©â–¡C$ consider some $y'âˆˆY'$ and some $z$ such that $y'Rz$. Then, by
      $(â‹†)$ it follows that $xRz$ and since $xâŠ©â–¡C$ we also have $xâŠ©C$.
    - \boxed{â‡} Let $a,b,câˆˆVar$ and assume $FâŠ©a â–· b â†’ (â™¢ a âˆ§ â–¡ c) â–· (b âˆ§ â–¡ c)$
      and assume that for some $w,x,y,Y$ we have $wRxRyS_wY$. Then consider a
      model based on $F$ such that.
      \begin{flalign*}
      âŸ¦aâŸ§ &= \{y\}; \\
      âŸ¦bâŸ§ &= Y; \\
      âŸ¦câŸ§ &= \{v:xRv\}.
      \end{flalign*}
      Observe that $wâŠ©aâ–·b$ as $a$ is only forced in $y$ and we have $yS_wYâŠ©b$.
      Consequently it holds that $wâŠ©(â™¢ a âˆ§ â–¡ c) â–· (b âˆ§ â–¡ c)$. See also that
      $xâŠ©â™¢a$ since $xRyâŠ©a$ and also $xâŠ©â–¡c$ by definition of the model. Then
      there must exist some set $Y'$ such that $xS_wY'âŠ©bâˆ§â–¡c$. Clearly $Y'âŠ†Y$ since
      $Y'âŠ©b$. To show the remaining condition pick some $y'âˆˆY'$ and some $z$
      such that $y'Rz$. Since $Y'âŠ©â–¡c$ then $zâŠ©c$ and thus $xRz$.
    {{{endproof}}}

** The principle \prin{Pâ‚€}
   The \prin{Pâ‚€} principle reads as follows:
   \[A â–· â™¢ B â†’ â–¡ (A â–· B).\]

   We give some context borrowed from cite:joosten2020interpretability. The
   principle \prin{Pâ‚€} appeared in 1998 and is due to Albert Visser. It appeared
   during the search of the modal completeness proof of \prin{ILM_0}. In an attempt
   to strengthen the logic, Visser modified the frame condition of
   $\prin{ILM_0}$ to make it stronger and arrive at a stronger principle, which
   was coined as $\prin{P_0}$. Since the frame condition of $\prin{P_0}$ implies
   the frame condition of $\prin{M_0}$ every $\text{\prin{ILP_0}-frame}$ is also
   an $\text{\prin{ILM_0}-frame}$. In cite:joosten-master it is proven that
   $\prin{ILP_0}âŠ¬\prin{ILM_0}$ and thus we have that $\prin{ILP_0}$ is
   modally incomplete.

   The principle \prin{P_0} is valid in all reasonable arithmetical theories and
   thus it should be in \ilall{}.

*** Ordinary semantics
    The $\kord{Pâ‚€}$ condition reads as follows:

    \[âˆ€w,x,y,z,u(wRxRyS_wzRuâ‡’yS_xu).\]

   #+caption: Ordinary frame condition for \prin{Pâ‚€}.
   #+name: fig:P_0-ord
   #+attr_latex: :float t :width 0.15\textwidth :placement [H]
   [[file:img/P_0-ord.pdf]]

   {{{begintheorem}}} For any ordinary frame $F$, we have that $F$ satisfies the
   $\kord{Pâ‚€}$ condition iff any model based on $F$ forces every instantiation of
   the \prin{Pâ‚€} principle. In symbols:

   \[F âŠ¨ \kord{Pâ‚€} â‡” F âŠ© Pâ‚€.\] {{{endtheorem}}}

   {{{beginproof}}}
   {{{agda}}}
   - \boxed{â‡’} Let $M$ be a model based on $F$ and let $w$ be any world. Assume
     that $wâŠ©Aâ–·â™¢B$ and that there is a world $x$ such that $wRx$. Our goal is to
     show that $xâŠ©Aâ–·B$. Consider a world $y$ such that $xRyâŠ©A$. As $wRy$ and
     $wâŠ©Aâ–·â™¢B$ then there exist some worlds $z,u$ such that $yS_wzRuâŠ©B$. By the
     $\kord{Pâ‚€}$ condition it follows that $yS_xu$ and thus $xâŠ©Aâ–·B$.
   - \boxed{â‡} Let $a,bâˆˆVar$ and assume $FâŠ©a â–· â™¢ b â†’ â–¡ (a â–· b)$ and assume that
     $wRxRyS_wzRu$. We want to show $yS_xu$. Consider a model based on $F$ such
     that:
     \begin{flalign*}
     âŸ¦aâŸ§ = \{y \}; \\
     âŸ¦bâŸ§ = \{u \}.
     \end{flalign*}
     Observe that $wâŠ©aâ–·â™¢b$ as the only world that forces $a$ is $y$ and we have
     $yS_wzâŠ©â™¢b$, because $zRuâŠ©b$. Consequently we have $wâŠ©â–¡(aâ–·b)$ and therefore
     $xâŠ©aâ–·b$. Then, since $xRyâŠ©a$ it follows that there exist some $v$ such that
     $yS_xvâŠ©b$, but since $b$ is only forced in $u$, it must be $u=v$ and so
     $yS_xu$.
   {{{endproof}}}

*** Generalized semantics
    The $\kgen{P_0}$ condition reads as follows:
    \[âˆ€w,x,y,V,Z((wRxRyS_wV,âˆ€vâˆˆYâˆƒzâˆˆZ(vRz))â‡’âˆƒZ'âŠ†Z(yS_xZ')).\]

   #+caption: Generalized frame condition for \prin{Pâ‚€}.
   #+name: fig:P_0-gen
   #+attr_latex: :float t :width 0.31\textwidth :placement [H]
   [[file:img/P_0-gen.pdf]]


   {{{begintheorem}}} For any generalized frame $F$, we have that $F$ satisfies the
   $\kgen{Pâ‚€}$ condition iff any model based on $F$ forces every instantiation of
   the \prin{Pâ‚€} principle. In symbols:

   \[F âŠ¨ \kgen{Pâ‚€} â‡” F âŠ© Pâ‚€.\] {{{endtheorem}}}

   {{{beginproof}}}
   {{{agda}}}
   - \boxed{â‡’} Let $M$ be a model based on $F$ and let $w$ be any world. Assume
     that $wâŠ©Aâ–·â™¢B$ and that there is a world $x$ such that $wRx$. We aim to show
     that $xâŠ©Aâ–·B$. Assume there is a world $u$ such that $xRuâŠ©A$ and as $wRu$
     and $wâŠ©Aâ–·â™¢B$ then there exists a set $V$ $uS_xVâŠ©â™¢B$. Let $ğ”¹=\{v:vâŠ©B\}$.
     Then observe that because $VâŠ©â™¢B$ we have that for all $v$ in $V$ there
     exists some $zâˆˆğ”¹$ such that $vRz$. Hence by the $\kgen{Pâ‚€}$ condition
     there exists some $ğ”¹'âŠ†ğ”¹$ such that $yS_xğ”¹'$. Clearly $ğ”¹'âŠ©B$, therefore
     $xâŠ©Aâ–·B$.
   - \boxed{â‡} Let $a,bâˆˆVar$ and assume $FâŠ©a â–· â™¢ b â†’ â–¡ (a â–· b)$ and assume
     that for some $w,x,y,V,Z$ we have $wRxRyS_wY$ and $(â‹†)\ âˆ€vâˆˆVâˆƒzâˆˆZ(vRz)$.
     Consider a model based on $F$ such that:
     \begin{flalign*}
    âŸ¦aâŸ§ &= \{y\}; \\
    âŸ¦bâŸ§ &= Z.
     \end{flalign*}
     See that $wâŠ©aâ–·â™¢b$ as the only world that forces $a$ is $y$ and we have
     $yS_wV$ and by $(â‹†)$ it follows that $VâŠ©â™¢b$. Consequently it holds that
     $wâŠ©â–¡(aâ–·b)$ and since $wRx$ then $xâŠ©aâ–·b$. Also, since $xRyâŠ©a$ then there
     exists $Z'$ such that $yS_xZ'âŠ©b$. Clearly $Z'âŠ©b$ implies $Z'âŠ†Z$ so we are
     done.
   {{{endproof}}}

** The principle \prin{R}
   The \prin{R} principle reads as follows:

   \[A â–· B â†’ Â¬ (A â–· Â¬C) â–· (B âˆ§ â–¡ C)\ .\]

   The principle \prin{R} is due to Goris and Joosten. In cite:a-new-principle
   they show that \prin{R} does follow semantically but not syntactically from
   \prin{ILP_0W^*}, which was the best known lower bound for \ilall{} in 2011.
   They also show that \prin{R} is valid in all reasonable arithmetical theories
   and thus giving a strictly better lower bound for \ilall{}.

   Note that \prin{R} is the same as \prin{R_0} and \prin{R^0}. The \prin{R^n}
   and \prin{R_n} series of principles which generalize \prin{R} and are
   discussed in Sections [[sec:Rsubn]] and [[sec:Rsupn]].
*** Ordinary semantics
    The $\kord{R}$ condition reads as follows:

    \[âˆ€w,x,y,z,u(wRxRyS_wzRuâ‡’yS_xu).\]

   #+caption: Ordinary frame condition for \prin{R}.
   #+name: fig:ord-R-condition
   #+attr_latex: :float t :width 0.15\textwidth :placement [H]
   [[file:img/R-ord.pdf]]

   {{{joost(TO NOT OVERLOAD WRITING\, SHALL WE SPEAK OF FRAMES WHEN SPEAKING OF
   REGULAR/ORDINARY FRAMES AND ONLY INDICATE GENERALISED WHERE NEEDED? LUKA\, WHAT
   DO YOU THINK?)}}}

\luka{ I agree, that's what Croatian authors do}

   {{{begintheorem}}}
   For any ordinary frame $F$, we have that $F$ satisfies the
   $\kord{R}$ condition iff any model based on $F$ forces every instantiation of
   the \prin{R} principle. In symbols:

   \[F âŠ¨ \kord{R} â‡” F âŠ© R\ .\]
   {{{endtheorem}}}

# {{{joost(HERE AND IN THE THESIS IN GENERAL\, I MISS A DISCUSSION ABOUT
# ASSURINGNESS. THIS SHOULD BE ADDED AND USED. AT THIS PARTICULAR POINT IN YOUR
# PROOF YOU SHOULD MENTION THAT y IS A C-assuring SUCCESSOR OF x SO THAT YOU
# OBTAIN (*).)}}}

# {{{luka(Joost\, would you use assuringness/criticality even in semantic
# context? I would add a note\, something along the lines of "of course\, we can
# associate a MCS with every world of a model\, if we suppose e.g. that all
# propositional variables $p_i$ for $i > ...$ are evaluated as false and let $mcs(w) =
# \{A : w \Vdash A\}$".)}}}

# a world \(y\) such that \(xRyâŠ©A\) and \((â‹†)\ âˆ€v(yS_xvâ‡’vâŠ©C)\).

# {{{joost(MAKE THIS FORMULA DISPLAYED. MOREOVER\, IT IS BETTER TO GENERATE A
# LABEL. FOR EXAMPLE:)}}}


   {{{beginproof}}}
   {{{agda}}}
   - \boxed{â‡’} Let $M$ be a model based on $F$ and let $w$ be any world. Assume
     that $wâŠ©Aâ–·B$ and that there is a world $x$ such that $wRxâŠ©Â¬(Aâ–·Â¬C)$. We need
     to see that there is some world $z$ such that $xS_wzâŠ©Bâˆ§â–¡C$. From
     $xâŠ©Â¬(Aâ–·Â¬C)$ we get a world $y$ such that $xRyâŠ©A$ and $(â‹†)\ âˆ€v(yS_xvâ‡’vâŠ©C)$.
     Since $wâŠ©Aâ–·B$, and by transitivity we have $wRy$, it follows that there
     exists a world $z$ such that $yS_wzâŠ©B$. To see that $z$ is the desired
     world we first see that $zâŠ©â–¡C$. Let $u$ be such that $zRu$, then by
     $\kord{R}$ it follows that $yS_xu$ and by $(â‹†)$ we get $uâŠ©C$. Finally, we
     have to see that $xS_wz$. Since $wRxRy$ we have that $xS_wy$ and we have
     $yS_wz$ from before, hence by transitivity of $S_w$ we get $xS_wz$.

   To see that \(z\) is the desired world.

   {{{joost(I WOULD SAY HERE: "WE HAVE TO VERIFY
   TWO THINGS". THEN YOU MENTION THE TWO THINGS AND THEN YOU PROVE THEM ONE BY ONE.
   LIKE THIS\, YOU HELP THE NON-EXPERIENCED READER REMIND WHAT IS IT THAT YOU ARE
   AFTER)}}}


   - \boxed{â‡} Let $a,b,câˆˆVar$ and assume that for some $w,x,y,z$ we have
     $wRxRyS_wz$ . Consider a model
     based on $F$ that satisfies the following.
    \begin{flalign*}
     âŸ¦aâŸ§ &= \{y\}; \\
     âŸ¦bâŸ§ &= \{z\}; \\
     âŸ¦câŸ§ &= \{u:yS_xu\}.
    \end{flalign*}
     By assumption we have that $wâŠ©a â–· b â†’ (Â¬ (a â–· Â¬c) â–· (b âˆ§ â–¡ c))$. Clearly
     $wâŠ©aâ–·b$ as we have $yS_wzâŠ©b$. Consequently it holds that $wâŠ©Â¬ (a â–· Â¬c) â–· (b
     âˆ§ â–¡ c)$. In order to show that $xâŠ©Â¬ (a â–· Â¬c)$, considering that $a$ is only
     forced in $y$, it suffices to observe that $âˆ€z(yS_xzâ‡’zâŠ©c)$, which clearly
     holds. Then there must exist some world $v$ such that $xS_wvâŠ©bâˆ§â–¡c$ but
     $v=z$ since $z$ is the only world that forces $b$, hence $xS_wzâŠ©â–¡c$. Now to
     show $âˆ€v(zRvâ‡’yS_xv)$ consider some $v$ such that $zRv$. From $zâŠ©â–¡c$ we get
     $vâŠ©c$ and thus $yS_xv$.
   {{{endproof}}}

*** Generalized semantics

    We first introduce the concept of choice set.

   {{{begindef}}} If $xRy$ we say that a set of worlds $K$ is a \gls{choice-set}
   for $âŸ¨x,yâŸ©$ iff for any $V$ such that $yS_xV$ we have $Vâˆ©Kâ‰ âˆ…$. We denote the
   family of choice sets for $âŸ¨x,yâŸ©$ by $ğ’(x,y)$. Note that this definition
   depends on the frame, but it should always be clear from context.
   {{{enddef}}}

    The $\kgen{R}$ condition reads as follows:
    \begin{flalign*}
    &âˆ€w,x,y,Y,K(wRxRyS_wY,Kâˆˆğ’(x,y)   \\
    â‡’& âˆƒY'âŠ†Y(xS_wY',âˆ€y'âˆˆY'âˆ€z(y'Rzâ‡’zâˆˆK))).
    \end{flalign*}

   #+caption: Generalized frame condition for \prin{R}.
   #+name: fig:gen-R-condition
   #+attr_latex: :float t :width 0.35\textwidth :placement [H]
   [[file:img/R-gen.pdf]]

   {{{begintheorem}}}
   <<theorem:Râ°>>
   For any generalized frame $F$, we have that $F$ satisfies the
   $\kgen{R}$ condition iff any model based on $F$ forces every instantiation of
   the \prin{R} principle. In symbols:

   \[F âŠ¨ \kgen{R} â‡” F âŠ© R.\]
   {{{endtheorem}}}
   {{{beginproof}}}
   {{{agda}}}
   - \boxed{â‡’} Let $M$ be a model based on $F$ and assume there is a world $w$ such
     that $wâŠ©Aâ–·B$ and a world $x$ such that $wRx$ and $xâŠ©Â¬(Aâ–·Â¬C)$. We need to
     show that there is a set $Z$ such that $xS_wZâŠ©Bâˆ§â–¡C$. From $xâŠ©Â¬(Aâ–·Â¬C)$ it
     follows that there is a world $y$ such that $xRyâŠ©A$ and $(â‹†)\
     âˆ€V(yS_xVâ‡’âˆƒcâˆˆV(câŠ©C))$. Consider the set $Kâ‰”\{c:câŠ©C,âˆƒV(câˆˆV,yS_xV)\}$. Clearly
     by $(â‹†)$ it follows that $K$ is a choice set for $âŸ¨x,yâŸ©$. By transitivity
     of $R$ we get $wRy$ and since $wâŠ©Aâ–·B$ then there must exist some $Y$ such
     that $yS_wYâŠ©B$. We can now apply the $\kgen{R}$ condition and get a $Y'âŠ†Y$
     such that $xS_wY'$ and $(â€ )\ âˆ€y'âˆˆY'âˆ€z(y'Rzâ‡’zâˆˆK)$. To show that $Y'$ is the
     desired set it remains to see that $Y'âŠ©Bâˆ§â–¡C$. From the fact that $Y'âŠ†YâŠ©B$
     it easily follows that $Y'âŠ©B$. Now, let $y'âˆˆY'$ and $u$ such that $y'Ru$,
     from $(â€ )$ we get $uâˆˆK$ and by definition of $K$ we have $uâŠ©C$.
   - \boxed{â‡} Let $a,b,câˆˆVar$ and assume $FâŠ© a â–· b â†’ Â¬ (a â–· Â¬c) â–· (b âˆ§ â–¡ c)$.
     Assume also that for some $w,x,y,Y,K$ we have $wRxRyS_wY,Kâˆˆğ’(x,y)$. Now
     consider a model based on $F$ that satisfies the following:
    \begin{flalign*}
    âŸ¦aâŸ§ &=\{y\}; \\
    âŸ¦bâŸ§ &=Y; \\
    âŸ¦câŸ§ &= K. \\
    \end{flalign*}
    By assumption we have $wâŠ©a â–· b â†’ Â¬ (a â–· Â¬c) â–· (b âˆ§ â–¡ c)$. Observe that that
     $wâŠ©aâ–·b$ since $yS_wYâŠ©b$. Thus $wâŠ©Â¬ (a â–· Â¬c) â–· (b âˆ§ â–¡ c)$. As $y$ is the
     only world that forces $a$, in order to show $xâŠ©Â¬(aâ–·Â¬c)$ we need to see
     that $âˆ€V(yS_xVâ‡’âˆƒzâˆˆV(zâŠ©c))$, which is equivalent to $âˆ€V(yS_xVâ‡’âˆƒzâˆˆVâˆ©K)$ and
     this holds since $Kâˆˆğ’(x,y)$. As a consequence of $xâŠ©Â¬(aâ–·Â¬c)$ we have that
     there exists a set $Y'$ such that $xS_wY'âŠ©bâˆ§â–¡c$. From $Y'âŠ©b$ we get $Y'âŠ†Y$ and
     from $Y'âŠ©â–¡c$ we get $âˆ€y'âˆˆY'(âˆ€z(y'Rzâ†’zâˆˆK))$, hence $Y'$ is the desired set.
   {{{endproof}}}

** The principle \prin{Râ‚}
  The $R_1$ principle reads as follows:
  \[A â–· B â†’ (Â¬(A â–· Â¬C)âˆ§ (Dâ–·â™¢E))â–·(Bâˆ§â–¡Câˆ§(Dâ–·E)).\]

  It is the second principle of the $\prin{R_n}$ series, which is discussed in
  section [[sec:Rsubn]].
*** Ordinary semantics

    The $\kord{R_1}$ frame condition reads as follows:
    \[âˆ€w,x,y,z(wRxRyS_wzâ‡’âˆ€u(zRuâ‡’yS_xu,âˆ€v(uS_xvâ‡’âˆ€m(vRmâ‡’uS_zm))))\]

    # #+caption: Ordinary frame condition for \prin{Râ‚}
    # #+name: fig:ord-Râ‚-condition
    # #+attr_latex: :float t :width 0.20\textwidth :placement [H]
    # [[file:img/wip.png]]

    {{{begintheorem}}}
    For any ordinary frame $F$, we have that $F$ satisfies the
    $\kord{R_1}$ condition iff any model based on $F$ forces every instantiation of
    the \prin{Râ‚} principle. In symbols:

    \[F âŠ¨ \kord{R_1} â‡” F âŠ© Râ‚.\]
    {{{endtheorem}}}

    {{{beginproof}}}
    The details of the proof can be found in cite:two-new-series.
    # - \boxed{â‡} Let $a,b,c,d,eâˆˆVar$ and assume $FâŠ© a â–· b â†’ ((Â¬ (a â–· Â¬c) âˆ§(dâ–·â™¢e))
    #   â–· (b âˆ§ â–¡ c âˆ§ (dâ–·e)))$. Consider some worlds $w,x,y,z,u,v,m$ and assume for
    #   a contradiction that $wRxRyS_wzRu,yS_xuâ‡’(uS_xv,vRm,u\cancel{S}_zm)$. Now
    #   consider a model based on $F$ that satisfies the following:
    #   \begin{flalign*}
    #   âŸ¦aâŸ§ &= \{y\} \\
    #   âŸ¦bâŸ§ &= \{z\} \\
    #   âŸ¦câŸ§ &= \{w:yS_xw\} \\
    #   âŸ¦dâŸ§ &= \{?\} \\
    #   âŸ¦eâŸ§ &= \{?\} \\
    #   \end{flalign*}
    #   First observe that $wâŠ©aâ–·b$ since $a$ is only forced in $y$ and we have
    #   $yS_wzâŠ©b$. Therefore $wâŠ©Â¬ (a â–· Â¬c) âˆ§(dâ–·â™¢e) â–· (b âˆ§ â–¡ c âˆ§ (dâ–·e))$. Now we
    #   show that $xâŠ©Â¬ (a â–· Â¬c)$. Since $a$ is only forced in $y$ and $xRy$, we
    #   need to show that $âˆ€u(yS_xuâ‡’uâŠ©c)$, which clearly holds. We proceed by
    #   showing $xâŠ©dâ–·â™¢e$ (????).
    # - \boxed{â‡’} Let $M$ be a model based on $F$ assume there is a world $w$ such
    #   that $wâŠ©Aâ–·B$ and a world $x$ such that $wRx$ and $xâŠ©Â¬(Aâ–·Â¬C)âˆ§(Dâ–·â™¢E)$. Then
    #   there exists world $y$ such that $xRyâŠ©A$ and $(â‹†)\ âˆ€v(yS_xvâ‡’vâŠ©C)$. As
    #   $wRyâŠ©A$ and $wâŠ©Aâ–·B$ there exists a world $z$ such that $yS_wzâŠ©B$. It
    #   remains to show that $zâŠ©â–¡Câˆ§(Dâ–·E)$. We first see that $zâŠ©â–¡C$. Consider
    #   $v$ such that $zRv$, by $\kord{R_1}$ it follows that $yS_xv$ and by $(â‹†)$
    #   we get $vâŠ©C$. Now we show $zâŠ©Dâ–·E$. Let $u$ be such that $zRuâŠ©D$, we need
    #   to find some $m$ such that $uS_zmâŠ©E$. By $\kord{R_1}$ we get $yS_xu$ and
    #   $(â€ )\ âˆ€v,m((uS_xv,vRm)â‡’uS_zm)$. See that $yS_xu$ implies $xRu$ and since
    #   $xâŠ©Dâ–·â™¢E$ and $uâŠ©D$ we get that there is some $n$ such that $uS_xnâŠ©â™¢E$.
    #   Hence there is a world $m$ such that $nRmâŠ©E$. Finally by $(â€ )$ and $uS_xn$
    #   and $nRm$ we get $uS_zm$ and thus we have the desired $m$ and we conclude
    #   $zâŠ©Dâ–·E$.
    {{{endproof}}}

*** Generalized semantics
    Some definitions:
    1. $R^{-1}[E] â‰” \{x : âˆƒyâˆˆE. xRy\}$. $E$ denotes a set.
    2. $Râ‚“^{-1}[E]â‰”R^{-1}[E]âˆ©R[x]$. $E$ denotes a set.

    The $\kgen{R_1}$ condition reads as follows:
    \begin{flalign*}
    âˆ€w,&x,u,ğ”¹,â„‚,ğ”¼.\\
    &wRxRuS_wğ”¹, â„‚âˆˆğ’(x,u) \\
    â‡’\ & âˆƒğ”¹'âŠ†ğ”¹.xS_wğ”¹',R[ğ”¹']âŠ†â„‚,âˆ€vâˆˆğ”¹'.âˆ€câˆˆâ„‚.(âˆƒUâŠ†Râ‚“^{-1}[ğ”¼],vRcSâ‚“U)â‡’âˆƒğ”¼'âŠ†ğ”¼.cS_vğ”¼'\Big)
    \end{flalign*}

    {{{begintheorem}}}
    <<theorem:Râ‚>>
    For any generalized frame $F$, we have that $F$ satisfies the
    $\kgen{R_1}$ condition iff any model based on $F$ forces every instantiation of
    the \prin{Râ‚} principle. In symbols:

    \[FâŠ¨\kgen{Râ‚}â‡”FâŠ©Râ‚.\]
    {{{endtheorem}}}

    {{{beginproof}}}
    {{{agda}}}
    - \boxed{â‡’} Let's fix the model and let $w âˆˆ W$ be arbitrary. Suppose $wâŠ© A
      â–·B$, and let $x$ be such that $wRx$ and $xâŠ© Â¬(A â–· Â¬C) âˆ§ (D â–· â™¢E)$. It
      follows from $x âŠ©Â¬(A â–·Â¬C)$ that there exists $u$ such that $xRu$, such
      that $uâŠ©A$, and for every $Z$ such that $uS_x Z$ there is some $c_Z âˆˆ Z$
      such that $c_Z âŠ©C$. From $wRu$, $wâŠ© Aâ–· B$ and $uâŠ© A$ follows in particular
      that there is a $ğ”¹$, $uS_w ğ”¹ âŠ©B$. Let $â„‚ â‰” \{c_Z: uS_x Z\}$. It is easy to
      check that $â„‚ âˆˆ ğ’(x, u)$. Let $ğ”¼ â‰” âŸ¦EâŸ§$. For the selected $w, x, u, ğ”¹, â„‚,
      ğ”¼$ the property $\kgen{R_1}$ implies that there exists $ğ”¹' âŠ† ğ”¹$ such that:

      \[ xS_wğ”¹',R[ğ”¹']âŠ†â„‚,âˆ€vâˆˆğ”¹'.âˆ€câˆˆâ„‚.(âˆƒUâŠ†Râ‚“^{-1}[ğ”¼],vRcSâ‚“U)â‡’âˆƒğ”¼'âŠ†ğ”¼.cS_vğ”¼'\]
      # \[xS_wğ”¹',R[ğ”¹']âŠ†â„‚ ,(âˆ€vâˆˆğ”¹')(âˆ€câˆˆâ„‚)(vRcS_xR_x^{-1}[ğ”¼]â‡’(âˆƒğ”¼'âŠ†ğ”¼)cS_vğ”¼').\]

      We have that $ğ”¹' âŠ©B$ since $ğ”¹'âŠ†ğ”¹$ and $ğ”¹'âŠ©â–¡ C$ since $R[ğ”¹']âŠ†â„‚$. We now
      show that $ğ”¹'âŠ© Dâ–· E$. Let $vâˆˆB'$ and assume that for some $c$ such that
      $vRc$ we have $câŠ© D$. From earlier we have $xâŠ© D â–· â™¢E$. Since $c âˆˆ R [ğ”¹']
      âŠ† C âŠ† R [x]$, then $xRc$ so it follows that there exists $U$ such that
      $cS_x U$ and $UâŠ©â™¢E$. Clearly $UâŠ†R_x^{-1}[ğ”¼]$ so by the above property
      there exists $ğ”¼'âŠ†ğ”¼$ such that $cS_v ğ”¼'$. Because $ğ”¼'âŠ†ğ”¼$ we have $ğ”¼'âŠ©E$.
    - \boxed{â‡} Assume for a contradiction that $FâŠ­\kgen{R_1}$. It follows that
      there exist $w,x,u,ğ”¹,â„‚,ğ”¼$ such that $wRxRuS_wğ”¹$, $â„‚âˆˆğ’(x,u)$ and:
      \[âˆ€ğ”¹'âŠ†ğ”¹.xS_wğ”¹', R[ğ”¹']âŠ†â„‚â‡’ âˆƒvâˆˆğ”¹'.âˆƒcâˆˆâ„‚.âˆƒZâŠ†R_x^{-1}[ğ”¼].vRcS_xZ,âˆ€ğ”¼'âŠ†ğ”¼.
      c\cancel{S}_v ğ”¼'.\]

      Let $ğ’±$ be a family of sets defined thus:
      \[ğ’±â‰” \{U : UâŠ†ğ”¹, xS_wU,R[U]âŠ†â„‚\}.\]

      From the condition it follows that for every $Uâˆˆğ’±$ the following is valid:
      \[âˆƒv_UâˆˆU.âˆƒc_Uâˆˆâ„‚.
      (âˆƒZ_UâŠ†R_x^{-1}[ğ”¼](v_URc_US_xZ_U,âˆ€ğ”¼'âŠ†ğ”¼.
      c_U\cancel{S}_{v_U} ğ”¼')).\]

      Let us fix such $v_U$ and $c_U$ and $Z_U$ for all $Uâˆˆğ’±$.

      Define a valuation such that the following applies:
      \begin{flalign*}
      âŸ¦aâŸ§ &= \{u\}; \\
      âŸ¦bâŸ§ &= ğ”¹; \\
      âŸ¦câŸ§ &= â„‚; \\
      âŸ¦dâŸ§ &= \{c_U:Uâˆˆğ’±\}; \\
      âŸ¦eâŸ§ &= ğ”¼.
      \end{flalign*}

      By assumption we have $w âŠ© a â–· b â†’ (Â¬(aâ–·Â¬c)âˆ§(dâ–·â™¢e))â–·(bâˆ§â–¡câˆ§(dâ–·e))$.

      It is easy to see that $w âŠ© a â–· b$ and $x âŠ© Â¬(a â–· Â¬c)$.

      Let us prove $x âŠ© dâ–·â™¢e$. Let $xRcâŠ© D$. Then $c = c_U$ for some $U âˆˆ ğ’±$.
      From the definition of $c_U$ we have that $c_U S_x Z_U$. The valuation is
      defined such that $e$ is true exactly on the set $ğ”¼$. Hence
      $R_x^{-1}[ğ”¼]âŠ©â™¢e$ and since $Z_UâŠ†R_x^{-1}[ğ”¼]$ it follows that $x âŠ© dâ–·â™¢e$.

      We can also check that for every $U âˆˆ ğ’±$ we have $UâŠ© b âˆ§ â–¡c$. Furthermore,
      for any set $U$ we have
      \begin{flalign*}
        (â‹†)\ xS_wU âŠ© b âˆ§ â–¡câ‡’Uâˆˆ ğ’±.
      \end{flalign*}
      Since $wâŠ©aâ–·b$ and $wRxâŠ©Â¬(aâ–·Â¬c)âˆ§(dâ–·â™¢e)$ there must exist some set $U$
      such that $xS_wUâŠ©bâˆ§â–¡câˆ§(dâ–·e)$. From $(â‹†)$ follows that $Uâˆˆğ’±$ hence
      there exist $v_U,c_U,Z_U$ such that $Z_UâŠ†R_x^{-1}[ğ”¼]$ and
      $v_URc_US_xZ_U,(âˆ€ğ”¼'âŠ†ğ”¼) c_U\cancel{S}_{v_U} ğ”¼'$. Since $c_UâŠ©d$ there must
      exist some $Y$ such that $c_US_{v_U}YâŠ©e$, however, by the definition of
      the valuation it follows that $YâŠ†ğ”¼$ and thus $c_U\cancel{S}_{v_U} Y$,
      which is a contradiction.

    {{{endproof}}}

# \newpage
** The principle \prin{R_2} :noexport:
  The \prin{R_2} principle reads as follows:
  \[Aâ‚€ â–· (Bâ‚€ âˆ§ (Aâ‚ â–· Bâ‚)) â†’ Â¬(Aâ‚€ â–· Â¬Câ‚€)âˆ§ (Eâ‚â–·Â¬(Aâ‚â–·Â¬Câ‚))â–· Bâ‚€âˆ§(Aâ‚â–·Bâ‚)âˆ§â–¡Câ‚€âˆ§(Eâ‚â–·Aâ‚)âˆ§(Eâ‚â–·Bâ‚âˆ§â–¡Câ‚)\]

*** Generalized semantics
    Some definitions:

    The $\kgen{R_2}$ condition reads as follows:
    \begin{flalign*}
    &âˆ€w,x,u,ğ”¹,â„‚,ğ”¼(wRxRuS_wğ”¹, â„‚âˆˆğ’(x,u) \\
    â‡’\ & (âˆƒğ”¹'âŠ†ğ”¹)(xS_wğ”¹',R[ğ”¹']âŠ†â„‚,(âˆ€vâˆˆğ”¹')(âˆ€câˆˆâ„‚)(vRcSâ‚“Râ‚“^{-1}[ğ”¼]â‡’(âˆƒğ”¼'âŠ†ğ”¼)cS_vğ”¼')))
    \end{flalign*}
    \begin{flalign*}
    &âˆ€w,x,u,ğ”¹,â„‚,ğ”¼(wRxRuS_wğ”¹, â„‚âˆˆğ’(x,u) \\
    â‡’\ & (âˆƒğ”¹'âŠ†ğ”¹)(xS_wğ”¹',R[ğ”¹']âŠ†â„‚,(âˆ€vâˆˆğ”¹')(âˆ€câˆˆâ„‚)(âˆƒUâŠ†Râ‚“^{-1}[ğ”¼],vRcSâ‚“U)â‡’(âˆƒğ”¼'âŠ†ğ”¼)cS_vğ”¼')))
    \end{flalign*}

    {{{begintheorem}}}
    <<theorem:Râ‚‚>>
    For any generalized frame $F$, we have that $F$ satisfies the
    $\kgen{R_2}$ condition iff any model based on $F$ forces every instantiation of
    the \prin{R_2} principle. In symbols:

    \[FâŠ¨\kgen{R_2}â‡”FâŠ©Râ‚‚\]
    {{{endtheorem}}}

    {{{beginproof}}}
    {{{endproof}}}

# \newpage

** The principle \prin{RÂ¹}

   The \prin{RÂ¹} principle reads as follows:
   \[A â–· B â†’ (â™¢Â¬(D â–· Â¬C)âˆ§ (Dâ–·A))â–·(Bâˆ§â–¡C).\]

*** Generalized semantics
    The $\kgen{RÂ¹}$ condition reads as follows:
    \begin{flalign*}
    âˆ€w&,x,y,z,ğ”¸,ğ”¹,â„‚,ğ”». \\
    &wRxRyRz, \\
    & (âˆ€u.wRu,uâˆˆğ”¸â‡’âˆƒV.uS_wV,VâŠ†ğ”¹), \\
    & (âˆ€u.xRu,uâˆˆğ”»â‡’âˆƒV.uS_xV,VâŠ†ğ”¸), \\
    & (âˆ€V.zS_yVâ‡’âˆƒvâˆˆV.vâˆˆâ„‚),      \\
    & zâˆˆğ”» \\
    â‡’\ & âˆƒVâŠ†ğ”¹(xS_wV,R[V]âŠ†â„‚).
    \end{flalign*}

    {{{begintheorem}}}
    For any generalized frame $F$, we have that $F$ satisfies the
    $\kgen{RÂ¹}$ condition iff any model based on $F$ forces every instantiation of
    the \prin{RÂ¹} principle. In symbols:

    \[FâŠ¨\kgen{RÂ¹}â‡”FâŠ©RÂ¹.\]
    {{{endtheorem}}}


    {{{beginproof}}}
    {{{agda}}}
    - \boxed{â‡’} Fix a model $M$ and a world $w$, we are to prove that $wâŠ©A â–· B â†’
      (â™¢Â¬(D â–· Â¬C)âˆ§ (Dâ–·A))â–·(Bâˆ§â–¡C)$. For that assume that $wâŠ©Aâ–·B$ and that for
      some $x,y,z$ we have $wRxRyRz$ and satisfy the conditions on the left hand
      side of the implication in the $\kgen{R^1}$ condition. From that we derive that
      $xâŠ©Dâ–·A$, $yâŠ©Â¬(Dâ–·Â¬C)$ and $zâŠ©D$. Now let $ğ”¸â‰”\{w:wâŠ©A\}$. We define $ğ”¹,â„‚,ğ”»$
      likewise for formulas $B,C,D$ respectively. It is routine to check that
      the left part of the implication of $\kgen{RÂ¹}$ is met. Hence there exist
      a set $VâŠ†ğ”¹$ such that $xS_wV$ and $R[V]âŠ†â„‚$. By the definition of the sets
      $ğ”¹$ and $â„‚$ it follows that $VâŠ©Bâˆ§â–¡C$.
    - \boxed{â‡} Fix a frame $F$ and let $a,b,c,d$ be propositional variables and
      assume $FâŠ©a â–· b â†’ (â™¢Â¬(d â–· Â¬c)âˆ§ (dâ–·a))â–·(bâˆ§â–¡c)$. Assume that the left part
      of the implication of $\kgen{RÂ¹}$ holds. Now consider a model extending
      $F$ such that:
      \begin{flalign*}
       âŸ¦aâŸ§ &= ğ”¸, \\
       âŸ¦bâŸ§ &= ğ”¹, \\
       âŸ¦câŸ§ &= â„‚, \\
       âŸ¦dâŸ§ &= ğ”».
      \end{flalign*}
      Now one can easily check that $wâŠ©Aâ–·B$, $xâŠ©â™¢Â¬(Dâ–·Â¬C)âˆ§(Dâ–·A)$, hence there exists $U$
      such that $xS_wU$ and $UâŠ©Bâˆ§â–¡C$. From that we derive that $UâŠ†ğ”¹$ and $R[U]âŠ†â„‚$.
    {{{endproof}}}

** The principle $\prin{RÂ²}$ :noexport:

   The $RÂ²$ principle reads as follows:
   \[A â–· B â†’ (â™¢ [(E â–· D) âˆ§ â™¢ Â¬ (E â–· Â¬ C)] âˆ§ (D â–· A)) â–· (B âˆ§ â–¡ C) \]

*** Generalized semantics
    The $\kgen{RÂ²}$ condition reads as follows:
    \begin{flalign*}
    &âˆ€w,x,y,z,s,ğ”¸,ğ”¹,â„‚,ğ”»,ğ”¼.\\
    &wRxRyRzRs, \\
    & (âˆ€u.wRuâˆˆğ”¸â‡’âˆƒV.uS_wVâŠ†ğ”¹), \\
    & (âˆ€u.xRuâˆˆğ”»â‡’âˆƒV.uS_xVâŠ†ğ”¸), \\
    & (âˆ€u.yRuâˆˆğ”¼â‡’âˆƒV.uS_yVâŠ†ğ”»), \\
    & (âˆ€V.sS_zVâ‡’Vâˆ©â„‚â‰ 0),      \\
    & sâˆˆğ”» \\
    â‡’\ & âˆƒVâŠ†ğ”¹.xS_wV,R[V]âŠ†â„‚
    \end{flalign*}

    {{{begintheorem}}}
    For any generalized frame $F$, we have that $F$ satisfies the
    $\kgen{RÂ²}$ condition iff any model based on $F$ forces every instantiation of
    the $RÂ²$ principle. In symbols:

    \[FâŠ¨\kgen{RÂ²}â‡”FâŠ©RÂ²\]
    {{{endtheorem}}}

    {{{beginproof}}}
    - \boxed{â‡’} Fix a model and assume that for some world $w$ we have $wâŠ©Aâ–·B$.
      Consider some $x$ such that $wRxâŠ©â™¢ [(E â–· D) âˆ§ â™¢ Â¬ (E â–· Â¬ C)] âˆ§ (D â–· A)$.
      Hence there exists some $y$ such that $xRyâŠ©(E â–· D) âˆ§ â™¢ Â¬ (E â–· Â¬ C)$. It
      follows that there exists some $z$ such that $yRzâŠ© Â¬ (E â–· Â¬ C)$ and thus
      there exists some $s$ such that $zRsâŠ©E$ and $(â‹†)\ âˆ€V(sS_zVâ‡’âˆƒcâˆˆV(câŠ©C))$.
    - \boxed{â‡}
    {{{endproof}}}

** The principle \prin{Râ¿}
   <<sec:Rsupn>>
   The \prin{R^n} principle is defined thus:
   \begin{flalign*}
   U_0 &â‰” â™¢Â¬(D_0â–·Â¬C) \\
   U_{r+1} &â‰” â™¢((Dáµ£â–·D_{r+1}) âˆ§ Uáµ£) \\
   \\
   Râ°& â‰” A â–· B â†’ Â¬ (A â–· Â¬ C) â–· B âˆ§ â–¡ C \\
   R^{n+1}& â‰” A â–· B â†’ ((D_{n}â–·A) âˆ§ U_{n}) â–· B âˆ§ â–¡ C
   \end{flalign*}

   The \prin{R^n} and \prin{R_n} series of principles are due to Goris and
   Joosten. Both series are presented in cite:two-new-series. In their article
   they generalize the principle \prin{R} in two series of principles which they
   use to give the best known lower bound for the logic \ilall{}, which is
   $\prin{ILWR^nR_n}$.

   The \prin{R^n} series is also referred to as the /broad/ series, whereas
   \prin{R^n} is referred to as the /slim/ series.
*** Ordinary semantics
    The frame condition for ordinary semantics $\kord{R^n}$ can be found in
    cite:two-new-series.

*** Generalized semantics

    The $\kgen{Râ¿}$ condition reads as follows:
    \begin{flalign*}
    âˆ€w,&xâ‚€,â€¦,x_{n-1},y,z,ğ”¸,ğ”¹,â„‚,ğ”»â‚€,â€¦,ğ”»_{n-1}.\\
    &wRx_{n-1}Râ€¦Rx_0RyRz, \\
    & (âˆ€u.wRu,uâˆˆğ”¸â‡’âˆƒV.uS_wVâŠ†ğ”¹), \\
    & (âˆ€u.x_{n-1}Ruâˆˆğ”»_{n-1}â‡’âˆƒV.uS_{x_{n-1}}VâŠ†ğ”¸), \\
    & (âˆ€iâˆˆ\{1,â€¦,n-2\}âˆ€u.xáµ¢Ruâˆˆğ”»_iâ‡’âˆƒV.uS_{x_i}VâŠ†ğ”»_{i+1}), \\
    & (âˆ€V.zS_yVâ‡’Vâˆ©â„‚â‰ 0),      \\
    & zâˆˆğ”»â‚€ \\
    â‡’\ & âˆƒVâŠ†ğ”¹.x_{n-1}S_wV,R[V]âŠ†â„‚.
    \end{flalign*}
    {{{beginlemma}}}
    <<lemma:Râ¿>>
    Let $M$ be a model, let $x$ be a world of $M$ and let $nâˆˆâ„•$. For any $iâ‰¤n$ we have
    that if $M , x âŠ© U_i$ then there exist some worlds $y,z,xâ‚€,â€¦,x_{i}$ such that:
    1. $xáµ¢=x$;
    2. $x_iRâ€¦Rxâ‚€RyRz$;
    3. for all $jâ‰¤i$ we have that $M,x_jâŠ©U_j$;
    4. for all $j<i$ we have that $M,x_jâŠ©D_jâ–·D_{j+1}$;
    5. for all $V$ we have that if $zS_yV$ then $Vâˆ©\{w:M,wâŠ©C\}â‰ âˆ…$;
    6. $M,zâŠ©Dâ‚€$.
    {{{beginproof}}}
    {{{agda}}}

    By induction on $i$.
    - For $i=0$ we have that $xâŠ©â™¢Â¬(Dâ‚€â–·Â¬C)$. It follows that there exists some
      $y$ such that $xRyâŠ©Â¬(Dâ‚€â–·Â¬C)$ and therefore there exists some $z$ such that
      $yRzâŠ©Dâ‚€$ and for any $V$, if $zS_yV$, then $Vâˆ©\{w:M,wâŠ©C\}â‰ âˆ…$. It is clear
      that all claims are met.
    - For $i+1$ we have that $xâŠ©â™¢((D_iâ–·D_{i+1})âˆ§U_i)$. It follows that there
      exists some $x_{i}$ such that $x_iâŠ©D_iâ–·D_{i+1}âˆ§U_i$. By IH there exist
      $y,z,xâ‚€,â€¦,x_{i}$ such that they satisfy claims $1,â€¦,6$. We set
      $x_{i+1}â‰”x$. It is trivial to observe that by using the IH all conditions
      are met for $i+1$.
    {{{endproof}}}
    {{{endlemma}}}
    {{{begintheorem}}}
    <<theorem:Râ¿>>
    For any generalized frame $F$, we have that $F$ satisfies
    the $\kgen{Râ¿}$ condition iff any model based on $F$ forces every
    instantiation of the \prin{Râ¿} principle. In symbols:

    \[FâŠ¨\kgen{Râ¿}â‡”FâŠ©Râ¿.\]
    {{{endtheorem}}}

    {{{beginproof}}}
    {{{agda}}}

    If $n=0$ we refer to theorem [[theorem:Râ°]]. For $n+1$ proceed as follows.
    - \boxed{â‡’} Fix a model and assume that for some world $w$ we have $wâŠ©Aâ–·B$.
      Then assume also that $wRxâŠ©((Dâ‚™â–·A)âˆ§U_n)$. Our goal is to find a set $V$
      such that $xS_wVâŠ©Bâˆ§â–¡C$. By lemma [[lemma:Râ¿]] it follows that there exist
      $y,z,xâ‚€,â€¦,x_{n}$ satisfying $1,â€¦,6$. Then let $ğ”¸â‰”âŸ¦AâŸ§$, $ğ”¹â‰”âŸ¦BâŸ§$, $â„‚â‰”âŸ¦CâŸ§$
      and for $iâ‰¤n$ let $ğ”»áµ¢â‰”âŸ¦Dáµ¢âŸ§$.

      It is routine to check that the left part of the $\kgen{R^{n+1}}$ holds
      and thus we get that there exists some $VâŠ†ğ”¹$ such that $x_nS_wV$ and
      $R[V]âŠ†â„‚$. Since $VâŠ†ğ”¹$ we have that $VâŠ©B$ and since $R[V]âŠ†â„‚$ we have
      $VâŠ©â–¡C$. Finally, since $x_{n}=x$ we conclude $xS_wVâŠ©Bâˆ§â–¡C$.
    - \boxed{â‡} Fix a frame $F$ and let $a,b,c,dâ‚€,â€¦,dâ‚™$ be propositional
      variables and assume $FâŠ©R^{n+1}$. Assume that the left part of the
      implication of $\kgen{R^{n+1}}$ holds. Now consider a model based on $F$
      that satisfies the following:
      \begin{flalign*}
       âŸ¦aâŸ§ &= ğ”¸; \\
       âŸ¦bâŸ§ &= ğ”¹; \\
       âŸ¦câŸ§ &= â„‚; \\
       âŸ¦dáµ¢âŸ§ &= ğ”»áµ¢, \text{ for all } iâˆˆ\{0â€¦n\}.
      \end{flalign*}
      Now one can routinely check that $wâŠ©Aâ–·B$ and $xâŠ©((D_nâ–·A)âˆ§U_n)$, hence there
      exists $U$ such that $xS_wU$ and $UâŠ©Bâˆ§â–¡C$. From that we derive that $UâŠ†ğ”¹$
      and $R[U]âŠ†â„‚$.
    {{{endproof}}}

** The principle \prin{Râ‚™}
   <<sec:Rsubn>>
   The $R_n$ principle is defined in cite:two-new-series:

** Generic generalized frame condition
   In this section we present a method that given a formula $A$, builds a second
   order formula that is a generalized frame condition for $A$.

   {{{begindef}}} Given a generalized frame $F=âŸ¨W,R,SâŸ©$ and a formula $A$ with
   $Var(A)=\{xâ‚,â€¦,xâ‚™\}$. Let $â„±$ be defined by (we write $ğ•_*$ instead of $ğ•â‚,â€¦,ğ•â‚™$).
 \begin{flalign*}
   â„±&:\underbrace{ğ’«(W)Ã—â‹¯Ã—ğ’«(W)}_nÃ—Fmâ†’ğ’«(W) \\
   â„±(ğ•_*,xáµ¢) &â‰”  ğ•áµ¢;\\
   â„±(ğ•_*,âŠ¥) &â‰” âˆ…; \\
   â„±(ğ•_*,Aâ†’B) &â‰” \{w:w âˆˆ â„±(ğ•_*,A) â‡’ w âˆˆ â„±(ğ•_*,B)\}; \\
   â„±(ğ•_*,Aâ–·B) &â‰” \{w:âˆ€ u.(wRu,uâˆˆâ„±(ğ•_*,A))â‡’âˆƒY.uS_wYâŠ†â„±(ğ•_*,B))\}. \\
 \end{flalign*}

   Then define
   # \[(A)^*_{gen}â‰”âˆ€ğ•_*âˆ€wâˆˆW.wâˆˆâ„±(ğ•_*,A). \]
   \[\kgen{A^*}â‰”âˆ€ğ•_*âˆ€wâˆˆW.wâˆˆâ„±(ğ•_*,A). \]

   {{{enddef}}}

   {{{begintheorem}}}

   Let $A$ be a formula. For any generalized frame $F$, we have that $F$
   satisfies the $\kgen{A^*}$ condition iff any model based on $F$ forces $A$.
   In symbols:

     \[FâŠ¨\kgen{A^*}â‡”FâŠ©A.\]
   {{{endtheorem}}}

   {{{beginproof}}}
   {{{agda}}}
   {{{endproof}}}

   {{{beginremark}}}
   For instance, if we want the frame condition for \prin{Pâ‚€} we would look at
    \[\kgen{(a â–· â™¢ b â†’ â–¡ (a â–· b))^*}.\]
    Where $a,b$ are different variables.
   {{{endremark}}}
* The logic of Agda

  In this part we give an informal overview of the basic Agda constructions,
  which will hopefully help the reader get an intuition of how dependent types
  can be used to formalize and prove mathematical properties. We will also
  highlight some intricacies of the language that are relevant to our project.
  This part of the thesis is not meant to be an exhaustive analysis of the inner
  workings of Agda, as this falls out of the scope of this project. The original
  author of Agda, Ulf Norell, has suggested[fn::In correspondence via email.]
  cite:cockx2018elaborating as a good reference for that purpose.

  As for the logical basis of Agda... Quote from (cite:sep-type-theory-intuitionistic)
  \begin{quote}
  Agda is another proof assistant which is based on the logical framework
  formulation of intuitionistic type theory, but adds numerous features
  inspired by practical programming languages (\cite{norell:thesis}). It is an
  intensional theory with decidable judgments and a type-checker similar to
  Coqâ€™s. However, in contrast to Coq it is based on Martin-LÃ¶fâ€™s predicative
  intuitionistic type theory.
  \end{quote}


** Introduction to types
   Type theory is a branch of mathematical symbolic logic. It formalizes
   mathematical concepts through terms, types and a typing relation between
   them. One could think of types as predicates on terms. We write $T:A$ to say
   that term $T$ satisfies predicate $A$, or synonymously, that term $T$ has
   type $A$. Later in this section we will see that types in /simply typed
   lambda calculus/ provide a basic classification of lambda terms. For
   instance, a term representing a natural number will have a different type
   from a lambda term representing a Boolean value. In more expressive type
   theories which feature dependent types, such as /intuitionistic type theory/,
   we can express complex mathematical properties such as ``$2*n$ is
   always even'' or that ``any finite sequence of numbers can be sorted''.

   Type theory has become especially relevant in the following areas.
   - *Programming languages and proof assistants*. Simple (non-dependent) types
     are present in almost every modern programming language. Programming
     languages use types to classify its objects and functions with the goal of
     minimizing the amount of errors caused by misusing them. For instance, the
     term $1 + true$ does not make sense and types are used to rule out the
     validity of such term.

     Furthermore, the expressiveness of type theories with dependent types make
     them an adequate basis for modern proof assistants. Due to the constructive
     nature of the theory the proof assistants can be used as programming
     languages too. Agda and Coq are examples of that.
   - *Foundations of mathematics*. (This paragraph is a paraphrase from
     cite:sep-type-theory-intuitionistic) A sufficiently expressive type theory
     such as Martin-LÃ¶f type theory is a formal logical system and philosophical
     foundation for constructive mathematics. It is a full-scale system which is
     based on the /propositions-as-types/ principle and aims to play a similar
     role for constructive mathematics as Zermelo-Fraenkel set theory does for
     classical mathematics.

     (This paragraph is a quote from cite:hottbook) /Univalent Foundations
     of Mathematics/ is Vladimir Voevodskyâ€™s new program for a comprehensive,
     computational foundation for mathematics based on the homotopical
     interpretation of type theory. The type theoretic univalence axiom relates
     propositional equality on the universe with homotopy equivalence of small
     types. The program is currently being implemented with the help of the
     automated proof assistant Coq. The Univalent Foundations program is closely
     tied to homotopy type theory.
**** The origins of types
       (cite:sep-type-theory) Types were first introduced by Russel in 1903 in
      ``Apendix B: The Doctrine of Types, from Principia Mathematica'' while
      trying to avoid a contradiction in set theory, namely Russel's paradox. In
      Principia Mathematica types are defined as follows.
       1. $i$ is the type of individuals (elements of some fixed domain);
       2. if $A_1,â€¦,A_n$ (for $nâ‰¥0$) are types then $(A_1,â€¦,A_n)$ is the type of
          n-ary relations over objects of respective types $A_1,â€¦,A_n$. Note that
          for $n=0$ we have that $()$ is the type of propositions.
       For instance, the type of binary relations over individuals is $(i,i)$,
       the type of binary propositional connectives is $((),())$. Observe that
       this formulation prevents a proposition of the form $R(R)$. Assume for a
       contradiction that $R(R)$ is a proposition, then we have that (by looking
       at the outer occurrence) $R$ has type $(A)$ for some type $A$ and thus
       (by looking at the inner occurrence) $R$ has type $A$ but $Aâ‰ (A)$. This
       observation is the key for avoiding Russel's paradox using types.

       The more habitual definition of types is the one that stems from Church's
       formalization of lambda calculus which includes functions as primitive
       objects.
       1. $i$ is the type of individuals;
       2. $o$ is the type of propositions;
       3. if $A$ and $B$ are types then $Aâ†’B$ is the type of functions from $A$ to $B$.
       We may observe that $iâ†’o$ is the type of predicates on individuals, $iâ†’i$ is
       the type of functions on individuals and $\underbrace{iâ†’(iâ†’â€¦â†’(i}_{n}â†’o))$ is
       an \text{$n$-ary} relation. Although this definition of types is relevant
       for historical reasons, it has become obsolete and we proceed by giving a
       short introduction to three (out of many) versions of lambda calculus
       available today.

**** Untyped lambda calculus
      For the language of terms we present a refinement of Church's version due to
      Curry:
      1. /variable/: every variable is a term;
      2. /function application/: If $A$ and $B$ are terms then $A\ B$ is a term.
         Note that application associates to the left, thus $A\ B\ C=(A\ B)\ C$.
      3. /lambda abstraction/: If $x$ is a variable and $A$ is a term then $Î»x.A$
         is a term. The body of a lambda abstraction (the expression after the
         .) extends to the rightmost part. Thus $Î»x.Î»y.x\ y=Î»x.(Î»y.x\ y)$.
      This can be more succinctly expressed in Backus-Naur form: \[Tâ‰”x\ |\ T\
      T\ |\ Î»x.T\] In lambda calculus we have the following equation known as
      \text{$Î²$-reduction}. \[(Î»x.T)\ A=T[xâ†¦A]\] This equation is often given as
      a reduction rule from left to right, giving computational value to lambda
      terms. In other words, \text{$Î²$-reduction} gives an algorithm based on a
      rewrite rule that /reduces/, /evaluates/ or /computes/ a lambda term until
      it can no longer be reduced. When a term cannot be reduced we say that it
      is in /normal form/. Note that not every term can be reduced to a normal
      form term as showcased by the following term, which reduces to itself:
      \[(Î»x.x\ x)\ (Î»x.x\ x) \] Notice how this term is of the form $R(R)$ (or
      $R\ R$, in the new syntax), which we were able to rule out before by using
      types. In fact, in the next section we will see how this term cannot be
      assigned a type.

      Turing showed that untyped lambda calculus is equivalent in terms of
      computability to Turing machines (cite:turing1937computability), therefore
      any computable function has a lambda term that computes it.

      It might be difficult to imagine how we could express every computable
      function in a lambda term. We believe that showing some practical examples
      will be enlightening, thus we will briefly introduce the /Church
      encoding/ for Booleans and natural numbers.
      - *Booleans*. We define /true/ and /false/ thus: \[true:=Î»a.Î»b.a;\ \ \
        falseâ‰”Î»a.Î»b.b\] As we can see, both /true/ and /false/ are defined as a
        function that takes two arguments. The former returns the first argument
        while the latter returns the second. Thus, this encoding of Booleans
        conveniently allows us to define an /if then else/ expression.
        \[iteâ‰”Î»b.Î»x.Î»y.b\ x\ y\] It is immediate to see by means of
        \text{$Î²$-reduction} that \[ite\ b\ x\ y=b\ x\ y\] hence, we will
        usually prefer to write $b\ x\ y$ instead of $ite\ b\ x\ y$. We can use
        the /if then else/ concept to encode the /and/ and /or/ operators. It
        may help to read the /and/ as ``if the first argument is true return the
        second argument else return false''. Likewise for the /or/.
        \[and:=Î»a.Î»b.a\ b\ false;\ \ \ orâ‰”Î»a.Î»b. a\ true\ b\]
      - *Natural numbers*. The natural number $n$ is encoded as a lambda term
        that applies $n$ times some parameter function $f$.
        \[0:=Î»f.Î»a.a;\ \ \ 1â‰”Î»f.Î»a.f\ a;\ \ \ 2â‰”Î»f.Î»a.f\ (f\ a); \ \ \ â€¦\]
        Then we can define the successor function:
        \[sucâ‰”Î»n.Î»f.Î»a.f\ (n\ f\ a)\]
        Let us show that the successor of 1 is indeed 2.
        \begin{flalign*}
        suc\ 1 &= (Î»n.Î»f.Î»a.f\ (n\ f\ a))\ (Î»f.Î»a.f\ a) & \text{Def}\\
         &= Î»f.Î»a.f\ ((Î»f.Î»a.f\ a)\ f\ a)  & \text{$Î²$-reduction for $n$}\\
         &= Î»f.Î»a.f\ (Î»a.f\ a)\ a  & \text{$Î²$-reduction for $f$}\\
         &= Î»f.Î»a.f\ (f\ a)  & \text{$Î²$-reduction for $a$}\\
         &= 2 & \text{Def}
        \end{flalign*}
        It is also easy to define addition and multiplication. It may help to
        read /add n m/ as ``apply $m$ times $f$, then apply $n$ times $f$'' and
        /mul n m/ as ``apply $n$ times (apply $m$ times)''. \[addâ‰”Î»n.Î»m.Î»f.Î»a.n\ f\ (m\ f\
        a);\ \ \ mulâ‰”Î»n.Î»m.Î»f.Î»a.n\ (m\ f)\ a \]

**** Simply typed lambda calculus
      Let us introduce the idea of types in lambda calculus due to Curry. We
      view types as predicates on lambda terms. We write $T:A$ to say that the
      term $T$ has type $A$.

      We fix a set of base types $ğ$ and a set of term constants
      \[Î“=\{âŸ¨câ‚€^0:Bâ‚€âŸ©,âŸ¨câ‚€^1:Bâ‚€âŸ©,â€¦,âŸ¨câ‚^0:Bâ‚âŸ©,âŸ¨câ‚^1:Bâ‚âŸ©,â€¦\},\], where each $B_iâˆˆğ$.

      The syntax of terms is defined thus. \[Tâ‰”x\ |\ T\ T\ |\ Î»(x:S).T\ |\ c\]
      Where $S$ is a type, $c$ a term constant and $x$ a variable.

      The syntax of types is defined thus. \[Sâ‰”B\ |\ Sâ†’S\] With $Bâˆˆğ$. The $â†’$
      symbol has right associativity, so $Aâ†’Bâ†’C=Aâ†’(Bâ†’C)$.

      Then we define typing rules to assign a type to suitable terms. We define
      a context to be a set of tuples $âŸ¨x:AâŸ©$ where $x$ is either a variable or
      a constant and $A$ is a type. If $Î“$ is a context write $Î“âŠ¢t:A$ to mean
      that $y$ has type $A$ in context $Î“$. When a term can be assigned a type
      in a context we say that it is well-typed in that context. Only well-typed
      terms are considered valid in simply typed lambda calculus.
      #+caption: Typing rules for simply typed lambda calculus.
      #+name: fig:simply_typed
      #+attr_latex: :float
      \begin{figure}[H]
      \begin{mathpar}
      \inferrule[Id]{c : A âˆˆ Î“}{Î“ âŠ¢ c : A}
      \and
      \inferrule[App]{Î“ âŠ¢ f : A â†’ B \\ Î“ âŠ¢ t : A}{Î“âŠ¢f\ t : B}
      \and
      \inferrule[Abstraction]{Î“âˆª\{âŸ¨x:AâŸ©\} âŠ¢ t : B}{Î“âŠ¢Î»(x:S).t :A â†’ B}
      \end{mathpar}
      \end{figure}

      Let us now see how we can give types to Booleans and natural numbers
      following the encoding given in the previous section. For that, we
      consider a singleton set of base types $Bâ‰”\{Î±\}$.
      - *Booleans*. We define the type of Booleans thus: \[ğ”¹â‰”Î±â†’Î±â†’Î±\]
        \[true:=Î»(a:Î±).Î»(b:Î±).a;\ \ \ falseâ‰”Î»(a:Î±).Î»(b:Î±).b\]
        We proceed by showing that $âˆ…âŠ¢true:ğ”¹$.
        \begin{figure}[H]
        \begin{mathpar}
        \inferrule*[Left=Def]{
        \inferrule*[Left=Abs]{
        \inferrule*[Left=Abs]{
        \inferrule*[Left=Id]
        {\ }
        {\{âŸ¨a:Î±âŸ©,âŸ¨b:Î±âŸ©\} âŠ¢a:Î±}}
        {\{âŸ¨a:Î±âŸ©\} âŠ¢Î»(b:Î±).a:Î±â†’Î±}}
        {âˆ… âŠ¢Î»(a:Î±).Î»(b:Î±).a:Î±â†’Î±â†’Î±}}{âˆ… âŠ¢ true : ğ”¹}
        \end{mathpar}
        \end{figure}
        Likewise we can show that $âˆ…âŠ¢false:ğ”¹$. It is routine to check that
        $âˆ…âŠ¢and:ğ”¹â†’ğ”¹â†’ğ”¹$ and that $âˆ…âŠ¢or:ğ”¹â†’ğ”¹â†’ğ”¹$. As we can see, types give us
        information about the nature of the term. For instance, $and:ğ”¹â†’ğ”¹â†’ğ”¹$ tells
        us that $and$ is a lambda term that expects two Booleans as arguments and
        returns a Boolean.

      - *Natural numbers*. We define the type of natural numbers thus:
        \[â„•â‰”(Î±â†’Î±)â†’Î±â†’Î±\] \[0:=Î»(f:Î±â†’Î±).Î»(a:Î±).a;\ \ \ 1â‰”Î»(f:Î±â†’Î±).Î»(a:Î±).f\ a; \ \
        \ â€¦\] We can routinely check that for any natural number $n$ we have
        $âˆ…âŠ¢n:â„•$ and $âˆ…âŠ¢add:â„•â†’â„•â†’â„•$ and $âˆ…âŠ¢mul:â„•â†’â„•â†’â„•$.

      It is a well known property that simply typed lambda calculus is /strongly
      normalizing/, which means that every well-typed term can be reduced to a
      normal form. Thus it must be the case, and it is easy to observe, that
      the non-normalizing term we presented before cannot be typed for any
      choice of $A$. \[(Î»(x:A).x\ x)\ (Î»(x:A).x\ x)\]

      \jan{is next paragraph needed?}
      Strong normalization is a desirable property, but it comes at the price of
      losing equivalence to Turing machines as there are many computable
      functions that cannot be expressed in simply typed lambda calculus.
      To circumvent this, some extensions of simply typed lambda calculus are
      extended with Curry's $Y$ combinator defined below. The $Y$ combinator, also
      known as the fixed-point combinator, is a primitive lambda term that can
      be added to the language and be assigned the type $(A â†’A)â†’A$ for any type
      $A$. \[Yâ‰”Î»g.(Î»x.g\ (x\ x))\ (Î»x.g\ (x\ x))\] The $Y$ combinator gives general
      recursion and thus the strong normalization property no longer holds.

**** Type theory with dependent types
     In this section we will present the intuitionistic type theory presented in
     cite:nordstrom1990programming.

     In this logic we have four types of judgment:
     1. $a$ has type $A$. We write $a:A$. Crucially, in a type theory that
        follows the paradigm of /propositions as types/ we may interpret the
        statement $a:A$ in several ways, all of them equivalent in such paradigm:
        - The term $a$ has type $A$;
        - the term $a$ satisfies the proposition $A$;
        - the term $a$ is a proof of the proposition $A$;
        - the term $a$ is a program that satisfies the specification $A$.
     2. $A$ is a type. We write $A:Type$.
     3. $A_1$ and $A_2$ are equal types. We write $A_1=A_2:Type$.
     4. $a_1$ and $a_2$ are equal elements of the type $A$. We write $a_1=a_2:A$.

     We say that some proposition (or type) $A$ is true if there exists some $t$
     such that $t:A$.

     We will proceed by introducing the syntax of types:
     - /top/. The constant $âŠ¤$ is a type;
     - /bottom/. The constant $âŠ¥$ is a type;
     - /disjoint sum/. If $A$ and $B$ are types then $AâŠB$ is a type;
     - /dependent product/. If $x$ is a variable, $A$ is a type and $B(x)$ is a
       type that may depend on $x$, then $Î£\ (x: A)\ B(x)$ is a type. When
       $B$ is independent of $x$ we may write $A Ã— B$ instead;
     - /dependent function/. If $x$ is a variable, $A$ is a type and $B(x)$ is a
       type that may depend on $x$, then $(x: A) â†’ B(x)$ is a type. When $B$
       is independent of $x$ we may write $A â†’ B$ instead.
     Summarizing in BNF we have: \[âŠ¤\ |\ âŠ¥ \ |\ SâŠS\ |\ Î£\ (x : S)\ S(x)\ |\
     (x:S)â†’S(x)\]

     while
     identifying in the sense of Heyting (cite:heyting1966intuitionism) the
     types with the logical constants and operators, namely $âˆ§,âˆ¨,â†’,âŠ¤,âŠ¥$.
     1. A proof of $Aâ†’B$ is an algorithm that transforms an arbitrary proof of
        $A$ into a proof of $B$;
     2. a proof of $AÃ—B$ is a proof of $A$ and a proof of $B$;
     3. a proof of $Aâˆ¨B$ is an algorithm telling to which of $A$ or $B$ we
        commit to and according to that, a proof of $A$ or a proof of $B$;
     4. nothing is a proof of $âŠ¥$;
     5. $âŠ¤$ is always true and provable.


     We now introduce the concept of /arity/. Arities are used to enforce some
     structure to the terms that we consider valid. For instance, arities reject
     terms such as $R(R)$.
     \begin{quote}
     Per Martin-LoÌˆf has suggested that with
     each expression there should be associated an arity, showing the â€œfunctionalityâ€
     of the expression. Instead of just having one syntactical category of expressions,
     as in combinatory logic, the expressions are divided into different categories
     according to which syntactical operations are applicable. The arities are similar
     to the types in typed lambda calculus, at least from a formal point of view.
     \end{quote}
     We define arities recursively as follows:
     1. $ğŸ¬$ is an arity;
     2. if $Î±â‚,â€¦,Î±â‚™$ (for $nâ‰¥2$) are arities, then $(Î±â‚âŠ—â€¦âŠ—Î±â‚™)$ is an arity;
     3. if $Î±$ and $Î²$ are arities, then $(Î±â† Î²)$ is an arity.
     In BNF we have: \[Aâ‰”ğŸ¬\ |\ (AâŠ—â€¦âŠ—A)\ |\ (Aâ† A)\] We usually can avoid
     parentheses by setting $âŠ—$ to have higher precedence than $â† $. Also, $â† $
     has right associativity. Thus, $ğŸ¬â†  ğŸ¬â†  ğŸ¬âŠ•ğŸ¬=(ğŸ¬â†  (ğŸ¬â†  (ğŸ¬âŠ•ğŸ¬)))$.

     We proceed by defining terms and their arities.
     1. /Variable/. If $x$ is a variable of arity $Î±$, then $x$ is term of arity
        $Î±$;
     2. /Constant/. If $c$ is a constant of arity $Î±$, then $c$ is a term of arity $Î±$;
     3. /Defined identifier/. If $i$ is an identifier defined as $t$ and $t$ has
        arity $Î±$, then $i$ is a term of arity $Î±$;
     4. /Application/. If $d$ is term of arity $Î±â† Î²$ and $Î±$ is a term of
        arity $Î±$, then $d\ a$ is a term of arity $Î²$;
     5. /Combination/. If $tâ‚,â€¦,tâ‚™$ (for $nâ‰¥1$) are terms of arities $Î±â‚,â€¦,Î±â‚™$
        respectively, then $âŸ¨tâ‚,â€¦,tâ‚™âŸ©$ is a term of arity $Î±â‚âŠ—â€¦âŠ—Î±â‚™$;
     6. /Selection/. If $t$ is a term of arity $Î±â‚âŠ—â€¦âŠ—Î±â‚™$ (for $nâ‰¥1$), then
        $seláµ¢\ t$ is a term of arity $Î±áµ¢$.
     The syntax of terms is introduced in conjunction with the introduction
     typing rules:
     \begin{mathpar}
     \inferrule[$âŠ¤$-intro]{\ }{Î“âŠ¢\texttt{tt}:âŠ¤}
     \end{mathpar}

     - $a , b$

***** pend
         define sets
         define arity: Arities are defined inductively in the following way:
           - $ğŸ¬$
         - define expressions
** Martin-LÃ¶f dependent type theory
   Martin-LÃ¶fs type theory is also known as intuitionistic type theory, and it
   can serve as the basis for constructive mathematics, furthermore, it can be
   used as the specification of a programming language.

   The results presented in this section have been gathered from
   cite:martin1984intuitionistic,sep-type-theory-intuitionistic,nlab:martin-lÃ¶f_dependent_type_theory.

   See chapter 5 and 14 of cite:nordstrom1990programming.
** Basic Agda
   In this section we precisely define a moderate subset of Agda. We have tried
   to remain faithful to the semantics of the real Agda language, however, this
   is an incomplete simplification and thus is not meant to be a precise
   reference for the real Agda language. We comment on some of the
   simplifications in Section [[sec:agda-limitations]].

   We introduce several concepts that have cyclic dependencies and thus a linear
   presentation is not possible. {{{jan(write something to help the reader.)}}}
   To ease a first reading we summarize the concepts presented in this section.

   {{{begindef}}} *Identifier*. An identifier is a sequence of characters which
   do not contain any white space or parentheses (normal =()= or curly ={}=) and
   furthermore it is different than all reserved keywords. Some identifier
   examples are =a=, =x=, =Â¬Â¬x=, =Aâ–·B=, =Aâ†’B=, =Some-Long-Word=. For all
   practical purposes, we can assume we have an infinite set of identifiers.

   Some of the Agda reserved keywords are =Î»=, =âˆ€=, =â†’=, ===,
   =data=, =where=, =:=. {{{jan(I don't think this has to be exhaustive.)}}}

   It is worth noting that syntactically constructors and identifiers are
   subject to the same rules. Agda detects constructors by using the datatype
   definitions in scope. For more information on constructors see the definition
   of a datatype ([[def:agda-datatype]]). {{{jan(should this be in?)}}} {{{enddef}}}

   {{{begindef}}} <<def:agda-term>> *Term/Type*. An Agda term is recursively
   defined as shown in the figure below.

   An Agda *type* is a term =A= such that =A : Set â„“= for some =â„“=. Definition
   [[def:agda-well-typed]] gives a description of the Agda typing rules. We want to
   emphasize, and it is obvious from the definition, that all types are also terms.

   We use =x= to denote an arbitrary identifier, we use =pâ‚=, â€¦, =pâ‚™= to denote
   arbitrary patterns (see Definition [[def:agda-pattern]]), we use =A,=, =B=, =Aâ‚=,
   =â€¦=, =Aâ‚™= to denote arbitrary terms and we use =c= to denote an arbitrary
   constructor (see Definition [[def:agda-constructor]]).

   # #+caption: The syntax of terms (and types).
   #+name: fig:agda-term
   #+attr_latex: :align llll :float t :center t :placement [H]
    | $term$ | $â‰”$   | =f=                        | identifier;                               |
    |        | \vert | =(x : A) â†’ B=              | function type;                            |
    |        | \vert | =Î» x â†’ A=                  | lambda abstraction;                       |
    |        | \vert | =Î» {pâ‚ â†’ Aâ‚; â€¦ ; pâ‚™ â†’ Aâ‚™}= | lambda abstraction with pattern matching; |
    |        | \vert | =A B=                      | function application;                     |
    |        | \vert | =Set â„“=                    | universe $(â„“âˆˆÏ‰)$.                         |

   {{{jan(Is the following presentation preferred?)}}}
   #+name: fig:agda-term2
   #+attr_latex: :align llll :float t :center t :placement [H]
    | $term$ | $â‰”$   | =iden=                           | identifier;                               |
    |        | \vert | =(iden : type) â†’ term=           | function type;                       |
    |        | \vert | =Î» iden â†’ term=                  | lambda abstraction;                       |
    |        | \vert | =Î» {pat â†’ term; â€¦ ; pat â†’ term}= | lambda abstraction with pattern matching; |
    |        | \vert | =term term=                      | function application;                     |
    |        | \vert | =Set â„“=                          | universe $(â„“âˆˆÏ‰)$.                         |

   The =â†’= in the function type has right associativity, hence =(a : A) â†’ (b :
   B) â†’ C= is the same as =(a : A) â†’ ((b : B) â†’ C)=. The =â†’= in the lambda
   abstraction extends to the rightmost part, hence =Î» x â†’ Î» y â†’ A B= is the
   same as =(Î» x â†’ (Î» y â†’ A B))=. Function application has left associativity,
   hence =a b c= is the same as =(a b) c=. Also note that the =i= in =Set i= can
   be an identifier but for simplicity in this section we restrict the =i= to be
   an arbitrary constant natural number.

   An example term:
   #+begin_example
   Î» (A : Set 0) â†’ Î» (B : Set 0) â†’ (f : A â†’ B) â†’ (a : A) â†’ B
   #+end_example
   {{{enddef}}}


  {{{begindef}}} *Function definition*. A function definition is used to bind a
  new[fn::By new we mean that is has not yet been bound by another definition.]
  identifier to a term.

  /Note/: Maybe the name ``term definition'' or ``term binding'' would be more
  appropriate for the concept defined here. We have decided to use the name
  ``Function definition'' since it is widely used in the field of computer
  science.

  # #+name: fig:agda-fundef
  # #+attr_latex: :align llll :float t :center t :placement [H]
  # | $fundef$ | $â‰”$ | =x : term= | function def; |
  # |          |     | =x = term= |               |

  Below we present two schemes of function definitions:
  #+begin_example
  x : T
  x = A

  y : T'
  y = A'
  #+end_example
  The above code should read as: The identifier =x= is bound to =A=, which is a
  term of type =T=. Likewise, the identifier =y= is bound to =A'= which is a
  term of type =T'=.

  Note that =A : T= and =A' : T'= must be valid according to the typing rules
  (see Section [[sec:typing-rules]]).

  When we deal with two terms =A= and =T= which are related by the typing
  relation =A : T= we will use the word =term= for =A= and the word =type= for
  =T=. {{{jan(This should probably be stated in the section before. WIP)}}}

  Function definitions are evaluated in order, thus, in =T'= and in =A'= we can
  refer to =x=. However, neither in =A= or =T= we can refer to =y=.

  Recursive references are allowed in the term, thus we can refer to =x= in =A=.
  Likewise we can refer to =y= in =A'=.

  Also note that we cannot bind the same identifier twice.
  {{{enddef}}}

  {{{begindef}}} <<def:agda-constructor>> <<def:agda-datatype>> *Datatype
  definition*. Datatype definitions are used to introduce new terms/types to the
  language. We call datatypes the types which have been defined using a datatype
  definition. For instance, we would use a datatype definition to define a type
  representing the natural numbers.

  The general form of the definition of a datatype =D= is the following:
  #+begin_example
    data D (xâ‚ : Pâ‚) â€¦ (xâ‚– : Pâ‚–) : (yâ‚ : Qâ‚) â†’ â€¦ â†’ (yâ‚— : Qâ‚—) â†’ Set â„“ where
      câ‚ : Tâ‚
      â€¦
      câ‚™ : Tâ‚™
    #+end_example
  Note that $kâ‰¥0$, $lâ‰¥0$ and $nâ‰¥0$.
  We distinguish the following parts of the declaration:
  1. /Name/. =D= is an identifier, which is the name of the newly introduced
     datatype. =D= is assigned the following type and is brought into scope:
     #+begin_example
     (xâ‚ : Pâ‚) â†’ â€¦ â†’ (xâ‚– : Pâ‚–) â†’ (yâ‚ : Qâ‚) â†’ â€¦ â†’ (yâ‚— : Qâ‚—) â†’ Set â„“
     #+end_example
     By bringing =D= into scope we mean that =D= can be referenced in the
     constructor types =Tâ‚=, â€¦, =Tâ‚™=, also in subsequent datatypes definitions
     and in terms defined after the definition of the datatype =D=.
  2. /Indices/. =(yâ‚ : Qâ‚) â€¦ (yâ‚— : Qâ‚—)= are the indices of the datatype. For any
     $iâˆˆ\{1,â€¦,l\}$ we have that:
     1. =yáµ¢= is an identifier with associated type =Qáµ¢=;
     2. the type =Qáµ¢= can reference =xâ±¼= for any $jâˆˆ\{1,â€¦,k\}$;
     3. if $i>1$ we have that the type =Qáµ¢= can reference any =yâ±¼= for $j<i$.
  3. /Parameters/. =(xâ‚ : Pâ‚) â€¦ (xâ‚– : Pâ‚–)= are the parameters of the datatype.
     For every $iâˆˆ\{1,â€¦,k\}$ we have that:
     1. =xáµ¢= is an identifier with associated
        type =Páµ¢=;
     2. if $i>1$ we have that the type =Páµ¢= can reference any =xâ±¼= for $j<i$.
  4. /Constructors/. =câ‚ â€¦ câ‚™= are identifiers, which we call the constructors
     of the datatype. For every $iâˆˆ\{1,â€¦,n\}$ we have that:
     1. =Táµ¢= is the type of the constructor =cáµ¢=.
     2. =Táµ¢= has to be of the form
       #+begin_example
       (zâ‚ : Bâ‚) â†’ ... â†’ (zâ‚˜ : Bâ‚˜) â†’ D xâ‚ â€¦ xâ‚– tâ‚ â€¦ tâ‚—
     #+end_example
        Where for every $iâˆˆ\{1,â€¦,l\}$ we have that =táµ¢ : Qáµ¢=, furthermore =táµ¢=
        can refer to =zâ±¼= for any $jâˆˆ\{1,â€¦,m\}$.

        If we focus on the return type[fn::The rightmost term which is not a
        function type.] of =cáµ¢=, namely =D xâ‚ â€¦ xâ‚– tâ‚ â€¦ tâ‚—=, we see that the
        first $k$ arguments to =D= are required to be precisely the parameters
        of =D=, while the remaining $l$ arguments, the indices, can be any terms
        =tâ‚=, â€¦, =tâ‚—= of type =Qâ‚=, â€¦, =Qâ‚—= respectively and may vary for each
        constructor. For that reason, we say that parameters are shared among
        all constructors, while indices are specified on a constructor basis.
        Refer to Section [[sec:agda-ref-datatype]] for a meaningful example.

     The following is fundamental: the only way to build a term of type =D xâ‚ â€¦
     xâ‚– tâ‚ â€¦ tâ‚—= is to build a term of the form =cáµ¢ wâ‚ ... wâ‚˜=, for some
     $iâˆˆ\{1,â€¦,n\}$, assuming =cáµ¢= is declared to have the type =(zâ‚ : Bâ‚) â†’ ...
     â†’ (zâ‚˜ : Bâ‚˜) â†’ D xâ‚ â€¦ xâ‚– tâ‚ â€¦ tâ‚—= and =wâ‚=, ... =wâ‚˜= are terms of type =Bâ‚=,
     ... =Bâ‚˜= respectively.

     There are no datatypes or constructors which are inherent to the language,
     thus, every datatype and constructor will be defined by the user in a
     datatype definition.
  {{{enddef}}}

  {{{begindef}}} <<def:agda-pattern>> *Pattern*. A pattern is recursively
  defined as follows. We use =pâ‚,= â€¦, =pâ‚™= to denote patterns.
  #+name: fig:agda-pattern
  #+attr_latex: :align llll :float t :center t :placement [H]
  | $pattern$ | $â‰”$   | =c pâ‚ â€¦ pâ‚™= | constructor of arity =n â‰¥ 0=; |
  |           | \vert | =x=         | identifier.                   |
  A pattern cannot contain repeated identifiers. We define $ids(p)$ to be the
  set of identifiers that appear in a pattern.

  Note that patterns of the form =c pâ‚ â€¦ pâ‚™= for $nâ‰¥1$ must be surrounded by
  parentheses. {{{enddef}}}

  {{{begindef}}} *Module*. A module is a sequence of function definitions and
  datatype definitions. Each function definition exposes the bound identifier to
  the subsequent definitions. Each datatype definition exposes the name of the
  datatype and its constructors to the subsequent definitions.

  #+name: fig:agda-module
  #+attr_latex: :align llll :float t :center t :placement [H]
  | $module$ | $â‰”$   | =fundef â†µ module=  | function definition; |
  |          | \vert | =datadef â†µ module= | datatype definition; |
  |          | \vert |                    | empty.               |
  The =â†µ= symbol represents a line break.


  An example module which contains a definition of the =Bool=
  datatype and the =not= function:
  #+begin_example
    data Bool : Set 0 where
      true : Bool
      false : Bool

    not : (b : Bool) â†’ Bool
    not = Î» { false â†’ true; true â†’ false}
  #+end_example
  {{{enddef}}}

  # {{{begindef}}} *Well-scoped term*. A well-scoped term is a term where every
  # identifier in it is bound. In other words, there are no free identifiers.

  # The set of free identifiers is defined as usual (following the syntax defined
  # in Definition [[def:agda-term]]):
  # \begin{flalign*}
  # &free(x) â‰” âˆ…  &\text{if identifier $x$ is bound.} \\
  # &free(x) â‰” \{x\} &\text{otherwise.}  \\
  # &free(Î»xâ†’A) â‰” free(A)âˆ–\{x\}  \\
  # &free(Î»\ \{\ pâ‚â†’Aâ‚;\ â€¦;\ pâ‚™â†’Aâ‚™\}) â‰” â‹ƒ_{i}\Big(free(Aáµ¢)âˆ–ids(páµ¢)\Big)  \\
  # &free(A\ B) â‰” free(A)âˆªfree(B)  \\
  # &free(Set\ i) â‰” âˆ…  \\
  # \end{flalign*}

  # We always assume terms to be well-scoped.
  # {{{enddef}}}

*** Contexts, and typing rules
    <<sec:typing-rules>>

    {{{begindef}}} *Context*. A context is a pair of (finite) sets $âŸ¨Î¤,Î”âŸ©$. The
    set $Î¤$ consists of pairs $âŸ¨identifier:typeâŸ©$. It is used to keep track of
    what identifiers are bound and what is their type. The set $Î”$ consists of
    pairs $âŸ¨identifier=termâŸ©$ which are the identifiers which have been assigned
    a term through a function definition.

    In order to simplify things we assume that there is no /shadowing/, which
    means that an identifier which is already bound in the current context
    cannot be bound again. Thus, the term =Î» x â†’ Î» x â†’ x= would be invalidated
    by this assumption since the identifier =x= is rebound by the second lambda
    function. This restriction is not a limiting as we can always rename our
    identifiers to De Bruijn indices (cite:de1972lambda), which guarantee this
    assumption.

    *Notation*. We refer to contexts by a single letter, thus if $Î“=âŸ¨Î¤,Î”âŸ©$ we
    abuse notation and write $a:tâˆˆÎ“$ instead of $âŸ¨a:tâŸ©âˆˆÎ¤$ and $a=tâˆˆÎ“$ instead of
    $âŸ¨a=tâŸ©âˆˆÎ”$. Also, we use $Î“;t:A$ as short for $âŸ¨Î¤ âˆª\{âŸ¨t:AâŸ©\},Î”âŸ©$.
    {{{enddef}}}

    {{{begindef}}} <<def:agda-well-typed>> *Well-typed term (and patterns)*. We
    say that a term $t$ is well-typed in context $Î“$ if $Î“âŠ¢t:A$ for some type
    $A$. The rules for $âŠ¢$ are presented below. We also define the relation
    $âŠ¢_{Î¡}$, which is for typing patterns. For that purpose we need an auxiliary
    function definition, $Ï„$, which is defined afterwards.

    The structure of a module implicitly assigns a context to each term in it.
    We usually use the concept of well-typed term in the context of a module, in
    that case, we implicitly refer to the context assigned by the structure of
    the module. See Definition [[def:agda-check-module]] for a thorough explanation.
    {{{enddef}}}

   #+caption: Typing rules for terms.
   #+name: fig:type
   #+attr_latex: :float
   \begin{figure}[H]
   \begin{mathpar}
   \inferrule[Id]{t : A âˆˆ Î“}{Î“ âŠ¢ t : A}
   \and
   \inferrule[Level]{\ }{Î“âŠ¢Set\ i : Set\ (i+1)}
   \and
   \inferrule[Arrow]{Î“ âŠ¢ A:Set\ i \\ Î“; x:A âŠ¢ B : Set\ i}{Î“ âŠ¢ (x:A)â†’B:Set\ i}
   \\
   \inferrule[Abstraction]{x:A; Î“ âŠ¢ t:B }{Î“âŠ¢Î»xâ†’t:(x:A)â†’B}
   \and
   \inferrule[Application]{Î“âŠ¢f:(x:A)â†’B \\ Î“âŠ¢a:A }{Î“âŠ¢f\ a : B[xâ†¦t]}
   \\
   \inferrule[Pattern abstraction]{\text{Let } \overline{D}â‰”D\ xâ‚\ â€¦\ xâ‚™\ tâ‚\ â€¦\ tâ‚™ \\\\
     Î“âŠ¢_{Î¡}pâ‚:\overline{D} \\ â€¦ \\  Î“âŠ¢_{Î¡}pâ‚™:\overline{D} \\\\
     Î“âˆªÏ„(Î“,\overline{D},pâ‚)âŠ¢ sâ‚:B[xâ†¦pâ‚] \\ â€¦ \\ Î“âˆªÏ„(Î“,\overline{D},pâ‚™)âŠ¢ sâ‚™:B[xâ†¦pâ‚™]}
     {Î“âŠ¢Î»\ \{pâ‚ â†’sâ‚;\ â€¦\ ;\ pâ‚™â†’sâ‚™\}:(x:\overline{D})â†’B}
   \end{mathpar}
   \end{figure}

   #+caption: Typing rules for patterns.
   #+name: fig:pat-type-rules
   #+attr_latex: :float
   \begin{figure}[H]
   \begin{mathpar}
   \inferrule[Identifier]{\ }{Î“âŠ¢_{Î¡}x : A}
   \\
   \inferrule[Constructor]{c:(bâ‚:Bâ‚)â†’â€¦â†’(bâ‚™:Bâ‚™)â†’D\ xâ‚\ â€¦\ xâ‚™\ tâ‚\ â€¦\ tâ‚™ âˆˆÎ“ \\\\
     âˆ€iâˆˆ\{1,â€¦,n-1\}.\ Î“âŠ¢_Î¡páµ¢:Báµ¢[bâ‚â†¦pâ‚, â€¦,b_{i-1}â†¦p_{i-1}]   }{Î“âŠ¢_Î¡c\ pâ‚\ â€¦\ pâ‚™ : D\ xâ‚\ â€¦\ xâ‚™\ tâ‚\ â€¦\ tâ‚™}
   \end{mathpar}
   \end{figure}
   {{{jan(explain $[bâ‚â†¦pâ‚]$)}}}

   Let $\overline{D}â‰”D\ xâ‚\ â€¦\ xâ‚™\ tâ‚\ â€¦\ tâ‚™$. We now define
   $Ï„(Î“,\overline{D},p)$, which is the set of identifiers bound by pattern $p$
   paired with their respective types. Assume that $Î“âŠ¢_{Î¡}p:\overline{D}$.
   Finally, let $Ï„$ be defined as follows:
  \begin{flalign*}
  &Ï„(Î“,\overline{D},x)â‰” \{x:\overline{D}\} & \text{Identifier} \\
  &Ï„(Î“,\overline{D},c\ pâ‚\ â€¦\ pâ‚™)â‰” Ï„(Î“,pâ‚,Bâ‚)âˆªâ€¦âˆªÏ„(Î“,pâ‚™,Bâ‚™) & \text{Constructor} \\
  &\hspace{3.5cm} \text{assuming } c:(bâ‚:Bâ‚)â†’â€¦â†’(bâ‚™:Bâ‚™)â†’\overline{D}âˆˆÎ“
  \end{flalign*}

  # The precise typing rule for the lambda abstraction with patterns falls out
  # of the scope of this thesis. We ask the reader to refer to Chapter 2 of
  # cite:norell:thesis for that purpose. Here we present a simplification.
  # {{{jan(pending.)}}}

  {{{begindef}}} <<def:agda-check-module>> *Scoping and type checking a module*.
  We understand by /scoping/ the process of implicitly assigning a context to
  each part of the module. We understand by /type checking/ the process of
  checking that all terms in a module are well-typed (in their corresponding
  context) and respect the typing annotations. These processes are tightly tied
  and thus we describe them together.

    # By respecting the
    # typing annotations we mean that if we have the following definition:
    # #+begin_example
    # x : A
    # x = t
    # #+end_example
    # Then we need check that =t= is well-typed and furthermore has type =A=.

    It may be worth noticing that sometimes the annotation =x : A= may be
    redundant since the type of =t= can be automatically inferred to be =A= from
    the rules. Type inference is widely used in the real Agda language, however,
    in this presentation we skip it for simplicity. We lightly touch the topic in
    section {{{jan(???)}}}.

    However, for simplicity we do not differentiate between type inference
    and type checking. assume that the annotation is always required.

    The process of type-checking a module is as follows:
    1. At the beginning of a module we start with an empty context $Î“ â‰” âˆ…$.
    2. We look at the next definition.
       - If it is a *function definition*, it is of the form
         #+begin_example
         x : A
         x = t
         #+end_example
         Check there is some $â„“$ such that $Î“âŠ¢A:Set\ â„“$. Then let $Î“'â‰”Î“;x:A$
         and check $Î“'âŠ¢t:A$.

         We repeat step 2 with context $Î“'$.
       - If it is a *datatype definition*, it is the form
           #+begin_example
       data D (xâ‚ : Pâ‚) â€¦ (xâ‚– : Pâ‚–) : (yâ‚ : Qâ‚) â†’ â€¦ â†’ (yâ‚— : Qâ‚—) â†’ Set â„“ where
         câ‚ : Tâ‚
         â€¦
         câ‚™ : Tâ‚™
           #+end_example
           where each =Táµ¢= is of the form
           #+begin_example
           (zâ‚ : Bâ‚) â†’ â€¦ â†’ (zâ‚˜ : Bâ‚˜) â†’ D xâ‚ â€¦ xâ‚– tâ‚ â€¦ tâ‚—
         #+end_example

         We check that:
         1. For each parameter =xáµ¢ : Páµ¢= check that for some $Îµâ‰¤â„“$ we have
            \[Î“;xâ‚:Pâ‚;â€¦;x_{i-1}:P_{i-1}âŠ¢Páµ¢:Set\ Îµ.\]
         2. Then let
            \begin{flalign*}
             Î“'â‰”&Î“;xâ‚ : Pâ‚; â€¦; xâ‚– : Pâ‚–; \\
               &D : (xâ‚ : Pâ‚) â†’ â€¦ â†’ (xâ‚– : Pâ‚–) â†’ (yâ‚ : Qâ‚) â†’ â€¦ â†’ (yâ‚— :
              Qâ‚—) â†’ Set\ â„“.
            \end{flalign*}
             # \[Î“'â‰”Î“;xâ‚ : Pâ‚; â€¦; xâ‚– : Pâ‚–;D : (xâ‚ : Pâ‚) â†’ â€¦ â†’ (xâ‚– : Pâ‚–) â†’ (yâ‚ : Qâ‚) â†’ â€¦ â†’ (yâ‚— :
             #  Qâ‚—) â†’ Set\ â„“. \]
            For each $iâˆˆ\{1,â€¦,n\}$ check that
            \[Î“'âŠ¢ (zâ‚ : Bâ‚) â†’ â€¦ â†’ (zâ‚˜ : Bâ‚˜) â†’ D\ xâ‚\ â€¦\ xâ‚–\ tâ‚\ â€¦\ tâ‚— : Set\ â„“.\]
            # #+begin_example
            # cáµ¢ : (zâ‚ : Bâ‚) â†’ â€¦ â†’ (zâ‚˜ : Bâ‚˜) â†’ D xâ‚ â€¦ xâ‚– tâ‚ â€¦ tâ‚—
            # #+end_example
            #  We check that for all
            # $jâˆˆ\{1,â€¦,m\}$ there is some $Îµâ‰¤â„“$ such that
            # \[Î“';xâ‚:Pâ‚;â€¦;x_{k}:P_{k}âŠ¢B_j :Set\ Îµ.\] Furthermore, for all
            # $jâˆˆ\{1,â€¦,l\}$ we check that
            # \[Î“';xâ‚:Pâ‚;â€¦;x_{k}:P_{k};zâ‚:Bâ‚;â€¦;zâ‚˜:Bâ‚˜;tâ‚:Qâ‚;â€¦;t_{j-1}:Q_{j-1}âŠ¢
            # tâ±¼:Qâ±¼. \]
            Then let
            \begin{flalign*}
             Î“''â‰”&Î“;\\
              &D : (xâ‚ : Pâ‚) â†’ â€¦ â†’ (xâ‚– : Pâ‚–) â†’ (yâ‚ : Qâ‚) â†’ â€¦ â†’ (yâ‚— :
              Qâ‚—) â†’ Set\ â„“; \\
              &câ‚ : (z^1â‚ : B^1â‚) â†’ â€¦ â†’ (z^1â‚˜ : B^1â‚˜) â†’ D\ xâ‚\ â€¦\ xâ‚–\ t^1â‚\ â€¦\ t^1â‚—; \\
              & â‹® \\
              &câ‚™ : (z^nâ‚ : B^nâ‚) â†’ â€¦ â†’ (z^nâ‚˜ : B^nâ‚˜) â†’ D\ xâ‚\ â€¦\ xâ‚–\ t^nâ‚\ â€¦\ t^nâ‚—
            \end{flalign*}
            and continue to step 2 with context $Î“''$.
    {{{enddef}}}
*** Normalization
    <<sec:agda-normalization>> Normalization is refers to the process of
    simplifying or evaluating a term via rewrite rules.

    In real Agda normalization is done at the same time as type-checking via an
    involved algorithm (see Section 3.3.2 of cite:norell:thesis). Here we
    present a collection normalization rules which are detached from the
    type-checking process. Our aim is to provide an intuition of how well-typed
    terms are simplified automatically in Agda rather than giving details of the
    algorithm.

    The reader may be already acquainted with the \textsc{$Î²$-reduction} rule,
    which is present in untyped lambda calculus, the most basic form of lambda
    calculus. Here we present the mentioned rule among others. We use the
    notation $Î”âŠ¢_Ntâ†“t'$ to say that term $t$ normalizes to term $t'$ in context
    $Î”$. We extend the definition of context to also contain all the pairs
    $âŸ¨identifier=termâŸ©$ which are defined in a function definition above in the
    module. To be more precise, now a context consists of two sets: One contains
    the typing relations $âŸ¨identifier:termâŸ©$ and the other contains the binding
    relations $âŸ¨identifier=termâŸ©$.

    Normalization can happen in nested terms. For instance, if we have that
    $tâ†“t'$ then $Î» xâ†’ tâ†“Î»xâ†’t'$. Likewise for the other kinds of terms.

    In the rule \textsc{Match} we use the notation $âˆƒ^{min}i$ to mean that in
    case there exist multiple values for $i$ such that the function
    $match(páµ¢,b)$ succeeds and returns a substitution $Ïƒ$, then we must take the
    minimum of such \text{$i$s}. In other words, we check patterns in order and
    we use the first that succeeds.

    We use $a,b,c,t$ to denote arbitrary terms and $x,f$ to denote arbitrary
    identifiers.
   #+caption: Normalization rules for terms.
   #+name: fig:normalization
   #+attr_latex: :float
    \begin{figure}[H]
    \begin{mathpar}
    \inferrule[$Î²$-reduction]{\ }{Î”âŠ¢_N(Î» x â†’ t)\ aâ†“t[xâ†¦a] } \and
    \inferrule[Transitivity]{Î”âŠ¢_Naâ†“b \\ Î”âŠ¢_Nbâ†“c }{Î”âŠ¢_Naâ†“c} \and
    \inferrule[Definition]{f=tâˆˆÎ”  }{Î”âŠ¢_Nfâ†“t}
    \\
    \inferrule[Match]{Î”âŠ¢_Naâ†“b \\ âˆƒ^{min}i.match(páµ¢,b)=Ïƒ  }{Î”âŠ¢_NÎ»\ \{pâ‚â†’tâ‚;â€¦;pâ‚™â†’tâ‚™\}\ aâ†“Ïƒ(táµ¢)}
    \end{mathpar}
    \end{figure}

    Here we define the partial function $match$, which takes a pattern and a
    term, then either fails or returns a substitution. We represent a substitution
    by a set of pairs of the form $âŸ¨xâ†¦tâŸ©$, which means ``replace identifier $x$
    by term $t$''. Keep in mind that a pattern does not contain repeated
    identifiers, so the result (if it succeeds) of $match$ is a proper function.
    \begin{flalign*}
    &match(x, t)â‰” \{âŸ¨xâ†¦tâŸ©\} \\
    &match(c\ pâ‚\ â€¦\ pâ‚™, c'\ tâ‚\ â€¦\ tâ‚™)â‰” \begin{cases}
             â‹ƒ_i(match(páµ¢,táµ¢)) & \text{if $c=c'$ and all recursive calls succed;}  \\
             \text{fail} & \text{otherwise.}\end{cases}
    \end{flalign*}

    Some examples for the \textsc{$Î²$-reduction} rule:
    \begin{flalign*}
    &Î» y â†’ (Î»xâ†’x)\ y â†“ Î» y â†’ y & \\
    &(Î»xâ†’x)\ a â†“ a &
    \end{flalign*}
    To see examples for the \textsc{Match} rule assume we have the following
    definition in scope:
    #+begin_example
    data Nat : Set 0 where
      zero : Nat
      suc : Nat â†’ Nat

    plus : Nat â†’ Nat â†’ Nat
    plus = Î» { zero â†’ (Î» b â†’ b); (suc a) â†’ (Î» b â†’ suc (plus a b) ) }
    #+end_example
    Then see that the term =plus zero= normalizes to the identity function:
    \begin{flalign*}
    &plus\ zeroâ†“Î» b â†’ b &
    \end{flalign*}

    As another example, see that the term =plus (suc zero)= normalizes to =Î» b â†’
    suc b=. We present this example step by step.
    \begin{flalign*}
    plus\ (suc\ zero)&â†“ &\textsc{Def}
    \\ Î»\ \{ zero â†’ (Î» b â†’ b);\ (suc\ a) â†’ (Î» b â†’ suc\ (plus\ a\ b) )\}\ (suc\ zero)& â†“ & \textsc{Match}
    \\ Î» b â†’ suc\ (plus\ zero\ b) &â†“ & \textsc{Def}
    \\ Î» b â†’ suc\ ((Î» b' â†’ b')\ b) &â†“ &\textsc{$Î²$-reduction}
    \\ Î» b â†’ suc\ b
    \end{flalign*}


    {{{begintheorem}}}
    Normalization is type-preserving.
    \begin{figure}[H]
    \begin{mathpar}
    \inferrule[]{Î“âŠ¢_N tâ†“t' \\ Î“âŠ¢t:A }{Î“âŠ¢t':A }
    \end{mathpar}
    \end{figure}
    {{{endtheorem}}}
    {{{beginproof}}}
    By an easy proof by induction.
    {{{endproof}}}

*** Totality
    <<sec:agda-totality>>
    In order to be a sound system, Agda requires all of its terms to be
    total. Thus, it needs to assure that:
    1. Every lambda abstraction with pattern matching of the form =Î» {pâ‚ â†’ Aâ‚; â€¦
       ; pâ‚™ â†’ Aâ‚™}= must have a set of exhaustive patterns =pâ‚=, â€¦, =pâ‚™=. For
       instance if we have the following:
       #+begin_example
       data Bool : Set 0 where
         true : Bool
         false : Bool

       wrong : (b : Bool) â†’ Bool
       wrong = Î» { true â†’ true }
       #+end_example
       Then the definition of =wrong= is rejected since it does not have the
       =false= pattern. The coverage algorithm (the algorithm which checks
       the exhaustivity of patterns) is described in
       cite:norell:thesis.
    2. There are no infinite loops. For instance
       #+begin_example
       loop : (A : Set 0) â†’ A
       loop = Î» A â†’ loop A
       #+end_example
       In order to do so Agda analyses every recursive call and tries to find a
       well-founded order on its arguments. If it succeeds the recursive call is
       considered save, otherwise it is rejected. The Agda online documentation
       (cite:agda-doc) references cite:abel1998foetus as the basis of the
       termination checker implemented in Agda. For instance, the checker is
       sophisticated enough to accept the definition of the Ackermann function
       (cite:agda-doc), which is non-primitive recursive.

*** Limitations
    <<sec:agda-limitations>>
    As mentioned at the beginning of this section we did not give a complete
    presentation of the language due to its complexity. Moreover, we had to
    simplify some of the concepts presented. Here we comment on those
    simplifications.

**** Pattern matching on indexed datatypes
     The typing rules given in section [[sec:typing-rules]] are not enough to
     sensibly deal with datatypes which have indices.

     Consider the following example:
     #+begin_example
     data Bool : Set 0 where
       true : Bool
       false : Bool

     data IsTrue : (b : Bool) â†’ Set 0 where
       is-true : IsTrue true

     data IsFalse : (b : Bool) â†’ Set 0 where
       is-false : IsFalse false

     not : (b : Bool) â†’ Bool
     not = Î» {true â†’ false; false â†’ true}
     #+end_example
     We see that we have the usual definition of =Bool=. We also an indexed
     datatype called =IsTrue=. Observe that it has a single constructor called
     =is-true= which gives a term of type =IsTrue true=. Since =is-true= is
     the only constructor it is impossible to build a term of type =IsTrue
     false=. After this we have a dual definition called =IsFalse=. Then we have
     the definition of the =not= function with the expected definition.

     We expect that we should be able to prove that if have a term =b : Bool=
     and a term of type =IsTrue b= we should be able to give a term of type
     =IsFalse (not b)=. We represent this property with the following type:
     #+begin_example
     property : (b : Bool) â†’ (p : IsTrue b) â†’ IsFalse (not b)
     #+end_example
     Providing a term of this type can be done in real Agda as follows:
     #+begin_example
     property : (b : Bool) â†’ (p : IsTrue b) â†’ IsFalse (not b)
     property = Î» b â†’ Î» { is-true â†’ is-false }
     #+end_example
     Unfortunately, giving a term of this type is not possible with the typing
     rules that we gave. To see this, consider the context $Î“$ at the =?= site
     below.
     #+begin_example
     property : (b : Bool) â†’ (p : IsTrue b) â†’ IsFalse (not b)
     property = Î» b â†’ Î» p â†’ ?
     #+end_example
     We have $b:BoolâˆˆÎ“$ and $p : IsTrue\ b âˆˆÎ“$. We can try to pattern match on
     =b=.
     #+begin_example
     property : (b : Bool) â†’ (p : IsTrue b) â†’ IsFalse (not b)
     property = Î» {true â†’ Î» pt â†’ is-false; false â†’ Î» pf â†’ ? }
     #+end_example
     Filling in the case where =b= is equal to =true= is straightforward because
     here the goal is to provide a term of type =IsFalse (not true)=, which
     normalizes to =IsFalse false=, therefore we can use the term =is-false=.
     The conflicting case is when =b= is equal to false. See that in this case
     we have that =pf= has type =IsTrue false=. Clearly we should be able to
     somehow derive a contradiction from this, because it is impossible that a
     term of this type exists. Agda deals with contradictions with absurd
     patterns, which are discussed in the next section.

     Another possibility to tackle the previous problem is to pattern match on
     =p= as we did in real Agda:
     #+begin_example
     property : (b : Bool) â†’ (p : IsTrue b) â†’ IsFalse (not b)
     property = Î» b â†’ Î» { is-true â†’ ? }
     #+end_example

     {{{jan(move this comment?)}}}
     See the Chapter 2 of cite:norell:thesis for an overview of how pattern
     matching works in real Agda, including the unification algorithm.

**** Absurd patterns
**** Unreachable patterns
**** Universes
*** Syntax sugar

** Agda tutorial
*** BHK interpretation of propositional logic
   Agda is based on an intuitionistic type theory with dependent types that
   extends Per Martin-LÃ¶f's type theory (cite:martin1984intuitionistic).
   {{{joost(Really\, who are you writing for? I guess we can assume that all
   professor (and thus\, intended readers) know what intuitionistic logic is.
   However\, ML type theory and dependent types need explanation. So this sentence
   is in need of some more context\, pointers and or explanation.)}}} Agda's
   constructive nature suggests that a fitting way start the introduction is
   through the BHK interpretation of intuitionistic logic
   (cite:sep-intuitionistic-logic-development). We start with propositional logic
   and later on (Section [[sec:bhk-fol]]) we continue with first order logic.

   The BHK interpretation states that:
   1. A proof of $Aâ†’B$ is an algorithm that transforms an arbitrary proof of $A$
      into a proof of $B$;
   2. A proof of $Aâˆ§B$ is a proof of $A$ and a proof of $B$;
   3. A proof of $Aâˆ¨B$ is an algorithm telling to which of $A$ or $B$ we commit to
      and according to that, a proof of $A$ or a proof of $B$;
   4. Nothing is a proof of $âŠ¥$;
   5. $âŠ¤$ is always true and provable.

   According to the BHK interpretation a proof of $Aâ†’A$ is an algorithm
   implementing the identity function. We can express this algorithm in Agda by
   writing the identity lambda term {{{joost(So this is exactly why one
   other student missed a lot of points. I know that the formal language of Agda
   (what is that called?) is very extensive. However\, you should formally specify
   your language or at least chunks of it. What are your symbols\, constructors\,
   etc. Reading conventions\, etc. It is BAD PRACTICE to have the reader distil
   this from the practice\, text\, examples and context. I know many introductions
   to type theory and proof assistants get this actually wrong. Please\, be more
   precise and formal. Part of your assignment is showing that you have learned
   this competence in our master. What are the terms? How are they inductively
   defined? What is your alphabet\, etc.)}}}:
   #+begin_src text
   Î» a â†’ a
   #+end_src
   {{{joost(full stop?)}}} {{{jan(I prefer not to put stops since they are not
   part of Agda's syntax and it may be confusing to insert them.)}}} See that we
   use the structure =Î» argâ‚ argâ‚‚ â€¦ â†’ term= to define lambda functions. The
   previous term is valid. However, in Agda we must give a name to all the terms
   that we define so we can refer to them in other parts of our code. We will
   name our term =id=:
   #+begin_src text
   id = Î» a â†’ a
   #+end_src
   When the term that we are defining is a lambda term, we are allowed to move
   the arguments to the left of the === sign. Furthermore, we should write the
   type {{{joost(what are types? Where do they historically come from? How are
   types defined in Agda? Again\, provide a formal definition of correct
   types)}}} of the function using the =:= symbol. The =:= symbol denotes the
   typing relation{{{joost(a relation between wellformed types and wellformed
   terms?)}}}, hence =a : A= reads as ``term =a= has type =A=''. Sometimes we
   also say that ``the term =a= is a proof of =A=''.
   #+begin_src text
   id : A â†’ A
   id a = a
   #+end_src
   {{{joost(How to parse the last line? Maybe say that we write â€id aâ€ instead of
   id(a) and that function application goes before =. Do we have both
   term-equality and type equality? What about equality?)}}} The previous
   function is only valid if the type =A= has been defined. Since our intention
   is that it {{{joost(what?)}}} should work for any type, we should rewrite it
   to be polymorphic {{{joost(ou cannot expect the reader to know what
   polymorphism is. This should be properly introduced. I would encourage you to
   rethink the setup of this chapter. You will be judged on your ability to apply
   logical techniques to exposing a field and clearly transmit ideas and concepts
   using crystal-clear definitions. Your current exposition is too informal and
   along the way. If I were in the jury â€“ which I willâ€“ I would be annoyed by
   it.)}}}. We can do that by declaring a type variable =A=. We can do this by
   adding an extra argument of the form =(A : Set)=. We see that =A= has type
   =Set=, which is the Agda word for type {{{joost(The new reader will be lost
   here. So we have concrete types? And we have type variables of type type? Does
   Set itself have a type? Please\, rethink your presentation.)}}}. Named
   arguments can be referenced in the right part of the =â†’=, thus we can write
   {{{joost((mention right-associativity of the arrow (is it called as
   such?)))}}}:
   #+begin_src text
   id : (A : Set) â†’ A â†’ A
   id A a = a
   #+end_src
   Since the argument named =A= will always be the type of the second argument
   {{{joost(second argument of what? of the polymorphic identity? Will the
   polymorphic version receive the same name?)}}}, we can infer its value and
   thus it is recommended to use an implicit argument (see Section
   [[sec:agda-implicit-args]]).
   #+begin_src text
   id : {A : Set} â†’ A â†’ A
   id a = a
   #+end_src
   {{{joost(the reader should be dizzy here: we have defined id using a lambda
   term\, then there are some schemes that follow the format (i deduce\, if
   correct this must be made explicit) type declaration\, term definition. Can we
   all give them the same name? Or should we understand that we erase the
   previous definition and replace it with a new one?)}}} With the technicalities
   out of the way, we can finally say that we have completed our first Agda proof
   of $Aâ†’A$ according to the BHK interpretation by implementing and typing the
   identity function in Agda. {{{joost(What does it mean to have a proof in
   Agda? Note that A to A is a type.... Be precise please. It may be a good place
   to mention the Curry Howard iso? Anyways\, do it in a structured fashion.)}}}

   Let us see another example involving functions[fn::The =â†’= function symbol has
   right associativity.].
   #+begin_src text
   commute : {A B C : Set} â†’ (A â†’ B â†’ C) â†’ B â†’ A â†’ C
   commute f b a = f a b
   #+end_src
   We see that =commute= has three arguments, namely =f : A â†’ B â†’ C=, =b : B= and
   =a : A=. Then in the right hand side of the === sign we have =f a b=, which
   should read as ``term =f= applied to =a= and =b='' {{{joost(It is good to
   recall this and I would leave it here. But, there should be another structure
   of this section. Maybe something like: basic ideas (what are types, terms,
   etc.), syntax, reading conventions (left associativity of application, right
   associativity of implication/abstraction), computation, etc.)}}}. Notice how
   function application is denoted by simple juxtaposition.

   Let us now put our attention on proofs that revolve around conjunction. For
   instance, let us prove that $Aâˆ§ B â†’ B âˆ§ A$. {{{joost(Again\, you mean ğ´ âˆ§ ğµ â†’ ğµ
   âˆ§ ğ´ as proposition? Or as type? What does it mean to prove something in
   Agda?)}}} In order to represent $Aâˆ§B$ in Agda we need to define a so called
   /product type/. A product type is in rough terms the type of a tuple. Consider
   the following pair definition:
   #+begin_src text
 data _Ã—_ (A B : Set) : Set where
   _,_ : A â†’ B â†’ A Ã— B
   #+end_src
   {{{joost(Help\, what is this syntax? What is the iterated â€:â€ supposed to
   mean? Is â€dataâ€ part of predefined syntax? Or is it a name? What about the
   bars? So\, we are now seeing something new? This is no longer of the format
   â€type declaration\, term definition of the corresponding typeâ€? We are
   defining new types? So this is another functionality of Agda? What of the
   things exposed here form part of the type constructors? We classic logicians
   get lost by so much computer science implicitness.)}}} This definition defines
   a new datatype {{{joost(help\, Help\, HELP\, HEEEELLP!!!!! All of a sudden
   there are datatypes? So\, they are different from types?)}}}called =_Ã—_= with
   parameters =(A B : Set)=. Datatypes with parameters are called parameterized
   datatypes. Parameters are shared among all constructors {{{joost(What does
   this sentence mean?)}}} . It has a single constructor named =_,_=. Underscores
   are used to denote infix operators. We see that the type of the constructor
   =_,_= is =A â†’ B â†’ A Ã— B=. {{{joost(So underscore times underscore A B is the
   same as A times B?)}}} This tells us that =_,_= is a constructor that takes an
   argument of type =A= (or a proof of =A=), an argument of type =B= and then
   returns a term of type =A Ã— B=. A constructor is a special kind of function
   {{{joost(from types to types?)}}} that is used to build terms of their
   corresponding datatype. When we /pattern match/ (or deconstruct) a term we
   will have a case for each possible constructor of the type of that term.

   Let us give a proof of the theorem $Aâˆ§ B â†’ B âˆ§ A$:
   #+begin_src text
   swap : {A B : Set} â†’ A Ã— B â†’ B Ã— A
   swap (a , b) = b , a
   #+end_src
   {{{joost(Why are there parenthesis on the left of the equality sign and not on
   the right?)}}} Note that we used pattern matching to deconstruct the term and
   access the components of the pair. For the =_Ã—_= type we only have one
   constructor so we only need one case.
   # Refer to Section [[sec:agda-datatype]] for more details on data type definition
   # and pattern matching.

   Let us show some more examples:
   #+begin_src text
   p1 : {A B : Set} â†’ A â†’ B â†’ A Ã— B
   p1 a b = a , b

   p2 : {A B : Set} â†’ A Ã— B â†’ A
   p2 (a , b) = a

   p3 : {A B C : Set} â†’ (A â†’ B â†’ C) â†’ (A Ã— B) â†’ C
   p3 f (a , b) = f a b

   p4 : {A B C : Set} â†’ ((A Ã— B) Ã— C) â†’ (A Ã— (B Ã— C))
   p4 ((a , b) , c) = a , (b , c)
   #+end_src
   {{{joost(maybe you can give informative names to the defined terms? Like
   â€Curryingâ€ for p1\, â€Projectionâ€ for p2? etc. Why are there parenthesis in p2
   but not in p1? Also\, in p3 and p4 one could have added parenthesis. Say when
   we may omit them.)}}} Now that we are familiarized with conjunction and
   product types we can proceed by exploring disjunction. In order to express
   options we can define a new datatype called sum type thus:
   #+begin_src text
 data _âŠ_ (A B : Set) : Set where
   injâ‚ : A â†’ A âŠ B
   injâ‚‚ : B â†’ A âŠ B
   #+end_src
   We see that the main difference with respect to the pair type is that now we
   have two constructors {{{joost(I think you can somewhere include a general
   discussion on constructors. What are they\, what do they? What is their syntax
   and use?)}}} which we named =injâ‚= and =injâ‚‚=. The constructor =injâ‚= is used
   to build a proof of =A âŠ B= by providing a proof of =A=. The constructor
   =injâ‚‚= builds a proof of =A âŠ B= given a proof of =B=.

   Since we have two constructors, when pattern matching against an argument of
   this type we will need to define two cases (if we want to access its
   contents). See as an example the following theorems {{{joost(theorems? who
   heard theorems? what are theorems?)}}}:
   #+begin_src text
   p1: {A B : Set} â†’ A âŠ B â†’ B âŠ A
   p1 (injâ‚ a) = injâ‚‚ a
   p1 (injâ‚‚ b) = injâ‚ b

   p2 : {A B : Set} â†’ A âŠ B â†’ (A â†’ C) â†’ (B â†’ C) â†’ C
   p2 (injâ‚ a) f g = f a
   p2 (injâ‚‚ b) f g = g b
   #+end_src
   {{{joost(Note that you have already defined p1 and p2. Are you overwriting
   them?)}}} The reader may have raised the following question in their mind:
   what if we leave out a case for the sum type? {{{joost(What do you mean? In
   defining a term for a non-inhabited type I guess\, but that is not clear from
   what you write.)}}} In other words, is the following definition acceptable?
   #+begin_src text
   wrong : {A B : Set} â†’ A âŠ B â†’ A
   wrong : (injâ‚ a) = a
   #+end_src
   The answer is no. Agda rejects it as it requires all of the definitions to be
   exhaustive, otherwise it would not be a sound system.

   We proceed with $âŠ¥$. We can define a datatype which we call /bottom type/ or
   /empty type/.
   #+begin_src text
   data âŠ¥ : Set where
   #+end_src
   Notice that =âŠ¥= has no constructors and hence it is impossible to construct a
   term with type =âŠ¥=. The bottom type is specially useful to define negation,
   which we define in the following way:
   #+begin_src text
   Â¬ : Set â†’ Set
   Â¬ A = A â†’ âŠ¥
   #+end_src
   The principle of explosion {{{joost(Allauakbar\, what is this principle?)}}}
   can be trivially proved as shown below. Agda uses =()= to denote the empty or
   impossible pattern.
   #+begin_src text
   explosion : {A : Set} â†’ âŠ¥ â†’ A
   explosion ()
   #+end_src
   {{{joost(I feel I need some extra explanation here. So explosion () is a term
   of type A. Where is that A reflected in the term? Should explosion not have two
   arguments here?)}}} Since the =âŠ¥= type has no constructors, we get the empty
   pattern when pattern matching against the argument of type =âŠ¥=.

   As we are in an intuitionistic logic the following properties are not
   provable[fn::See that we use the symbol =Â¬= in the name of the term =Â¬Â¬elim=.
   Here the =Â¬= symbol is just part of the name and serves the same purpose of
   any other character. Hence it is important to note that =Â¬a= (just a name with
   the =Â¬= character) is different from =Â¬ a= (the negation of =a=).]:
   #+begin_src text
   Â¬Â¬elim : {A : Set} â†’ Â¬ (Â¬ A) â†’ A
   Â¬Â¬elim = ?             -- not provable

   excluded-middle : {A : Set} â†’ A âŠ (Â¬ A)
   excluded-middle = ?    -- not provable
   #+end_src
   However, we can show that $Â¬Â¬Â¬Aâ†’Â¬A$:
   #+begin_src text
   Â¬Â¬Â¬elim : {A : Set} â†’ Â¬ (Â¬ (Â¬ A)) â†’ Â¬ A
   Â¬Â¬Â¬elim Â¬Â¬Â¬a a = Â¬Â¬Â¬a (Î» Â¬a â†’ Â¬a a)
   #+end_src
   It might help the reader to see that =Â¬ (Â¬ (Â¬ A)) â†’ Â¬ A = (((A â†’ âŠ¥) â†’ âŠ¥) â†’ âŠ¥)
   â†’ A â†’ âŠ¥=. {{{joost(Give the reader some more explanation. What is the lambda
   doing there? How does this work? Maybe compare it with a proof in ND (natural
   deduction) of the corresponding proposition?)}}}

   Some more examples:
   #+begin_src text
   p1 : {A B : Set} A â†’ Â¬ A â†’ B
   p1 a Â¬a = explosion (Â¬a a)
   #+end_src
   {{{joost(Are we overwriting p1 again? Again\, how do we see that explosion
   generates something of type B?)}}}

   We finally climb to the $âŠ¤$ by defining a datatype which we call the
   /unit type/.
   #+begin_src text
   data âŠ¤ : Set where
     tt : âŠ¤
   #+end_src
   We see that this type has a single constructor (=tt=) with no parameters, hence there
   only exists one term with this type, namely =tt=. Some examples:
   #+begin_src text
   âŠ¤âŠ¤ : âŠ¤ Ã— âŠ¤
   âŠ¤âŠ¤ = tt , tt

   Â¬Â¬âŠ¤ : Â¬ (Â¬ âŠ¤)
   Â¬Â¬âŠ¤ Â¬âŠ¤ = Â¬âŠ¤ tt
   #+end_src
   {{{joost(What is the purpose of those examples? Make that clear: we prove
   theorems about Top here)}}} This concludes the first part of the introduction.

*** Booleans and case analysis
    <<sec:agda-bool>> The /true or false/ concept is ubiquitous in computer
    science and in logic. In this section we show how we can define a datatype
    that represents this dichotomy and we give a small introduction to
    case analysis through pattern matching.

    In Agda we can define the =Bool= type in a similar fashion to the
    disjunction type we defined before.
    #+begin_src text
    data Bool : Set where
      true : Bool
      false : Bool
    #+end_src
    As a simple example, see how we can define the =not= and =and= Boolean
    operators using pattern matching:
    #+begin_src text
    not : Bool â†’ Bool
    not false = true
    not true = false

    and : Bool â†’ Bool â†’ Bool
    and false b = false
    and true b = b
    #+end_src
    We proceed by defining equality for the =Bool= type[fn::This definition is
    just for illustrative purposes. It is possible to define polymorphic equality
    as described in Section [[sec:agda-equality]].]. We use the symbol
    =â‰¡= because === is reserved for Agda.
    #+begin_src text
 data _â‰¡_ : Bool â†’ Bool â†’ Set where
   tâ‰¡t : true â‰¡ true
   fâ‰¡f : false â‰¡ false
    #+end_src
    We see that the type of =_â‰¡_= is =Bool â†’ Bool â†’ Set=. We say that =_â‰¡_= is an
    /indexed datatype/, in this case with two =Bool= indices. In contrast to
    parameters (recall the definitions of =_Ã—_= and =_âŠ_=) which are shared among
    all constructors, indices are specified on a constructor basis.

    Let us prove the following property:
    #+begin_src text
    notnot : (b : Bool) â†’ not (not b) â‰¡ b
    notnot true = tâ‰¡t
    notnot false = fâ‰¡f
    #+end_src
    There are a number of things that are worth mentioning. First, we see that we
    refer to =b= on the returning result =not (not b) â‰¡ b=, which is possible in
    virtue of dependent types. Then we see that we pattern match on =b= and thus
    we need to fill out two cases. We could make an analogy with a hand written
    proof by cases. The case split with pattern matching allows Agda to know via
    /normalization/ that in the =true= case we must provide a term (proof) of
    type =true â‰¡ true=, which we can provide using the =tâ‰¡t= constructor. We
    proceed analogously in the =false= case. Agda normalizes the terms when
    possible, for instance the term =not (not b)= is already normalized because
    we cannot apply any rule. On the other hand the term =not (not true)= can be
    normalized to =not false= and further normalized to =true= by using the
    definition of =not=. For further information on normalization refer to
    cite:norell:thesis. Another thing to notice is that we use the same
    construction (i.e. an Agda function definition) to provide function definitions,
    like =not=, and theorems, like =notnot=.

    Pattern matching (case analysis) is ubiquitous in Agda, be it in definitions
    or in proofs. We show some more examples below:
    #+begin_src text
    p1 : (b : Bool) â†’ and false b â‰¡ false
    p1 b = fâ‰¡f

    p2 : (b : Bool) â†’ and b false â‰¡ false
    p2 true = fâ‰¡f
    p2 false = fâ‰¡f
    #+end_src
    See that in the first case we did not need to do pattern matching while in
    the second we had to. This is due to how the definition of =and= is written
    which in our case performs pattern matching on the first argument.
*** Naturals and induction
    <<sec:agda-nat>>
    In this section we will have a look at the simplest possible recursive
    structure, the natural numbers. In Agda natural numbers can be defined in the
    following way:
    #+begin_src
    data Nat : Set where
      zero : Nat
      suc : Nat â†’ Nat
    #+end_src
    The definition should be intuitive enough for the reader at this point. We
    can represent the number $1$ with the term =suc zero=, the number $2$ with
    =suc (suc zero)= and so on.

    Let us continue by defining the equality relation for natural
    numbers[fn::Agda does not allow overloading of symbols so we would need to
    use a different name other than =_â‰¡_= to avoid the clash with the equality relation
    of Booleans that we defined before.].
    #+begin_src text
    data _â‰¡_ : Nat â†’ Nat â†’ Set where
      zâ‰¡z : zero â‰¡ zero
      sâ‰¡s : {a b : Nat} â†’ a â‰¡ b â†’ suc a â‰¡ suc b
    #+end_src
    We see that it has a similar structure to the datatype for Boolean equality.
    The only difference is that the =sâ‰¡s= constructor requires a proof of =a â‰¡ b=
    as an argument. Let us show that every natural number is equal to itself.
    #+begin_src text
    refl : (n : Nat) â†’ n â‰¡ n
    refl zero = zâ‰¡z
    refl (suc n) = sâ‰¡s (refl n)
    #+end_src
    We see that we pattern match on =n=, for the =zero= case we give the =zâ‰¡z=
    constructor. For the =suc= case we need to provide a proof of =suc n â‰¡ suc
    n=. By performing a recursive call with =n= as argument we get a proof of =n
    â‰¡ n=, then we can use the constructor =sâ‰¡s= to build a term of type =suc n â‰¡
    suc n=. It can be enlightening to observe that in a proof by induction, such
    as the previous one, a recursive call plays the role of an induction
    hypothesis.

    An inexperienced Agda user might try the following:
    #+begin_src text
    refl' : (n : Nat) â†’ n â‰¡ n
    refl' zero = zâ‰¡z
    refl' (suc n) = refl' (suc n)
    #+end_src
    While the types match we see that in the inductive case we perform a
    recursive call on the same argument and thus we get an infinite loop. Agda
    has a termination checker that rejects proofs where termination cannot be
    assured and thus rejects the previous definition. We know that termination is
    an undecidable problem hence it is inevitable that Agda will reject some
    programs that in fact would always terminate. For more information on Agda's
    termination checker refer to cite:norell:thesis,agda-doc.

    We now define addition on natural numbers:
    #+begin_src text
    _+_ : Nat â†’ Nat â†’ Nat
    zero + b = b
    (suc a) + b = suc (a + b)
    #+end_src

    Proving associativity can be achieved by means of an inductive proof
    following a similar structure as before. For the base case we use the =refl=
    property proved above.
    #+begin_src text
 assoc : (a b c : Nat) â†’ (a + b) + c â‰¡ a + (b + c)
 assoc zero b c = refl (b + c)
 assoc (suc a) b c = sâ‰¡s (assoc a b c)
    #+end_src

    Consider the following example involving negation. Keep in mind that =Â¬ (n â‰¡
    suc n) = n â‰¡ suc n â†’ âŠ¥=.
    #+begin_src text
    p1 : (n : Nat) â†’ Â¬ (n â‰¡ suc n)
    p1 zero ()
    p1 (suc n) (sâ‰¡s x) = p1 n x
    #+end_src
    For the base case we have the impossible pattern because when =n = zero= the
    second argument is supposed to have the type =zero â‰¡ suc zero= which is not
    unifiable with any type of a constructor and thus we get the empty pattern.
    For more information on Agda unification refer to cite:norell:thesis.

    Finally, let us focus on proving commutativity of addition, which is a more
    involved example. We first prove transitivity of equality, which is proved by
    an easy induction.
    #+begin_src text
 trans : {a b c : Nat} â†’ a â‰¡ b â†’ b â‰¡ c â†’ a â‰¡ c
 trans zâ‰¡z zâ‰¡z = zâ‰¡z
 trans (sâ‰¡s x) (sâ‰¡s y) = sâ‰¡s (trans x y)
    #+end_src
    Notice how there are two missing cases, that is, =zâ‰¡z= with =sâ‰¡s= and vice
    versa. We are allowed to do that because Agda was able to
    detect the empty pattern. We could have also omitted the =p1 zero ()= case in
    the theorem above.

    We proceed by proving two lemmas by an easy induction:
    #+begin_src text
 zero-r : (a : Nat) â†’ a â‰¡ (a + zero)
 zero-r zero = zâ‰¡z
 zero-r (suc a) = sâ‰¡s (zero-r a)

 suc-r : (a b : Nat) â†’ suc (a + b) â‰¡ (a + suc b)
 suc-r zero b = refl (suc b)
 suc-r (suc a) b = sâ‰¡s (suc-r a  b)
    #+end_src

    At last, we put all the pieces together to prove our theorem:
    #+begin_src text
 +commut : (a b : Nat) â†’ (a + b) â‰¡ (b + a)
 +commut zero b = zero-r b
 +commut (suc a) b = trans (sâ‰¡s (+commut a b)) (suc-r b a)
    #+end_src
    For the base case we must prove =0 + b â‰¡ b + 0= which normalizes to =b â‰¡ b +
    0= and then we can use our =zero-r= lemma. For the inductive case we must
    prove =suc a + b â‰¡ b + suc a= which normalizes to =suc (a + b) â‰¡ b + suc a=.
    By IH we know that =a + b â‰¡ b + a= so by =sâ‰¡s= we get =suc (a + b) â‰¡ suc (b +
    a)=. Then by our lemma =suc-r= we get =suc (b + a) â‰¡ b + suc a=. Finally by
    transitivity we get the desired =suc (a + b) â‰¡ b + suc a=.

    We hope that at this point the user has a grasp of how properties can be
    proved in Agda.

    # To summarize, we outline the usual course of action when we
    # want to prove a theorem.
    # 1. We define the datatypes and functions that represent our relations,
    #    operators, assumptions and so on. Usually there are multiple
    #    routes that we can take, and it is important to implement definitions in a
    #    way that they are easy to work with.
    # 2. We prove intermediary lemmas...
    # 3. The type of a function can represent a mathematical proposition.
    # 4. The term
*** Universe hierarchy
    <<sec:universe-hierarchy>> In Agda every well-typed term is assigned a type.
    For instance, the type of =true= is =Bool= and the type of =0= is =Nat=. As
    we have seen before, in a dependent type theory we are allowed to mix types
    and terms, hence =Nat= is a term in itself and must be assigned a type. Agda
    calls the type of (small) types =Set=, hence we have that =Nat= has type
    =Set=. But then =Set= is also a term an must be assigned a type as well.
    Could we have that the type of =Set= is =Set=? No. The first version of
    Martin-LÃ¶fâ€™s type theory (cite:martin-lof-1971a) had an axiom stating that
    there is a type of all types and thus we would have that the type of =Set= is
    =Set=. However Girard showed (cite:sep-type-theory-intuitionistic) that
    having =Set : Set= allowed the Burali-Forti paradox[fn::The assumption that
    there is a set of all ordinal numbers leads to a contradiction.] to be
    encoded in the theory, and thus the relation =Set : Set= needs to be
    rejected. In order to avoid such inconsistency Agda builds a hierarchy of
    universes where small types such as =Nat= and =Bool= are assigned the type
    =Set 0= and then for every $iâˆˆÏ‰$ we have that =Set i : Set i+1=. Notice
    however, that =Set i : Set i+1= is true while =Set i : Set i+n= does not hold
    for $n>1$. In Agda we write =Set= instead of =Set 0=. When the level is a
    constant natural number we can also write =Setâ‚=, =Setâ‚‚=, etc. instead of
    =Set 1=, =Set 2=, etc.

    It is possible to combine types of different universe levels. The biggest type
    is the one that counts. For instance:
    #+begin_src text
    function : Setâ‚ƒ â†’ Setâ‚ â†’ Setâ‚ƒ
    function A B = A â†’ B
    #+end_src
    The typing rule is analogous for product and sum types.

    Agda provides a primitive[fn::/primitive/ means that it is built in the
    language and it cannot be defined by the user.] type for universe levels called
    =Level=. Essentially it is the same as =Nat= (we have =lzero= for the base
    level and =lsuc= for the successor level), but it is designed to work as a universe
    index. Having the =Level= type allows us to write universe polymorphic
    functions. See the same function as before, but now with universe
    polymorphism.
    #+begin_src text
    function' : {a b : Level} â†’ Set a â†’ Set b â†’ Set (a âŠ” b)
    function' A B = A â†’ B
    #+end_src
    The =_âŠ”_= operator is a primitive operator of type =Level â†’ Level â†’ Level=
    that normalizes to the the maximum of its two operands.

    Most of the functions that we have defined before should be rewritten to be
    universe polymorphic if possible. For instance, we can now rewrite the
    identity function thus:
    #+begin_src text
    id : {a : Level} {A : Set a} â†’ A â†’ A
    id a = a
    #+end_src

    In the most recent version of Agda (2.6.1) there is an option to enable
    /universe cumulativity/ (cite:agda-doc). This extension adds the typing rule
    $Setáµ¢:Setâ±¼$ for $i<j$. Hence it allows us to write the following:
    #+begin_src text
    a : Set              -- always allowed
    a = Nat
    b : Setâ‚             -- only with cumulativity
    b = Nat
    c : {i : Level} â†’ Set i    -- only with cumulativity
    c = Nat
    #+end_src
    In our project we have not used this extension.

*** BHK interpretation of first order logic
    <<sec:bhk-fol>>
    <<sec:predicates>>

    We extend the interpretation that we gave before to include the universal and
    existential quantifiers (cite:sep-intuitionistic-logic-development):
    1. A proof of $âˆ€x.P(x)$ is a function that given an arbitrary element $c$ in
       the domain, builds a proof that $c$ satisfies $P$.
    2. A proof of $âˆƒx.P(x)$ is a witness $c$ in the domain and a proof that $c$
      satisfies $P$.
    Before diving into quantifiers we first discuss how to represent relations in
    Agda. Recall the equality relation for natural numbers =_â‰¡_= that we defined
    before. Its type is =Nat â†’ Nat â†’ Set=. Let us say that we want to define a
    generic type =REL= for relations on any type. A first attempt could be:

    #+begin_src text
 REL : Set â†’ Set â†’ Setâ‚
 REL A B = A â†’ B â†’ Set
    #+end_src

    This first definition is somewhat limited. Recall that =Set = Set 0=, thus we
    restrict =A= and =B= to be small types, furthermore, we require the relation
    to be a small type as well. If we make our =REL= definition universe
    polymorphic it turns out like this.\glsadd{REL}
    #+begin_src text
 REL : {a b : Level} â†’ Set a â†’ Set b â†’ (â„“ : Level) â†’ Set (a âŠ” b âŠ” lsuc â„“)
 REL A B â„“ = A â†’ B â†’ Set â„“
    #+end_src
    This is the definition used in the Agda standard library (cite:agda-stdlib)
    and is the one that we use in our project.

    For homogeneous relations we use the name =Rel=:\glsadd{Rel}
    #+begin_src text
 Rel : {a : Level} â†’ Set a â†’ (â„“ : Level) â†’ Set (a âŠ” lsuc â„“)
 Rel A â„“ = REL A A â„“
    #+end_src

    By using these new definitions we could have defined the type of =_â‰¡_= thus
    (observe that =Rel Nat lzero= normalizes to =Nat â†’ Nat â†’ Set=):
    #+begin_src text
    data _â‰¡_ : Rel Nat lzero where
      ... -- same as before
    #+end_src

    \glsadd{Pred}
    In a similar way we can define predicates:
    #+begin_src text
    Pred : {a : Level} â†’ Set a â†’ (â„“ : Level) â†’ Set (a âŠ” lsuc â„“)
    Pred A â„“ = A â†’ Set â„“
    #+end_src

    We proceed by giving a representation of the universal quantifier:
    #+begin_src text
 data âˆ€[_] {a â„“ : Level} (A : Set a) (P : Pred A â„“) : Set (a âŠ” â„“) where
   proofâˆ€ : ((a : A) â†’ P a) â†’ âˆ€[ A ] P
    #+end_src
    The definition is straightforward. In fact this datatype is just a wrapper
    for a function of type =(a : A) â†’ P a=.

    For instance, let us prove that every successor of a natural number is
    different than zero:
    #+begin_src text
 aux : (n : Nat) â†’ Â¬ (suc n â‰¡ zero)
 aux n ()

 sâ‰ z : âˆ€[ Nat ] (Î» n â†’ Â¬ (suc n â‰¡ zero))
 sâ‰ z = proofâˆ€ aux
    #+end_src
    Alternatively we could have written a shorter version that does not use an
    auxiliary lemma.
    #+begin_src text
 sâ‰ z : âˆ€[ Nat ] (Î» n â†’ Â¬ (suc n â‰¡ zero))
 sâ‰ z = proofâˆ€ Î» {n ()}
    #+end_src
    Proving \text{$âˆ€$-elimination} (if $âˆ€x.P(x)$ and $c$ is in the domain then
    $P(c)$) is straightforward:
    #+begin_src text
    âˆ€-elim : {a â„“ : Level} {A : Set a} {P : Pred A â„“} â†’ âˆ€[ A ] P â†’ (a : A) â†’ P a
    âˆ€-elim (proofâˆ€ f) a = f a
    #+end_src

    We now move on to the existential quantifier. Recall that according to the
    BHK interpretation a proof $âˆƒx.P(x)$ is an element $c$ of the domain and a
    proof that $P(c)$. The first plan could be to use the pair type we defined
    before to contain the needed elements. We repeat the definition here:
    #+begin_src text
 data _Ã—_ (A B : Set) : Set where
   _,_ : A â†’ B â†’ A Ã— B
    #+end_src
    The problem is that the type of the second component, =B=, is independent of
    the first component and thus we cannot express what we need. Here is where
    the $Î£$ type (or \gls*{dependent-pair}) comes into play. A
    dependent pair is a structure where the type of the second component depends
    on the value of the first component. This concept is defined by the following
    datatype.
    #+begin_src text
 data Î£ {â„“ â„“' : Level} (A : Set â„“) (B : A â†’ Set â„“') : Set (â„“ âŠ” â„“') where
   _,_ : (a : A) â†’ B a â†’ Î£ A B
    #+end_src
    Proving \text{$âˆƒ$-introduction} is trivial:
    #+begin_src
    âˆƒ-intro : {â„“ â„“' : Level} {A : Set â„“} {P : A â†’ Set â„“'}
      â†’ (a : A) â†’ P a â†’ Î£ A P
    âˆƒ-intro a p = a , p
    #+end_src
    We now show that $âˆ€x(P(x))â‡’Â¬âˆƒx(Â¬P(x))$.
    #+begin_src text
    p1 : {â„“ â„“' : Level} {A : Set â„“} {P : A â†’ Set â„“'}
      â†’ âˆ€[ A ] P â†’ Â¬ (Î£ A (Î» x â†’ Â¬ (P x)))
    p1 (proofâˆ€ f) (c , b) = b (f c)
    #+end_src
    Our goal is to give a term of type =âŠ¥=. We have that =f= has type =(a : A) â†’
    P a= so =f c= has type =P c=, then =b= has type =Â¬ (P c)= which is the same
    as =P c â†’ âŠ¥=, thus by applying =b= to =(f c)= we get a term of type =âŠ¥=.

    Of course, as we are in an intuitionistic logic we cannot show
    the other direction, namely $Â¬âˆƒx(Â¬P(x))â‡’âˆ€x(P(x))$.

    *A note on syntax*. The reader may find the $Î£$ syntax a bit too different
    from the usual existential notation: $âˆƒx(Px)$. We can fix that thanks to
    Agda's syntax versatility. Agda provides a tool to define custom syntax.
    Below we show how we can use that tool to improve the syntax of $Î£$ pairs. We
    will not go into more detail since this feature is of shallow mathematical
    interest.
    #+begin_src text
 Î£-syntax : {â„“ â„“' : Level} â†’ (A : Set â„“) â†’ (A â†’ Set â„“') â†’ Set (â„“ âŠ” â„“')
 Î£-syntax = Î£
 syntax Î£-syntax A (Î» x â†’ B) = Î£[ x âˆˆ A ] B
    #+end_src
    With this syntax enhancement we can replace =Î£ A (Î» c â†’ P c)= by =Î£[ c âˆˆ A ] (P c)=.
    The previous theorem becomes:
    #+begin_src text
    âˆƒ-intro : {â„“ â„“' : Level} {A : Set â„“} {P : A â†’ Set â„“'}
      â†’ (a : A) â†’ P a â†’ Î£[ c âˆˆ A ] (P c)
    #+end_src
    There is a variation of this notation which omits the type of the variable as
    it can be inferred in many cases. That is, instead of =Î£[ c âˆˆ A ] (P c)= we
    would have =âˆƒ[ c ] (P c)=. We prefer this notation when possible in the
    project[fn::For instance, in the definition of Veltman semantics in Section
    [[sec:agda-ord-semantics]].]. See again the =âˆƒ-intro= theorem type using this
    notation:
    #+begin_src text
    âˆƒ-intro : {â„“ â„“' : Level} {A : Set â„“} {P : A â†’ Set â„“'}
      â†’ (a : A) â†’ P a â†’ âˆƒ[ c ] (P c)
    #+end_src

*** Equality
    <<sec:agda-equality>>

    In Sections [[sec:agda-nat]] and [[sec:agda-bool]] we have seen how we can define
    equality for Booleans and naturals. In this section we explore polymorphic
    equality and some of its properties and limitations. Of course, the main
    advantage of polymorphic equality is that we can use it for every type and
    thus there is no need to redefine it for every new datatype that we
    define.

    Below we present a slight simplification of polymorphic equality as defined in
    cite:agda-stdlib.
    #+begin_example
 data _â‰¡_ {a : Level} {A : Set a} (x : A) : A â†’ Set a where
   refl : x â‰¡ x
    #+end_example

    It may help the reader to read the following description of the polymorphic
    equality datatype defined above taken from cite:plfa2019: For any type =A=
    and for any =x= of type =A=, the constructor =refl= provides evidence that =x
    â‰¡ x=. Hence, every value is equal to itself, and we have no other way of
    showing values equal. The definition features an asymmetry, in that the first
    argument to =_â‰¡_= is given by the parameter =x : A=, while the second is
    given by an index in =A â†’ Set a=. The first argument to =_â‰¡_= can be a
    parameter because it does not vary, while the second must be an index, so it
    can be required to be equal to the first.

    It is easy to see that equality is a reflexive relation.
    #+begin_src text
 reflexive : {â„“ : Level} {A : Set â„“} {a : A} â†’ a â‰¡ a
 reflexive = refl
    #+end_src
    We can also show that it is symmetric.
    #+begin_src text
 symmetric : {â„“ : Level} {A : Set â„“} {a b : A} â†’ a â‰¡ b â†’ b â‰¡ a
 symmetric aâ‰¡b = ?
    #+end_src
    The argument =aâ‰¡b= has type =a â‰¡ b= and our goal is to give a term of type =b
    â‰¡ a=. However, the only way to give a term of type =b â‰¡ a= is by unifying =a=
    and =b= since we only have the =refl= constructor. We achieve that by pattern
    matching against the argument =aâ‰¡b=. Then the goal becomes =a â‰¡ a= and we can
    use the =refl= constructor.
    #+begin_src text
 symmetric : {â„“ : Level} {A : Set â„“} {a b : A} â†’ a â‰¡ b â†’ b â‰¡ a
 symmetric refl = refl
    #+end_src
    We can prove transitivity in an analogous way.
    #+begin_src text
 transitivity : {â„“ : Level} {A : Set â„“} {a b c : A} â†’ a â‰¡ b â†’ b â‰¡ c â†’ a â‰¡ c
 transitivity refl refl = refl
    #+end_src
    We can also show that if =x â‰¡ y= then for any =f= we have =f x â‰¡ f y=.
    #+begin_src text
 cong : {â„“A â„“B : Level} {A : Set â„“A} {B : Set â„“B} {x y : A}
   â†’ (f : A â†’ B) â†’ x â‰¡ y â†’ f x â‰¡ f y
 cong f refl = refl
    #+end_src

    We now see that this new equality datatype is equivalent to the previously
    defined equality for naturals. To avoid a name clash, we redefine equality
    for naturals with the =_â„•â‰¡_= symbol. We also rename reflexivity for =_â„•â‰¡_=
    as =â„•refl=.
    #+begin_src text
    data _â„•â‰¡_ : Nat â†’ Nat â†’ Set where
      zâ‰¡z : zero â„•â‰¡ zero
      sâ‰¡s : {a b : Nat} â†’ a â„•â‰¡ b â†’ suc a â„•â‰¡ suc b

    â„•refl : (n : Nat) â†’ n â„•â‰¡ n
    â„•refl zero = zâ‰¡z
    â„•refl (suc n) = sâ‰¡s (â„•refl n)
    #+end_src
    We show that the new equality implies the old equality.
    #+begin_example
    â‰¡â†’â„•â‰¡ : {a b : Nat} â†’ a â‰¡ b â†’ a â„•â‰¡ b
    â‰¡â†’â„•â‰¡ {a} refl = â„•refl a
    #+end_example
    We see that the old equality implies the new equality.
    #+begin_example
    â„•â‰¡â†’â‰¡ : {a b : Nat} â†’ a â„•â‰¡ b â†’ a â‰¡ b
    â„•â‰¡â†’â‰¡ z=z = refl
    â„•â‰¡â†’â‰¡ (s=s aâ„•â‰¡b) = cong suc (â„•â‰¡â†’â‰¡ aâ„•â‰¡b)
    #+end_example

    See Section [[sec:agda-ext]] for a note on extensionality.
*** Predicates as mathematical sets
    <<sec:sets>>
    In this section when we say /set/ we refer to a subset of an Agda type. The
    most natural way to represent subsets in Agda is to use predicates. See
    [[sec:predicates]] for an introduction. A predicate represents the characteristic
    function of the associated subset. For instance consider the predicate:
    #+begin_src text
    Pos : Pred Nat lzero
    Pos n = Â¬ (n â‰¡ 0)
    #+end_src
    It represents the subset of strictly positive natural numbers.

    We proceed by defining the usual concepts related to mathematical sets. In
    order to make the types less verbose we assume that we already have =A : Set
    â„“= in scope.
     1. \boxed{âˆˆ} A proof of membership is a simple function application.
        #+begin_src text
        _âˆˆ_ : REL A (Pred A)
        a âˆˆ X = X a
        #+end_src
        This definition is mostly superfluous but it helps to have a syntax closer
        to regular mathematics.
     2. \boxed{âˆ‰} A proof of non membership is function from a proof of membership to =âŠ¥=.
        #+begin_src text
        _âˆ‰_ : REL A (Pred A)
        a âˆ‰ X = Â¬ (a âˆˆ X)
        #+end_src
     3. \boxed{âŠ†} A proof of inclusion =X âŠ† Y= is a function that maps a proof of
        membership to =X= to a proof of membership to =Y=.
        #+begin_example
        _âŠ†_ : Rel (Pred A)
        X âŠ† Y = âˆ€ {x} â†’ x âˆˆ X â†’ x âˆˆ Y
        #+end_example
     4. \boxed{âˆ©} We use pairs to represent the intersection. Each component is a
        proof of membership to =X= and =Y= respectively.
        #+begin_src text
        _âˆ©_ : Pred A â†’ Pred A â†’ Pred A
        X âˆ© Y = Î» x â†’ x âˆˆ X Ã— x âˆˆ Y
        #+end_src
     5. \boxed{âˆª} We use a sum type to represent the union.
        #+begin_src text
        _âˆª_ : Pred A â†’ Pred A â†’ Pred A
        X âˆª Y = Î» x â†’ x âˆˆ X âŠ x âˆˆ Y
        #+end_src
     6. \boxed{âˆ…}
        The empty set is represented by a characteristic constant function to =âŠ¥=.
        #+begin_src text
        âˆ… : Pred A
        âˆ… = Î» x â†’ âŠ¥
        #+end_src
     7. \boxed{ğŸ}
        Similarly, the universe set is represented by a characteristic constant function to =âŠ¤=.
        #+begin_src text
        U : Pred A
        U = Î» x â†’ âŠ¤
        #+end_src
     8. \(\boxed{\{x\}}\) A singleton set is defined using equality (assuming we
        have equality defined for that type).
        #+begin_example
        ï½›_ï½ : A â†’ Pred A
        ï½› x ï½ = Î» y â†’ x â‰¡ y
        #+end_example

*** Extensionality
    <<sec:agda-ext>> In Set theory we call axiom of extensionality the property
    that if two sets have the same elements, then they are equal. As in Agda we
    represent sets as functions we reword extensionality for functions: if two
    functions have the same domain and coincide for every element in their domain then
    they are equal. In symbols: \[âˆ€fg.(âˆ€x.f(x)=g(x))â‡’f=g.\]

    In Agda we can represent this concept thus (cite:agda-stdlib):
    #+begin_src text
Extensionality : (a b : Level) â†’ Set _
Extensionality a b =
  {A : Set a} {B : A â†’ Set b} {f g : (x : A) â†’ B x} â†’
  ((x : A) â†’ f x â‰¡ g x) â†’ f â‰¡ g
    #+end_src

    {{{jan(give simplified version without dependent function?)}}}

    #+begin_src text
Extensionality : (a b : Level) â†’ Set _
Extensionality a b = {A : Set a} {B : Set b} {f g : A â†’ B} â†’
  ((x : A) â†’ f x â‰¡ g x) â†’ f â‰¡ g
    #+end_src
    It is usually the case that we accept the axiom of extensionality as part of
    our metalogic as it is part of the most popular logical framework
    $\textsf{ZFC}$, however, in Agda the property of extensionality is not an axiom
    nor a provable theorem.

    An direct consequence of the lack of extensionality is that we cannot show
    equality of sets by double inclusion.
    #+begin_src text
    âŠ†âŠ‡â†’â‰¡ : {â„“S â„“A : Level} {A : Set â„“A} {X Y : Pred A â„“S} â†’ X âŠ† Y â†’ Y âŠ† X â†’ X â‰¡ Y
    âŠ†âŠ‡â†’â‰¡ = ? -- not provable
    #+end_src

    We will see that this has a small effect on
    the definition of generalized Veltman frames in Section
    [[sec:agda-gen-semantics]].

*** Positivity
    <<sec:positivity>>

    In this section we present a technicality as described in the Agda
    documentation (cite:agda-doc) regarding datatype definitions that will become
    relevant in Section [[sec:agda-ord-semantics]] where we define ordinary Veltman
    semantics.

    When defining a datatype =D=, Agda poses an additional requirement on the types
    of the constructors of =D=, namely that =D= may only occur strictly positively in
    the types of their arguments. Concretely, for a datatype with constructors
    =câ‚ : Aâ‚, â€¦, câ‚™ : Aâ‚™=, Agda checks that each =Aáµ¢= has the form
    #+begin_src text
    (yâ‚ : Bâ‚) â†’ ... â†’ (yâ‚— : Bâ‚—) â†’ D
    #+end_src
    where an argument of type =Báµ¢= of the constructors does not mention =D= or has
    the form
    #+begin_example
    (zâ‚ : Câ‚) â†’ ... â†’ (zâ‚– : Câ‚–) â†’ D
    #+end_example

    The following example showcases the possibility to build a term of type =âŠ¥=
    by defining a non strictly positive type =Bad=. As mentioned above, Agda
    rejects the definition of =Bad=.
    #+begin_src text
 data âŠ¥ : Set where

 data Bad : Set where
   bad : (Bad â†’ âŠ¥) â†’ Bad

 self-app : Bad â†’ âŠ¥
 self-app (bad f) = f (bad f)

 absurd : âŠ¥
 absurd = self-app (bad self-app)
    #+end_src
** Agda official reference
   This section contains a thorough description of some of the topics that were
   touched in the introduction prior to this section. We believe that the
   intuition given in the introduction should be enough for the reader to be
   able to read Section [[sec:agda-project]], however, we encourage the reader to
   resort to the ensuing reference if they wish for more precise information on
   the language. The contents of this section have been merely copied from the
   online Agda documentation (cite:agda-doc).

*** Function definitions and pattern matching
    A function is defined by first declaring its type followed by a number of
    equations called clauses. Each clause consists of the function being defined
    applied to a number of patterns, followed by = and a term called the
    right-hand side. For example:
    #+begin_example
    not : Bool â†’ Bool
    not true  = false
    not false = true
    #+end_example
    Functions are allowed to call themselves recursively, for example:
    #+begin_example
    twice : Nat â†’ Nat
    twice zero    = zero
    twice (suc n) = suc (suc (twice n))
    #+end_example

    The general form for defining a function is
    #+begin_example
    f : (xâ‚ : Aâ‚) â†’ â€¦ â†’ (xâ‚™ : Aâ‚™) â†’ B
    f pâ‚ â€¦ pâ‚™ = d
    â€¦
    f qâ‚ â€¦ qâ‚™ = e
    #+end_example
    where =f= is a new identifier, =páµ¢= and =qáµ¢= are patterns of type =Aáµ¢=, and =d= and =e=
    are expressions.

    The declaration above gives the identifier =f= the type =(xâ‚ : Aâ‚) â†’ â€¦ â†’ (xâ‚™ :
    Aâ‚™) â†’ B= and =f= is defined by the defining equations. Patterns are matched
    from top to bottom, i.e., the first pattern that matches the actual
    parameters is the one that is used.

    By default, Agda checks the following properties of a function definition:
    1. The patterns in the left-hand side of each clause should consist only of
       constructors and variables.
    2. No variable should occur more than once on the left-hand side of a single
       clause.
    3. The patterns of all clauses should together cover all possible inputs of
       the function.
    4. The function should be terminating on all possible inputs.

*** Implicit arguments and automatic inference
    <<sec:agda-implicit-args>>

    It is possible to omit terms that the type checker can figure out for
    itself, replacing them by =_=. If the type checker cannot infer the value of
    an =_= it will report an error. For instance, for the polymorphic identity
    function
    #+begin_example
    id : (A : Set) â†’ A â†’ A
    #+end_example
    the first argument can be inferred from the type of the second argument, so
    we might write =id _ zero= for the application of the identity function to
    =zero=.

    We can even write this function application without the first argument. In
    that case we declare an implicit function space:
    #+begin_example
    id : {A : Set} â†’ A â†’ A
    #+end_example
    and then we can use the notation =id zero=.

    Another example:
    #+begin_example
    _==_  : {A : Set} â†’ A â†’ A â†’ Set
    subst : {A : Set} (C : A â†’ Set) {x y : A} â†’ x == y â†’ C x â†’ C y
    #+end_example
    Note how the first argument to =_==_= is left implicit. Similarly, we may
    leave out the implicit arguments =A=, =x=, and =y= in an application of
    =subst=. To give an implicit argument explicitly, enclose it in curly braces.
    The following two expressions are equivalent:
    #+begin_example
    x1 = subst C eq cx
    x2 = subst {_} C {_} {_} eq cx
    #+end_example
    It is worth noting that implicit arguments are also inserted at the end of
    an application, if it is required by the type. For example, in the
    following, =y1= and =y2= are equivalent.
    #+begin_example
    y1 : a == b â†’ C a â†’ C b
    y1 = subst C

    y2 : a == b â†’ C a â†’ C b
    y2 = subst C {_} {_}
    #+end_example
    Implicit arguments are inserted eagerly in left-hand sides so =y3= and =y4= are
    equivalent. An exception is when no type signature is given, in which case
    no implicit argument insertion takes place. Thus in the definition of =y5= the
    only implicit is the =A= argument of =subst=.
    #+begin_example
    y3 : {x y : A} â†’ x == y â†’ C x â†’ C y
    y3 = subst C

    y4 : {x y : A} â†’ x == y â†’ C x â†’ C y
    y4 {x} {y} = subst C {_} {_}

    y5 = subst C
    #+end_example
    It is also possible to write lambda abstractions with implicit arguments.
    For example, given =id : (A : Set) â†’ A â†’ A=, we can define the identity
    function with implicit type argument as
    #+begin_example
    idâ€™ = Î» {A} â†’ id A
    #+end_example
    Implicit arguments can also be referred to by name, so if we want to give
    the expression =e= explicitly for =y= without giving a value for =x= we can
    write
    #+begin_example
    subst C {y = e} eq cx
    #+end_example
    In rare circumstances it can be useful to separate the name used to give an
    argument by name from the name of the bound variable, for instance if the
    desired name shadows an existing name. To do this you write
    #+begin_example
    idâ‚‚ : {A = X : Set} â†’ X â†’ X  -- name of bound variable is X
    idâ‚‚ x = x

    use-idâ‚‚ : (Y : Set) â†’ Y â†’ Y
    use-idâ‚‚ Y = idâ‚‚ {A = Y}      -- but the label is A
    #+end_example

    Labeled bindings must appear by themselves when typed, so the type =Set= needs
    to be repeated in this example:
    #+begin_example
    const : {A = X : Set} {B = Y : Set} â†’ A â†’ B â†’ A
    const x y = x
    #+end_example

    When constructing implicit function spaces the implicit argument can be
    omitted, so both expressions below are valid expressions of type ={A : Set}
    â†’ A â†’ A=:
    #+begin_example
    z1 = Î» {A} x â†’ x
    z2 = Î» x â†’ x
    #+end_example
    The =âˆ€= (or =forall=) syntax for function types also has implicit variants:

    #+begin_example
    â‘  : (âˆ€ {x : A} â†’ B)    is-the-same-as  ({x : A} â†’ B)
    â‘¡ : (âˆ€ {x} â†’ B)        is-the-same-as  ({x : _} â†’ B)
    â‘¢ : (âˆ€ {x y} â†’ B)      is-the-same-as  (âˆ€ {x} â†’ âˆ€ {y} â†’ B)
    #+end_example

    In very special situations it makes sense to declare unnamed hidden
    arguments ={A} â†’ B=. In the following =example=, the hidden argument to
    =scons= of type =zero â‰¤ zero= can be solved by \text{$Î·$-expansion}, since
    this type reduces to =âŠ¤=.
    #+begin_example
    data âŠ¥ : Set where

    _â‰¤_ : Nat â†’ Nat â†’ Set
    zero â‰¤ _      = âŠ¤
    suc m â‰¤ zero  = âŠ¥
    suc m â‰¤ suc n = m â‰¤ n

    data SList (bound : Nat) : Set where
    []    : SList bound
    scons : (head : Nat) â†’ {head â‰¤ bound} â†’ (tail : SList head) â†’ SList bound

    example : SList zero
    example = scons zero []
    #+end_example
    There are no restrictions on when a function space can be implicit. Internally,
    explicit and implicit function spaces are treated in the same way. This means
    that there are no guarantees that implicit arguments will be solved. When there
    are unsolved implicit arguments the type checker will give an error message
    indicating which application contains the unsolved arguments. The reason for
    this liberal approach to implicit arguments is that limiting the use of implicit
    argument to the cases where we guarantee that they are solved rules out many
    useful cases in practice.
*** datatype definitions and constructors
    <<sec:agda-ref-datatype>>
    <<sec:agda-datatype>>

    The general form of the definition of a simple datatype =D= is the following
    #+begin_src text
  data D (xâ‚ : Pâ‚) ... (xâ‚– : Pâ‚–) : (yâ‚ : Qâ‚) â†’ ... â†’ (yâ‚— : Qâ‚—) â†’ Set â„“ where
    câ‚ : Aâ‚
    ...
    câ‚™ : Aâ‚™
    #+end_src

    The name D of the data type and the names =câ‚=, â€¦, =câ‚™= of the constructors
    must be new w.r.t. the current signature and context, and the types =Aâ‚=, â€¦,
    =Aâ‚™= must be function types ending in =D=, i.e. they must be of the form
    #+begin_example
    (yâ‚ : Bâ‚) â†’ ... â†’ (yâ‚˜ : Bâ‚˜) â†’ D
    #+end_example

    Datatypes can have parameters. They are declared after the name of the
    datatype but before the colon, for example:
    #+begin_example
    data List (A : Set) : Set where
      []  : List A
      _âˆ·_ : A â†’ List A â†’ List A
    #+end_example

    In addition to parameters, datatypes can also have indices. In contrast to
    parameters which are required to be the same for all constructors, indices
    can vary from constructor to constructor. They are declared after the colon
    as function arguments to =Set=. For example, fixed-length vectors can be
    defined by indexing them over their length of type =Nat=:

    #+begin_example
    data Vector (A : Set) : Nat â†’ Set where
      []  : Vector A zero
      _âˆ·_ : {n : Nat} â†’ A â†’ Vector A n â†’ Vector A (suc n)
    #+end_example

    Notice that the parameter =A= is bound once for all constructors, while the
    index ={n : Nat}= must be bound locally in the constructor =_âˆ·_=.

    Indexed datatypes can also be used to describe predicates, for example the
    predicate =Even : Nat â†’ Set= can be defined as follows:

    #+begin_example
    data Even : Nat â†’ Set where
      even-zero  : Even zero
      even-plus2 : {n : Nat} â†’ Even n â†’ Even (suc (suc n))
    #+end_example

    The general form of the definition of a (parametrized, indexed) datatype =D=
    is the following
    #+begin_example
    data D (xâ‚ : Pâ‚) ... (xâ‚– : Pâ‚–) : (yâ‚ : Qâ‚) â†’ ... â†’ (yâ‚— : Qâ‚—) â†’ Set â„“ where
      câ‚ : Aâ‚
      ...
      câ‚™ : Aâ‚™
    #+end_example

    where the types =Aâ‚=, â€¦, =Aâ‚™= are function types of the form
    #+begin_example
    (zâ‚ : Bâ‚) â†’ ... â†’ (zâ‚˜ : Bâ‚˜) â†’ D xâ‚ ... xâ‚– tâ‚ ... tâ‚—
    #+end_example
*** Function types
    Function types are written =(x : A) â†’ B=, or in the case of non-dependent
    functions simply =A â†’ B=. For instance, the type of the addition function
    for natural numbers is:
    #+begin_example
    Nat â†’ Nat â†’ Nat
    #+end_example
    and the type of the addition function for vectors is:
    #+begin_example
    (A : Set) â†’ (n : Nat) â†’ (u : Vec A n) â†’ (v : Vec A n) â†’ Vec A n
    #+end_example

    where =Set= is the type of sets and =Vec A n= is the type of vectors with =n=
    elements of type =A=. Arrows between consecutive hypotheses of the form =(x :
    A)= may also be omitted, and =(x : A) (y : A)= may be shortened to =(x y : A)=:
    #+begin_example
    (A : Set) (n : Nat) (u v : Vec A n) â†’ Vec A n
    #+end_example

    Functions are constructed by lambda abstractions, which can be either typed
    or untyped. For instance, both expressions below have type =(A : Set) â†’ A â†’ A=
    (the second expression checks against other types as well):
    #+begin_example
    exampleâ‚ = Î» (A : Set) (x : A) â†’ x
    exampleâ‚‚ = Î» A x â†’ x
    #+end_example

    The application of a function =f : (x : A) â†’ B= to an argument =a : A= is
    written =f a= and the type of this is \texttt{B[x := a]}.

    Some notation conventions follow.
    - Function types:
      #+begin_example
      propâ‚ : ((x : A) (y : B) â†’ C) is-the-same-as   ((x : A) â†’ (y : B) â†’ C)
      propâ‚‚ : ((x y : A) â†’ C)      is-the-same-as   ((x : A)(y : A) â†’ C)
      propâ‚ƒ : (âˆ€ (x : A) â†’ C)  is-the-same-as   ((x : A) â†’ C)
      propâ‚„ : (âˆ€ x â†’ C)        is-the-same-as   ((x : _) â†’ C)
      propâ‚… : (âˆ€ x y â†’ C)      is-the-same-as   (âˆ€ x â†’ âˆ€ y â†’ C)
      #+end_example

    - Functional abstraction:
      #+begin_example
      (Î» x y â†’ e)                    is-the-same-as   (Î» x â†’ (Î» y â†’ e))
      #+end_example

    - Functional application:
      #+begin_example
      (f a b)                       is-the-same-as    ((f a) b)
      #+end_example

*** Record types
    The general form of a record declaration is as follows:
    #+begin_example
    record <recordname> <parameters> : Set <level> where
      <directives>
      constructor <constructorname>
      field
        <fieldname1> : <type1>
        <fieldname2> : <type2>
        -- ...
      <declarations>
    #+end_example
    All the components are optional, and can be given in any order. In
    particular, fields can be given in more than one block, interspersed with
    other declarations. Each field is a component of the record. Types of later
    fields can depend on earlier fields.

    The directives available are eta-equality, no-eta-equality, inductive and
    co-inductive. For more information visit cite:agda-doc.
** old :noexport:
  #   What sets dependent type theory apart from other type theories is that types
  #   can depend on terms. In a non-dependent theory types and terms live in
  #   separate worlds and they only meet to decide what terms have which types. In a
  #   dependent theory, on the other hand, types can talk about terms and so it is
  #   possible to express things like the precise characterisation of the sorting
  #   function mentioned above.

  #   In this section we present a dependent type theory
  #   which can serve as basis for the extensions discussed in later chapters. The
  #   particular choice of type theory is not crucial and the theory we choose is
  #   roughly Luoâ€™s UTT [Luo94] extended with Î£-types and Î·-laws. In the following
  #   we will refer to this theory as UTT Î£ . The syntax of UTT Î£ is presented in
  #   Figure 1.1. A telescope [dB91b] âˆ† = (x 1 : A 1 ) . . . (x n : A n ) is a
  #   sequence of types where later types may depend on elements of previous types.
  #   W

  # #+name: fig:agda-syntax
  # #+caption: The syntax of $\textsf{UTT}_Î£$.
  # #+attr_latex: :align llll :float t :center t :placement [H]
  # | $s,t,A,B$ | $â‰”$   | $x$                   | variable                     |
  # |           | \vert | $(x:A)â†’B$             | dependent function type      |
  # |           | \vert | $Î»x.t$                | lambda abstraction           |
  # |           | \vert | $s\ t$                | function application         |
  # |           | \vert | $(x:A)Ã—B$             | dependent pair  type         |
  # |           | \vert | $âŸ¨s,tâŸ©$               | dependent pairs              |
  # |           | \vert | $Ï€â‚\ t$ \vert $Ï€â‚‚\ t$ | projections                  |
  # |           | \vert | $\textsf{Set}_i$          | universes $(iâˆˆÏ‰)$            |
  # |           | \vert | $ğŸ$                   | the unit type                |
  # |           | \vert | $âŸ¨âŸ©$                  | the element of the unit type |
  # | $Î“,Î”$     | $â‰”$   | $Îµ$                   |                              |
  # |           | \vert | $(x:A)Î“$              | telescopes                   |

* Agda in the project
  <<sec:agda-project>>
  The goal of this section is to guide the reader through some key parts of the
  code that we have implemented. It is worth noting that we have started from
  scratch as we believe that no other previous work in interpretability logics
  has been done in Agda.

  The implementation relies on the Agda standard library (cite:agda-stdlib).

** Naming conventions :noexport:
   1. If we have =f : T= we say that =f= has type =T= or that =f= is a proof of =T=.
   2. If we have =f : A â†’ B â†’ C= we say =f= has arguments =A= and =B= and it has
      return type =C=.
** Modal formulas
   Here we present the Agda type that represents a formula as defined in section
   [[sec:language]].

   First we define variables to be natural numbers:
   #+begin_src text
Var : Set
Var = Nat
   #+end_src

   We proceed by inductively defining the formula type: =Fm=. We add a
   constructor for variables and one for each primitive operator.
   #+begin_src text
data Fm : Set where
  var : Var â†’ Fm
  âŠ¥' : Fm
  _â†_ : Fm â†’ Fm â†’ Fm
  _â–·_ : Fm â†’ Fm â†’ Fm
   #+end_src
   We have named the bottom constructor =âŠ¥'= since the symbol =âŠ¥= is commonly
   used in Agda as the empty type. We have used the =â†= to denote a implication
   since =â†’= is a reserved symbol for the Agda function type.

   We finally add definable operators as Agda functions. For instance, we define
   $Â¬$ and $â–¡$ thus:
  #+begin_src text
infix 60 Â¬'_
Â¬'_ : Fm â†’ Fm
Â¬' a = a â† âŠ¥'

infix 70 â–¡_
â–¡_ : Fm â†’ Fm
â–¡_ a = Â¬' a â–· âŠ¥'
  #+end_src
  We use the symbol =Â¬'= instead of =Â¬= for the same reason we used =âŠ¥'= instead
  of =âŠ¥=.

  It is often the case that we define priority and associativity for our infix
  operators in order to minimize the amount of needed parentheses. The following
  code defines the /infixity/ (level or priority) of =_â†_= and =_â–·_=.
    #+begin_src text
  infixr 20 _â†_
  infixr 50 _â–·_
    #+end_src
  A greater number means higher priority. Then we can drop the parentheses
  from the previous formula =var 1 â–· var 0 â† âŠ¥'=. The $r$ in =infixr= stands
  for right associativity.

** Predicates and relations :noexport:
   In this section we give a short description on how to represent predicates
   and relations in Agda.

   We define a predicate to have the following type[fn::We leave universe
   polymorphism out for simplicity.]:\glsadd{Pred}
   #+begin_src text
   Pred : Set â†’ Setâ‚
   Pred A = A â†’ Set
   #+end_src
   Hence, a predicate on the elements of some type =A= is a function from =A= to
   =Set=.

   Relations follow the same pattern:\glsadd{REL}
   #+begin_src text
   REL : Set â†’ Set â†’ Setâ‚
   REL A B = A â†’ B â†’ Set
   #+end_src
   For homogeneous relations we use the name =Rel=:\glsadd{Rel}
   #+begin_src text
   Rel : Set â†’ Set â†’ Setâ‚
   Rel A = REL A A
   #+end_src

   Now consider as an example the natural numbers and the =â‰¤= relation, which is
   defined inductively according to the following definition.
   1. For all $aâˆˆâ„•$ we have $0â‰¤a$;
   2. for all $a,bâˆˆâ„•$ we have that if $aâ‰¤b$ then also $a+1â‰¤b+1$.
   #+begin_src text
   data Nat : Set where
     zero : Nat
     suc : Nat â†’ Nat

   data _â‰¤_ : Rel Nat where
     zâ‰¤n : (a : Nat) â†’ zero â‰¤ a
     sâ‰¤s : {a b : Nat} â†’ a â‰¤ b â†’ suc a â‰¤ suc b
   #+end_src
   Note that =â‰¤= is the first indexed type that we present as it is indexed by
   two natural numbers. Keep in mind that =Rel Nat = Nat â†’ Nat â†’ Set=.
   If =t : a â‰¤ b= we say that =t= is a proof that =a= is less or equal than =b=.

   Let us prove that $1â‰¤2$; hence we need to build a term of type =suc zero â‰¤
   suc (suc zero)=.
   #+begin_src text
   1â‰¤2 : suc zero â‰¤ suc (suc zero)
   1â‰¤2 = sâ‰¤s (zâ‰¤n (suc zero))
   #+end_src
   Note that we did not explicitly give parameters =a, b= for the =sâ‰¤s=
   constructor as they are declared in curly braces[fn::Arguments defined in
   curly braces do not need to be given explicitly so long as Agda can infer its
   values.] and can be inferred by the type =a â‰¤ b=. Note that we could have
   done the same with the argument =a= of =zâ‰¤n= but we keep it explicit for
   illustrating the difference.

   We can also build proofs recursively. Let us prove that =_â‰¤_= is reflexive by
   induction:
   #+begin_src text
   â‰¤-refl : (a : Nat) â†’ a â‰¤ a
   â‰¤-refl zero = zâ‰¤n zero
   â‰¤-refl (suc a) = sâ‰¤s (â‰¤-refl a)
   #+end_src
   A key feature to notice is that we can name arguments and refer to them in
   subsequent arguments and in the return type. For instance here we have named
   =a= the first argument, which is a natural number. We use the syntax =(a :
   Nat)=. And then we use the name =a= to build the return type, that is: =a â‰¤ a=.

   We can also define the property of transitivity.
   #+begin_src text
   Transitive : {A : Set} â†’ Rel A â†’ Set
   Transitive R = âˆ€ {a b c} â†’ R a b â†’ R b c â†’ R a c
   #+end_src
   We see that a proof that some relation is transitive is a function that given
   proofs of =R a b= and =R b c= constructs a proof of =R a c=. Notice that the
   arguments =a b c= are declared implicit as they can be inferred from the types
   =a â‰¤ b= and =b â‰¤ c=. Let us prove that =â‰¤= is transitive:
   #+begin_src text
   â‰¤-trans : Transitive _â‰¤_
   â‰¤-trans {a} {b} {c} (zâ‰¤n b) bâ‰¤c = zâ‰¤n c
   â‰¤-trans {suc a} {suc b} {suc c} (sâ‰¤s aâ‰¤b) (sâ‰¤s bâ‰¤c) = sâ‰¤s (â‰¤-trans aâ‰¤b bâ‰¤c)
   #+end_src
   The previous proof works as follows. We perform induction on the proof of =a
   â‰¤ b=, that is, the first explicit argument.
   - Case =zâ‰¤n=; we know that =a = zero= and we can easily build a proof of
     =a â‰¤ c= by using the =zâ‰¤n= constructor.
   - Case =sâ‰¤s aâ‰¤b=; then is must be that the second proof is built using the
     =sâ‰¤s= constructor since we have =suc b=. Hence we have =aâ‰¤b : a â‰¤ b= and
     =bâ‰¤c : b â‰¤ c=. By using a recursive call (induction hypothesis) to
     =â‰¤-trans= we can build a proof of =a â‰¤ c=. Finally we can apply the
     constructor =sâ‰¤s= to obtain a proof of =suc a â‰¤ suc c=.
** Dependent pairs :noexport:
    Consider the following non-dependent pair definition (again, we present a non universe
    polymorphic version for simplicity):
    #+begin_src text
data _Ã—_ (A B : Set) : Set where
  _,_ : A â†’ B â†’ A Ã— B
    #+end_src
    Notice that =_Ã—_= is a parameterized type as it has parameters =(A B :
    Set)=, which are the types of each component of the pair. Parameters are
    shared parameters by all constructors (in this case there is only one
    constructor).

    See that we can easily build a pair $âŸ¨0,1âŸ©$ thus:
    #+begin_src text
    p : Nat Ã— Nat
    p = zero , (suc zero)
    #+end_src

    We now introduce the notion of \glspl*{dependent-pair}, also called
    \(Î£\)-pairs. Consider the following definition.
    #+begin_src text
data Î£ {a b : Level} (A : Seta a) (B : A â†’ Set b) : Set (a âŠ” b) where
  _,_ : (a : A) â†’ (b : B a) â†’ Î£ A B
    #+end_src
    The only, although essential, difference, is that the type of the second
    parameter is indexed by the value of the first. This is specially useful to
    represent existential quantification. For instance, we can design a type
    that asserts that some predicate is satisfiable[fn::we could simply write
    =P= instead of =(Î» a â†’ P a)= since eta-reductions are valid in Agda.]:
    #+begin_src text
    Satisfiable : {A : Set} â†’ Pred A â†’ Set
    Satisfiable {A} P = Î£ A (Î» a â†’ P a)
    #+end_src
    For instance:
    #+begin_src text
    TODO: show meaningful example of dependent pair
    #+end_src

    It useful to define the projection of each component:
    #+begin_src text
    projâ‚ : {A : Set} {B : A â†’ Set} â†’ Î£ A B â†’ A
    projâ‚ (a , b) = a

    projâ‚‚ : {A : Set} {B : A â†’ Set} â†’ (p : Î£ A B) â†’ B (projâ‚ p)
    projâ‚‚ (a , b) = b
    #+end_src
** Noetherian relations
   <<sec:agda-noetherian>>
    We say that a relation is \gls*{noetherian} if it is conversely
    well-founded. We begin by formalizing the concept of infinite ascending
    chain in Agda. In order to do that, we define a coinductive record datatype
    (cite:agda-doc,norell:thesis). A coinductive record is allowed to be
    infinite.
    #+begin_src text
record InfiniteChain {â„“W â„“R} {W : Set â„“W} (_<_ : Rel W â„“R) (a : W)
  : Set (â„“R âŠ” â„“W)where
  coinductive
  constructor infiniteChain
  field
    b : W
    a<b : a < b
    tail : InfiniteChain _<_ b
    #+end_src
    We see that the previous record datatype represents an infinite ascending
    chain starting at =a= of some relation =_<_=. It has three fields. =b=: The
    next element in the chain. =a<b=: A proof that $a < b$ and =tail=: an
    infinite chain starting at =b=.

    Then we can define being Noetherian as the negation of the existence of an
    infinite chain:
    #+begin_src text
Noetherian : âˆ€ {â„“R â„“W} {W : Set â„“W} â†’ Rel W â„“R â†’ Set (â„“R âŠ” â„“W)
Noetherian _<_ = âˆ€ {a} â†’ Â¬ (InfiniteChain _<_ a)
    #+end_src

    For instance, we can prove that a Noetherian relation is irreflexive. First
    we show that from a proof that $xRx$ we can build an infinite chain:
    #+begin_src text
infiniteRefl : âˆ€ {â„“} {R : Rel A â„“} {x} â†’ R x x â†’ InfiniteChain R x
InfiniteChain.b (infiniteRefl {x = x} Rxx) = x
InfiniteChain.a<b (infiniteRefl {x = x} Rxx) = Rxx
InfiniteChain.tail (infiniteRefl {x = x} Rxx) = infiniteRefl Rxx
    #+end_src
    We see that each equation corresponds to a different field in the record
    datatype. This construction is known as /copattern/. Coinductive
    datatypes must be constructed in this way. Copatterns are for
    coinductive types what patterns are for inductive (finite) types. In
    cite:abel2013programming copatterns are described in detail.

    And then we can apply the Noetherian definition.
    #+begin_src text
Noetherianâ‡’Irreflexive : âˆ€ {â„“R â„“W} {W : Set â„“W} {R : Rel W â„“R}
     â†’ Noetherian R â†’ âˆ€ {x} â†’ Â¬ R x x
Noetherianâ‡’Irreflexive noetherian Rxx = noetherian (infiniteRefl Rxx)
    #+end_src

    To see another example refer to Section [[sec:agda-L]].
** Ordinary semantics
   <<sec:agda-ord-semantics>>
   In this section we explain how we have represented ordinary Veltman semantics
   in Agda.

   To represent ordinary Veltman semantics in Agda, the first step is to
   define the type of an ordinary Veltman frame:
   #+begin_src text
record Frame {â„“W â„“R â„“S : Level} (W : Set â„“W) (R : Rel W â„“R) (S : Relâ‚ƒ W â„“S)
  : Set (â„“W âŠ” â„“R âŠ” â„“S) where
  constructor frame
  field
    witness : W
    R-trans : Transitive R
    R-noetherian : Noetherian R
    SwâŠ†R[w]Â² : âˆ€ {w u v} â†’ S w u v â†’ R w u Ã— R w v
    Sw-refl : âˆ€ {w u} â†’ R w u â†’ S w u u
    Sw-trans : âˆ€ {w} â†’ Transitive (S w)
    R-Sw-trans : âˆ€ {w u v} â†’ R w u â†’ R u v â†’ S w u v
   #+end_src
   The keyword =record= is used to define a new product type (a tuple) in which
   each component (or field) has a name that we can use to access it.

   We see that the datatype is parameterized by the universe =W=, the =R=
   relation, the =S= relation and their respective universe levels =â„“W, â„“R, â„“S=.

   The first component, =witness=, is required to make sure that the set of worlds is
   not empty. The remaining components are the properties that must be satisfied
   according to definition [[def:ordinary-frames]].

   We define a valuation on a frame thus:
   #+begin_src text
Valuation : Frame {â„“W} {â„“R} {â„“S} W R S â†’ Set (lsuc lzero âŠ” â„“W)
Valuation {W = W} F = REL W Var lzero
   #+end_src

   And then we define a model to be a frame parameterized with a valuation on that
   frame.
   #+begin_src text
record Model (W : Set â„“W) (R : Rel W â„“R) (S : Relâ‚ƒ W â„“S) (V : REL W Var lzero)
  : Set (â„“W âŠ” â„“R âŠ” â„“S) where
  constructor model
  field
    F : Frame {â„“W} {â„“R} {â„“S} W R S
   #+end_src

   Our next step is to define the forcing relation.
   #+begin_src text
data _,_âŠ©_ (M : Model {â„“W} {â„“R} {â„“S} W R S V) (w : W)
  : Fm â†’ Set (â„“W âŠ” â„“R âŠ” â„“S)
   #+end_src
   We set a model and a world of that model as parameters as they should be
   shared by all constructors. We leave the formula as an index as it may vary
   depending on the constructor. We should introduce a constructor for each case
   in definition [[def:ord-forcing]]:
   1. We do not need a constructor for =âŠ¥'= as its absence implicitly implies that
      we can never build an instance of =M , w âŠ© âŠ¥'= regardless of =M= and =w=.
   2. if $xâˆˆVar$, then $wâŠ©x$ iff $âŸ¨w,xâŸ©âˆˆV$;
      #+begin_src text
  var : {p : Var} â†’ p âˆˆ V w â†’ M , w âŠ© var p
      #+end_src
   3. if $A,BâˆˆFm$, then $wâŠ©Aâ†’B$ iff if $wâŠ©A$ then $wâŠ©B$;
      #+begin_src text
  impl : {A B : Fm} â†’ ((M , w âŠ© A) â†’ (M , w âŠ© B)) â†’ M , w âŠ© (A â† B)
      #+end_src
   4. if $A,BâˆˆFm$, then $wâŠ©Aâ–·B$ iff if $wRu$ and $uâŠ©A$ then there exists $v$ such
      that $vâŠ©B$ and $uS_wv$.
      #+begin_src text
   rhd : {A B : Fm} â†’
     ({u : W} â†’ R w u â†’ M , u âŠ© A â†’ (âˆƒ[ v ] (S w u v Ã— (M , v âŠ© B))))
     â†’ M , w âŠ© A â–· B
      #+end_src

   Unfortunately the definition above is not valid in Agda. The reason is that
   constructors =rhd= and =impl= both fail the positivity check (see
   [[sec:positivity]]). For instance, see that in the =impl= constructor type we have
   =(M , w âŠ© A)= on the left of an arrow =â†’=.

   We have circumvented this problem by providing mutually recursive definitions
   for /forcing/ (=_,_âŠ©_=) and /not forcing/ (=_,_âŠ®_=). Agda allows the
   definition of mutually recursive datatypes (and functions) by first providing
   the type of both[fn::Or more if it is the case.] definitions and after those
   giving the rest of the definition, that is, the constructors for datatypes
   and the equations for functions.

   The type of the two datatypes that we want to define are as follows.
   #+begin_src text
data _,_âŠ©_ (M : Model {â„“W} {â„“R} {â„“S} W R S V) (w : W)
  : Fm â†’ Set (â„“W âŠ” â„“R âŠ” â„“S) -- forcing relation

data _,_âŠ®_ (M : Model {â„“W} {â„“R} {â„“S} W R S V) (w : W)
  : Fm â†’ Set (â„“W âŠ” â„“R âŠ” â„“S) -- not forcing relation
   #+end_src

   Next we provide the strictly positive types of each constructor of the
   =_,_âŠ©_= and =_,_âŠ®_= relations.
   1. For the =âŠ¥'= constant.
      1. Forcing (=_,_âŠ©_=). No constructor is required.
      2. Not forcing (=_,_âŠ®_=).
        #+begin_example
        bot : M , w âŠ® âŠ¥'
        #+end_example
   2. For variables.
    1. Forcing (=_,_âŠ©_=).
       #+begin_src text
  var : {p : Var} â†’ p âˆˆ V w â†’ M , w âŠ© var p
       #+end_src
    2. Not forcing (=_,_âŠ®_=).
       #+begin_example
  var : {p : Var} â†’ p âˆ‰ V w â†’ M , w âŠ® var p
       #+end_example

   3. For implication (=â†=).
    1. Forcing (=_,_âŠ©_=).
       #+begin_src text
  impl : {A B : Fm} â†’ M , w âŠ® A âŠ M , w âŠ© B â†’ M , w âŠ© A â† B
       #+end_src
    2. Not forcing (=_,_âŠ®_=).
       #+begin_src text
  impl : {A B : Fm} â†’ M , w âŠ© A â†’ M , w âŠ® B â†’ M , w âŠ® A â† B
       #+end_src
   4. For interpretability (=â–·=).
    1. Forcing (=_,_âŠ©_=).
       #+begin_src text
  rhd : {A B : Fm} â†’
    (âˆ€ {u} â†’ R w u â†’ M , u âŠ® A âŠ (âˆƒ[ v ] (S w u v Ã— M , v âŠ© B)))
    â†’ M , w âŠ© A â–· B
       #+end_src
    2. Not forcing (=_,_âŠ®_=).
       #+begin_src text
  rhd : {A B : Fm} â†’
    âˆƒ[ u ] (R w u Ã— M , u âŠ© A Ã— ((v : W) â†’ (Â¬ S w u v) âŠ M , v âŠ® B))
    â†’ M , w âŠ® A â–· B
       #+end_src

   Putting it all together results in the following definitions:
   #+begin_src text
data _,_âŠ©_ M w where
  var : {x : Var} â†’ V w x â†’ M , w âŠ© var x
  impl : {A B : Fm} â†’ M , w âŠ® A âŠ M , w âŠ© B â†’ M , w âŠ© A â† B
  rhd : {A B : Fm} â†’
    (âˆ€ {u} â†’ R w u â†’ M , u âŠ® A âŠ (âˆƒ[ v ] (S w u v Ã— M , v âŠ© B)))
    â†’ M , w âŠ© A â–· B
   #+end_src
   #+begin_src text
data _,_âŠ®_ M w where
  var : {x : Var} â†’ Â¬ (V w x) â†’ M , w âŠ® var a
  impl : {A B : Fm} â†’ M , w âŠ© A â†’ M , w âŠ® B â†’ M , w âŠ® A â† B
  rhd : {A B : Fm} â†’
    âˆƒ[ u ] (R w u Ã— M , u âŠ© A Ã— ((v : W) â†’ (Â¬ S w u v) âŠ M , v âŠ® B))
    â†’ M , w âŠ® A â–· B
  bot : M , w âŠ® âŠ¥'
   #+end_src

   To prove that =_,_âŠ©= and =_,_âŠ®= are indeed the negation of each other
   we should prove two lemmas. We define =A â‡” B â‰” A â†’ B Ã— B â†’ A=. Then the lemma in
   Agda types is as follows:
   {{{beginlemma}}}
   <<lemma:forcing-neg>>
   \hfill
   1. =âˆ€ {M w A} â†’ M , w âŠ© A â‡” Â¬ (M , w âŠ® A)=.
   2. =âˆ€ {M w A} â†’ Â¬ (M , w âŠ© A) â‡” M , w âŠ® A=.
   {{{endlemma}}} For part 1 we can prove $â‡’$ and for part 2 we can prove $â‡$
   (see lemma [[lemma:equiv]]). However, it is not possible to prove the remaining
   directions. In general terms, this is due to the fact that in Agda (and in
   intuitionistic logic in general) we can prove that =(Â¬ A âŠ B) â†’ A â†’ B= but we
   cannot prove =A â†’ B â†’ (Â¬ A âŠ B)=. The reason being that we lack the law of
   excluded middle, as it is a non-constructive axiom. In order to prove the
   remaining directions we need to assume that the forcing relation is
   decidable.

   {{{begindef}}} <<def:ord-decidable-model>>

   We say that =M= is \gls*{decidable model} if for any world =w= and formula
   =A= we have that either =M , w âŠ© A= or =M , w âŠ® A=.

   In Agda terms:
   #+begin_src text
DecidableModel : Model â†’ Set
DecidableModel M = âˆ€ w A â†’ M , w âŠ© A âŠ M , w âŠ® A
   #+end_src
   {{{enddef}}}

   {{{beginproof}}}
   {{{agda}}}

   Under the assumption that we restrict ourselves to decidable models we can
   prove lemma [[lemma:forcing-neg]].
   {{{endproof}}}

   {{{beginlemma}}} <<lemma:equiv>> The following is true:

   1. =âŠ©âŠ¥ : âˆ€ {M w} â†’ Â¬ (M , w âŠ© âŠ¥')=;
   2. =âŠ®â†’Â¬âŠ© : âˆ€ {M w A} â†’ M , w âŠ® A â†’ Â¬ (M , w âŠ© A)=;
   3. =âŠ©â†’Â¬âŠ® : âˆ€ {M w A} â†’ M , w âŠ© A â†’ Â¬ (M , w âŠ® A)=;
   4. =âŠ©MP : âˆ€ {M w A B} â†’ M , w âŠ© A â† B â†’ M , w âŠ© A â†’ M , w âŠ© B=;
   5. =âŠ©Â¬ : âˆ€ {M w A} â†’ (M , w âŠ© Â¬' A) â‡” (M , w âŠ® A)=;
   6. =âŠ®Â¬ : âˆ€ {M w A} â†’ M , w âŠ® Â¬' A â‡” M , w âŠ© A=;
   7. =âŠ©Â¬Â¬ : âˆ€ {M w A} â†’ M , w âŠ© Â¬' Â¬' A â‡” M , w âŠ© A=;
   8. =âŠ®Â¬Â¬ : âˆ€ {M w A} â†’ M , w âŠ® Â¬' Â¬' A â‡” M , w âŠ® A=;
   9. =âŠ©âˆ§ : âˆ€ {M w A B} â†’ M , w âŠ© A âˆ§ B â‡” (M , w âŠ© A Ã— M , w âŠ© B)=;
   10. =âŠ®âˆ§ : âˆ€ {M w A B} â†’ M , w âŠ® A âˆ§ B â‡” (M , w âŠ® A âŠ M , w âŠ® B)=;
   11. =âŠ©âˆ¨ : âˆ€ {M w A B} â†’ M , w âŠ© A âˆ¨ B â‡” (M , w âŠ© A âŠ M , w âŠ© B)=;
   12. =âŠ©â–¡ : âˆ€ {M w A} â†’ M , w âŠ© â–¡ A â‡” (âˆ€ {v} â†’ R w v â†’ M , v âŠ© A)=;
   13. =âŠ®â–¡ : âˆ€ {M w A} â†’ M , w âŠ® â–¡ A â‡” (âˆƒ[ u ] (R w u Ã— M , u âŠ® A))=;
   14. =âŠ©â™¢ : âˆ€ {M w A} â†’ M , w âŠ© â™¢ A â‡” (âˆƒ[ u ] (R w u Ã— M , u âŠ© A))=;
   15. =âŠ®â™¢ : âˆ€ {M w A} â†’ M , w âŠ® â™¢ A â‡” (âˆ€ {u} â†’ R w u â†’ M , u âŠ® A)=;
   16. =âŠ©â†â‡¨ : âˆ€ {M w A B} â†’ M , w âŠ© A â† B â†’ M , w âŠ© A â†’ M , w âŠ© B=;
   17. =âŠ©â–·â‡¨ : âˆ€ {M w A B} â†’ M , w âŠ© A â–· B â†’ (âˆ€ {u} â†’ R w u â†’ M , u âŠ© A â†’ âˆƒ[ v ] (S w u v Ã— M , v âŠ© B)=.
   {{{endlemma}}}
   {{{beginproof}}} {{{agda}}} {{{coq}}} The above properties have been proven
   in Agda and Coq without assuming that the model is decidable. {{{endproof}}}


   {{{beginlemma}}} <<lemma:ord-equiv-dec>> The following series of equivalences
   can be proven for decidable models.

   1. =âŠ©â† : âˆ€ {w A B} â†’ M , w âŠ© A â† B â‡” (M , w âŠ© A â†’ M , w âŠ© B)=;
   2. =âŠ©â–· : âˆ€ {w A B} â†’ M , w âŠ© A â–· B â‡”
      (âˆ€ {u} â†’ R w u â†’ M , u âŠ© A â†’ âˆƒ[ v ] (S w u v Ã— M , v âŠ© B))=;
   3. =âŠ©â‡”Â¬âŠ® : âˆ€ {w A} â†’ M , w âŠ© A â‡” (Â¬ M , w âŠ® A)=;
   4. =âŠ®â‡”Â¬âŠ© : âˆ€ {w A} â†’ M , w âŠ® A â‡” (Â¬ M , w âŠ© A)=.
   {{{endlemma}}} {{{beginproof}}} {{{agda}}} {{{coq}}} Note that we only need the
   decidability assumption for 1 ($â‡$), 2 ($â‡$), 3 ($â‡$) and 4 ($â‡$). {{{endproof}}}

   From now on, we always restrict ourselves to decidable models as the usage of
   lemma [[lemma:ord-equiv-dec]] is ubiquitous. If we were to assume that we are
   outside of Agda and that we accept the law of excluded middle as part of our
   metalogic, the mentioned assumption could be dropped.

** Subsets (predicates revisited) :noexport:
   In Agda, the keyword =Set= refers to an Agda type (insert ref to previous
   section), which is the closest concept to regular mathematics /set/. In this
   section when we say /set/ we refer to a subset of an Agda type. The most
   natural way to represent subsets in Agda is to use predicates. See
   [[sec:predicates]] for an introduction. A predicate represents the characteristic
   function of the associated subset. For instance consider the predicate:
   #+begin_src text
   even : Pred Nat
   even = ...
   #+end_src
   Then =even= represents the subset of natural numbers that are even. It is
   important to note that predicates are always restricted to a specific type,
   in this case =Nat=, and for that reason the term /subset/ may be more adequate.

   Next we present how we represent in Agda common operations on sets.
   Assume for the below definitions that we have some =A : Set= in scope.
** Generalized semantics
   <<sec:agda-gen-semantics>> In this section we explain how we have represented
   generalized Veltman semantics in Agda. As explained in Section [[sec:trans]] we
   consider eight different quasi-transitivity properties, thus, we need to
   define everything related to generalized Veltman semantics to be generic with
   respect to the quasi-transitivity condition used, which was certainly
   presented some challenges.

   Analogously to ordinary semantics we start by defining a frame. We begin by
   defining a datatype that represents a frame without the quasi-transitivity
   condition. See that we define the type =ğ• â‰” Pred W â„“W=, which means that a
   term of type =ğ•= is a subset of =W= (see Section [[sec:sets]] for details on how
   to represent mathematical sets in Agda). See that the =S-ext= field adds
   extensionality restricted to the third component of the =S= relation.
   #+begin_src text
record FrameNoTrans (W : Set â„“W) (R : Rel W â„“R) (S : RELâ‚ƒ W W (Pred W â„“W) â„“S)
  : Set (lsuc lzero âŠ” â„“R âŠ” â„“S âŠ” lsuc â„“W) where
  constructor frame
  ğ• : Set (lsuc â„“W)
  ğ• = Pred W â„“W
  field
    witness : W
    Swu-sat : âˆ€ {w u Y} â†’ S w u Y â†’ Satisfiable Y
    R-trans : Transitive R
    R-noetherian : Noetherian R
    SwâŠ†R[w] : âˆ€ {w u Y} â†’ S w u Y â†’ R w u
    SwuYâŠ†Rw : âˆ€ {w u Y} â†’ S w u Y â†’ âˆ€ {y} â†’ y âˆˆ Y â†’ R w y
    S-quasirefl : âˆ€ {w u} â†’ R w u â†’ S w u ï½› u ï½
    R-Sw-trans : âˆ€ {w u v} â†’ R w u â†’ R u v â†’ S w u ï½› v ï½
    S-ext : âˆ€ {w x V V'} â†’ S w x V â†’ V âŠ† V' â†’ V' âŠ† V â†’ S w x V'
   #+end_src

   Then we define a new datatype =Frame= which represents a non-transitive
   Generalized Veltman frame plus some quasi-transitivity condition, which is
   left as a parameter =T=.
   #+begin_example
record Frame (W : Set â„“W) (R : Rel W â„“R) (S : RELâ‚ƒ W W (Pred W â„“W) â„“S)
  (T : (W : Set â„“W) â†’ RELâ‚ƒ W W (Pred W â„“W) â„“S â†’ Set (lsuc â„“W âŠ” â„“S))
  : Set (lsuc â„“W âŠ” â„“R âŠ” â„“S) where
  constructor frame
  field
    frame-0 : FrameNoTrans {â„“W} {â„“R} {â„“S} W R S
    quasitrans : T W S
   #+end_example

   We now define all the quasi-transitivity conditions. Here we only present
   Condition (4).
   #+begin_example
  Trans-4 : (W : Set â„“W) â†’ RELâ‚ƒ W W (Pred W â„“W) â„“S â†’ Set (lsuc â„“W âŠ” â„“S))
  Trans-4 W S = âˆ€ {x u Y} â†’ S x u Y â†’ âˆƒ[ y ] (y âˆˆ Y Ã— (âˆ€ {Y'} â†’ S x y Y' â†’ S x u Y'))
   #+end_example

   And finally we can define a datatype that represents a generalized Veltman
   frame for each of the quasi-transitivity conditions as a simple instantiation
   of the generic =Frame= defined before. Here we only present Condition (4).
   #+begin_example
Frame4 : (W : Set â„“W) (R : Rel W â„“R) (S : RELâ‚ƒ W W (Pred W â„“W) â„“S) â†’ Set _
Frame4 W R S = Frame W R S (Trans-4 W S)
   #+end_example


   In order to define the generalized Veltman semantics forcing relation, since
   we need to define it generically to work for any quasi-transitivity condition
   assume that we have some term =T= representing such condition of typed thus:
   #+begin_example
   (T : âˆ€ {â„“W â„“S} (W : Set â„“W) â†’ RELâ‚ƒ W W (Pred W â„“W) â„“S â†’ Set (lsuc â„“W âŠ” â„“S))
   #+end_example

   Then we define a generalized model in an analogous way to how we did it for
   ordinary semantics:
   #+begin_example
  record Model
    {â„“W â„“R â„“S}
    (W : Set â„“W)
    (R : Rel W â„“R)
    (S : RELâ‚ƒ _ _ _ â„“S)
    (V : REL W Var lzero)
    : Set (lsuc â„“W âŠ” â„“R âŠ” â„“S) where
    constructor model
    field
      F : Frame {â„“W} {â„“R} {â„“S} W R S T
   #+end_example

   And finally we define the forcing relation using mutually recursive datatypes
   as we did for ordinary semantics. The only difference is in the =rhd=
   constructor.
   #+begin_example
  data _,_âŠ®_ {â„“W â„“R â„“S W R S V} (M : Model {â„“W} {â„“R} {â„“S} W R S V) (w : W)
    : Fm â†’ Set (lsuc â„“W âŠ” â„“R âŠ” â„“S)

  data _,_âŠ©_ {â„“W â„“R â„“S W R S V} (M : Model {â„“W} {â„“R} {â„“S} W R S V) (w : W)
    : Fm â†’ Set (lsuc â„“W âŠ” â„“R âŠ” â„“S)

  data _,_âŠ©_ {â„“W} {â„“R} {â„“S} {W} {R} {S} {V} M w where
    var : âˆ€ {a : Var} â†’ a âˆˆ V w â†’ M , w âŠ© var a
    impl : âˆ€ {A B} â†’ M , w âŠ® A âŠ M , w âŠ© B â†’ M , w âŠ© A â† B
    rhd : âˆ€ {A B} â†’
      (âˆ€ {u} â†’ R w u â†’ M , u âŠ® A âŠ (âˆƒ[ Y ] (S w u Y Ã— (Y âŠ† M ,_âŠ© B))))
      â†’ M , w âŠ© A â–· B

  data _,_âŠ®_ {â„“W} {â„“R} {â„“S} {W} {R} {S} {V} M w where
    var : âˆ€ {a : Var} â†’ a âˆ‰ V w â†’ M , w âŠ® var a
    impl : âˆ€ {A B} â†’ M , w âŠ© A â†’ M , w âŠ® B â†’ M , w âŠ® A â† B
    rhd : âˆ€ {A B} â†’
      âˆƒ[ u ] (R w u Ã— M , u âŠ© A
      Ã— âˆ€ Y â†’ Satisfiable Y â†’ (Â¬ S w u Y) âŠ (Satisfiable (Y âˆ© (M ,_âŠ® B))))
      â†’ M , w âŠ® A â–· B
    bot : M , w âŠ® âŠ¥'
   #+end_example

   Recall that in section [[sec:agda-ord-semantics]] in order to prove some
   properties we had to assume that the ordinary models where decidable in the
   sense defined in Definition [[def:ord-decidable-model]]. For generalized
   semantics we need to make a stronger assumption described in the next
   definition.

   {{{begindef}}} We say that =M= is \gls*{multi decidable model} if for any set
   of worlds =Y= and formula =A= we can decide whether
   1. for every element =y= in =Y= we have =M , y âŠ® A=; or
   2. there is an element =y= in =Y= such that =M , y âŠ® A=.

   In Agda terms:
   #+begin_src text
  MultiDecidableModel : âˆ€ {â„“W â„“R â„“S W R S V} â†’ Model {â„“W} {â„“R} {â„“S} W R S V
    â†’ Set (lsuc â„“W âŠ” â„“R âŠ” â„“S âŠ” lsuc â„“W)
  MultiDecidableModel {â„“W = â„“W} {W = W} M =
    âˆ€ (Y : Pred W â„“W) A â†’ Y âŠ† M ,_âŠ© A âŠ Satisfiable (Y âˆ© (M ,_âŠ® A))
   #+end_src
   Observe that any multi-decidable model is also decidable.
   {{{enddef}}}

   {{{beginlemma}}} <<lemma:gen-lemmas>> Assuming that we restrict ourselves to
   multi-decidable models then properties in lemmas [[lemma:forcing-neg]],
   [[lemma:equiv]] and [[lemma:ord-equiv-dec]] also hold for generalized semantics.
   {{{endlemma}}} {{{beginproof}}} {{{agda}}}
   {{{endproof}}}

*** A guided Agda proof
    <<sec:agda-L>> In this section we guide the user through a non-trivial Agda
    proof, which will hopefully give the reader a feel of how we can proof
    generalized Veltman semantic properties in Agda. We prove that for any
    generalized Veltman model $M$ and world $w$ we have that $w$ forces LÃ¶b's
    axiom. In symbols: \[âˆ€MwA.\ M , w âŠ© â–¡ (â–¡ A â†’ A) â†’ â–¡ A.\] Note that since
    LÃ¶b's axiom is in $\textsf{IL}$ we need to show this as part of the
    soundness proof.

    We begin by outlining the proof without Agda. Assume that for some world
    $wâ‚€$ we have $w_0âŠ©â–¡ (â–¡ A â†’ A)$. Assume for a contradiction that $wâŠ®â–¡A$, then
    there exists some $wâ‚$ such that $wâ‚€Rwâ‚âŠ®A$. Since $wâ‚€Rwâ‚$ it follows that
    $wâ‚âŠ©â–¡Aâ†’A$. Then since $wâ‚âŠ®A$ we necessarily have that $wâ‚âŠ®â–¡A$. Then there
    exists $wâ‚‚$ such that $wâ‚Rwâ‚‚âŠ®A$. Since $R$ is transitive we have that
    $wâ‚€Rwâ‚‚$ and thus $wâ‚‚âŠ©â–¡Aâ†’A$. We can repeat the previous argument indefinitely
    to build an infinite chain $wâ‚€Rwâ‚Râ€¦$, which is a contradiction since $R$ is
    Noetherian. This concludes the pen and paper proof.

    We proceed with the Agda proof. During the course of this example we use
    some lemmas listed below, which we have proved in Agda, however, we just
    display their type here and we omit their proof in order to save space. Also,
    assume that we have some model =M= in scope.
    #+begin_src text
    âŠ©4' : âˆ€ {w A} â†’ M , w âŠ© â–¡ A â†’ M , w âŠ© â–¡ â–¡ A
    âŠ®â–¡ : âˆ€ {w A} â†’ M , w âŠ® â–¡ A â‡” (âˆƒ[ u ] (R w u Ã— M , u âŠ® A))
    âŠ©â–¡ : âˆ€ {w A} â†’ M , w âŠ© â–¡ A â‡” (âˆ€ {v} â†’ R w v â†’ M , v âŠ© A)
    âŠ©â‡”Â¬âŠ® : âˆ€ {w A} â†’ M , w âŠ© A â‡” Â¬ (M , w âŠ® A)
    _â‡’_ : âˆ€ {a b} {A : Set a} {B : Set b} â†’ A â‡” B â†’ A â†’ B
    #+end_src

    *Naming convention*. In this proof we use the popular convention to name
    variables after their type, which greatly improves the readability of
    proofs. For instance, if we bind some variable of type =R w u= we will name
    it =Rwu=; if we bind a variable of type =M , w âŠ© A= we will name it =wâŠ©A=;
    and so on.

    We begin by showing a useful lemma: for any $w,u,A$, if $wRu$ and $uâŠ®A$ and
    $wâŠ©â–¡(â–¡Aâ†’A)$ then we can build an infinite \text{$R$-chain} starting at $w$.
    The following type expresses the aforementioned property.
    #+begin_src text
    R-chain : âˆ€ {w u A} â†’ R w u â†’ M , u âŠ® A â†’ M , w âŠ© â–¡ (â–¡ A â† A) â†’ InfiniteChain R w
    #+end_src
    Recall that infinite chains are defined as coinductive datatypes in Section
    [[sec:agda-noetherian]]. Hence we proceed by building the infinite chain using
    copatterns. The first two components are clear:
    #+begin_src text
  InfiniteChain.b (R-chain {w} {u} Rwu uA uF) = u
  InfiniteChain.a<b (R-chain {w} {u} Rwu uA uF) = Rwu
    #+end_src
    Then we must show that there is an infinite chain starting at $u$. The
    argument =wâŠ©â–¡âŸ¨â–¡Aâ†AâŸ©= has type =M , w âŠ© â–¡ (â–¡ A â† A)=, hence by applying the
    lemma =âŠ©â–¡= in the right (=â‡’=) direction and using the fact that =Rwu= has type =R
    w u= we get a term of type =M , u âŠ© â–¡ A â† A= which we pattern match using
    the =widh= construct[fn::The =width= construct allows us to pattern match
    on terms that can be build from the arguments of the function.]. By the
    definition of the constructor =impl= for the =_,_âŠ©_= datatype it follows
    that we have two cases: either =M , u âŠ© A= or =M , u âŠ® â–¡ A=.

    If it is the case that =M , u âŠ© A= we can build a term of type =âŠ¥= by using
    the =âŠ©â†’Â¬âŠ®= lemma and then we can use the principle of explosion to return
    anything.
    #+begin_src text
  InfiniteChain.tail (R-chain Rwu uâŠ®A wâŠ©â–¡âŸ¨â–¡Aâ†AâŸ©) with (âŠ©â–¡ â‡’ wâŠ©â–¡âŸ¨â–¡Aâ†AâŸ©) Rwu
  ... | impl (injâ‚‚ uâŠ©A) = explosion (âŠ©â†’Â¬âŠ® uâŠ©A uâŠ®A)
    #+end_src

    On the contrary, if we have that =M , u âŠ® â–¡ A= then by the =âŠ®â–¡= lemma we get
    that there exists some =v= such that =R u v= and =M , v âŠ© A=. Then we can
    use the =âŠ©4'= lemma to get a term of type =M , w âŠ© â–¡ (â–¡ (â–¡ A â† A))=, then by
    lemma =âŠ©â–¡= and the fact we have a proof of =R w u= we can build a term of
    type =M , u âŠ© â–¡ (â–¡ A â† A)=. Finally by a recursive call (induction
    hypothesis) to =R-chain= with =R u v= and =vâŠ©A= and the term described above
    we get a term of the desired type.
    #+begin_src text
  ... | impl (injâ‚ xâŠ®â–¡A) with âŠ®â–¡ â‡’ xâŠ®â–¡A
  ... | (v â¸´ Ruv â¸´ vâŠ©A) = R-chain Ruv vâŠ©A ((âŠ©â–¡ â‡’ âŠ©4' wâŠ©â–¡âŸ¨â–¡Aâ†AâŸ©) Rwu)
    #+end_src
    This concludes the proof of the lemma. We now proceed to prove our theorem.
    The statement of the theorem is represented by the following type:
    #+begin_src text
  âŠ©L : âˆ€ {w A} â†’ M , w âŠ© â–¡ (â–¡ A â† A) â† â–¡ A
    #+end_src
    We use lemma =âŠ©â†= to get a proof of =M , w âŠ© â–¡ (â–¡ A â† A)=. Then we use lemma
    =âŠ©â–¡= on the left direction, so we assume =R w u= and our goal is to show =M
    , u âŠ© A=. By using lemma =âŠ©â‡”Â¬âŠ®= on the left direction. Our goal is to show
    =Â¬ (M , w âŠ® A)= which normalizes to =M , w âŠ® A â†’ âŠ¥=, hence we assume =M , u
    âŠ® A= and we aim to build a proof of =âŠ¥=. We can build an infinite chain with
    lemma =R-chain= proved above and the facts that =R w u=, =M , u âŠ® A= and =M
    , w âŠ© â–¡ (â–¡ A â† A)=. Before the final step it may be useful to recall the
    definition of a =Noetherian= relation (see Section [[sec:agda-noetherian]]):
    #+begin_src text
Noetherian _<_ = âˆ€ {a} â†’ Â¬ (InfiniteChain _<_ a)
    #+end_src
    Finally we use the property that the =R= relation of the model is Noetherian
    to get a term of type =âŠ¥= as desired.
    #+begin_example
  âŠ©L : âˆ€ {w A} â†’ M , w âŠ© â–¡ (â–¡ A â† A) â† â–¡ A
  âŠ©L {w} {A} = âŠ©â† â‡ Î» wâŠ©â–¡âŸ¨â–¡Aâ†’AâŸ© â†’ âŠ©â–¡ â‡ Î» {u} Rwu â†’ âŠ©â‡”Â¬âŠ® â‡
    Î» {uâŠ®A â†’ R-noetherian (R-chain Rwu uâŠ®A wâŠ©â–¡âŸ¨â–¡Aâ†’AâŸ©)}
    #+end_example

    Putting it all together we have:
    #+begin_src text
  R-chain : âˆ€ {w u A} â†’ R w u â†’ M , u âŠ® A â†’ M , w âŠ© â–¡ (â–¡ A â† A) â†’ InfiniteChain R w
  InfiniteChain.b (R-chain {w} {u} Rwu uA uF) = u
  InfiniteChain.a<b (R-chain {w} {u} Rwu uA uF) = Rwu
  InfiniteChain.tail (R-chain {w} {u} Rwu uâŠ®A wâŠ©â–¡âŸ¨â–¡Aâ†AâŸ©)
     with (âŠ©â–¡ â‡’ wâŠ©â–¡âŸ¨â–¡Aâ†AâŸ©) Rwu
  ... | impl (injâ‚‚ uâŠ©A) = âŠ¥-elim (âŠ©â†’Â¬âŠ® uâŠ©A uâŠ®A)
  ... | impl (injâ‚ xâŠ®â–¡A) with âŠ®â–¡ â‡’ xâŠ®â–¡A
  ... | (v â¸´ Ruv â¸´ vâŠ©A) = R-chain Ruv vâŠ©A ((âŠ©â–¡ â‡’ âŠ©4' wâŠ©â–¡âŸ¨â–¡Aâ†AâŸ©) Rwu)

  âŠ©L : âˆ€ {w A} â†’ M , w âŠ© â–¡ (â–¡ A â† A) â† â–¡ A
  âŠ©L {w} {A} = âŠ©â† â‡ Î» wâŠ©â–¡âŸ¨â–¡Aâ†’AâŸ© â†’ âŠ©â–¡ â‡ Î» {u} Rwu â†’ âŠ©â‡”Â¬âŠ® â‡
    Î» {uâŠ®A â†’ R-noetherian (R-chain Rwu uâŠ®A wâŠ©â–¡âŸ¨â–¡Aâ†’AâŸ©)}
    #+end_src
** \il{} and syntactic proofs
   Here we present our efforts on formalizing syntactic \il{} proofs in Agda. We
   restrict ourselves to finite sets of assumptions.

   We begin by defining the necessary type to represent a finite list:
   #+begin_src text
data List {a : Level} (A : Set a) : Set a where
  []  : List A
  _âˆ·_ : A â†’ List A â†’ List A
   #+end_src
   Then we can define a proof of membership inductively in the following way:
   #+begin_src text
data _âˆˆ_ {a : Level} {A : Set a} (a : A) : Pred (List A) a where
  here  : {x : A} {xs : List A} â†’ a â‰¡ x â†’ a âˆˆ (x âˆ· xs)
  there : {x : A} {xs : List A} â†’ a âˆˆ xs â†’ a âˆˆ (x âˆ· xs)
   #+end_src

   Now that we have all the necessary tools, we proceed to define the relation
   =_âŠ¢_=, which represents the \il{} logic in Agda.
   #+begin_src text
data _âŠ¢_ (Î  : List Fm) : Fm â†’ Set where
  -- identity rule
  Ax : âˆ€ {A} â†’ A âˆˆ Î  â†’ Î  âŠ¢ A
  -- classical axioms
  C1 : âˆ€ {A B} â†’ Î  âŠ¢ A â† (B â† A)
  C2 : âˆ€ {A B C} â†’ Î  âŠ¢ (A â† (B â† C)) â† ((A â† B) â† (A â† C))
  C3 : âˆ€ {A B} â†’ Î  âŠ¢ (Â¬' A â† Â¬' B) â† (B â† A)
  -- IL axioms
  K : âˆ€ {A B} â†’ Î  âŠ¢ (â–¡ (A â† B)) â† (â–¡ A â† â–¡ B)
  L : âˆ€ {A} â†’ Î  âŠ¢ â–¡ (â–¡ A â† A) â† â–¡ A
  J1 : âˆ€ {A B} â†’ Î  âŠ¢ â–¡ (A â† B) â† A â–· B
  J2 : âˆ€ {A B C} â†’ Î  âŠ¢ A â–· B âˆ§ B â–· C â† A â–· C
  J3 : âˆ€ {A B C} â†’ Î  âŠ¢ (A â–· C âˆ§ B â–· C) â† (A âˆ¨ B) â–· C
  J4 : âˆ€ {A B} â†’ Î  âŠ¢ A â–· B â† â™¢ A â† â™¢ B
  J5 : âˆ€ {A} â†’ Î  âŠ¢ â™¢ A â–· A
  -- rules
  MP : âˆ€ {A B} â†’ Î  âŠ¢ A â† B â†’ Î  âŠ¢ A â†’ Î  âŠ¢ B
  nec : âˆ€ {A} â†’ [] âŠ¢ A â†’ Î  âŠ¢ â–¡ A
   #+end_src
   We include constructor =Ax= so we can use assumptions. We include
   constructors =C1=, =C2= and =C3= so that every classical tautology in the
   language of \il{} can be proved. Then we add the axioms of \il{} and finally we add
   =MP= for modus ponens and =nec= for necessitation. Note that the
   necessitation rule only accepts \il{} theorems (empty set of assumptions) and
   thus this definition is fitting for local semantics.
   We have proven several results about \il, which are presented in Section
   [[sec:il]].

   Consider the pen and paper syntactic proof of $Aâ†’A$.
   \begin{flalign*}
   0.\ &(A â†’ ((A â†’ A) â†’ A)) â†’ ((A â†’ (A â†’ A)) â†’ (A â†’ A)) & \text{By } C2 \\
   1.\ &A â†’ ((A â†’ A) â†’ A) & \text{By } C1 \\
   2.\ &A â†’ (A â†’ A) & \text{By } C1 \\
   3.\ & (A â†’ (A â†’ A)) â†’ A â†’ A   &\text{By MP 0, 1} \\
   4.\ & A â†’ A   &\text{By MP 3, 2} \\
   â– &
   \end{flalign*}
   Now see how we could replicate the proof in Agda using our definition of =_âŠ¢_=.
   #+begin_src text
âŠ¢Aâ†A : âˆ€ {A Î } â†’ Î  âŠ¢ A â† A
âŠ¢Aâ†A {A} = MP (MP (C2 {Î } {A} {A â† A} {A}) (C1 {Î } {A} {A â† A})) (C1 {Î } {A} {A})
   #+end_src
   We see that it is extremely verbose and hard to read. We can substantially
   improve it by relying on Agda's type inference to automatically infer the
   instantiation of almost all of the axiom schemes used.
   #+begin_src text
âŠ¢Aâ†A : âˆ€ {A Î } â†’ Î  âŠ¢ A â† A
âŠ¢Aâ†A {A} = MP (MP C2 C1) (C1 {B = A})
   #+end_src
   From the previous result it is easy to show that $Aâ–·A$ is an \il{} theorem.
   \begin{flalign*}
        0.\ &  A â†’ A                        &\text{By } âŠ¢Aâ†’A \\
        1.\ &  â–¡ (A â†’ A)                    &\text{By necessitation on 0} \\
        2.\ &  â–¡ (A â†’ A) â†’ (A â–· A)          &\text{By J1} \\
        3.\ &  A â–· A                        &\text{By MP 2, 1} \\
       â– 
   \end{flalign*}
   And now the same proof in Agda.
   #+begin_src text
âŠ¢Aâ–·A : âˆ€ {A Î } â†’ Î  âŠ¢ A â–· A
âŠ¢Aâ–·A {A} = MP J1 (nec âŠ¢Aâ†A)
   #+end_src
   Although the Agda proofs of $Aâ†’A$ and $Aâ–·A$ are short, it is very hard for a
   human to fully understand them with the Agda syntax used above. This problem
   motivates our next section, in which we present a way to express syntactic
   proofs in Agda using paper-like syntax.

*** An eDSL for syntactic proofs
     In this section we present a language for writing Hilbert style proofs for
     logic \il. This language was first presented by the author of this paper in
     cite:slug for logic $K$.

     We begin by introducing the concept of eDSL. The acronym eDSL stands for
     Embedded Domain Specific Language. It refers to a small language (a set of
     functions and datatypes) embedded in another language (in this case Agda)
     that has been designed to solve a problem in a very specific domain, in this
     case, Hilbert style proofs.

     We begin by showing how we could write the two syntactic proofs presented
     in the previous section in our eDSL. Then we will present the language in
     detail.

     First example:
   #+begin_src text
âŠ¢Aâ†A : âˆ€ {A} â†’ [] âŠ¢ A â† A
âŠ¢Aâ†A {A} =
  begin[ 0 ] (A â† ((A â† A) â† A)) â† ((A â† (A â† A)) â† (A â† A)) By C2
       [ 1 ] A â† ((A â† A) â† A)                               By C1
       [ 2 ] A â† (A â† A)                                     By C1
       [ 3 ] (A â† (A â† A)) â† A â† A                           ByMP 0 , 1
       [ 4 ] A â† A                                           ByMP 3 , 2
       â– 
   #+end_src

   Second example:
   #+begin_src text
âŠ¢Aâ–·A : âˆ€ {A} â†’ [] âŠ¢ A â–· A
âŠ¢Aâ–·A {A} =
  begin[ 0 ] A â† A                        By âŠ¢Aâ†A
       [ 1 ] â–¡ (A â† A)                    ByNec 0
       [ 2 ] â–¡ (A â† A) â† (A â–· A)          By J1
       [ 3 ] A â–· A                        ByMP 2 , 1
       â– 
   #+end_src

   We see that our eDSL allows us to write syntactic proofs in a very similar
   human-friendly syntax which is almost identical to the pen and paper usual
   syntax with the standout benefit that the proof is computer checked. We want
   to emphasize, as it may be surprising to the reader, that the proofs shown
   above are actual Agda code.

   We proceed by giving a short description of the language, which consists of
   four types of instructions:
   1. =[_]_By_=. This instruction is used to include a theorem in the proof. The
      theorem can be any axiom scheme of \il{} or anything proved to be a theorem.
      More precisely, the theorem can be any =A= if we have =Î  âŠ¢ A= for some =Î =.
      The first instruction must be of this kind and must be preceded with =begin=.
   2. =[_]_ByNec_=. This instruction applies the necessitation rule to a formula
      in a previous line referenced by its number. This rule can only be applied
      if we have an empty set of assumptions.
   3. =[_]_ByMP_=. This instruction applies the modus ponens rule to two
      formulas in previous lines referenced by their number.
   4. =â– =. The proof must be closed using this instruction.
   Every instruction must be increasingly numbered starting at 0.

   Thanks to the design of the language, if the user mistakenly numbers one of
   the instructions Agda will report an error indicating where the error is. If
   the user improperly instantiates an axiom scheme or theorem or references an
   incorrect line, it will also be prompted with an error. Summarizing, an error
   will appear if the proof has any deficiency. This holds true as the eDSL is
   implemented in Agda and thus it is verified.

   We proceed by giving a rough approximation on how the language has been
   implemented. Details of the inner workings of the language are left out as
   they fall out of the scope of this paper, however, we encourage the reader to look
   for further information in cite:slug if they are interested.

   We begin by defining the datatype that represents our language.
   #+begin_src text
data HilbertProof : List Fm â†’ Fm â†’ Nat â†’ Set where
  begin : âˆ€ {Î£ A} â†’ Î£ âŠ¢ A â†’ HilbertProof Î£ A 0
  by : âˆ€ {Î£ A B n} â†’ Î£ âŠ¢ B â†’ HilbertProof Î£ A n â†’ HilbertProof Î£ B (suc n)
   Ax : âˆ€ {Î£ B n} â†’ (A : Fm) â†’ HilbertProof Î£ B n â†’ HilbertProof (A âˆ· Î£) A (suc n)
  nec : âˆ€ {Î£ n â–¡A C} (H : HilbertProof [] C n) (i : HilbertRef H (â–¡A) â–¡_)
    â†’ HilbertProof Î£ (â–¡A) (suc n)
  MP : âˆ€ {n Î£ A B C} (H : HilbertProof Î£ C n) â†’ HilbertRef H (A â† B) id
    â†’ HilbertRef H A id â†’ HilbertProof Î£ B (suc n)
   #+end_src
   Each instruction (except =â– =) has its corresponding constructor. We see that
   the datatype is indexed by a list of formulas and a formula. Those are the set of
   assumptions and the formula that is shown to be a theorem. The third index is
   a natural number. This number keeps track of the length of the proof and it
   is needed to ensure that references to previous lines are not out of bounds.
   The type =HilbertRef= represents a reference to a previous line in the proof.
   We omit its definition here as is not crucial for understanding the overall
   idea.

   Then we define the front end syntax for each of the constructors. For
   instance, the definition of the =[_]_By_= instruction is as follows (we omit
   the type for simplicity as it is the same the type of the constructor =by=).
   #+begin_src text
infixl 10 _[_]_By_
_[_]_By_ : ...
H [ n ] B By p = by p H
   #+end_src
   Notice that we also declare the instruction to have left associativity
   (=infixl=), which will allow us to write each subsequent instruction below
   the other without need of parentheses.

   We skip how references work for simplicity, as they use advanced Agda
   features (type classes and instance arguments (cite:agda-doc)) in order to be
   automatically checked without an explicit proof.

   Observe now how we can build a proof in this language.
   #+begin_src text
âŠ¢Aâ–·A' : âˆ€ {A} â†’ HilbertProof [] (A â–· A) 3
âŠ¢Aâ–·A' {A} =
  begin[ 0 ] A â† A                 By âŠ¢Aâ†A
       [ 1 ] â–¡ (A â† A)             ByNec 0
       [ 2 ] â–¡ (A â† A) â† (A â–· A)   By J1
       [ 3 ] A â–· A                 ByMP 2 , 1
   #+end_src
   It is essentially the same as we showcased before but it is lacking the
   closing =â– = instruction. The type of such instruction is:
   #+begin_src text
_â–  : âˆ€ {n Î£ A} â†’ HilbertProof Î£ A n â†’ Î£ âŠ¢ A
   #+end_src
   We see that =â– = is defined as a postfix operator which translates a proof
   =HilbertProof Î£ A n= into a proof =Î£ âŠ¢ A=. This translation step is where
   most of the complexity lays. Needless to say, as is implemented and verified
   in Agda it is guaranteed to be correct. This ends the tour of the language.

   We strongly believe in the practical utility of this language as it can be
   used by logicians that are not Agda experts due to its simple and familiar
   syntax. We are all aware that long syntactic proofs are error prone. This
   language completely removes such problem. Of course, there is some room for
   improvement, for instance, the language does not include the deduction
   theorem rule, which is frequently used in practice. Note that this limitation
   can be ameliorated as we can use the deduction theorem outside of the eDSL
   and then include the result by using a =[_]_By_= instruction.
* other

\printglossary

\printbibliography[
heading=bibintoc,
title=Bibliography
]

* TODO Appendix
  TODO: include all the necessary unicode characters.

  # #+INCLUDE: "./latex/all.tex" export latex
