#+latex_compiler: xelatex
#+latex_class: scrreprt
#+options: H:4
#+options: toc:nil

#+latex_header: \usepackage{hyperref}
#+latex_header: \usepackage{mathpartir}
#+latex_header: \usepackage{graphicx}
#+latex_header: \usepackage{unicode-math}
#+latex_header: \usepackage{fontspec}
#+latex_header: \usepackage[x11names, table]{xcolor}
#+latex_header: \usepackage[margin=2.5cm]{geometry}
#+latex_header: \usepackage{lmodern}
#+latex_header: \setmonofont{FreeMono}
#+latex_header: \usepackage{cancel}
#+latex_header: \usepackage{amsthm}
#+latex_header: \usepackage{float}
#+latex_header: \usepackage{newunicodechar}
#+latex_header: \usepackage[toc,indexonlyfirst,docdef=restricted]{glossaries-extra}
#+latex_header: \usepackage[style=ieee]{biblatex}
#+latex_header: \usepackage{multicol}
#+latex_header: \usepackage{stmaryrd}
#+latex_header: \usepackage{spverbatim}


#+latex_header: \bibliography{refs}
#+latex_header: \makeglossaries

#+latex_header: \hypersetup{colorlinks=true,urlcolor=DodgerBlue4,linkcolor=Salmon4,citecolor=Green4}
#+latex_header: \newcommand{\ie}[0]{i.e.}
#+latex_header: \newcommand{\todo}[0]{\textcolor{red}{pending}}
#+latex_header: \newcommand{\pend}[0]{\textcolor{Tomato3}{pending }}
#+latex_header: \newcommand{\red}[1]{\textcolor{red}{#1 }}

#+macro: begindef @@latex:\begin{definition}@@
#+macro: enddef @@latex:\end{definition}@@

#+macro: begincoro @@latex:\begin{corollary}@@
#+macro: endcoro @@latex:\end{corollary}@@

#+macro: beginremark @@latex:\begin{remark}@@
#+macro: endremark @@latex:\end{remark}@@

#+macro: begintheorem @@latex:\begin{theorem}@@
#+macro: endtheorem @@latex:\end{theorem}@@

#+macro: beginlemma @@latex:\begin{lemma}@@
#+macro: endlemma @@latex:\end{lemma}@@

#+macro: beginproof @@latex:\begin{proof}@@
#+macro: endproof @@latex:\end{proof}@@


#+macro: defglossary @@latex:\newglossaryentry{$1}{name=$2,description={$3}}@@
#+macro: defacronym @@latex:\newacronym{$1}{$2}{$3}@@


#+latex_header: \newtheorem{theorem}{Theorem}
#+latex_header: \theoremstyle{definition}
#+latex_header: \newtheorem{corollary}[theorem]{Corollary}
#+latex_header: \theoremstyle{definition}
#+latex_header: \newtheorem{lemma}[theorem]{Lemma}
#+latex_header: \theoremstyle{definition}
#+latex_header: \newtheorem{definition}[theorem]{Definition}
#+latex_header: \theoremstyle{definition}
#+latex_header: \newtheorem{remark}[theorem]{Remark}

#+latex_header: \newglossaryentry{agdaprf}{name={\includegraphics[height=\baselineskip]{img/agda}},description={A proof formalized in Agda}}
#+latex_header: \newglossaryentry{coqprf}{name={\includegraphics[height=\baselineskip]{img/coq}},description={A proof formalized in Coq}}

#+macro: beginmulticols @@latex:\begin{multicols}{$1}@@
#+macro: endmulticols @@latex:\end{multicols}@@

#+latex_header: \newcommand{\joost}[1]{\textcolor{purple}{\textbf Joost: #1}}
#+latex_header: \newcommand{\jan}[1]{\textcolor{blue}{\textbf Jan: #1}}
#+latex_header: \newcommand{\luka}[1]{\textcolor{green}{\textbf Luka: #1}}
#+macro: joost @@latex:\joost{$1}@@
#+macro: jan @@latex:\jan{$1}@@
#+macro: luka @@latex:\luka{$1}@@

{{{defglossary(gvm,model,Generalized Veltman model)}}}
{{{defglossary(gvf,frame,Generalized Veltman frame)}}}
{{{defglossary(ovf,frame,Ordinary Veltman frame)}}}
{{{defglossary(ovm,model,Ordinary Veltman model)}}}
{{{defglossary(forcing-gen,{\ensuremath{‚ä©^{gen}_M}},Forcing relation for generalized semantics)}}}
{{{defglossary(forcing-ord,{\ensuremath{‚ä©^{ord}_M}},Forcing relation for ordinary semantics)}}}
{{{defglossary(choice-set,choice set,Choice set)}}}
{{{defglossary(noetherian,Noetherian,Conversely well-founded relation)}}}
#+latex_header: \newglossaryentry{dependent-pair}{name={dependent pair},description={A pair in which the type of the second component is indexed by the first component}}
#+latex_header: \newglossaryentry{sum type}{name={sum type},description={A disjunction of two ore more types}}
#+latex_header: \newglossaryentry{decidable model}{name={decidable model},description={A model whose forcing relation is decidable}}
#+latex_header: \newglossaryentry{multi decidable model}{name={multi-decidable model},description={A model whose forcing relation is decidable for sets}}
#+latex_header: \newglossaryentry{Rel}{name={\texttt{Rel}},description={Homogeneous relation}}
#+latex_header: \newglossaryentry{REL}{name={\texttt{REL}},description={Heterogeneous relation}}
#+latex_header: \newglossaryentry{Pred}{name={\texttt{Pred}},description={A predicate or a subset}}

#+macro: agda @@latex:\gls{agdaprf}\glsadd{agdaprf}@@
#+macro: coq @@latex:\gls{coqprf}\glsadd{coqprf}@@
#+latex_header: \newcommand{\prin}[1]{\ensuremath{\mathsf{#1}}}
#+latex_header: \newcommand{\il}[0]{\prin{IL}}
#+latex_header: \newcommand{\pa}[0]{\prin{PA}}
#+latex_header: \newcommand{\gl}[0]{\prin{GL}}
#+latex_header: \newcommand{\kgen}[1]{\text{($\mathsf{#1}$)\textsubscript{gen}}}
#+latex_header: \newcommand{\kord}[1]{\text{($\mathsf{#1}$)}}
#+latex_header: \newcommand{\ilall}[0]{\ensuremath{\mathsf{IL}}(All)}
#+latex_header: \newcommand{\rep}[1]{‚åú#1‚åù}
#+latex_header: \newcommand{\prov}[1]{\prin{Prov}(#1)}
#+latex_header: \newcommand{\fm}[0]{\ensuremath{\mathsf{Fm}}}
#+latex_header: \newcommand{\var}[0]{\ensuremath{\mathsf{Var}}}
#+latex_header: \renewcommand{\sf}[1]{\ensuremath{\mathsf{#1}}}
#+latex_header: \newcommand{\el}[1]{\ensuremath{\mathsf{El}(#1)}}
#+latex_header: \newcommand{\set}[0]{\ensuremath{\mathsf{Set}}}
#+latex_header: \newcommand{\type}[0]{\ensuremath{\mathsf{Set}}}


# remember to invoke with \ilall{} and not \ilall so that the space at the end
# is inserted if needed.


# Missing monospaced characters
#+latex_header: \setmathfont{XITS Math}
#+latex_header: \newfontfamily{\myfont}{XITS Math}
#+latex_header: \newunicodechar{ùïé}{\makebox[1em]{\myfontùïé}}
#+latex_header: \newunicodechar{·µ¢}{\makebox[0.5em]{\textsubscript{i}}}
#+latex_header: \newunicodechar{‚±º}{\makebox[0.5em]{\textsubscript{j}}}
#+latex_header: \newunicodechar{‚Çñ}{\makebox[0.5em]{\textsubscript{k}}}
#+latex_header: \newunicodechar{‚Çô}{\makebox[0.5em]{\textsubscript{n}}}
#+latex_header: \newunicodechar{‚Çò}{\makebox[0.5em]{\textsubscript{m}}}
#+latex_header: \newunicodechar{·µ§}{\makebox[0.5em]{\textsubscript{u}}}
#+latex_header: \newunicodechar{‚Çó}{\makebox[0.5em]{\textsubscript{l}}}
#+latex_header: \newunicodechar{‚∏¥}{\makebox[0.5em]{,}}
#+latex_header: \newunicodechar{ÔΩõ}{\ensuremath{\{}}
#+latex_header: \newunicodechar{ÔΩù}{\ensuremath{\}}}
#+latex_header: \newunicodechar{ùî∏}{\ensuremath{ùî∏}}
#+latex_header: \newunicodechar{ùîπ}{\ensuremath{ùîπ}}
#+latex_header: \newunicodechar{ùîª}{\ensuremath{ùîª}}
#+latex_header: \newunicodechar{ùîº}{\ensuremath{ùîº}}
#+latex_header: \newunicodechar{ùîΩ}{\ensuremath{ùîΩ}}
#+latex_header: \newunicodechar{ùîæ}{\ensuremath{ùîæ}}
#+latex_header: \newunicodechar{ùí±}{\ensuremath{ùí±}}
#+latex_header: \newunicodechar{ùíû}{\ensuremath{ùíû}}
#+latex_header: \newunicodechar{‚Ñ±}{\ensuremath{‚Ñ±}}



# inexact replacements. I don't know how to exactly replace these as they do
# not exist in Latin Modern Math.
#+latex_header: \newunicodechar{‚¶É}{\ensuremath{‚ü¶}}
#+latex_header: \newunicodechar{‚¶Ñ}{\ensuremath{‚üß}}
#+latex_header: \newunicodechar{‚¶Ö}{\ensuremath{‚ü¶}}
#+latex_header: \newunicodechar{‚¶Ü}{\ensuremath{‚üß}}

#+latex_header: \setmathfont{Latin Modern Math}
#+latex_header: \newcommand{\horrule}[1]{\rule{\linewidth}{#1}}

\begin{titlepage}
  \begin{center}

    \textsc{\Large Master's thesis to obtain the degree\\ Master in pure and applied logic}
     \\[1.4cm]

    % \horrule{0.5pt} \\[0.4cm]
    { \huge \bfseries Interpretability logics and generalized Veltman semantics in Agda \\[0.01cm] }

    \horrule{0.7pt} \\[2cm]
    % \horrule{1.6pt}
    % \sectionlinetwo{black}{87}

    ~\textsc{\LARGE Jan Mas Rovira}

    ~\\[1.2cm]
    \begin{tabular}[!htb]{ll}
    \text{\large Supervised by } &\textsc{\Large Joost J. Joosten} \\
    \text{\large and } &\textsc{\Large Luka Mikec}
    \end{tabular}
    ~\\[6.2cm]

    \begin{figure}[H]
      \centering
      \includegraphics[width=9cm]{img/ub_logo}
    \end{figure}
    \vfill

    \text{\Large Facultat de Filosofia de Barcelona and}\\
    \text{\Large Facultat de Matem√†tiques de Barcelona}\\
    {\Large July 2020}

  \end{center}
\end{titlepage}

#+BEGIN_abstract
abstract
#+END_abstract

\newpage

\renewcommand{\abstractname}{Acknowledgements}
#+BEGIN_abstract
thanks
#+END_abstract

\newpage
#+toc: headlines 2
\newpage
* [0/2] Pending                                                    :noexport:
** [0/2] Apply Luka's comments for review 1
   [[file:./jan_thesis_comments_16_06_20.pdf][pdf-link]].
*** TODO Fix drawings
** TODO Apply Luka's comments for review 2
   [[file:./jan_thesis_comments_07_07_2020.pdf][pdf-link]].
* Introduction
** Overview of interpretability logics
   We begin by giving a short introduction on provability logics. For more
   information refer to cite:sep-logic-provability. The reason to start here is
   that interpretability logics extend provability logics. Furthermore the
   ecosystem of interpretability logics is similar to the one of provability
   logics, albeit more complex, thus it will help establish an idea of the
   problems that we will tackle further in the report.

   Since G√∂del's incompleteness theorems, we have been interested in studying
   how much arithmetical theories like Peano Arithmetic can say about
   themselves, more precisely, about their provability capacity. As we know,
   sufficiently strong arithmetical theories like \pa{} can represent, by means
   of a clever syntactical encoding, their provability predicate, \prin{Prov},
   which states ``this formula is provable in $T$''. We call this predicate
   \prin{Prov}. A landmark result on this predicate is known as L√∂b's theorem,
   which states that \pa{} shows $\prov{\rep{A}}‚ÜíA$ only if \pa{} shows $A$.
   L√∂b's theorem can be expressed in the language of \pa{} thus:
   \[\prov{\prov{\rep{A}} ‚ÜíA}‚Üí\prov{\rep{A}}.\] This result sparked an interest
   in studying provability logic from a modal centered point of view which
   birthed the axiomatization of the propositional provability logic \gl{},
   named after G√∂del and L√∂b. The logic \gl{} extends propositional classical
   logic and its language consists in the language of propositional logic
   $‚ü®‚Üí,‚ä•‚ü©$ plus the $‚ñ°$ modal operator, which stands for the provability
   predicate. In this language L√∂b's theorem reads as \[‚ñ°(‚ñ°A‚ÜíA)‚Üí‚ñ°A.\] The above
   principle is in fact one of the axioms of \gl{}. The value of \gl{} directly
   depends on the arithmetical soundness and completeness theorems that we will
   present shortly, but first we need to introduce the concept of /arithmetical
   realization/. A realization $*$ is a map from modal formulas in the language
   of \gl{} to arithmetical sentences such that it satisfies the following:
   \begin{flalign*}
   ‚ä•^* &= (0=1) ; \\
   (A ‚Üí B)^* &= A^*‚ÜíB^*; \\
   (‚ñ°A)^* &= \prov{\rep{A}}.
   \end{flalign*}
   The arithmetical soundness theorem states that if $\gl{}‚ä¢A$ then $\pa{}‚ä¢A^*$
   for any realization $*$. Solovay proved that arithmetical completeness, which
   is the converse of soundness, also holds.

   Provability logics have Kripke (relational) semantics. As a reminder a
   Kripke model is a tuple $‚ü®W,R,V‚ü©$ where $W$ is a non-empty set of worlds, $R$
   is a binary relation on worlds and $V‚äÜW√ó\var{}$ is a valuation. Then we define a
   forcing relation $‚ä©\ ‚äÜW√ó\fm{}$ thus:
   1. $w‚äÆ‚ä•$;
   2. if $p‚àà\var{}$, then $w‚ä©p$ iff $‚ü®w,p‚ü©‚ààV$;
   3. if $A,B‚àà\fm{}$, then $w‚ä©A‚ÜíB$ iff if $w‚ä©A$ then $w‚ä©B$;
   4. if $A,B‚àà\fm{}$, then $w‚ä©‚ñ°A$ iff if $wRu$ then $u‚ä©A$.
   In order to have modal soundness and completeness we ought to restrict the
   class of frames that we consider. We say that a frame $‚ü®W,R‚ü©$ is a
   $\text{\gl{}-frame}$ if $R$ is transitive and conversely well-founded, that
   is, there are no infinite ascending chains $w‚ÇÄRw‚ÇÅ‚Ä¶$. Then we have that
   \[\gl{}‚ä¢A‚áî‚ü®W,R,V‚ü©‚ä©A \text{ for any \gl{}-frame $‚ü®W,R‚ü©$ and valuation $V$.} \]
   With this we conclude the introduction to provability logics and continue
   with interpretability logics.

   We introduce the concept of /interpretation/ as a first step towards
   understanding interpretability logics. Given two theories $V$ and $U$, an
   interpretation of $V$ into $U$ is a translation $f$ from \text{$V$-formulas}
   to \text{$U$-formulas} such that if $V‚ä¢A$ then $U‚ä¢f(A)$. In the history of
   mathematics we find numerous examples (cite:visser1997overview) of theorems
   that use interpretations as a cornerstone in their proofs. For instance,
   G√∂del's incompleteness theorems translate syntactical constructions into
   natural numbers. As another example we have that G√∂del's interpretation of
   \prin{ZF} plus the axiom of constructibility ($V=L$) serves as a proof of
   relative consistency of the continuum hypothesis with respect to \prin{ZF}.

   Interpretability logics, as the name foretells, studies the behaviour of
   interpretations. There are a number of things that we need to specify. We do
   not study the behaviour of interpretations between two arbitrary theories.
   Instead, we fix a base theory $T$ and we only consider interpretability
   between finite extensions of such theory. Thus when we say that $T+A$
   interprets $T+B$ we assume that $A$ and $B$ are formulas. In interpretability
   logics we only consider first order arithmetical theories which are
   recursively enumerable and are sequential[fn::A sequential theory is an
   arithmetical which can code and decode sequences of elements.]. Moreover, we
   are only concerned with the provable, within $T$, interpretability
   properties. In other words, we study the behaviour of the binary
   interpretability predicate $\sf{Int}_T$. Naturally, the predicate
   $\sf{Int}_T(A,B)$ must hold when we can formalize in $T$ that $T+A$
   interprets $T+B$. For a theory $T$, we denote the logic that describes the
   behaviour of the interpretability predicate of $T$ as $\sf{IL}(T)$. The
   language of $\sf{IL}(T)$ extends the language of \sf{GL} with the binary
   modal operator $‚ñ∑$, thus the language becomes $‚ü®‚ä•,‚Üí,‚ñ°,‚ñ∑‚ü©$. In order to give a
   more detailed definition of $\sf{IL}(T)$ we first extend the definition of
   arithmetical realization with an extra equation for the $‚ñ∑$ case. A
   realization $*$ is a map from formulas in $\sf{IL}(T)$ to sentences in the
   language of $T$. Moreover, it must satisfy the following constraints:
   \begin{flalign*}
   ‚ä•^* &= (0=1);\\
   (A‚ÜíB)^*&= A^*‚ÜíB^* ; \\
   (‚ñ°A)^*&= \sf{Prov}_T(‚åúA‚åù) ; \\
   (A‚ñ∑B)^*&= \sf{Int}_T(‚åúA‚åù,‚åúB‚åù).
   \end{flalign*}
   Then we define \[\sf{IL}(T)‚âî\{A\ |\ T‚ä¢A^* \text{ for any realization } *\}.\]

   There is an important difference with respect to provability logics that we
   need to highlight here. In provability logics we have that \sf{GL} is an
   axiomatization of the provability logics for all reasonable arithmetical
   theories {{{jan(double check this)}}} but we do not have an equivalent Swiss
   army knife that works for all theories in interpretability logics. Instead,
   we define different logics for various classes of theories. There is an
   essential logic which we call \il{} that serves as the basis for all these
   variants. We define this variants as extensions of \il{} by adding axiom
   schemes to it as we will see later in this overview. The logic \il{} extends
   the \sf{GL} logic with five new axiom schemes. We will precisely define logic
   \il{} and comment the significance of the new axiom schemes in Section
   [[sec:il]].

   The logic \il{} has two relational semantics, which are the main topic of
   this document, known as /ordinary Veltman semantics/ (introduced by Frank
   Veltman) and /generalized Veltman semantics/ (introduced by Rineke
   Verbrugge). Ordinary Veltman semantics are defined much in the same spirit as
   Kripke semantics for \sf{GL}, however, Veltman frames have an additional
   indexed (by each of the worlds) binary relation $S_w$ on worlds which is used
   to model the behaviour of the $‚ñ∑$ binary modal operator. In generalized
   Veltman semantics each of the $S_w$ relations, instead of relating two
   individual worlds, relates an individual world to a set of worlds. This type
   of definition seems to be inspired by the topological (or neighborhood)
   semantics that exist for other modal logics with unary modal operators.
   Topological semantics have not been studied yet for interpretability logics.
   As expected, both kinds of Veltman semantics are suitable for \il{} as we
   have soundness (which we present in this document) and completeness
   ({{{jan(REF needed)}}}) proofs. As we have already mentioned, \il{} is just
   the logic that we use as basis in interpretability logics, thus, each time we
   extend it with an axiom scheme (or principle, as we call them) we will need
   to find new semantics for it. We find these new semantics by finding frame
   conditions for the various principles that we work with. More precisely, a
   /frame condition/ for a principle $P$ is a first (or higher) order formula
   such that for every Veltman frame $F$ we have \[F‚ä®ùíû ‚áî ‚ü®F,V‚ü©‚ä©P \text{ for any
   valuation $V$ and instance of $P$.} \] To show an example, let us put our
   focus on the interpretability logic of \sf{PA} or similar theories. It
   happens that the axiomatization of this logic is given by adding the so
   called principle \sf{M} to the logic \il{}. We denote this new logic as
   $\sf{ILM}$. The \prin{M} principle is defined as follows: \[\sf{M}‚âîA ‚ñ∑ B ‚Üí (A
   ‚àß ‚ñ° C) ‚ñ∑ (B ‚àß ‚ñ° C).\] We give the definition for illustrative purposes, but
   the details of this formula are not relevant for this example. Then, consider
   the following condition:
   #+begin_center
   if $xS_wy$ and $yRz$ then $xRz$.
   #+end_center
   Again, the details of this condition are not relevant here. The important
   fact to notice is the following. If we consider the class of Veltman frames
   that satisfy this condition, we have soundness and completeness of \sf{ILM}
   and thus the presented condition is an adequate frame condition for \sf{M}.
   There are plenty of principles similar to \sf{M} in the literature. In this
   work we list a number of interpretability principles, including \sf{M}, and
   we prove their frame condition for both ordinary and generalized Veltman
   semantics.

   Some principles, like \sf{M}, are useful because they allow us to axiomatize
   the interpretability logic for certain classes of theories. However, there
   are other principles which are interesting because they are arithmetically
   valid in a large number of theories. These principles play a crucial role in
   the search of an axiomatization for the logic \ilall{}. The logic \ilall{} is
   defined to be the intersection of the interpretability logics of all
   reasonable arithmetical theories. Finding an axiomatization of such theory,
   as already hinted, remains an open problem, however a lot of progress has
   been made in the form of finding lower bounds for this logic. In this project
   we study the frame conditions for two series of principles: \prin{R^n} and
   \prin{R_n}, which appear in the current best known lower bound of \ilall.

** Original contributions
   This work includes the following original contributions:
   1. We have found a generalized frame condition for $\prin{R‚ÇÅ}$ (in
      collaboration with Mikec). [[theorem:R‚ÇÅ][Link]];
   2. we have found a generalized frame condition for $\prin{R‚Åø}$. [[theorem:R‚Åø][Link]];
   3. we performed a detailed analysis of the quasi-transitivity conditions
      available in the literature for generalized semantics. [[theorem:trans][Link]];
   4. we discovered a flawed proof in a published article. [[sec:flawed-proof][Link]];
   5. we worked out all the details of a proof in an unpublished manuscript by
      Verbrugge (cite:Verbrugge). [[sec:verbrugge][Link]];
   6. we present the implementation of a verified language to write Hilbert
      style proofs (for the logic \prin{IL}) in Agda with paper-like syntax.
      [[sec:edsl][Link]];
   7. we give details for an embedding of propositional intuitionistic logic
      into Martin L√∂f's logical framework. This result is expected. Our
      contribution has been to provide detailed definitions and proofs, which we
      were unable to find somewhere else. The proof detailed proof that $n+0=n$
      in Martin L√∂f's logical framework is also original. [[sec:def-new-types][Link]];
   9. during the development of this project we have coauthored two publications:
      - /An overview of Generalised Veltman Semantics/ (cite:joosten2020overview);
      - /Generalised Veltman Semantics in Agda/ (cite:masrovira2020generalised).
   10. we have implemented an Agda library for interpretability logics which
       includes every theorem and proof marked with {{{agda}}} that is presented
       in this document. It is worth pointing out that we started from scratch
       since there was no previous published work of interpretability logics in
       Agda, or in any other proof assistant. The code comprises ~5000
       lines of code and is freely available online:
       \begin{center}
       \href{https://gitlab.com/janmasrovira/interpretability-logics}
             {gitlab.com/janmasrovira/interpretability-logics}
       \end{center}
       We also provide the code in the annex of this document. [TODO: ADD LINK]
   11. we have reimplemented a small portion of the Agda library in the Coq proof
       assistant. This portion includes the definitions of the theorems and
       proofs marked with {{{coq}}}. Namely this subset is composed of the definition
       of ordinary Veltman semantics, the axiomatization of the logic \il{} and
       its proof of soundness. The code comprises ~500 lines of code and is
       available online:
       \begin{center}
       \href{https://gitlab.com/janmasrovira/coq-interpretability-logics}
            {gitlab.com/janmasrovira/coq-interpretability-logics}
       \end{center}

** Language
   <<sec:language>> The symbols of interpretability logics are $‚ä•,‚Üí,‚ñ∑$.
   Formulas are defined recursively as usual:
   1. /Variable/. If $x$ is a variable, then $x$ is a formula. We assume that we
      have an infinite countable set of variables. In particular we shall define
      $\var{}‚âî‚Ñï$. However, we use non-capital letters $a,b,c,x,y,z‚Ä¶$ to refer to
      variables.
   2. /Bottom/. The constant $‚ä•$ is a formula;
   3. /Implication/. If $A$ and $B$ are formulas, then $(A‚ÜíB)$ is a formula;
   4. /Interprets/. If $A$ and $B$ are formulas, then $(A‚ñ∑B)$ is a formula.
   We denote the set of valid formulas as \fm{}.

   We define the usual operators and constants in the following way:
   1. $¬¨ A ‚âî A ‚Üí ‚ä•$;
   2. $‚ä§ ‚âî ¬¨ ‚ä•$;
   3. $A ‚à® B ‚âî (¬¨ A) ‚Üí B$;
   4. $A ‚àß B ‚âî ¬¨ (A ‚Üí ¬¨ B)$;
   5. $A ‚Üî B ‚âî (A ‚Üí B) ‚àß (B ‚Üí A)$;
   6. $‚ñ° A ‚âî (¬¨ A) ‚ñ∑ ‚ä•$;
   7. $‚ô¢ A ‚âî ¬¨ ‚ñ° ¬¨ A$.

   The precedence (from higher to lower) of the operators is in the following
   order: \[‚àß,‚ñ∑,‚à®,‚Üí\]

   The scope of unary symbols $‚ñ°,‚ô¢,¬¨$ is as small as possible. Thus $‚ñ°A‚àß¬¨¬¨B$ is
   the same as $(‚ñ°A)‚àß(¬¨¬¨B)$.
** Notation
   Some notation that we use throughout the report:
   1. If $A$ and $B$ are binary relations, then $wAuBv$ means $wAu$ and $uBv$.
      For instance $wRuS_xv$ means $wRu$ and $uS_xv$. Another example: $wRu‚ä©A$
      means $wRu$ and $u‚ä©A$;
   2. $Y‚ä©A$ iff for all $y‚ààY$ we have $y‚ä©A$;
   3. $Y‚äÆA$ iff there is some $y‚ààY$ such that $y‚äÆA$;
   4. $‚ü¶A‚üß‚âî\{w:w‚ä©A\}$;
   5. {{{agda}}} this is Agda's logo. Each proof that is formalized in Agda
      has been tagged with it;
   5. {{{coq}}} this is Coq's logo. Each proof that is formalized in Coq
      has been tagged with it;
   6. when we write a dot after the quantification of some variables, the scope of
      the variables extends to the rightmost part of what follows. Hence the
      formula  $‚àÄx‚àÉy.Pxy‚àß‚àÄz.Pyz$ is equivalent to $‚àÄx‚àÉy(Pxy‚àß‚àÄz(Pyz))$.


   In Section [[sec:trans]] and Part [[sec:frame-condition]] we present some diagrams.
   We use straight arrows to represent the $R$ relation and curvy arrows to
   represent some $S_w$ relation. We sometimes use red ink when an arrow is in a
   positive position in the formula to emphasize its role. We use discontinuous
   arrows when it is quantified universally.

   We believe that diagrams can help the reader have a better understanding of
   the underlying formula, however, they are not meant to be a replacement as
   they cannot unambiguously convey all the information in the formula.

** Logic \il
   <<sec:il>>

   {{{begindef}}} The logic \il{} encompasses all classical theorems in the new
   language (given by C1, C2 and C3), all theorems of \prin{GL} in the new
   language (given by L and K) plus some new axiom schemes:
   - C1: $A ‚Üí (B ‚Üí A)$;
   - C2: $(A ‚Üí (B ‚Üí C)) ‚Üí ((A ‚Üí B) ‚Üí (A ‚Üí C))$;
   - C3: $(¬¨ A ‚Üí ¬¨ B) ‚Üí (B ‚Üí A)$;
   - K: $‚ñ° (A ‚Üí B) ‚Üí ‚ñ° A ‚Üí ‚ñ° B$;
   - L: $‚ñ° (‚ñ° A ‚Üí A) ‚Üí ‚ñ° A$;
   - J1: $‚ñ° (A ‚Üí B) ‚Üí A ‚ñ∑ B$;
   - J2: $A ‚ñ∑ B ‚àß B ‚ñ∑ C ‚Üí A ‚ñ∑ C$;
   - J3: $(A ‚ñ∑ C ‚àß B ‚ñ∑ C) ‚Üí (A ‚à® B) ‚ñ∑ C$;
   - J4: $A ‚ñ∑ B ‚Üí ‚ô¢ A ‚Üí ‚ô¢ B$;
   - J5: $‚ô¢ A ‚ñ∑ A$.
   If $A$ is an instantiation of any of the previous axiom schemes, then $A$ is
   a theorem of $\il{}$, which we denote with $‚ä¢_{\il}A$. Additionally it has
   the following rules:
   - Necessitation: if $‚ä¢_{\il}A$ then $‚ä¢_{\il}‚ñ°A$;
   - modus ponens: if $Œ†‚ä¢_{\il}A‚ÜíB$ and $Œ†‚ä¢_{\il}A$ then $Œ†‚ä¢_{\il}B$;
   - identity: If $A‚ààŒ†$ then $Œ†‚ä¢_{\il}A$.
   {{{enddef}}}

   {{{beginremark}}} While it is acceptable to have an infinite set of
   assumptions $Œ†$, when verifying properties in Agda we have restricted
   ourselves to finite sets and thus we assume that $Œ†$ is finite in the Agda
   proof. This restriction is not meaningful in the context of this project.
   {{{endremark}}}

   {{{begintheorem}}} *Weakening*. If $Œ†‚ä¢_{\il}A$ then $B,Œ†‚ä¢_{\il}A$.
   {{{endtheorem}}} {{{beginproof}}} {{{agda}}} The proof is trivial. In Agda it
   is done by an induction on the proof. We only need to take care of shifting
   one position the references to assumptions. {{{endproof}}}

   {{{begintheorem}}} *Deduction*.
   $Œ†‚ä¢_{\il}A‚ÜíB$ iff $A,Œ†‚ä¢_{\il}B$. {{{endtheorem}}}
   {{{beginproof}}} {{{agda}}} {{{endproof}}}

   {{{begintheorem}}} *Cut*. If
   $Œ†‚ä¢_{\il}B$ and $B,Œ†‚ä¢_{\il}A$ then $Œ†‚ä¢_{\il}A$. {{{endtheorem}}}
   {{{beginproof}}} {{{agda}}} {{{endproof}}}

   {{{begintheorem}}} *Structurality*. If $Œ†‚ä¢_{\il}B$ and $œÉ$ is a
   substitution then $œÉ[Œ†]‚ä¢_{\il}œÉ(A)$. {{{endtheorem}}} {{{beginproof}}}
   {{{agda}}} {{{endproof}}}

   {{{begintheorem}}} <<thm:conjunction>> \label{thm:conjunction} *Conjunction*.
   $Œ†‚ä¢_{\il}A‚àßB$ iff $Œ†‚ä¢_{\il}A$ and $Œ†‚ä¢_{\il}B$. {{{endtheorem}}}
   {{{beginproof}}} {{{agda}}} {{{endproof}}}

   {{{begintheorem}}} The following holds:
    1. $‚ä¢_{\il} A ‚Üí A$;
    2. $‚ä¢_{\il} A ‚ñ∑ A$;
    3. $‚ä¢_{\il} (A ‚Üí B) ‚Üí (B ‚Üí C) ‚Üí A ‚Üí C$;
    4. $‚ä¢_{\il} A ‚Üí ¬¨ ¬¨ A$;
    5. $‚ä¢_{\il} (¬¨ ¬¨ A) ‚Üí A$;
    6. $‚ä¢_{\il} (A ‚Üí B) ‚Üí ¬¨ B ‚Üí ¬¨ A$;
    7. $‚ä¢_{\il} A ‚Üí ‚ä§$;
    8. $‚ä¢_{\il} ‚ä• ‚Üí A$;
    9. $‚ä¢_{\il} ¬¨ A ‚Üí A ‚Üí B$;
    10. $‚ä¢_{\il} A ‚àß B ‚Üí A$;
    11. $‚ä¢_{\il} A ‚àß B ‚Üí B$;
    12. $‚ä¢_{\il} (A ‚Üí B ‚Üí C) ‚Üí B ‚Üí A ‚Üí C$;
    13. $‚ä¢_{\il} A ‚Üí B ‚Üí A ‚àß B$;
    14. $‚ä¢_{\il} A ‚Üí A ‚à® B$;
    15. $‚ä¢_{\il} B ‚Üí A ‚à® B$;
    16. $‚ä¢_{\il} A ‚ñ∑ (A ‚à® ‚ô¢ A)$;
    17. $‚ä¢_{\il} (A ‚à® ‚ô¢ A) ‚ñ∑ A$;
    18. $‚ä¢_{\il} A ‚Üí B ‚áí ‚ä¢_{\il} ‚ñ° A ‚Üí ‚ñ° B$;
    19. $‚ä¢_{\il} A ‚Üî B ‚áí ‚ä¢_{\il} ‚ñ° A ‚Üî ‚ñ° B$;
    20. $‚ä¢_{\il} ‚ñ° (A ‚àß B) ‚Üî (‚ñ° A ‚àß ‚ñ° B)$;
    21. $‚ä¢_{\il} A ‚Üí B ‚áí ‚ä¢_{\il} ‚ô¢ A ‚Üí ‚ô¢ B$;
    22. $‚ä¢_{\il} A ‚Üî B ‚áí ‚ä¢_{\il} ‚ô¢ A ‚Üî ‚ô¢ B$;
    23. $‚ä¢_{\il} ¬¨ (A ‚àß B) ‚Üî ¬¨ A ‚à® ¬¨ B$;
    24. $‚ä¢_{\il} (A ‚à® ¬¨ B) ‚Üí (A ‚àß B ‚à® ¬¨ B)$.
   {{{endtheorem}}} {{{beginproof}}} {{{agda}}} All proofs have been formalized
   in Agda. Here we only show two examples. Consider theorems 16 and 17, namely
   $A ‚ñ∑ (A ‚à® ‚ô¢ A)$ and $(A ‚à® ‚ô¢ A) ‚ñ∑ A$. To prove 16 we assume that we have
   already showed theorem 14, that is, $‚ä¢_{\il}A‚ÜíA‚à®B$.
   \begin{flalign*}
   &1.\ A‚ÜíA‚à®‚ô¢A & \text{by $A‚ÜíA‚à®B$} \\
   &2.\ ‚ñ° (A‚ÜíA‚à®‚ô¢A) & \text{by Nec} \\
   &3.\ ‚ñ° (A‚ÜíA‚à®‚ô¢A)‚ÜíA‚ñ∑(A‚à®‚ô¢A) & \text{by J1} \\
   &4.\ A‚ñ∑(A‚à®‚ô¢A) & \text{by MP on 2, 3}
   \end{flalign*}
   To prove 17 we assume we have already showed theorem 2, that is,
   $‚ä¢_{\il}A‚ñ∑A$.
   \begin{flalign*}
   &1.\ A‚ñ∑A &\text{} \\
   &2.\ (‚ô¢A‚ñ∑A) &\text{by J5} \\
   &3.\ (A‚ñ∑A)‚àß(‚ô¢A‚ñ∑A) &\text{Conjunction theorem (\ref{thm:conjunction})} \\
   &4.\ (A‚ñ∑A)‚àß(‚ô¢A‚ñ∑A)‚Üí ((A ‚à® ‚ô¢ A) ‚ñ∑ A)& \text{by J3} \\
   &5.\ (A ‚à® ‚ô¢ A) ‚ñ∑ A & \text{by MP 3, 4}
   \end{flalign*}

  # ‚á® : Œ† ‚ä¢ A ‚ñ∑ (A ‚à® ‚ô¢ A)
  # ‚á® = MP J1 (nec ‚ä¢A‚ÜùA‚à®B)
  # ‚á¶ : Œ† ‚ä¢ (A ‚à® ‚ô¢ A) ‚ñ∑ A
  # ‚á¶ = MP J3 (‚ä¢‚àß ‚áê (‚ä¢A‚ñ∑A ‚∏¥ J5))

   {{{endproof}}}

** Veltman Semantics
   In this document we consider two variants of relational semantics for
   interpretability logics similar to Kripke semantics for other modal logics.

*** Ordinary Veltman semantics
    {{{begindef}}} <<def:ordinary-frames>> cite:modal-matters An ordinary
    Veltman \gls{ovf} $F=‚ü®W,R,S‚ü©$ is a structure constituted by a non-empty set
    of worlds $W$, a binary relation $R‚äÜW¬≤$ and a ternary relation $S‚äÜW√óW√óW$. We
    write $wRu$ instead of $‚ü®w,u‚ü©‚ààR$ and $uS_wv$ instead of $‚ü®w,u,v‚ü©‚ààS$. The
    structure must satisfy the following conditions:

    1. $R$ is transitive;
    2. $R$ is conversely well-founded. That is, there is no infinite ascending
       chain $w‚ÇÅRw‚ÇÇR‚Ä¶$;
    3. if $uS_wv$ then $wRu$ and $wRv$;
    4. if $wRu$ then $uS_wu$;
    5. if $wRu$ and $uRv$ then $uS_wv$;
    6. for every $w$, $S_w$ is transitive.
    {{{enddef}}}

    {{{begindef}}} An ordinary Veltman \gls{ovm} $M=‚ü®F,V‚ü©$ is a structure
    constituted by an ordinary Veltman frame $F$ and a valuation $V‚äÜW√ó\var{}$. If
    $F=‚ü®W,R,S‚ü©$ we will write $M=‚ü®W,R,S,V‚ü©$ instead of $M=‚ü®‚ü®W,R,S‚ü©,V‚ü©$. {{{enddef}}}

    {{{begindef}}} <<def:ord-forcing>> Given a model $M$, we define a forcing
    relation $\gls{forcing-ord}‚äÜW √ó \fm{}$. We write $M,w‚ä©A$ instead of
    $‚ü®w,A‚ü©‚àà\gls*{forcing-ord}$ or simply $w‚ä©A$ when the model is clear from the
    context. We write $w‚äÆA$ when $‚ü®w,A‚ü©‚àâ‚ä©_M$.
    1. $w‚äÆ‚ä•$;
    2. if $p‚àà\var{}$, then $w‚ä©p$ iff $‚ü®w,p‚ü©‚ààV$;
    3. if $A,B‚àà\fm{}$, then $w‚ä©A‚ÜíB$ iff if $w‚ä©A$ then $w‚ä©B$;
    4. if $A,B‚àà\fm{}$, then $w‚ä©A‚ñ∑B$ iff if $wRu$ and $u‚ä©A$ then there exists some $v$ such
       that $v‚ä©B$ and $uS_wv$.
    {{{enddef}}}

    If $F$ is an ordinary Veltman frame and $A$ a formula, we write $F‚ä©A$ to
    denote that for every valuation we have $‚ü®F,V‚ü©‚ä©A$.

    {{{begincoro}}}
    <<coro:ord-semantics>>
    It can be shown that:
    1. If $A,B‚àà\fm{}$, then $w‚ä©A‚àßB$ iff $w‚ä©A$ and $w‚ä©B$;
    1. If $A,B‚àà\fm{}$, then $w‚ä©A‚à®B$ iff $w‚ä©A$ or $w‚ä©B$;
    2. if $A‚àà\fm{}$, then $w‚ä©¬¨A$ iff $w‚äÆA$;
    3. if $A‚àà\fm{}$, then $w‚ä©‚ô¢A$ iff there exists $u$ such that $wRu$ and $u‚ä©A$;
    4. if $A‚àà\fm{}$, then $w‚ä©‚ñ°A$ iff for every $u$ such that $wRu$ we have $u‚ä©A$.
    {{{endcoro}}}
    {{{beginproof}}}
    {{{agda}}}
    {{{coq}}}
    {{{endproof}}}

    {{{begintheorem}}} *Decidability* If $W$ is finite and $R,S,V$ are decidable relations,
    then the forcing relation associated to the model $M‚âî‚ü®W,R,S,V‚ü©$ is decidable.
    {{{endtheorem}}} {{{beginproof}}} {{{agda}}} We have implemented a verified
    algorithm that given the mentioned conditions, a world $w$ and a formula
    $A$, constructs either a proof of $M,w‚ä©A$ or a proof of $M,w‚äÆA$. {{{endproof}}}

    {{{begintheorem}}} *Local soundness for ordinary semantics*. That is, if
    $Œ†‚ä¢_{\il}A$ and $M$ is an ordinary model with a world $w$ such that $w‚ä©Œ†$,
    then $w‚ä©A$. {{{endtheorem}}} {{{beginproof}}} {{{agda}}} {{{coq}}} {{{endproof}}}

*** Generalized Veltman semantics
    {{{begindef}}} cite:mikec2019interpretability A generalized Veltman \gls{gvf}
    $F=‚ü®W,R,S‚ü©$ is a structure constituted by a non-empty set of worlds $W$, a binary
    relation $R‚äÜW¬≤$ and a ternary relation $S‚äÜW√óW√ó(ùí´(W)‚àñ\{‚àÖ\})$. We write $wRu$
    instead of $‚ü®w,u‚ü©‚ààR$ and $uS_wY$ instead of $‚ü®w,u,Y‚ü©‚ààS$. The structure must
    satisfy the following conditions :

    1. $R$ is transitive; <<R-trans>>
    2. $R$ is conversely well-founded. That is, there is no infinite ascending
       chain $w‚ÇÅRw‚ÇÇR‚Ä¶$;
    3. if $uS_wY$ then $wRu$ and for all $y‚ààY$ we have $wRy$;
    4. /quasi-reflexivity/: if $wRu$ then $uS_w\{u\}$;
    5. if $wRu$ and $uRv$ then $uS_w\{v\}$;
    6. /quasi-transitivity/: if $uS_wY$ and $yS_wZ_y$ for all $y‚ààY$, then
       $uS_w\left(‚ãÉ_{y‚ààY}Z_y\right)$. This is a particular notion of
       quasi-transitivity, throughout this document we explore a total of eight
       notions, see Section [[sec:trans]].
    # 7. $S$ is monotone in the following sense: if $uS_wV‚äÜZ‚äÜ\{u:wRu\}$ then
    #    $uS_wZ$.
    {{{enddef}}}

    {{{begindef}}}
    <<def:gen-frame>>
    A generalized Veltman \gls{gvm} $M=‚ü®F,V‚ü©$ is a structure
    constituted by a generalized Veltman \gls{gvf} $F$ and a valuation $V‚äÜW√ó\var{}$.
    {{{enddef}}}
    {{{begindef}}}
    Given a model $M$, we define a forcing relation $\gls{forcing-gen}‚äÜW √ó
    \fm{}$. We use the same notational conventions as in the ordinary semantics.
    1. $w‚äÆ‚ä•$;
    2. if $p‚àà\var{}$, then $w‚ä©p$ iff $‚ü®w,p‚ü©‚ààV$;
    3. if $A,B‚àà\fm{}$, then $w‚ä©A‚ÜíB$ iff if $w‚ä©A$ then $w‚ä©B$;
    4. if $A,B‚àà\fm{}$, then $w‚ä©A‚ñ∑B$ iff if $wRu$ and $u‚ä©A$ then there exists some $Y$ such
       that $Y‚ä©B$ and $uS_wY$. When we write $Y‚ä©B$ we mean that for all $y‚ààY$ we
       have $y‚ä©B$;
    {{{enddef}}}

    If $F$ is a generalized Veltman frame and $A$ a formula, we write $F‚ä©A$ to
    denote that for every valuation we have $‚ü®F,V‚ü©‚ä©A$.

    {{{begincoro}}} We can show the same results in Corollary [[coro:ord-semantics]]
    for generalized semantics:
    1. If $A,B‚àà\fm{}$, then $w‚ä©A‚àßB$ iff $w‚ä©A$ and $w‚ä©B$;
    1. If $A,B‚àà\fm{}$, then $w‚ä©A‚à®B$ iff $w‚ä©A$ or $w‚ä©B$;
    2. If $A‚àà\fm{}$, then $w‚ä©¬¨A$ iff $w‚äÆA$;
    3. If $A‚àà\fm{}$, then $w‚ä©‚ô¢A$ iff there exists $u$ such that $wRu$ and $u‚ä©A$;
    4. If $A‚àà\fm{}$, then $w‚ä©‚ñ°A$ iff for every $u$ such that $wRu$ we have $u‚ä©A$.
    {{{endcoro}}}
    {{{beginproof}}}
    {{{agda}}}
    {{{endproof}}}

    {{{begintheorem}}} <<theorem:il-sound>> *Local soundness for generalized
    semantics*. That is, if $Œ†‚ä¢_{\il}A$ and $M$ is a generalized model with a world
    $w$ such that $w‚ä©Œ†$, then $w‚ä©A$. {{{endtheorem}}}

    {{{beginproof}}} {{{agda}}} We have verified this in Agda for all the presented
    quasi-transitivity conditions in Table [[fig:table-trans]]. {{{endproof}}}

** Quasi-transitivity
   <<sec:trans>> In the literature one can find several semantic requirements
   for the quasi-transitivity condition which we present in the table below. See
   that in definition [[def:gen-frame]] we used Condition (2). Theorem [[theorem:trans]] presents
   some direct implications between them. Theorems [[theorem:il-sound]] and
   [[theorem:trans-extend]] are sufficient to argue that all of them are appropriate
   for proving completeness of \il{}. It is worth mentioning however, that not
   all of them are sufficiently expressive to prove completeness for extensions
   of \il{}.

#+name: fig:table-trans
#+caption: Semantic requirements for quasi-transitivity mentioned in the literature.
#+attr_latex: :align c|l|l :float t :center t :placement [H] :font \small
| Nr. | Semantic requirement for transitivity                                                  | Mentioned in                                  |
|-----+----------------------------------------------------------------------------------------+-----------------------------------------------|
| (1) | $uS_xY ‚áí ‚àÄ \, \{ Y_y\}_{y‚àà Y} \Big((‚àÄ\, y‚ààY\ yS_xY_y) ‚áí ‚àÉ Z‚äÜ ‚ãÉ_{y‚àà Y}Y_y ‚àß uS_xZ\Big)$ | Joosten et al. '20 \cite{joosten2020overview} |
| (2) | $uS_xY ‚áí ‚àÄ \, \{ Y_y\}_{y‚àà Y} \Big((‚àÄ\, y‚ààY\ yS_xY_y) ‚áí uS_x‚ãÉ_{y‚àà Y}Y_y\Big)$          | Verbrugge '92 '20 \cite{Verbrugge}            |
| (3) | $uS_xY ‚áí ‚àÉ\, y‚ààY\, ‚àÄ Y'(yS_xY' ‚áí ‚àÉ \, Y''{‚äÜ}Y' ‚àß uS_xY'')$                             | Joosten et al. \cite{joosten2020overview}     |
| (4) | $uS_xY ‚áí ‚àÉ\, y‚ààY\, ‚àÄ Y'(yS_xY' ‚áí uS_xY')$                                              | Joosten '98 \cite{joosten-master}             |
| (5) | $uS_xY ‚áí ‚àÄ\, y‚ààY\, ‚àÄ Y'(yS_xY' ‚áí ‚àÉ \, Y''{‚äÜ}Y' ‚àß uS_xY'')$                             | Joosten et al. '20 \cite{joosten2020overview} |
| (6) | $uS_xY ‚áí ‚àÄ\, y‚ààY\, ‚àÄ Y'(yS_xY' ‚áí uS_xY')$                                              | Verbrugge '92 \cite{Verbrugge}                |
| (7) | $uS_xY ‚áí ‚àÄ\, y‚ààY\, ‚àÄ Y'(yS_xY'\wedge y‚àâY' ‚áí ‚àÉ \, Y''{‚äÜ}Y'\ uS_xY'')$                   | Joosten et al. '20 \cite{joosten2020overview} |
| (8) | $uS_xY ‚áí ‚àÄ\, y‚ààY\, ‚àÄ Y'(yS_xY'\wedge y‚àâY' ‚áí uS_xY')$                                   | Goris, Joosten '09 \cite{a-new-principle}     |

   #+caption: Diagrams for conditions 2, 4 and 6.
   #+name: fig:diagrams-transitivity
   #+attr_latex: :float t :width 0.9\textwidth :placement [H]
   [[file:img/trans-2-4-6.pdf]]

# I NOW SEE THAT THE TABLE IN YOUR SECTION 1.6 HAS BEEN UPDATED IN OUR PAPER

# OF COURSE, YOU SHOULD ADAPT IT TO YOUR THESIS.
# SHORTLY WE WILL PUT IT ON THE ARXIV SO THAT YOU CAN INCLUDE A REFERENCE



 # All of the presented quasi-transitivity requirements are adequate for proving
 # IL soundness and completeness. For soundness it is routine to check that every
 # instantiation of $J2$ holds. For the completeness part it is enough to see that
 # any ordinary Veltman model $M=‚ü®W,R,S,V‚ü©$ can be transformed into a generalized
 # Veltman model $M'=‚ü®W,R,S',V‚ü©$ where $S'‚âî\{‚ü®w,x,\{y\}‚ü©:‚ü®w,x,y‚ü©‚ààS\}$ and see that
 # $M'$ has the same truth value as $M$. This has been verified in Agda.

 {{{begintheorem}}} <<theorem:trans>> Let $F$ be a generalized Veltman frame. Let
 \[\sf{Mon}‚âî‚àÄw,u,V,Z(uS_wV‚äÜZ‚äÜ\{u:wRu\}‚áíuS_wZ)\] represent the monotonicity condition. The
 following implications hold.

 The first item should be read as $F‚ä®\sf{Mon}‚àß(1)‚Üí(2)$.

 {{{beginmulticols(3)}}}

   1. $\sf{Mon} ‚àß (1) ‚áí (2)$
   2. $(2) ‚áí (1)$
   3. $\sf{Mon} ‚àß (3) ‚áí (4)$
   4. $(4) ‚áí (3)$
   5. $(5) ‚áí (1)$
   6. $\sf{Mon} ‚àß (5) ‚áí (2)$
   7. $(5) ‚áí (3)$
   8. $\sf{Mon} ‚àß (5) ‚áí (4)$
   9. $\sf{Mon} ‚àß (5) ‚áí (6)$
   10. $(5) ‚áí (7)$
   11. $\sf{Mon} ‚àß (5) ‚áí (8)$
   12. $(6) ‚áí (1)$
   13. $\sf{Mon} ‚àß (6) ‚áí (2)$
   14. $(6) ‚áí (3)$
   15. $(6) ‚áí (4)$
   16. $(6) ‚áí (5)$
   17. $(6) ‚áí (7)$
   18. $(6) ‚áí (8)$
   19. $\sf{Mon} ‚àß (7) ‚áí (8)$
   20. $(8) ‚áí (7)$

 {{{endmulticols}}} {{{endtheorem}}}

 {{{beginproof}}}
 {{{agda}}}
 {{{endproof}}}

 {{{begintheorem}}} <<theorem:trans-extend>> Given an ordinary Veltman model
 $M=‚ü®W,R,S,V‚ü©$ we can find some generalized Veltman model $M'=‚ü®W,R,S',V‚ü©$, where
 we can replace our notion of quasi-transitivity by any of the Conditions
 $(i)‚àà\{1,‚Ä¶,8\}$. Furthermore, for every world $w$ and formula $A$:
 \[M,w‚ä©A‚áîM',w‚ä©A.\] {{{endtheorem}}}

 {{{beginproof}}} We prove it for the quasi-transitivity Condition (2) (the rest
 can be proven in the same way). Let $M=‚ü®W,R,S,V‚ü©$ be an ordinary model. Let
 $M'‚âî‚ü®W,R,S',V‚ü©$ with $S'$ defined thus: \[S'‚âî\{‚ü®w,x,\{y\}‚ü©:‚ü®w,x,y‚ü©‚ààS\}.\] It is
 easy to observe that $M'$ satisfies conditions 1--5 from definition
 [[def:gen-frame]]. It is also easy to see that it satisfies quasi-transitivity (2).
 We show that they force the same formulas by induction on the complexity of the
 formula. The only interesting case is $A‚ñ∑B$.
   - Assume $M,w‚ä©A‚ñ∑B$ and that for some $x$ we have $wRx‚ä©A$. It follows that
     there exists some $y$ such that $xS_wy‚ä©B$. By definition of $M'$ we have
     $xS'_w\{y\}$ and also $\{y\}‚ä©B$, therefore $M',w‚ä©A‚ñ∑B$.
   - Assume $M,w‚äÆA‚ñ∑B$, then there exists some $x$ such that $wRx‚ä©A$ and
     $‚àÄy(xS_wy‚áíy‚äÆB)$. It is obvious that for $M'$ we have $‚àÄy(xS'_w\{y\}‚áíy‚äÆB)$
     and also $‚àÄY(xS'_wY‚áíY‚äÆB)$, which is the required property.
 {{{endproof}}}

** Monotonicity
   Recall the monotonicity condition that we presented in the previous section:

  #+begin_center
    if $uS_wV‚äÜZ‚äÜ\{v:wRv\}$ then $uS_wZ$.
  #+end_center

  It happens that this condition can be assumed (and in fact, is a standard
  assumption in the literature) to be satisfied by generalized Veltman frames
  without harm. This is desirable as a good number of proofs and definitions
  (especially definitions related to filtrations) can be simplified when
  assuming the monotonicity condition. By ``can be assumed without harm'', we
  mean that for any generalized Veltman frame, we can find another generalized
  Veltman frame that it satisfies the monotonicity condition and moreover both
  frames will share truth value when expanded to a generalized Veltman model
  with a valuation. In the following theorem we prove this fact.

  {{{begintheorem}}} <<theorem:mono>> Let $F=‚ü®W,R,S‚ü©$ be a generalized Veltman
  frame with quasi-transitivity $(i)‚àà\{1,‚Ä¶,8\}$. Let $F'=‚ü®W,R,S'‚ü©$ where $S'$ is
  the monotone closure of $S$:

  \[S'‚âî\{‚ü®w,x,Y'‚ü© : ‚ü®w,x,Y‚ü©‚ààS, Y‚äÜY'‚äÜ\{u:wRu\}\}.\]

  Then $F'$ is a generalized Veltman frame satisfying quasi-transitivity
  Condition (2). Furthermore, let $V$ be an arbitrary valuation and $A$ an
  arbitrary formula. Let $M‚âî‚ü®F,V‚ü©$ and $M'‚âî‚ü®F',V‚ü©$. We have that for every world
  $w$: \[M,w‚ä©A‚áîM',w‚ä©A.\] {{{endtheorem}}}


  {{{beginproof}}} {{{agda}}}

  We check conditions listed in definition [[def:gen-frame]].
  - Conditions 1 and 2 are clear since $R$ is unchanged;
  - Condition 3 follows from the fact that in the definition of $S'$ we require
    $Y'‚äÜ\{u:wRu\}$;
  - for Conditions 4 and 5 observe that $S‚äÜS'$. Then, since these conditions hold for
    $F$ they also hold for $F'$;
  - for quasi-transitivity Condition (2) assume that $uS'_xY'$ and that for
    every $y'‚ààY'$ we have $y'S'_xŒ•_{y'}$. We need to show that
    $uS'_x‚ãÉ_{y'‚ààY'}Œ•_{y'}$. By definition of $S'$ it follows that there exists
    $Y‚äÜY'$ such that $uS_xY$, furthermore, for every $y'‚ààY'$ we have that there
    exists $f(Œ•_{y'})‚äÜŒ•_{y'}$ such that $y'S_xf(Œ•_{y'})$. From $Y‚äÜY'$ it follows
    that for all $y‚ààY$ there exists $f(Œ•_{y})‚äÜŒ•_{y}$ such that $yS_xf(Œ•_{y})$.
    Then by (2) for $F$ it follows that $uS_x‚ãÉ_{y‚ààY}f(Œ•_{y})$. Then see that
    $‚ãÉ_{y‚ààY}f(Œ•_{y})‚äÜ‚ãÉ_{y'‚ààY'}Œ•_{y'}$. It remains to show
    $‚ãÉ_{y'‚ààY'}Œ•_{y'}‚äÜxR\{u:xRu\}$. Consider some $u$ such that there is some
    $y'‚ààY'$ with $u‚ààŒ•_{y'}$. By assumption we have $y'S'_xŒ•_{y'}$ and thus
    $xRu$.
  To show $M,w‚ä©A‚áîM',w‚ä©A$ we proceed by induction on $A$. The only
  interesting case is $A‚ñ∑B$.
  - Assume that $M,w‚ä©A‚ñ∑B$ and that there is some world $x$ such that $wRx$ and
    $M',x‚ä©A$. By IH we have $M,x‚ä©A$, so there exists some $Y$ such that $xS_wY$
    and $M,Y‚ä©B$. By IH we have $M',Y‚ä©B$ and by definition of $S'$ it follows
    that $xS'_wY$, therefore $M',w‚ä©A‚ñ∑B$.
  - Assume that $M,w‚äÆA‚ñ∑B$. It follows that there is some $x$ such that $wRx$,
    $M,x‚ä©A$ and $(‚ãÜ)\ ‚àÄY(xS_wY‚áíM,Y‚äÆB)$. We want to prove that
    $‚àÄY'(xS'_wY'‚áíM',Y'‚äÆB)$. Assume that for some $Y'$ we have $xS'_wY'$. By
    definition of $S'$ it follows there exists some $Y$ such that $Y‚äÜY'$ and
    $xS_wY$. Hence by $(‚ãÜ)$ we have that $M,Y‚äÆB$ and thus there exists $y‚ààY$
    such that $M,y‚äÆB$. By IH we get that $M',y‚äÆB$ and since $y‚ààY‚äÜY'$ we have
    $Y'‚äÆB$, so $M',w‚äÆA‚ñ∑B$.
  {{{endproof}}}

  # As we see in Theorem [[theorem:mono]] taking the monotone closure of each $S_w$ does not
  # change the forcing relation and the resulting frame satisfies quasi-transitivity
  # Condition (2).

  # The previous lemma allows us to safely assume that monotonicity is a condition
  # for a Veltman frame with quasi-transitivity (2).

  {{{beginremark}}} Taking the monotone closure of each $S_w$ is essentially
  different than assuming that each $S_w$ is monotone by definition of the
  frame, as then the forcing relation may change. In the following example we
  present a generalized Veltman model with Condition (8) that showcases such
  behaviour.

   #+caption: Example frame: $wRv_0,wRv_1,wRv_2,wRv_3$, $v_0S_w\{v_1\}$, $v_2S_w\{v_3\}$.
   #+name: fig:example-trans
   #+attr_latex: :float t :width 0.28\textwidth :placement [H]
   [[file:img/example.pdf]]

  Let $M$ be a model based on the frame displayed[fn::In the figure we do not
  show the $S_w$ relations required by quasi-reflexivity for clarity.] in figure
  [[fig:example-trans]] such that $‚ü¶p‚üß = \{v_0\}$, $‚ü¶q‚üß = \{v_2\}$. We see that
  $w‚ä©¬¨(p ‚ñ∑ q)$ as $p$ is only true in $v_0$ and we only have $v_0S_w\{v_1\}$ and
  $v_0S_w\{v_0\}$ (by quasi-reflexivity) with $v_0‚äÆq$ and $v_1‚äÆq$. If we take
  the monotonic closure of $S$ we have $v_0S_w \{v_1, v_2\}$ and by
  quasi-transitivity (8) we get $v_0S_w \{v_3\}$ and consequently $w‚ä©¬¨(p ‚ñ∑ q)$
  is no longer true.

  {{{endremark}}}

* Generalized vs ordinary models
  In this section we explore the expressiveness of ordinary and generalized
  Veltman semantics. In particular, we discuss how we can transform an ordinary
  model into a generalized model and vice versa. Needless to say, we have the
  requirement that the transformation preserves the truth value of the original
  model.

  In Section [[sec:ord-to-gen]] we see a straightforward transformation from an
  ordinary Veltman model into a generalized Veltman model. In Section
  [[sec:verbrugge]] we see an involved transformation from a generalized model into
  an ordinary model. This transformation is due to Verbrugge and was described
  in cite:Verbrugge. The proof was originally described to work with
  quasi-transitivity Condition (6). We have slightly improved the result by
  showing that the same transformation also works for Conditions (3), (4) and
  (5). In Section [[sec:gen-to-ord-luka]] we show a transformation that achieves the
  same as Verbrugge's transformation but it is much simpler. This transformation
  was suggested by Mikec during online correspondence.

** From ordinary to generalized
   <<sec:ord-to-gen>> In this section we present a theorem that shows how an
   ordinary model naturally gives rise to a generalized model for any of the
   presented quasi-transitivity conditions. The resulting generalized model has
   the same set of worlds as the original and truth value is preserved.

   {{{begintheorem}}} Let $M=‚ü®W,R,S,V‚ü©$ be an ordinary Veltman model. We define
   $M'‚âî‚ü®W,R,S',V‚ü©$ where $S'‚âî\{‚ü®w,u,\{v\}:‚ü®w,u,v‚ü©‚ààS‚ü©\}$. Then M' is a generalized
   Veltman frame with quasi-transitivity condition $(i)‚àà\{1,‚Ä¶,8\}$.
   Furthermore, for any world $w$ and formula $A$ we have that
   \[M,w‚ä©A‚áîM',w‚ä©A.\]{{{endtheorem}}} {{{beginproof}}} We observe that the
   transitivity condition for the ordinary models $M$ entails the
   quasi-transitivity Condition (6) for the $M'$ generalized model. Keep in mind
   that by definition of $M'$ we only have singleton sets in the third component
   of $S'$. Now assume that $uS'_x\{y\}$ and $yS'_x\{y'\}$. By definition of
   $S'$ it follows that $uS_xyS_xy'$ and by quasi-transitivity of $M$ we have
   $uS_xy'$ and thus $uS_x\{y'\}$. Then, by theorem [[theorem:trans]] we know that
   quasi-transitivity Condition (6) implies Conditions (1), (3)-(8), thus, the
   presented transformation works for any of those notions of
   quasi-transitivity. Moreover, if we wish to obtain a generalized Veltman
   frame with quasi-transitivity Condition (2) we take monotone closure of $S'$
   as described in theorem [[theorem:mono]]. We leave the rest of the details to be
   worked out by the reader. {{{endproof}}}

** From generalized to ordinary
   <<sec:verbrugge>> In this section we show that given a generalized Veltman
   model $M$ with quasi-transitivity condition $(i)‚àà\{3,4,5,6\}$, we can build
   an ordinary Veltman model $M'$ such that for every world in $M$ we can find a
   world in $M'$ with the same truth value.

   It is worth mentioning that there exists a much simpler transformation which
   we present in the next Section ([[sec:gen-to-ord-luka]]) and works for the same
   quasi-transitivity Conditions as the transformation presented here. We still
   believe that this transformation holds value for historical reasons as it was
   the first to be sketched by Verbrugge in an unpublished manuscript
   (cite:Verbrugge). In the manuscript there is a comment where the author says
   that the transformation may also hold for Condition (2) although she has not
   checked it yet. Unfortunately some steps in the proof do not work if we take
   a generalized model with quasi-transitivity Condition (2). In
   cite:vukovic2008bisimulations a variation of this transformation is presented
   with the claim that it works for Condition (2). However, as we will comment
   in section [[sec:flawed-proof]], the proof of the claim is flawed.

   For the rest of this section we fix a generalized Veltman model $M‚âî‚ü®W, R, S,
   V‚ü©$.

   We define an ordinary Veltman model $M'‚âî‚ü®W',R',S',V'‚ü©$ where
   \begin{flalign*}
   W'‚âî&\{‚ü®x,A‚ü©:A‚äÜW^2, \\ &(W1)\ ‚àÄ‚ü®u,v‚ü©‚ààA\ ‚àÉY(xS_uY,v‚ààY), \\
   & (W2)\ ‚àÄuV(xS_uV‚áí‚àÉv‚ààV(‚ü®u,v‚ü©‚ààA)\}; \\
   R'‚âî&\{‚ü®‚ü®x,A‚ü©,‚ü®y,B‚ü©‚ü© : xRy,‚àÄwz(wRx‚áí‚ü®w,z‚ü©‚ààB‚áí‚ü®w,z‚ü©‚ààA)\}; \\
   S'‚âî&\{‚ü®‚ü®w,C‚ü©,‚ü®x,A‚ü©,‚ü®y,B‚ü©‚ü© : ‚ü®w,C‚ü©R'‚ü®x,A‚ü©,‚ü®w,C‚ü©R'‚ü®y,B‚ü©, ‚àÄv(‚ü®w,v‚ü©‚ààB‚áí‚ü®w,v‚ü©‚ààA) \}; \\
   V'‚âî&\{‚ü®‚ü®x, A‚ü©,var‚ü©: ‚ü®x,var‚ü©‚ààV, ‚ü®x,A‚ü©‚ààW'\}.
   \end{flalign*}

   {{{beginlemma}}}
   The structure $‚ü®W',R',S',V'‚ü©$ is an ordinary Veltman model.
   {{{endlemma}}}
   {{{beginproof}}}
   {{{agda}}} It is routine to check that all the requirement are satisfied.
   {{{endproof}}}

   Let the conditions $(C_0)$ and $(C_1)$ be defined thus:
   \begin{flalign*}
   (C‚ÇÄ)&‚âî‚àÄwxV.xS_wV‚áí‚àÉy‚ààV.‚àÄbV'.yS_bV'‚áí‚àÉv‚ààV'. (b=w ‚áí xS_b\{v\}), (bRw ‚áí wS_b\{v\}); \\
   (C‚ÇÅ)&‚âî‚àÄwbxV.wRx‚áíxS_bV‚áí‚àÉv‚ààV.xS_b\{v\},(bRw‚áíwS_b\{v\}).
   \end{flalign*}
   {{{begintheorem}}}
   If $M$ satisfies both conditions $(C_0)$ and $(C_1)$ then
   for any world $‚ü®w,C‚ü©‚ààW'$ and formula $D$:
   \[w‚ä©D‚áî‚ü®w,C‚ü©‚ä©D\]
   {{{endtheorem}}}
   {{{beginproof}}} {{{agda}}}
   We proceed by induction on the formula. We only consider the
   case $D‚ñ∑E$ as the other cases are easy.
   - \boxed{‚áí} Assume $w‚ä©D‚ñ∑E$ and let $C$ be such that $‚ü®w,C‚ü©‚ààW'$. We
     want to prove $‚ü®w,C‚ü©‚ä©D‚ñ∑E$. Assume that for some $‚ü®x,A‚ü©‚ààW'$ we have
     $‚ü®w,C‚ü©R'‚ü®x,A‚ü©‚ä©D$. By IH it follows that $x‚ä©D$ and hence there exists $V$
     such that $xS_wV‚ä©E$. By $(C_0)$ there is some $y‚ààV$ such that

     #+name: eq:verb-y-cond
     \begin{equation}
     ‚àÄbV'.yS_bV'‚áí‚àÉv‚ààV'. (b=w ‚áí xS_b\{v\}), (bRw ‚áí wS_b\{v\})
     \end{equation}

     We proceed by showing that there is some $B$ such that
     $‚ü®x,A‚ü©S'_{‚ü®w,C‚ü©}‚ü®y,B‚ü©$. Let $B$ be defined thus:
     \[B‚âî\{‚ü®u,v‚ü©: ‚àÉY.yS_uY,v‚ààY,(u=w‚áí‚ü®w,v‚ü©‚ààA),(uRw‚áí‚ü®u,v‚ü©‚ààC)\}\]

     To show $‚ü®y,B‚ü©‚ààW'$ we need to prove that $(W1)$ and $(W2)$ hold. The
     condition $(W1)$ follows immediately from the definition of $B$. To show
     $(W2)$ assume that for some $b$ and $V$ we have $yS_bV$. We need to see that
     there exists $v‚ààV$ such that $‚ü®b,v‚ü©‚ààB$. From $yS_bV$ and [[eq:verb-y-cond]] we
     get that there exists $v‚ààV'$ such that
     \begin{flalign}
     b=w &‚áí xS_b\{v\} \label{eq:verb-b=w}, \\
     bRw &‚áí wS_b\{v\} \label{eq:verb-2}
     \end{flalign}
     To show that $‚ü®b,v‚ü©‚ààB$ we first see that $b=w‚áí‚ü®w,v‚ü©‚ààA$. Assume $b=w$, then
     by \ref{eq:verb-b=w} it follows that $xS_b\{v\}$ and therefore by condition
     $(W2)$ for $A$ it follows $‚ü®b,v‚ü©‚ààA$. We proceed likewise and use
     \ref{eq:verb-2} to show $bRw‚áí‚ü®b,v‚ü©‚ààC$. This concludes the proof that
     $‚ü®y,B‚ü©‚ààW'$.

     We now check the conditions for $‚ü®x,A‚ü©S'_{‚ü®w,C‚ü©}‚ü®y,B‚ü©$. We already have
     $‚ü®w,C‚ü©R'‚ü®x,A‚ü©$ by assumption. To see that $‚ü®w,C‚ü©R'‚ü®y,B‚ü©$ we first observe
     that $wRy$ holds since $xS_wV$ and $y‚ààV$. Then assume that for some $b,z$ we
     have $bRw$ and $‚ü®b,z‚ü©‚ààB$. Then from the definition of $B$ it follows that
     $‚ü®b,z‚ü©‚ààC$. The condition $‚àÄv(‚ü®w,v‚ü©‚ààB‚áí‚ü®w,v‚ü©‚ààA)$ follows immediately from the
     definition of $B$.

     Finally, since $V‚ä©E$ and $y‚ààV$ we have $y‚ä©E$ and thus by IH it follows that
     $‚ü®y,B‚ü©‚ä©E$.

   - \boxed{‚áê} We proceed by contraposition. Assume $w‚äÆD‚ñ∑E$, then there exists
     $x$ such that $wRx$ and
     #+name: eq:verb-neg
     \begin{equation}
     ‚àÄY(vS_wY‚áí‚àÉy‚ààY(y‚äÆE)).
     \end{equation}

     Let $A$ be defined thus:
     \[A‚âî \{‚ü®b,v‚ü©:(‚àÉY.xS_bY,v‚ààY),(b=w‚áíM,v‚äÆE),(bRw‚áí‚ü®b,v‚ü©‚ààC)\}.\]

     We first show that $‚ü®x,A‚ü©‚ààW'$. Condition $(W1)$ follows directly from the
     definition of $A$. To show that $(W2)$ holds assume that for some $b$ and
     $V$ we have $xS_bV$. We need to see that for some $v‚ààV$ we have $‚ü®b,v‚ü©‚ààA$.
     Since $wRx$ and $xS_bV$ it follows from condition $(C_1)$ that there exists
     $v‚ààV$ such that
     \begin{flalign}
     &xS_b\{v\}, \label{eq:verb-neg-b=w} \\
     bRw‚áí&wS_b\{v\}. \label{eq:verb-neg-bRw}
     \end{flalign}
     The first condition to show $‚ü®b,v‚ü©‚ààA$, namely that $‚àÉY.xS_bY,v‚ààY$, is met
     trivially. For the next condition assume $b=w$, then see that we have
     $xS_w\{v\}$ by \ref{eq:verb-neg-b=w} and thus by [[eq:verb-neg]] it follows that
     $v‚äÆE$. For the remaining condition assume $bRw$, then by \ref{eq:verb-neg-bRw} we
     have $wS_b\{v\}$ and thus by $(W2)$ for $C$ we have $‚ü®b,v‚ü©‚ààC$. Therefore we
     conclude $‚ü®b,v‚ü©‚ààA$ and thus $‚ü®x,A‚ü©‚ààW'$.

     To see that $‚ü®w,C‚ü©R'‚ü®x,A‚ü©$ we already have $wRx$ by assumption. The
     remaining condition, $‚àÄbz(bRx‚áí‚ü®b,z‚ü©‚ààA‚áí‚ü®b,z‚ü©‚ààC)$, follows directly from the
     definition of $A$.

     Since $x‚ä©D$, it follows from the IH that $‚ü®x,A‚ü©‚ä©D$.

     Lastly, assume that for some $‚ü®y,B‚ü©‚ààW'$ we have $‚ü®x,A‚ü©S'_{‚ü®w,C‚ü©}‚ü®y,B‚ü©$. By
     definition of $S'$ we have $xS_wy$ and thus $wRy$. By quasi-reflexivity of
     $S$ we then have $yS_w\{y\}$ and thus by $(W2)$ for $B$ we have $‚ü®w,y‚ü©‚ààB$.
     By definition of $S'$ we also have that $‚àÄv(‚ü®w,v‚ü©‚ààB‚áí‚ü®w,v‚ü©‚ààA)$, hence
     $‚ü®w,y‚ü©‚ààA$. By definition of $A$ it follows that $y‚äÆE$ and by IH we have
     $‚ü®y,B‚ü©‚äÆE$, which concludes the proof.
   {{{endproof}}}

   {{{begintheorem}}} If a generalized Veltman frame satisfies
   quasi-transitivity Condition 3, 4, 5 or 6, then it satisfies conditions
   $(C_0)$ and $(C_1)$. {{{endtheorem}}}

   {{{beginproof}}} {{{agda}}} Here we prove the property for a generalized
   Veltman frame satisfying quasi-transitivity Condition 3. Conditions 4, 5 and 6
   imply Condition 3 as shown in Theorem [[theorem:trans]].

   Assume $F$ is a generalized Veltman frame satisfying quasi-transitivity
   Condition 3.
   It is easy to observe that the following property holds:
   #+name: eq:verb-trans-prop
   \begin{equation}
   uS_xY ‚áí ‚àÉ\, y‚ààY\, ‚àÄ z(yS_x\{z\} ‚áí uS_x\{z\}).
   \end{equation}
   - \boxed{(C‚ÇÄ)} Assume that for some $w,x,V$ we have $xS_wV$. Then by
     [[eq:verb-trans-prop]] there is some $y‚ààV$ such that
     #+name: eq:verb-trans-y
     \begin{equation}
      ‚àÄ z(yS_w\{z\} ‚áí xS_w\{z\}).
     \end{equation}

     Now assume that for some $b,V'$ we have $yS_bV'$. It follows by
     [[eq:verb-trans-prop]] that there is some $v‚ààV'$ such that
     #+name: eq:verb-trans-v
     \begin{equation}
      ‚àÄ z(vS_b\{z\} ‚áí yS_b\{z\}).
     \end{equation}
     Assume that $b=w$, we need to see that $xS_b\{v\}$. From $xS_wV$ and $y‚ààV$
     it follows that $wRy$. Then by quasi-reflexivity we have $yS_w\{y\}$ and by
     [[eq:verb-trans-y]] we get $xS_w\{v\}$ which is the same as $xS_b\{v\}$. Assume
     that $bRw$, we need to see that $wS_b\{v\}$. From $bRwRy$ we have
     $wS_b\{y\}$ and from property [[eq:verb-trans-prop]] we get
     #+name: eq:verb-trans-Sbyz
     \begin{equation}
     ‚àÄz(yS_b\{z\}‚áíwS_b\{z\}).
     \end{equation}
     Then since $yS_bV'$ and $v‚ààV'$ we have $bRv$ so by quasi-reflexivity we have
     $vS_b\{v\}$. Finally by [[eq:verb-trans-v]] we get $yS_b\{v\}$ and by
     [[eq:verb-trans-Sbyz]] we get $wS_b\{v\}$.
   - \boxed{(C_1)} Assume that for some $w,b,x,V$ we have $wRxS_bV$.
     By [[eq:verb-trans-prop]] it follows that there is some $v‚ààV$ such that
     #+name: eq:verb-trans-SbxV
     \begin{equation}
      ‚àÄz(vS_b\{z\} ‚áí xS_b\{z\}).
     \end{equation}
     We first see that $xS_b\{v\}$. From $xS_bV$ and $v‚ààV$ we get $bRv$ and by
     quasi-reflexivity we get $vS_b\{v\}$. Then by [[eq:verb-trans-SbxV]] we have
     $xS_b\{v\}$. Assume $bRw$, we need to see $wS_b\{v\}$. By quasi-reflexivity
     we get $vS_b\{v\}$ and by [[eq:verb-trans-SbxV]] we get $xS_b\{v\}$. By $bRwRx$
     we get $wS_b\{x\}$ and thus by [[eq:verb-trans-prop]] we have
     #+name: eq:verb-Sbwx
     \begin{equation}
     ‚àÄz(xS_b\{z\}‚áíwS_b\{z\}).
     \end{equation}
     Finally by $xS_b\{v\}$ and [[eq:verb-Sbwx]] we get $wS_b\{v\}$.
   {{{endproof}}}
** From generalized to ordinary (a simpler approach)
   <<sec:gen-to-ord-luka>> In this section we present a transformation that
   achieves the same effect as the one presented in Section [[sec:verbrugge]].
   However, the process described here is much simpler as it does not modify the
   set of worlds.

   {{{begintheorem}}} Let $M$ a generalized Veltman model with
   quasi-transitivity Condition 3, 4, 5 or 6. By theorem [[theorem:trans]] we shall
   assume without loss of generality that $M$ satisfies quasi-transitivity
   Condition 3. We remind the reader that the condition reads thus: \[uS_xY ‚áí
   ‚àÉ\, \textcolor{blue}{y}‚ààY\, ‚àÄ Y'(yS_xY' ‚áí ‚àÉ \, Y''{‚äÜ}Y' ‚àß uS_xY'').\] For
   every $‚ü®x,u,Y‚ü©$ such that $uS_xY$ we fix the $y$ that is highlighted in blue
   and name it $y_{xuY}$.

   We define $M'‚âî‚ü®W,R,S',V‚ü©$ with $S'‚âî\{‚ü®w,x,v‚ü©:‚àÉY.wS_xY‚àß y_{xwY}=v\}$. Then
   $M'$ is an ordinary Veltman frame and it holds that for every $w‚ààW$ and
   $A‚àà\fm$ we have \[M,w‚ä©A‚áîM',w‚ä©A.\]

   {{{endtheorem}}} {{{beginproof}}} {{{agda}}} It is not hard to check that all
   the conditions hold. {{{endproof}}}
   # I tried reconstructing the remainder of Mladen's proof and got stuck on
   # another issue. Instead of trying to fix it, I started playing with another
   # formulation of the same (or similar) construction which I think is much more
   # convenient:

   # For every $u S_w V$ and $v \in V$, put $u_{(w, v)} S_w \{v\}$,
   # where $u_{(w, v)}$ is a fresh world that inherits transitions that the world
   # $u$ was a part of. The construction should be performed recursively, starting
   # with R-leaves $w$, then proceeding with their direct R-ancestors etc. Finally,
   # remove all transition $u S_w V$ where $|V| > 1$.

   # Unless I'm missing something, it is almost obvious that this preserves truth
   # values. There are details to be spelled out though, for example what does
   # $u_{(w, v)}$ inherit exactly (it shouldn't be too hard, I actually did
   # something similar in the old version of the IL complexity paper).

** A flawed proof in disguise
   <<sec:flawed-proof>>
   As we all know, mathematical proofs can get long and tedious to follow. It is
   an art to guide the reader through the key steps of the proof and prevent
   them from getting lost in the details. In order to achieve that, a resource
   that is often used is to omit details of trivial claims during the proof.
   Omitting details saves a lot of time and usually there is no harm in it.
   However, we may mistakenly believe that something is trivial, whereas in
   reality it may not be trivial, or in the worst case, it may not even be true.
   If the mistake is overlooked, we may end up building on top of an
   inconsistent basis. Needless to say, this is an unacceptable situation which
   we should try to avoid at all costs. In this section we present an example of
   a published flawed proof. We discovered the flaw while trying to formalize
   the proof in Agda. We proceed by giving some context to the proof.

   The transformations from a generalized to an ordinary Veltman model given in
   Sections [[sec:verbrugge]] and [[sec:gen-to-ord-luka]] work for simple notions of
   quasi-transitivity but do not work for Condition (2), which is the standard.
   In cite:vukovic2008bisimulations a transformation which is claimed to work
   for Condition (2) is presented. We studied the transformation and started to
   formalize in Agda the proof of its correctness following the proof of
   Proposition 2.8 in cite:vukovic2008bisimulations. Despite of our best efforts
   we could not follow some steps which are claimed to be obvious in the
   original paper. After that, we decided to ask the original author for a
   clarification. He kindly replied but was unable to find a satisfying fix for
   the holes in the proof. After further investigation we realized that the
   proof had fundamental flaws which could not be fixed easily. Sadly, we have
   to conclude that Proposition 2.8 of cite:vukovic2008bisimulations is no
   longer a proven theorem. Thus, the problem of finding transformation from a
   generalized model (with Condition (2)) to an ordinary model such that it
   preserves some structure of the original model remains an open question. By
   ``preserves some structure'' we mean that we should have a property of the form:
   \[M,w‚ä©A‚áîM',f(w)‚ä©A\ \ \ \text{for every }w‚ààW,A‚àà\fm{}.\]
   Where $f$ is a map from the set of worlds of $M$ to the set of worlds of $M'$.

   We believe that this example should be taken as a humbling reminder that we
   are humans and we make mistakes. Even if a proof has been through skilled
   reviewers from a well established journal it is still suspect of being flawed
   in some subtle way. For this reason, we believe that computer checked proofs
   should gain relevance in all fields of logic and mathematics. We know that
   nowadays proof assistants are far from perfect and usually require a lot of
   time investment both on learning and in formalizing big scale mathematical
   proofs. However, the confidence level that they offer certainly outweighs
   their negatives in some situations.
* Frame conditions
  <<sec:frame-condition>> An interpretability principle is a schema of modal
  formulas that carries some special significance.

  In this section we present a number of principles in conjunction with their
  respective frame conditions for ordinary semantics as well as generalized
  semantics.
** The principle \prin{M}
   The \prin{M} principle reads as follows:
   \[A ‚ñ∑ B ‚Üí (A ‚àß ‚ñ° C) ‚ñ∑ (B ‚àß ‚ñ° C).\]

   # {{{joost(AT SOME STAGE YOU SHOULD BE GIVING CONTEXT HERE. WHEN WAS THE
   # PRINCIPLE INTRODUCED AND BY WHOM. ALSO\, WHY IS IT IMPORTANT\, ETC.)}}}

   The \prin{M} principle is coined after Franco Montagna because the principle
   appeared during discussions between Franco Montagna and Albert Visser about
   interpretability logic (cite:bilkova2009interpretability).

   The theorems of $\textsf{ILM}$ are the set of interpretability principles
   that are always provable in theories which are $Œ£_1$ sound, have full
   induction and prove consistency of any of its finite subsystems
   (cite:visser1997overview,joosten2020overview). An example of such a theory is
   $\textsf{PA}$.
*** Ordinary semantics
   The frame condition for \prin{M} for ordinary semantics, which we write as $\kord{M}$,
   reads as follows:
   \[‚àÄw,x,y,z(xS_w yRz ‚áí xRz).\]

   #+caption: Ordinary frame condition for \prin{M}.
   #+name: fig:ord-M-condition
   #+attr_latex: :float t :width 0.20\textwidth :placement [H]
   [[file:img/M-ord.pdf]]

   {{{begintheorem}}} For any ordinary frame $F$, we have that $F$ satisfies the
   $\kord{M}$ condition iff any model based on $F$ forces every instantiation of the \prin{M}
   principle. In symbols:

   \[F ‚ä® \kord{M} ‚áî F ‚ä© M.\] {{{endtheorem}}}

   {{{beginproof}}}
   {{{agda}}}
   - \boxed{‚áí} Let $M$ be a model based on $F$ and let $w$ be any world. Assume
     that $w‚ä©A‚ñ∑B$ and that there is a world $x$ such that $wRx$ and $x‚ä©A‚àß‚ñ°C$.
     Our aim is to find a world $z$ such that $xS_wz‚ä©B‚àß‚ñ°C$. Since $wRx‚ä©A$ and
     $w‚ä©A‚ñ∑B$ there is a world $z$ such that $xS_wz‚ä©B$. We now show that $z‚ä©‚ñ°C$.
     Consider an arbitrary $u$ such that $zRu$. By the frame condition it
     follows that $xRu$ and we know $x‚ä©‚ñ°C$ hence $u‚ä©C$ and thus $z‚ä©‚ñ°C$. Hence
     $z$ is the desired world.

   - \boxed{‚áê} Let $a,b,c‚àà\var{}$, assume $F‚ä©a‚ñ∑b‚Üí(a‚àß‚ñ°c)‚ñ∑(b‚àß‚ñ°c)$. Assume also that
     for some $x,w,u$ we have $xS_wzRu$. Our goal is to prove $xRu$. Consider a
     model such that the following holds.
     \begin{flalign*}
     ‚ü¶a‚üß &= \{x\}; \\
     ‚ü¶b‚üß &= \{z\}; \\
     ‚ü¶c‚üß &= \{v:xRv\}.
     \end{flalign*}
     We observe that $w‚ä©a‚ñ∑b$ because $a$ is only forced in $x$ and we have
     $xS_wz‚ä©b$. Then it follows that $w‚ä©(a‚àß‚ñ°c)‚ñ∑(b‚àß‚ñ°c)$. It is easy to observe
     that $x‚ä©a‚àß‚ñ°c$, furthermore we have that by the definition of an ordinary frame
     $xS_wz‚áíwRx$, hence $wRx$ and thus there must exist some $v$ such that
     $xS_wv‚ä©b‚àß‚ñ°c$. Since $b$ is only true in $z$ it must be $z‚ä©b‚àß‚ñ°c$. Then,
     because $zRu$ we have $u‚ä©c$, therefore $xRu$.
   {{{endproof}}}

*** Generalized semantics
   The frame condition for \prin{M} for generalized semantics, which we write as
   $\kgen{M}$, reads as follows:

   \[ ‚àÄw,x,V(xS_wV‚áí ‚àÉV'‚äÜV(xS_wV',‚àÄv'‚ààV'‚àÄz(v'Rz‚áíxRz))).\]


   #+caption: Generalized frame condition for \prin{M}.
   #+name: fig:gen-M-condition
   #+attr_latex: :float t :width 0.20\textwidth :placement [H]
   [[file:img/wip.png]]

   {{{begintheorem}}} For any generalized frame $F$, we have that $F$ satisfies the
   $\kgen{M}$ condition iff any model based on $F$ forces every instantiation of
   the \prin{M} principle. In symbols:

   \[F ‚ä® \kgen{M} ‚áî F ‚ä© M.\] {{{endtheorem}}}

   {{{beginproof}}}
   {{{agda}}}
   - \boxed{‚áí} Let $M$ be a model based on $F$ and let $w$ be any world. Assume
     that $w‚ä©A‚ñ∑B$ and that there is a world $x$ such that $wRx$ and $x‚ä©A‚àß‚ñ°C$.
     Our aim is to find a set $Z$ such that $xS_wZ‚ä©B‚àß‚ñ°C$. Since $wRx‚ä©A$ and
     $w‚ä©A‚ñ∑B$ there is set $Z$ such that $xS_wZ‚ä©B$. Then by the $\kgen{M}$
     condition it follows that there is a set $Z'‚äÜZ$ such that $xS_wZ'$ and
     $‚àÄv‚ààZ'‚àÄz(vRz‚áíxRz)$. Now we show $Z'‚ä©‚ñ°C$. Let $v‚ààZ'$ and $u$ such that
     $vRu$, by the condition above it follows $xRu$ and since $x‚ä©‚ñ°C$ we have
     $u‚ä©C$. Hence $Z'$ is the desired set.
   - \boxed{‚áê} Let $a,b,c‚àà\var{}$ and assume $F‚ä©a ‚ñ∑ b ‚Üí (a ‚àß ‚ñ° c) ‚ñ∑ (b ‚àß ‚ñ° c)$ and
     $uS_wV$. Consider a model satisfying the following
     \begin{flalign*}
     ‚ü¶a‚üß &= \{u\}; \\
     ‚ü¶b‚üß &= V; \\
     ‚ü¶c‚üß &= \{v:uRv\}.
     \end{flalign*}
     We see that $w‚ä©a‚ñ∑b$ since $a$ is only true in $u$ and we have $uS_wV‚ä©b$. It
     follows that ${w‚ä©(a ‚àß ‚ñ° c)‚ñ∑(b‚àß‚ñ°c)}$. It is easy to see that $u‚ä©a‚àß‚ñ°c$, hence
     there must exist $V'$ such that $uS_wV'‚ä©b‚àß‚ñ°c$. Clearly $V'‚äÜV$ since $b$ is
     forced exactly in $V$. Now let $v',z$ such that $v'‚ààV'$ and $v'Rz$. Since
     $v'‚ä©‚ñ°c$, then $z‚ä©c$ and thus $uRz$. Therefore $V'$ is the desired set.
   {{{endproof}}}
** The principle \prin{M‚ÇÄ}
   The \prin{M‚ÇÄ} principle reads as follows:
   \[A ‚ñ∑ B ‚Üí ‚ô¢ A ‚àß ‚ñ° C ‚ñ∑ B ‚àß ‚ñ° C.\]

   The \prin{M‚ÇÄ} principle first appears in
   cite:Visser:1991:FormalizationOfInterpretability.

    The logic \prin{ILM_0} is complete (cite:modal-matters).
*** TODO Ordinary semantics
    {{{jan(update drawing)}}}

    The $\kord{M‚ÇÄ}$ condition reads as follows:
    # \[‚àÄw,x,y,z(wRxRyS_wz‚áíxS_wz,‚àÄu(zRu‚áíxRu)).\]
    \[‚àÄw,x,y,z(wRxRyS_wz‚áí‚àÄu(zRu‚áíxRu)).\]

   #+caption: Ordinary frame condition for \prin{M‚ÇÄ}.
   #+name: fig:M_0-ord
   #+attr_latex: :float t :width 0.25\textwidth :placement [H]
   [[file:img/M_0-ord.pdf]]

    {{{begintheorem}}} For any ordinary frame $F$, we have that $F$ satisfies the
    $\kord{M‚ÇÄ}$ condition iff any model based on $F$ forces every instantiation of
    the \prin{M‚ÇÄ} principle. In symbols:

    \[F ‚ä® \kord{M‚ÇÄ} ‚áî F ‚ä© M‚ÇÄ.\] {{{endtheorem}}}

    {{{beginproof}}}
    {{{agda}}}
    - \boxed{‚áí} Let $M$ be a model based on $F$ and let $w$ be any world. Assume
      that $w‚ä©A‚ñ∑B$ and that there exists some $x$ such that $wRx‚ä© ‚ô¢ A ‚àß ‚ñ° C$. It
      follows that there exists some world $y$ such that $xRy‚ä©A$, then since
      $wRy$ and $w‚ä©A‚ñ∑B$ there exists a world $z$ such that $yS_wz‚ä©B$. Observe
      that from $wRxRy$ it follows that $xS_wy$ and by transitivity of $S_w$ and
      $yS_wz$ we get $xS_wz$. It remains to show $z‚ä©‚ñ°C$. Consider some world $u$
      such that $zRu$, then by the $\kord{M‚ÇÄ}$ condition we have that
      $‚àÄu(zRu‚áíxRu)$ and thus it follows that $xRu$ and since $x‚ä©‚ñ°C$ we also have
      $u‚ä©C$.
    - \boxed{‚áê} Let $a,b,c‚àà\var{}$ and assume $F‚ä©a ‚ñ∑ b ‚Üí (‚ô¢ a ‚àß ‚ñ° c) ‚ñ∑ (b ‚àß ‚ñ° c)$ and
      assume that for some $w,x,y,z$ we have $wRxRyS_wz$. Consider a model based
      on $F$ such that the following holds:
      \begin{flalign*}
      ‚ü¶a‚üß &= \{y\}; \\
      ‚ü¶b‚üß &= \{z\}; \\
      ‚ü¶c‚üß &= \{v:xRv\}.
      \end{flalign*}
      Observe that $w‚ä©a‚ñ∑b$ since $a$ is forced only in $y$ and we have $yS_wz‚ä©b$.
      It follows that $w‚ä©(‚ô¢ a ‚àß ‚ñ° c) ‚ñ∑ (b ‚àß ‚ñ° c)$. Clearly $x‚ä©‚ô¢a‚àß‚ñ°c$, hence there
      must exist some world $v$ such that $xS_wv‚ä©b‚àß‚ñ°c$ but since $b$ is only
      forced in $z$ we have $z=v$ and thus $xS_wz$. To prove the remaining
      implication let $u$ such that $zRu$, then $u‚ä©c$ and thus $xRu$.
    {{{endproof}}}

*** Generalized semantics
    The $\kgen{M‚ÇÄ}$ condition reads as follows:
    \[‚àÄw,x,y,Y(wRxRyS_wY‚áí‚àÉY'‚äÜY(xS_wY',‚àÄy'‚ààY'‚àÄz(y'Rz‚áíxRz))).\]

   #+caption: Generalized frame condition for \prin{M‚ÇÄ}.
   #+name: fig:M_0-gen
   #+attr_latex: :float t :width 0.30\textwidth :placement [H]
   [[file:img/M_0-gen.pdf]]


    {{{begintheorem}}} For any ordinary frame $F$, we have that $F$ satisfies the
    $\kgen{M‚ÇÄ}$ condition iff any model based on $F$ forces every instantiation of
    the \prin{M‚ÇÄ} principle. In symbols:

    \[F ‚ä® \kgen{M‚ÇÄ} ‚áî F ‚ä© M‚ÇÄ.\] {{{endtheorem}}}

    {{{beginproof}}}
    {{{agda}}}
    - \boxed{‚áí} Let $M$ be a model based on $F$ and let $w$ be any world. Assume
      that $w‚ä©A‚ñ∑B$ and that there is a world $x$ such that $wRx‚ä©‚ô¢A‚àß‚ñ°C$. Then
      there must exist some world $y$ such that $xRy‚ä©A$. Since $wRy$ and $w‚ä©A‚ñ∑B$
      there exists some set $Y$ such that $yS_wY‚ä©B$. Then by the $\kgen{M‚ÇÄ}$
      condition we have that there exists some $Y'‚äÜY$ such that $xS_wY'$ and
      $(‚ãÜ)\ ‚àÄy'‚ààY'‚àÄz(y'Rz‚áíxRz)$. Clearly $Y'‚ä©B$ since $Y'‚äÜY$. To show that
      $Y'‚ä©‚ñ°C$ consider some $y'‚ààY'$ and some $z$ such that $y'Rz$. Then, by
      $(‚ãÜ)$ it follows that $xRz$ and since $x‚ä©‚ñ°C$ we also have $x‚ä©C$.
    - \boxed{‚áê} Let $a,b,c‚àà\var{}$ and assume $F‚ä©a ‚ñ∑ b ‚Üí (‚ô¢ a ‚àß ‚ñ° c) ‚ñ∑ (b ‚àß ‚ñ° c)$
      and assume that for some $w,x,y,Y$ we have $wRxRyS_wY$. Then consider a
      model based on $F$ such that.
      \begin{flalign*}
      ‚ü¶a‚üß &= \{y\}; \\
      ‚ü¶b‚üß &= Y; \\
      ‚ü¶c‚üß &= \{v:xRv\}.
      \end{flalign*}
      Observe that $w‚ä©a‚ñ∑b$ as $a$ is only forced in $y$ and we have $yS_wY‚ä©b$.
      Consequently it holds that $w‚ä©(‚ô¢ a ‚àß ‚ñ° c) ‚ñ∑ (b ‚àß ‚ñ° c)$. See also that
      $x‚ä©‚ô¢a$ since $xRy‚ä©a$ and also $x‚ä©‚ñ°c$ by definition of the model. Then
      there must exist some set $Y'$ such that $xS_wY'‚ä©b‚àß‚ñ°c$. Clearly $Y'‚äÜY$ since
      $Y'‚ä©b$. To show the remaining condition pick some $y'‚ààY'$ and some $z$
      such that $y'Rz$. Since $Y'‚ä©‚ñ°c$ then $z‚ä©c$ and thus $xRz$.
    {{{endproof}}}

** The principle \prin{P‚ÇÄ}
   The \prin{P‚ÇÄ} principle reads as follows:
   \[A ‚ñ∑ ‚ô¢ B ‚Üí ‚ñ° (A ‚ñ∑ B).\]

   We give some context borrowed from cite:joosten2020interpretability. The
   principle \prin{P‚ÇÄ} appeared in 1998 and is due to Albert Visser. It appeared
   during the search of the modal completeness proof of \prin{ILM_0}. In an attempt
   to strengthen the logic, Visser modified the frame condition of
   $\prin{ILM_0}$ to make it stronger and arrive at a stronger principle, which
   was coined as $\prin{P_0}$. Since the frame condition of $\prin{P_0}$ implies
   the frame condition of $\prin{M_0}$ every $\text{\prin{ILP_0}-frame}$ is also
   an $\text{\prin{ILM_0}-frame}$. In cite:joosten-master it is proven that
   $\prin{ILP_0}‚ä¨\prin{ILM_0}$ and thus we have that $\prin{ILP_0}$ is
   modally incomplete.

   The principle \prin{P_0} is valid in all reasonable arithmetical theories and
   thus it should be in \ilall{}.

*** Ordinary semantics
    The $\kord{P‚ÇÄ}$ condition reads as follows:

    \[‚àÄw,x,y,z,u(wRxRyS_wzRu‚áíyS_xu).\]

   #+caption: Ordinary frame condition for \prin{P‚ÇÄ}.
   #+name: fig:P_0-ord
   #+attr_latex: :float t :width 0.15\textwidth :placement [H]
   [[file:img/P_0-ord.pdf]]

   {{{begintheorem}}} For any ordinary frame $F$, we have that $F$ satisfies the
   $\kord{P‚ÇÄ}$ condition iff any model based on $F$ forces every instantiation of
   the \prin{P‚ÇÄ} principle. In symbols:

   \[F ‚ä® \kord{P‚ÇÄ} ‚áî F ‚ä© P‚ÇÄ.\] {{{endtheorem}}}

   {{{beginproof}}}
   {{{agda}}}
   - \boxed{‚áí} Let $M$ be a model based on $F$ and let $w$ be any world. Assume
     that $w‚ä©A‚ñ∑‚ô¢B$ and that there is a world $x$ such that $wRx$. Our goal is to
     show that $x‚ä©A‚ñ∑B$. Consider a world $y$ such that $xRy‚ä©A$. As $wRy$ and
     $w‚ä©A‚ñ∑‚ô¢B$ then there exist some worlds $z,u$ such that $yS_wzRu‚ä©B$. By the
     $\kord{P‚ÇÄ}$ condition it follows that $yS_xu$ and thus $x‚ä©A‚ñ∑B$.
   - \boxed{‚áê} Let $a,b‚àà\var{}$ and assume $F‚ä©a ‚ñ∑ ‚ô¢ b ‚Üí ‚ñ° (a ‚ñ∑ b)$ and assume that
     $wRxRyS_wzRu$. We want to show $yS_xu$. Consider a model based on $F$ such
     that:
     \begin{flalign*}
     ‚ü¶a‚üß = \{y \}; \\
     ‚ü¶b‚üß = \{u \}.
     \end{flalign*}
     Observe that $w‚ä©a‚ñ∑‚ô¢b$ as the only world that forces $a$ is $y$ and we have
     $yS_wz‚ä©‚ô¢b$, because $zRu‚ä©b$. Consequently we have $w‚ä©‚ñ°(a‚ñ∑b)$ and therefore
     $x‚ä©a‚ñ∑b$. Then, since $xRy‚ä©a$ it follows that there exist some $v$ such that
     $yS_xv‚ä©b$, but since $b$ is only forced in $u$, it must be $u=v$ and so
     $yS_xu$.
   {{{endproof}}}

*** Generalized semantics
    The $\kgen{P_0}$ condition reads as follows:
    \[‚àÄw,x,y,V,Z((wRxRyS_wV,‚àÄv‚ààY‚àÉz‚ààZ(vRz))‚áí‚àÉZ'‚äÜZ(yS_xZ')).\]

   #+caption: Generalized frame condition for \prin{P‚ÇÄ}.
   #+name: fig:P_0-gen
   #+attr_latex: :float t :width 0.31\textwidth :placement [H]
   [[file:img/P_0-gen.pdf]]


   {{{begintheorem}}} For any generalized frame $F$, we have that $F$ satisfies the
   $\kgen{P‚ÇÄ}$ condition iff any model based on $F$ forces every instantiation of
   the \prin{P‚ÇÄ} principle. In symbols:

   \[F ‚ä® \kgen{P‚ÇÄ} ‚áî F ‚ä© P‚ÇÄ.\] {{{endtheorem}}}

   {{{beginproof}}}
   {{{agda}}}
   - \boxed{‚áí} Let $M$ be a model based on $F$ and let $w$ be any world. Assume
     that $w‚ä©A‚ñ∑‚ô¢B$ and that there is a world $x$ such that $wRx$. We aim to show
     that $x‚ä©A‚ñ∑B$. Assume there is a world $u$ such that $xRu‚ä©A$ and as $wRu$
     and $w‚ä©A‚ñ∑‚ô¢B$ then there exists a set $V$ $uS_xV‚ä©‚ô¢B$. Let $ùîπ=\{v:v‚ä©B\}$.
     Then observe that because $V‚ä©‚ô¢B$ we have that for all $v$ in $V$ there
     exists some $z‚ààùîπ$ such that $vRz$. Hence by the $\kgen{P‚ÇÄ}$ condition
     there exists some $ùîπ'‚äÜùîπ$ such that $yS_xùîπ'$. Clearly $ùîπ'‚ä©B$, therefore
     $x‚ä©A‚ñ∑B$.
   - \boxed{‚áê} Let $a,b‚àà\var{}$ and assume $F‚ä©a ‚ñ∑ ‚ô¢ b ‚Üí ‚ñ° (a ‚ñ∑ b)$ and assume
     that for some $w,x,y,V,Z$ we have $wRxRyS_wY$ and $(‚ãÜ)\ ‚àÄv‚ààV‚àÉz‚ààZ(vRz)$.
     Consider a model based on $F$ such that:
     \begin{flalign*}
    ‚ü¶a‚üß &= \{y\}; \\
    ‚ü¶b‚üß &= Z.
     \end{flalign*}
     See that $w‚ä©a‚ñ∑‚ô¢b$ as the only world that forces $a$ is $y$ and we have
     $yS_wV$ and by $(‚ãÜ)$ it follows that $V‚ä©‚ô¢b$. Consequently it holds that
     $w‚ä©‚ñ°(a‚ñ∑b)$ and since $wRx$ then $x‚ä©a‚ñ∑b$. Also, since $xRy‚ä©a$ then there
     exists $Z'$ such that $yS_xZ'‚ä©b$. Clearly $Z'‚ä©b$ implies $Z'‚äÜZ$ so we are
     done.
   {{{endproof}}}

** The principle \prin{R}
   The \prin{R} principle reads as follows:

   \[A ‚ñ∑ B ‚Üí ¬¨ (A ‚ñ∑ ¬¨C) ‚ñ∑ (B ‚àß ‚ñ° C)\ .\]

   The principle \prin{R} is due to Goris and Joosten. In cite:a-new-principle
   they show that \prin{R} does follow semantically but not syntactically from
   \prin{ILP_0W^*}, which was the best known lower bound for \ilall{} in 2011.
   They also show that \prin{R} is valid in all reasonable arithmetical theories
   and thus giving a strictly better lower bound for \ilall{}.

   Note that \prin{R} is the same as \prin{R_0} and \prin{R^0}. The \prin{R^n}
   and \prin{R_n} series of principles which generalize \prin{R} and are
   discussed in Sections [[sec:Rsub1]] and [[sec:Rsupn]].
*** Ordinary semantics
    The $\kord{R}$ condition reads as follows:

    \[‚àÄw,x,y,z,u(wRxRyS_wzRu‚áíyS_xu).\]

   #+caption: Ordinary frame condition for \prin{R}.
   #+name: fig:ord-R-condition
   #+attr_latex: :float t :width 0.15\textwidth :placement [H]
   [[file:img/R-ord.pdf]]

   {{{joost(TO NOT OVERLOAD WRITING\, SHALL WE SPEAK OF FRAMES WHEN SPEAKING OF
   REGULAR/ORDINARY FRAMES AND ONLY INDICATE GENERALISED WHERE NEEDED? LUKA\, WHAT
   DO YOU THINK?)}}}

\luka{ I agree, that's what Croatian authors do}

   {{{begintheorem}}}
   For any ordinary frame $F$, we have that $F$ satisfies the
   $\kord{R}$ condition iff any model based on $F$ forces every instantiation of
   the \prin{R} principle. In symbols:

   \[F ‚ä® \kord{R} ‚áî F ‚ä© R\ .\]
   {{{endtheorem}}}

# {{{joost(HERE AND IN THE THESIS IN GENERAL\, I MISS A DISCUSSION ABOUT
# ASSURINGNESS. THIS SHOULD BE ADDED AND USED. AT THIS PARTICULAR POINT IN YOUR
# PROOF YOU SHOULD MENTION THAT y IS A C-assuring SUCCESSOR OF x SO THAT YOU
# OBTAIN (*).)}}}

# {{{luka(Joost\, would you use assuringness/criticality even in semantic
# context? I would add a note\, something along the lines of "of course\, we can
# associate a MCS with every world of a model\, if we suppose e.g. that all
# propositional variables $p_i$ for $i > ...$ are evaluated as false and let $mcs(w) =
# \{A : w \Vdash A\}$".)}}}

# a world \(y\) such that \(xRy‚ä©A\) and \((‚ãÜ)\ ‚àÄv(yS_xv‚áív‚ä©C)\).

# {{{joost(MAKE THIS FORMULA DISPLAYED. MOREOVER\, IT IS BETTER TO GENERATE A
# LABEL. FOR EXAMPLE:)}}}


   {{{beginproof}}}
   {{{agda}}}
   - \boxed{‚áí} Let $M$ be a model based on $F$ and let $w$ be any world. Assume
     that $w‚ä©A‚ñ∑B$ and that there is a world $x$ such that $wRx‚ä©¬¨(A‚ñ∑¬¨C)$. We need
     to see that there is some world $z$ such that $xS_wz‚ä©B‚àß‚ñ°C$. From
     $x‚ä©¬¨(A‚ñ∑¬¨C)$ we get a world $y$ such that $xRy‚ä©A$ and $(‚ãÜ)\ ‚àÄv(yS_xv‚áív‚ä©C)$.
     Since $w‚ä©A‚ñ∑B$, and by transitivity we have $wRy$, it follows that there
     exists a world $z$ such that $yS_wz‚ä©B$. To see that $z$ is the desired
     world we first see that $z‚ä©‚ñ°C$. Let $u$ be such that $zRu$, then by
     $\kord{R}$ it follows that $yS_xu$ and by $(‚ãÜ)$ we get $u‚ä©C$. Finally, we
     have to see that $xS_wz$. Since $wRxRy$ we have that $xS_wy$ and we have
     $yS_wz$ from before, hence by transitivity of $S_w$ we get $xS_wz$.

   To see that \(z\) is the desired world.

   {{{joost(I WOULD SAY HERE: "WE HAVE TO VERIFY
   TWO THINGS". THEN YOU MENTION THE TWO THINGS AND THEN YOU PROVE THEM ONE BY ONE.
   LIKE THIS\, YOU HELP THE NON-EXPERIENCED READER REMIND WHAT IS IT THAT YOU ARE
   AFTER)}}}


   - \boxed{‚áê} Let $a,b,c‚àà\var{}$ and assume that for some $w,x,y,z$ we have
     $wRxRyS_wz$ . Consider a model
     based on $F$ that satisfies the following.
    \begin{flalign*}
     ‚ü¶a‚üß &= \{y\}; \\
     ‚ü¶b‚üß &= \{z\}; \\
     ‚ü¶c‚üß &= \{u:yS_xu\}.
    \end{flalign*}
     By assumption we have that $w‚ä©a ‚ñ∑ b ‚Üí (¬¨ (a ‚ñ∑ ¬¨c) ‚ñ∑ (b ‚àß ‚ñ° c))$. Clearly
     $w‚ä©a‚ñ∑b$ as we have $yS_wz‚ä©b$. Consequently it holds that $w‚ä©¬¨ (a ‚ñ∑ ¬¨c) ‚ñ∑ (b
     ‚àß ‚ñ° c)$. In order to show that $x‚ä©¬¨ (a ‚ñ∑ ¬¨c)$, considering that $a$ is only
     forced in $y$, it suffices to observe that $‚àÄz(yS_xz‚áíz‚ä©c)$, which clearly
     holds. Then there must exist some world $v$ such that $xS_wv‚ä©b‚àß‚ñ°c$ but
     $v=z$ since $z$ is the only world that forces $b$, hence $xS_wz‚ä©‚ñ°c$. Now to
     show $‚àÄv(zRv‚áíyS_xv)$ consider some $v$ such that $zRv$. From $z‚ä©‚ñ°c$ we get
     $v‚ä©c$ and thus $yS_xv$.
   {{{endproof}}}

*** Generalized semantics

    We first introduce the concept of choice set.

   {{{begindef}}} If $xRy$ we say that a set of worlds $K$ is a \gls{choice-set}
   for $‚ü®x,y‚ü©$ iff for any $V$ such that $yS_xV$ we have $V‚à©K‚â†‚àÖ$. We denote the
   family of choice sets for $‚ü®x,y‚ü©$ by $ùíû(x,y)$. Note that this definition
   depends on the frame, but it should always be clear from context.
   {{{enddef}}}

    The $\kgen{R}$ condition reads as follows:
    \begin{flalign*}
    &‚àÄw,x,y,Y,K(wRxRyS_wY,K‚ààùíû(x,y)   \\
    ‚áí& ‚àÉY'‚äÜY(xS_wY',‚àÄy'‚ààY'‚àÄz(y'Rz‚áíz‚ààK))).
    \end{flalign*}

   #+caption: Generalized frame condition for \prin{R}.
   #+name: fig:gen-R-condition
   #+attr_latex: :float t :width 0.35\textwidth :placement [H]
   [[file:img/R-gen.pdf]]

   {{{begintheorem}}}
   <<theorem:R‚Å∞>>
   For any generalized frame $F$, we have that $F$ satisfies the
   $\kgen{R}$ condition iff any model based on $F$ forces every instantiation of
   the \prin{R} principle. In symbols:

   \[F ‚ä® \kgen{R} ‚áî F ‚ä© R.\]
   {{{endtheorem}}}
   {{{beginproof}}}
   {{{agda}}}
   - \boxed{‚áí} Let $M$ be a model based on $F$ and assume there is a world $w$ such
     that $w‚ä©A‚ñ∑B$ and a world $x$ such that $wRx$ and $x‚ä©¬¨(A‚ñ∑¬¨C)$. We need to
     show that there is a set $Z$ such that $xS_wZ‚ä©B‚àß‚ñ°C$. From $x‚ä©¬¨(A‚ñ∑¬¨C)$ it
     follows that there is a world $y$ such that $xRy‚ä©A$ and $(‚ãÜ)\
     ‚àÄV(yS_xV‚áí‚àÉc‚ààV(c‚ä©C))$. Consider the set $K‚âî\{c:c‚ä©C,‚àÉV(c‚ààV,yS_xV)\}$. Clearly
     by $(‚ãÜ)$ it follows that $K$ is a choice set for $‚ü®x,y‚ü©$. By transitivity
     of $R$ we get $wRy$ and since $w‚ä©A‚ñ∑B$ then there must exist some $Y$ such
     that $yS_wY‚ä©B$. We can now apply the $\kgen{R}$ condition and get a $Y'‚äÜY$
     such that $xS_wY'$ and $(‚Ä†)\ ‚àÄy'‚ààY'‚àÄz(y'Rz‚áíz‚ààK)$. To show that $Y'$ is the
     desired set it remains to see that $Y'‚ä©B‚àß‚ñ°C$. From the fact that $Y'‚äÜY‚ä©B$
     it easily follows that $Y'‚ä©B$. Now, let $y'‚ààY'$ and $u$ such that $y'Ru$,
     from $(‚Ä†)$ we get $u‚ààK$ and by definition of $K$ we have $u‚ä©C$.
   - \boxed{‚áê} Let $a,b,c‚àà\var{}$ and assume $F‚ä© a ‚ñ∑ b ‚Üí ¬¨ (a ‚ñ∑ ¬¨c) ‚ñ∑ (b ‚àß ‚ñ° c)$.
     Assume also that for some $w,x,y,Y,K$ we have $wRxRyS_wY,K‚ààùíû(x,y)$. Now
     consider a model based on $F$ that satisfies the following:
    \begin{flalign*}
    ‚ü¶a‚üß &=\{y\}; \\
    ‚ü¶b‚üß &=Y; \\
    ‚ü¶c‚üß &= K. \\
    \end{flalign*}
    By assumption we have $w‚ä©a ‚ñ∑ b ‚Üí ¬¨ (a ‚ñ∑ ¬¨c) ‚ñ∑ (b ‚àß ‚ñ° c)$. Observe that that
     $w‚ä©a‚ñ∑b$ since $yS_wY‚ä©b$. Thus $w‚ä©¬¨ (a ‚ñ∑ ¬¨c) ‚ñ∑ (b ‚àß ‚ñ° c)$. As $y$ is the
     only world that forces $a$, in order to show $x‚ä©¬¨(a‚ñ∑¬¨c)$ we need to see
     that $‚àÄV(yS_xV‚áí‚àÉz‚ààV(z‚ä©c))$, which is equivalent to $‚àÄV(yS_xV‚áí‚àÉz‚ààV‚à©K)$ and
     this holds since $K‚ààùíû(x,y)$. As a consequence of $x‚ä©¬¨(a‚ñ∑¬¨c)$ we have that
     there exists a set $Y'$ such that $xS_wY'‚ä©b‚àß‚ñ°c$. From $Y'‚ä©b$ we get $Y'‚äÜY$ and
     from $Y'‚ä©‚ñ°c$ we get $‚àÄy'‚ààY'(‚àÄz(y'Rz‚Üíz‚ààK))$, hence $Y'$ is the desired set.
   {{{endproof}}}

** The principle \prin{R‚ÇÅ}
   <<sec:Rsub1>>
   The $R_1$ principle reads as follows:
   \[A ‚ñ∑ B ‚Üí (¬¨(A ‚ñ∑ ¬¨C)‚àß (D‚ñ∑‚ô¢E))‚ñ∑(B‚àß‚ñ°C‚àß(D‚ñ∑E)).\]

   It is the second principle of the $\prin{R_n}$ series.
   The $R_n$ series of principles is defined in cite:two-new-series:
*** Ordinary semantics

    The $\kord{R_1}$ frame condition reads as follows:
    \[‚àÄw,x,y,z(wRxRyS_wz‚áí‚àÄu(zRu‚áíyS_xu,‚àÄv(uS_xv‚áí‚àÄm(vRm‚áíuS_zm))))\]

    # #+caption: Ordinary frame condition for \prin{R‚ÇÅ}
    # #+name: fig:ord-R‚ÇÅ-condition
    # #+attr_latex: :float t :width 0.20\textwidth :placement [H]
    # [[file:img/wip.png]]

    {{{begintheorem}}}
    For any ordinary frame $F$, we have that $F$ satisfies the
    $\kord{R_1}$ condition iff any model based on $F$ forces every instantiation of
    the \prin{R‚ÇÅ} principle. In symbols:

    \[F ‚ä® \kord{R_1} ‚áî F ‚ä© R‚ÇÅ.\]
    {{{endtheorem}}}

    {{{beginproof}}}
    The details of the proof can be found in cite:two-new-series.
    # - \boxed{‚áê} Let $a,b,c,d,e‚àà\var{}$ and assume $F‚ä© a ‚ñ∑ b ‚Üí ((¬¨ (a ‚ñ∑ ¬¨c) ‚àß(d‚ñ∑‚ô¢e))
    #   ‚ñ∑ (b ‚àß ‚ñ° c ‚àß (d‚ñ∑e)))$. Consider some worlds $w,x,y,z,u,v,m$ and assume for
    #   a contradiction that $wRxRyS_wzRu,yS_xu‚áí(uS_xv,vRm,u\cancel{S}_zm)$. Now
    #   consider a model based on $F$ that satisfies the following:
    #   \begin{flalign*}
    #   ‚ü¶a‚üß &= \{y\} \\
    #   ‚ü¶b‚üß &= \{z\} \\
    #   ‚ü¶c‚üß &= \{w:yS_xw\} \\
    #   ‚ü¶d‚üß &= \{?\} \\
    #   ‚ü¶e‚üß &= \{?\} \\
    #   \end{flalign*}
    #   First observe that $w‚ä©a‚ñ∑b$ since $a$ is only forced in $y$ and we have
    #   $yS_wz‚ä©b$. Therefore $w‚ä©¬¨ (a ‚ñ∑ ¬¨c) ‚àß(d‚ñ∑‚ô¢e) ‚ñ∑ (b ‚àß ‚ñ° c ‚àß (d‚ñ∑e))$. Now we
    #   show that $x‚ä©¬¨ (a ‚ñ∑ ¬¨c)$. Since $a$ is only forced in $y$ and $xRy$, we
    #   need to show that $‚àÄu(yS_xu‚áíu‚ä©c)$, which clearly holds. We proceed by
    #   showing $x‚ä©d‚ñ∑‚ô¢e$ (????).
    # - \boxed{‚áí} Let $M$ be a model based on $F$ assume there is a world $w$ such
    #   that $w‚ä©A‚ñ∑B$ and a world $x$ such that $wRx$ and $x‚ä©¬¨(A‚ñ∑¬¨C)‚àß(D‚ñ∑‚ô¢E)$. Then
    #   there exists world $y$ such that $xRy‚ä©A$ and $(‚ãÜ)\ ‚àÄv(yS_xv‚áív‚ä©C)$. As
    #   $wRy‚ä©A$ and $w‚ä©A‚ñ∑B$ there exists a world $z$ such that $yS_wz‚ä©B$. It
    #   remains to show that $z‚ä©‚ñ°C‚àß(D‚ñ∑E)$. We first see that $z‚ä©‚ñ°C$. Consider
    #   $v$ such that $zRv$, by $\kord{R_1}$ it follows that $yS_xv$ and by $(‚ãÜ)$
    #   we get $v‚ä©C$. Now we show $z‚ä©D‚ñ∑E$. Let $u$ be such that $zRu‚ä©D$, we need
    #   to find some $m$ such that $uS_zm‚ä©E$. By $\kord{R_1}$ we get $yS_xu$ and
    #   $(‚Ä†)\ ‚àÄv,m((uS_xv,vRm)‚áíuS_zm)$. See that $yS_xu$ implies $xRu$ and since
    #   $x‚ä©D‚ñ∑‚ô¢E$ and $u‚ä©D$ we get that there is some $n$ such that $uS_xn‚ä©‚ô¢E$.
    #   Hence there is a world $m$ such that $nRm‚ä©E$. Finally by $(‚Ä†)$ and $uS_xn$
    #   and $nRm$ we get $uS_zm$ and thus we have the desired $m$ and we conclude
    #   $z‚ä©D‚ñ∑E$.
    {{{endproof}}}

*** Generalized semantics
    Some definitions:
    1. $R^{-1}[E] ‚âî \{x : ‚àÉy‚ààE. xRy\}$. $E$ denotes a set.
    2. $R‚Çì^{-1}[E]‚âîR^{-1}[E]‚à©R[x]$. $E$ denotes a set.

    The $\kgen{R_1}$ condition reads as follows:
    \begin{flalign*}
    ‚àÄw,&x,u,ùîπ,‚ÑÇ,ùîº.\\
    &wRxRuS_wùîπ, ‚ÑÇ‚ààùíû(x,u) \\
    ‚áí\ & ‚àÉùîπ'‚äÜùîπ.xS_wùîπ',R[ùîπ']‚äÜ‚ÑÇ,‚àÄv‚ààùîπ'.‚àÄc‚àà‚ÑÇ.(‚àÉU‚äÜR‚Çì^{-1}[ùîº],vRcS‚ÇìU)‚áí‚àÉùîº'‚äÜùîº.cS_vùîº'\Big)
    \end{flalign*}

    {{{begintheorem}}}
    <<theorem:R‚ÇÅ>>
    For any generalized frame $F$, we have that $F$ satisfies the
    $\kgen{R_1}$ condition iff any model based on $F$ forces every instantiation of
    the \prin{R‚ÇÅ} principle. In symbols:

    \[F‚ä®\kgen{R‚ÇÅ}‚áîF‚ä©R‚ÇÅ.\]
    {{{endtheorem}}}

    {{{beginproof}}}
    {{{agda}}}
    - \boxed{‚áí} Let's fix the model and let $w ‚àà W$ be arbitrary. Suppose $w‚ä© A
      ‚ñ∑B$, and let $x$ be such that $wRx$ and $x‚ä© ¬¨(A ‚ñ∑ ¬¨C) ‚àß (D ‚ñ∑ ‚ô¢E)$. It
      follows from $x ‚ä©¬¨(A ‚ñ∑¬¨C)$ that there exists $u$ such that $xRu$, such
      that $u‚ä©A$, and for every $Z$ such that $uS_x Z$ there is some $c_Z ‚àà Z$
      such that $c_Z ‚ä©C$. From $wRu$, $w‚ä© A‚ñ∑ B$ and $u‚ä© A$ follows in particular
      that there is a $ùîπ$, $uS_w ùîπ ‚ä©B$. Let $‚ÑÇ ‚âî \{c_Z: uS_x Z\}$. It is easy to
      check that $‚ÑÇ ‚àà ùíû(x, u)$. Let $ùîº ‚âî ‚ü¶E‚üß$. For the selected $w, x, u, ùîπ, ‚ÑÇ,
      ùîº$ the property $\kgen{R_1}$ implies that there exists $ùîπ' ‚äÜ ùîπ$ such that:

      \[ xS_wùîπ',R[ùîπ']‚äÜ‚ÑÇ,‚àÄv‚ààùîπ'.‚àÄc‚àà‚ÑÇ.(‚àÉU‚äÜR‚Çì^{-1}[ùîº],vRcS‚ÇìU)‚áí‚àÉùîº'‚äÜùîº.cS_vùîº'\]
      # \[xS_wùîπ',R[ùîπ']‚äÜ‚ÑÇ ,(‚àÄv‚ààùîπ')(‚àÄc‚àà‚ÑÇ)(vRcS_xR_x^{-1}[ùîº]‚áí(‚àÉùîº'‚äÜùîº)cS_vùîº').\]

      We have that $ùîπ' ‚ä©B$ since $ùîπ'‚äÜùîπ$ and $ùîπ'‚ä©‚ñ° C$ since $R[ùîπ']‚äÜ‚ÑÇ$. We now
      show that $ùîπ'‚ä© D‚ñ∑ E$. Let $v‚ààB'$ and assume that for some $c$ such that
      $vRc$ we have $c‚ä© D$. From earlier we have $x‚ä© D ‚ñ∑ ‚ô¢E$. Since $c ‚àà R [ùîπ']
      ‚äÜ C ‚äÜ R [x]$, then $xRc$ so it follows that there exists $U$ such that
      $cS_x U$ and $U‚ä©‚ô¢E$. Clearly $U‚äÜR_x^{-1}[ùîº]$ so by the above property
      there exists $ùîº'‚äÜùîº$ such that $cS_v ùîº'$. Because $ùîº'‚äÜùîº$ we have $ùîº'‚ä©E$.
    - \boxed{‚áê} Assume for a contradiction that $F‚ä≠\kgen{R_1}$. It follows that
      there exist $w,x,u,ùîπ,‚ÑÇ,ùîº$ such that $wRxRuS_wùîπ$, $‚ÑÇ‚ààùíû(x,u)$ and:
      \[‚àÄùîπ'‚äÜùîπ.xS_wùîπ', R[ùîπ']‚äÜ‚ÑÇ‚áí ‚àÉv‚ààùîπ'.‚àÉc‚àà‚ÑÇ.‚àÉZ‚äÜR_x^{-1}[ùîº].vRcS_xZ,‚àÄùîº'‚äÜùîº.
      c\cancel{S}_v ùîº'.\]

      Let $ùí±$ be a family of sets defined thus:
      \[ùí±‚âî \{U : U‚äÜùîπ, xS_wU,R[U]‚äÜ‚ÑÇ\}.\]

      From the condition it follows that for every $U‚ààùí±$ the following is valid:
      \[‚àÉv_U‚ààU.‚àÉc_U‚àà‚ÑÇ.
      (‚àÉZ_U‚äÜR_x^{-1}[ùîº](v_URc_US_xZ_U,‚àÄùîº'‚äÜùîº.
      c_U\cancel{S}_{v_U} ùîº')).\]

      Let us fix such $v_U$ and $c_U$ and $Z_U$ for all $U‚ààùí±$.

      Define a valuation such that the following applies:
      \begin{flalign*}
      ‚ü¶a‚üß &= \{u\}; \\
      ‚ü¶b‚üß &= ùîπ; \\
      ‚ü¶c‚üß &= ‚ÑÇ; \\
      ‚ü¶d‚üß &= \{c_U:U‚ààùí±\}; \\
      ‚ü¶e‚üß &= ùîº.
      \end{flalign*}

      By assumption we have $w ‚ä© a ‚ñ∑ b ‚Üí (¬¨(a‚ñ∑¬¨c)‚àß(d‚ñ∑‚ô¢e))‚ñ∑(b‚àß‚ñ°c‚àß(d‚ñ∑e))$.

      It is easy to see that $w ‚ä© a ‚ñ∑ b$ and $x ‚ä© ¬¨(a ‚ñ∑ ¬¨c)$.

      Let us prove $x ‚ä© d‚ñ∑‚ô¢e$. Let $xRc‚ä© D$. Then $c = c_U$ for some $U ‚àà ùí±$.
      From the definition of $c_U$ we have that $c_U S_x Z_U$. The valuation is
      defined such that $e$ is true exactly on the set $ùîº$. Hence
      $R_x^{-1}[ùîº]‚ä©‚ô¢e$ and since $Z_U‚äÜR_x^{-1}[ùîº]$ it follows that $x ‚ä© d‚ñ∑‚ô¢e$.

      We can also check that for every $U ‚àà ùí±$ we have $U‚ä© b ‚àß ‚ñ°c$. Furthermore,
      for any set $U$ we have
      \begin{flalign*}
        (‚ãÜ)\ xS_wU ‚ä© b ‚àß ‚ñ°c‚áíU‚àà ùí±.
      \end{flalign*}
      Since $w‚ä©a‚ñ∑b$ and $wRx‚ä©¬¨(a‚ñ∑¬¨c)‚àß(d‚ñ∑‚ô¢e)$ there must exist some set $U$
      such that $xS_wU‚ä©b‚àß‚ñ°c‚àß(d‚ñ∑e)$. From $(‚ãÜ)$ follows that $U‚ààùí±$ hence
      there exist $v_U,c_U,Z_U$ such that $Z_U‚äÜR_x^{-1}[ùîº]$ and
      $v_URc_US_xZ_U,(‚àÄùîº'‚äÜùîº) c_U\cancel{S}_{v_U} ùîº'$. Since $c_U‚ä©d$ there must
      exist some $Y$ such that $c_US_{v_U}Y‚ä©e$, however, by the definition of
      the valuation it follows that $Y‚äÜùîº$ and thus $c_U\cancel{S}_{v_U} Y$,
      which is a contradiction.

    {{{endproof}}}

# \newpage
** The principle \prin{R_2} :noexport:
  The \prin{R_2} principle reads as follows:
  \[A‚ÇÄ ‚ñ∑ (B‚ÇÄ ‚àß (A‚ÇÅ ‚ñ∑ B‚ÇÅ)) ‚Üí ¬¨(A‚ÇÄ ‚ñ∑ ¬¨C‚ÇÄ)‚àß (E‚ÇÅ‚ñ∑¬¨(A‚ÇÅ‚ñ∑¬¨C‚ÇÅ))‚ñ∑ B‚ÇÄ‚àß(A‚ÇÅ‚ñ∑B‚ÇÅ)‚àß‚ñ°C‚ÇÄ‚àß(E‚ÇÅ‚ñ∑A‚ÇÅ)‚àß(E‚ÇÅ‚ñ∑B‚ÇÅ‚àß‚ñ°C‚ÇÅ)\]

*** Generalized semantics
    Some definitions:

    The $\kgen{R_2}$ condition reads as follows:
    \begin{flalign*}
    &‚àÄw,x,u,ùîπ,‚ÑÇ,ùîº(wRxRuS_wùîπ, ‚ÑÇ‚ààùíû(x,u) \\
    ‚áí\ & (‚àÉùîπ'‚äÜùîπ)(xS_wùîπ',R[ùîπ']‚äÜ‚ÑÇ,(‚àÄv‚ààùîπ')(‚àÄc‚àà‚ÑÇ)(vRcS‚ÇìR‚Çì^{-1}[ùîº]‚áí(‚àÉùîº'‚äÜùîº)cS_vùîº')))
    \end{flalign*}
    \begin{flalign*}
    &‚àÄw,x,u,ùîπ,‚ÑÇ,ùîº(wRxRuS_wùîπ, ‚ÑÇ‚ààùíû(x,u) \\
    ‚áí\ & (‚àÉùîπ'‚äÜùîπ)(xS_wùîπ',R[ùîπ']‚äÜ‚ÑÇ,(‚àÄv‚ààùîπ')(‚àÄc‚àà‚ÑÇ)(‚àÉU‚äÜR‚Çì^{-1}[ùîº],vRcS‚ÇìU)‚áí(‚àÉùîº'‚äÜùîº)cS_vùîº')))
    \end{flalign*}

    {{{begintheorem}}}
    <<theorem:R‚ÇÇ>>
    For any generalized frame $F$, we have that $F$ satisfies the
    $\kgen{R_2}$ condition iff any model based on $F$ forces every instantiation of
    the \prin{R_2} principle. In symbols:

    \[F‚ä®\kgen{R_2}‚áîF‚ä©R‚ÇÇ\]
    {{{endtheorem}}}

    {{{beginproof}}}
    {{{endproof}}}

# \newpage

** The principle \prin{R¬π}

   The \prin{R¬π} principle reads as follows:
   \[A ‚ñ∑ B ‚Üí (‚ô¢¬¨(D ‚ñ∑ ¬¨C)‚àß (D‚ñ∑A))‚ñ∑(B‚àß‚ñ°C).\]

*** Generalized semantics
    The $\kgen{R¬π}$ condition reads as follows:
    \begin{flalign*}
    ‚àÄw&,x,y,z,ùî∏,ùîπ,‚ÑÇ,ùîª. \\
    &wRxRyRz, \\
    & (‚àÄu.wRu,u‚ààùî∏‚áí‚àÉV.uS_wV,V‚äÜùîπ), \\
    & (‚àÄu.xRu,u‚ààùîª‚áí‚àÉV.uS_xV,V‚äÜùî∏), \\
    & (‚àÄV.zS_yV‚áí‚àÉv‚ààV.v‚àà‚ÑÇ),      \\
    & z‚ààùîª \\
    ‚áí\ & ‚àÉV‚äÜùîπ(xS_wV,R[V]‚äÜ‚ÑÇ).
    \end{flalign*}

    {{{begintheorem}}}
    For any generalized frame $F$, we have that $F$ satisfies the
    $\kgen{R¬π}$ condition iff any model based on $F$ forces every instantiation of
    the \prin{R¬π} principle. In symbols:

    \[F‚ä®\kgen{R¬π}‚áîF‚ä©R¬π.\]
    {{{endtheorem}}}


    {{{beginproof}}}
    {{{agda}}}
    - \boxed{‚áí} Fix a model $M$ and a world $w$, we are to prove that $w‚ä©A ‚ñ∑ B ‚Üí
      (‚ô¢¬¨(D ‚ñ∑ ¬¨C)‚àß (D‚ñ∑A))‚ñ∑(B‚àß‚ñ°C)$. For that assume that $w‚ä©A‚ñ∑B$ and that for
      some $x,y,z$ we have $wRxRyRz$ and satisfy the conditions on the left hand
      side of the implication in the $\kgen{R^1}$ condition. From that we derive that
      $x‚ä©D‚ñ∑A$, $y‚ä©¬¨(D‚ñ∑¬¨C)$ and $z‚ä©D$. Now let $ùî∏‚âî\{w:w‚ä©A\}$. We define $ùîπ,‚ÑÇ,ùîª$
      likewise for formulas $B,C,D$ respectively. It is routine to check that
      the left part of the implication of $\kgen{R¬π}$ is met. Hence there exist
      a set $V‚äÜùîπ$ such that $xS_wV$ and $R[V]‚äÜ‚ÑÇ$. By the definition of the sets
      $ùîπ$ and $‚ÑÇ$ it follows that $V‚ä©B‚àß‚ñ°C$.
    - \boxed{‚áê} Fix a frame $F$ and let $a,b,c,d$ be propositional variables and
      assume $F‚ä©a ‚ñ∑ b ‚Üí (‚ô¢¬¨(d ‚ñ∑ ¬¨c)‚àß (d‚ñ∑a))‚ñ∑(b‚àß‚ñ°c)$. Assume that the left part
      of the implication of $\kgen{R¬π}$ holds. Now consider a model extending
      $F$ such that:
      \begin{flalign*}
       ‚ü¶a‚üß &= ùî∏, \\
       ‚ü¶b‚üß &= ùîπ, \\
       ‚ü¶c‚üß &= ‚ÑÇ, \\
       ‚ü¶d‚üß &= ùîª.
      \end{flalign*}
      Now one can easily check that $w‚ä©A‚ñ∑B$, $x‚ä©‚ô¢¬¨(D‚ñ∑¬¨C)‚àß(D‚ñ∑A)$, hence there exists $U$
      such that $xS_wU$ and $U‚ä©B‚àß‚ñ°C$. From that we derive that $U‚äÜùîπ$ and $R[U]‚äÜ‚ÑÇ$.
    {{{endproof}}}

** The principle $\prin{R¬≤}$ :noexport:

   The $R¬≤$ principle reads as follows:
   \[A ‚ñ∑ B ‚Üí (‚ô¢ [(E ‚ñ∑ D) ‚àß ‚ô¢ ¬¨ (E ‚ñ∑ ¬¨ C)] ‚àß (D ‚ñ∑ A)) ‚ñ∑ (B ‚àß ‚ñ° C) \]

*** Generalized semantics
    The $\kgen{R¬≤}$ condition reads as follows:
    \begin{flalign*}
    &‚àÄw,x,y,z,s,ùî∏,ùîπ,‚ÑÇ,ùîª,ùîº.\\
    &wRxRyRzRs, \\
    & (‚àÄu.wRu‚ààùî∏‚áí‚àÉV.uS_wV‚äÜùîπ), \\
    & (‚àÄu.xRu‚ààùîª‚áí‚àÉV.uS_xV‚äÜùî∏), \\
    & (‚àÄu.yRu‚ààùîº‚áí‚àÉV.uS_yV‚äÜùîª), \\
    & (‚àÄV.sS_zV‚áíV‚à©‚ÑÇ‚â†0),      \\
    & s‚ààùîª \\
    ‚áí\ & ‚àÉV‚äÜùîπ.xS_wV,R[V]‚äÜ‚ÑÇ
    \end{flalign*}

    {{{begintheorem}}}
    For any generalized frame $F$, we have that $F$ satisfies the
    $\kgen{R¬≤}$ condition iff any model based on $F$ forces every instantiation of
    the $R¬≤$ principle. In symbols:

    \[F‚ä®\kgen{R¬≤}‚áîF‚ä©R¬≤\]
    {{{endtheorem}}}

    {{{beginproof}}}
    - \boxed{‚áí} Fix a model and assume that for some world $w$ we have $w‚ä©A‚ñ∑B$.
      Consider some $x$ such that $wRx‚ä©‚ô¢ [(E ‚ñ∑ D) ‚àß ‚ô¢ ¬¨ (E ‚ñ∑ ¬¨ C)] ‚àß (D ‚ñ∑ A)$.
      Hence there exists some $y$ such that $xRy‚ä©(E ‚ñ∑ D) ‚àß ‚ô¢ ¬¨ (E ‚ñ∑ ¬¨ C)$. It
      follows that there exists some $z$ such that $yRz‚ä© ¬¨ (E ‚ñ∑ ¬¨ C)$ and thus
      there exists some $s$ such that $zRs‚ä©E$ and $(‚ãÜ)\ ‚àÄV(sS_zV‚áí‚àÉc‚ààV(c‚ä©C))$.
    - \boxed{‚áê}
    {{{endproof}}}

** The series of principles \prin{R‚Åø}
   <<sec:Rsupn>>
   The \prin{R^n} principle is defined thus:
   \begin{flalign*}
   U_0 &‚âî ‚ô¢¬¨(D_0‚ñ∑¬¨C) \\
   U_{r+1} &‚âî ‚ô¢((D·µ£‚ñ∑D_{r+1}) ‚àß U·µ£) \\
   \\
   R‚Å∞& ‚âî A ‚ñ∑ B ‚Üí ¬¨ (A ‚ñ∑ ¬¨ C) ‚ñ∑ B ‚àß ‚ñ° C \\
   R^{n+1}& ‚âî A ‚ñ∑ B ‚Üí ((D_{n}‚ñ∑A) ‚àß U_{n}) ‚ñ∑ B ‚àß ‚ñ° C
   \end{flalign*}

   The \prin{R^n} and \prin{R_n} series of principles are due to Goris and
   Joosten. Both series are presented in cite:two-new-series. In their article
   they generalize the principle \prin{R} in two series of principles which they
   use to give the best known lower bound for the logic \ilall{}, which is
   $\prin{ILWR^nR_n}$.

   The \prin{R^n} series is also referred to as the /broad/ series, whereas
   \prin{R^n} is referred to as the /slim/ series.
*** Ordinary semantics
    The frame condition for ordinary semantics $\kord{R^n}$ can be found in
    cite:two-new-series.

*** Generalized semantics

    The $\kgen{R‚Åø}$ condition reads as follows:
    \begin{flalign*}
    ‚àÄw,&x‚ÇÄ,‚Ä¶,x_{n-1},y,z,ùî∏,ùîπ,‚ÑÇ,ùîª‚ÇÄ,‚Ä¶,ùîª_{n-1}.\\
    &wRx_{n-1}R‚Ä¶Rx_0RyRz, \\
    & (‚àÄu.wRu,u‚ààùî∏‚áí‚àÉV.uS_wV‚äÜùîπ), \\
    & (‚àÄu.x_{n-1}Ru‚ààùîª_{n-1}‚áí‚àÉV.uS_{x_{n-1}}V‚äÜùî∏), \\
    & (‚àÄi‚àà\{1,‚Ä¶,n-2\}‚àÄu.x·µ¢Ru‚ààùîª_i‚áí‚àÉV.uS_{x_i}V‚äÜùîª_{i+1}), \\
    & (‚àÄV.zS_yV‚áíV‚à©‚ÑÇ‚â†0),      \\
    & z‚ààùîª‚ÇÄ \\
    ‚áí\ & ‚àÉV‚äÜùîπ.x_{n-1}S_wV,R[V]‚äÜ‚ÑÇ.
    \end{flalign*}
    {{{beginlemma}}}
    <<lemma:R‚Åø>>
    Let $M$ be a model, let $x$ be a world of $M$ and let $n‚àà‚Ñï$. For any $i‚â§n$ we have
    that if $M , x ‚ä© U_i$ then there exist some worlds $y,z,x‚ÇÄ,‚Ä¶,x_{i}$ such that:
    1. $x·µ¢=x$;
    2. $x_iR‚Ä¶Rx‚ÇÄRyRz$;
    3. for all $j‚â§i$ we have that $M,x_j‚ä©U_j$;
    4. for all $j<i$ we have that $M,x_j‚ä©D_j‚ñ∑D_{j+1}$;
    5. for all $V$ we have that if $zS_yV$ then $V‚à©\{w:M,w‚ä©C\}‚â†‚àÖ$;
    6. $M,z‚ä©D‚ÇÄ$.
    {{{beginproof}}}
    {{{agda}}}

    By induction on $i$.
    - For $i=0$ we have that $x‚ä©‚ô¢¬¨(D‚ÇÄ‚ñ∑¬¨C)$. It follows that there exists some
      $y$ such that $xRy‚ä©¬¨(D‚ÇÄ‚ñ∑¬¨C)$ and therefore there exists some $z$ such that
      $yRz‚ä©D‚ÇÄ$ and for any $V$, if $zS_yV$, then $V‚à©\{w:M,w‚ä©C\}‚â†‚àÖ$. It is clear
      that all claims are met.
    - For $i+1$ we have that $x‚ä©‚ô¢((D_i‚ñ∑D_{i+1})‚àßU_i)$. It follows that there
      exists some $x_{i}$ such that $x_i‚ä©D_i‚ñ∑D_{i+1}‚àßU_i$. By IH there exist
      $y,z,x‚ÇÄ,‚Ä¶,x_{i}$ such that they satisfy claims $1,‚Ä¶,6$. We set
      $x_{i+1}‚âîx$. It is trivial to observe that by using the IH all conditions
      are met for $i+1$.
    {{{endproof}}}
    {{{endlemma}}}
    {{{begintheorem}}}
    <<theorem:R‚Åø>>
    For any generalized frame $F$, we have that $F$ satisfies
    the $\kgen{R‚Åø}$ condition iff any model based on $F$ forces every
    instantiation of the \prin{R‚Åø} principle. In symbols:

    \[F‚ä®\kgen{R‚Åø}‚áîF‚ä©R‚Åø.\]
    {{{endtheorem}}}

    {{{beginproof}}}
    {{{agda}}}

    If $n=0$ we refer to theorem [[theorem:R‚Å∞]]. For $n+1$ proceed as follows.
    - \boxed{‚áí} Fix a model and assume that for some world $w$ we have $w‚ä©A‚ñ∑B$.
      Then assume also that $wRx‚ä©((D‚Çô‚ñ∑A)‚àßU_n)$. Our goal is to find a set $V$
      such that $xS_wV‚ä©B‚àß‚ñ°C$. By lemma [[lemma:R‚Åø]] it follows that there exist
      $y,z,x‚ÇÄ,‚Ä¶,x_{n}$ satisfying $1,‚Ä¶,6$. Then let $ùî∏‚âî‚ü¶A‚üß$, $ùîπ‚âî‚ü¶B‚üß$, $‚ÑÇ‚âî‚ü¶C‚üß$
      and for $i‚â§n$ let $ùîª·µ¢‚âî‚ü¶D·µ¢‚üß$.

      It is routine to check that the left part of the $\kgen{R^{n+1}}$ holds
      and thus we get that there exists some $V‚äÜùîπ$ such that $x_nS_wV$ and
      $R[V]‚äÜ‚ÑÇ$. Since $V‚äÜùîπ$ we have that $V‚ä©B$ and since $R[V]‚äÜ‚ÑÇ$ we have
      $V‚ä©‚ñ°C$. Finally, since $x_{n}=x$ we conclude $xS_wV‚ä©B‚àß‚ñ°C$.
    - \boxed{‚áê} Fix a frame $F$ and let $a,b,c,d‚ÇÄ,‚Ä¶,d‚Çô$ be propositional
      variables and assume $F‚ä©R^{n+1}$. Assume that the left part of the
      implication of $\kgen{R^{n+1}}$ holds. Now consider a model based on $F$
      that satisfies the following:
      \begin{flalign*}
       ‚ü¶a‚üß &= ùî∏; \\
       ‚ü¶b‚üß &= ùîπ; \\
       ‚ü¶c‚üß &= ‚ÑÇ; \\
       ‚ü¶d·µ¢‚üß &= ùîª·µ¢, \text{ for all } i‚àà\{0‚Ä¶n\}.
      \end{flalign*}
      Now one can routinely check that $w‚ä©A‚ñ∑B$ and $x‚ä©((D_n‚ñ∑A)‚àßU_n)$, hence there
      exists $U$ such that $xS_wU$ and $U‚ä©B‚àß‚ñ°C$. From that we derive that $U‚äÜùîπ$
      and $R[U]‚äÜ‚ÑÇ$.
    {{{endproof}}}

** Generic generalized frame condition
   In this section we present a method that given a formula $A$, builds a second
   order formula that is a generalized frame condition for $A$.

   {{{begindef}}} Given a generalized frame $F=‚ü®W,R,S‚ü©$ and a formula $A$ with
   $Var(A)=\{x‚ÇÅ,‚Ä¶,x‚Çô\}$. Let $‚Ñ±$ be defined by (we write $ùïè_*$ instead of $ùïè‚ÇÅ,‚Ä¶,ùïè‚Çô$).
 \begin{flalign*}
   ‚Ñ±&:\underbrace{ùí´(W)√ó‚ãØ√óùí´(W)}_n√ó\fm{}‚Üíùí´(W) \\
   ‚Ñ±(ùïè_*,x·µ¢) &‚âî  ùïè·µ¢;\\
   ‚Ñ±(ùïè_*,‚ä•) &‚âî ‚àÖ; \\
   ‚Ñ±(ùïè_*,A‚ÜíB) &‚âî \{w:w ‚àà ‚Ñ±(ùïè_*,A) ‚áí w ‚àà ‚Ñ±(ùïè_*,B)\}; \\
   ‚Ñ±(ùïè_*,A‚ñ∑B) &‚âî \{w:‚àÄ u.(wRu,u‚àà‚Ñ±(ùïè_*,A))‚áí‚àÉY.uS_wY‚äÜ‚Ñ±(ùïè_*,B))\}. \\
 \end{flalign*}

   Then define
   # \[(A)^*_{gen}‚âî‚àÄùïè_*‚àÄw‚ààW.w‚àà‚Ñ±(ùïè_*,A). \]
   \[\kgen{A^*}‚âî‚àÄùïè_*‚àÄw‚ààW.w‚àà‚Ñ±(ùïè_*,A). \]

   {{{enddef}}}

   {{{begintheorem}}}

   Let $A$ be a formula. For any generalized frame $F$, we have that $F$
   satisfies the $\kgen{A^*}$ condition iff any model based on $F$ forces $A$.
   In symbols:

     \[F‚ä®\kgen{A^*}‚áîF‚ä©A.\]
   {{{endtheorem}}}

   {{{beginproof}}}
   {{{agda}}}
   {{{endproof}}}

   {{{beginremark}}}
   For instance, if we want the frame condition for \prin{P‚ÇÄ} we would look at
    \[\kgen{(a ‚ñ∑ ‚ô¢ b ‚Üí ‚ñ° (a ‚ñ∑ b))^*}.\]
    Where $a,b$ are different variables.
   {{{endremark}}}
* The logic of Agda

  In this part we give an informal overview of the basic Agda constructions,
  which will hopefully help the reader get an intuition of how dependent types
  can be used to formalize and prove mathematical properties. We will also
  highlight some intricacies of the language that are relevant to our project.
  This part of the thesis is not meant to be an exhaustive analysis of the inner
  workings of Agda, as this falls out of the scope of this project. The original
  author of Agda, Ulf Norell, has suggested[fn::In correspondence via email.]
  cite:cockx2018elaborating as a good reference for that purpose.

  As for the logical basis of Agda... Quote from (cite:sep-type-theory-intuitionistic)
  \begin{quote}
  Agda is another proof assistant which is based on the logical framework
  formulation of intuitionistic type theory, but adds numerous features
  inspired by practical programming languages (\cite{norell:thesis}). It is an
  intensional theory with decidable judgments and a type-checker similar to
  Coq‚Äôs. However, in contrast to Coq it is based on Martin-L√∂f‚Äôs predicative
  intuitionistic type theory.
  \end{quote}

** Introduction to types
   Type theory is a branch of mathematical symbolic logic. It formalizes
   mathematical concepts through terms, types and a typing relation between
   them. One could think of types as predicates on terms. We write $T:A$ to say
   that term $T$ satisfies predicate $A$, or synonymously, that term $T$ has
   type $A$. Later in this section we will see that types in /simply typed
   lambda calculus/ provide a basic classification of lambda terms. For
   instance, a term representing a natural number will have a different type
   from a lambda term representing a Boolean value. In more expressive type
   theories which feature dependent types, such as /intuitionistic type theory/,
   we can express complex mathematical properties such as ``$2*n$ is
   always even'' or that ``any finite sequence of numbers can be sorted''.

   Type theory has become especially relevant in the following areas.
   - *Programming languages and proof assistants*. Simple (non-dependent) types
     are present in almost every modern programming language. Programming
     languages use types to classify its objects and functions with the goal of
     minimizing the amount of errors caused by misusing them. For instance, the
     term $1 + true$ does not make sense and types are used to rule out the
     validity of such term.

     Furthermore, the expressiveness of type theories with dependent types make
     them an adequate basis for modern proof assistants. Due to the constructive
     nature of the theory the proof assistants can be used as programming
     languages too. Agda and Coq are examples of that.
   - *Foundations of mathematics*. (This paragraph is a paraphrase from
     cite:sep-type-theory-intuitionistic) A sufficiently expressive type theory
     such as Martin-L√∂f type theory is a formal logical system and philosophical
     foundation for constructive mathematics. It is a full-scale system which is
     based on the /propositions-as-types/ principle and aims to play a similar
     role for constructive mathematics as Zermelo-Fraenkel set theory does for
     classical mathematics.

     (This paragraph is a quote from cite:hottbook) /Univalent Foundations
     of Mathematics/ is Vladimir Voevodsky‚Äôs new program for a comprehensive,
     computational foundation for mathematics based on the homotopical
     interpretation of type theory. The type theoretic univalence axiom relates
     propositional equality on the universe with homotopy equivalence of small
     types. The program is currently being implemented with the help of the
     automated proof assistant Coq. The Univalent Foundations program is closely
     tied to homotopy type theory.
*** The origins of types
      (cite:sep-type-theory) Types were first introduced by Russel in 1903 in
     ``Apendix B: The Doctrine of Types, from Principia Mathematica'' while
     trying to avoid a contradiction in set theory, namely Russel's paradox. In
     Principia Mathematica types are defined as follows.
      1. $i$ is the type of individuals (elements of some fixed domain);
      2. if $A_1,‚Ä¶,A_n$ (for $n‚â•0$) are types then $(A_1,‚Ä¶,A_n)$ is the type of
         n-ary relations over objects of respective types $A_1,‚Ä¶,A_n$. Note that
         for $n=0$ we have that $()$ is the type of propositions.
      For instance, the type of binary relations over individuals is $(i,i)$,
      the type of binary propositional connectives is $((),())$. Observe that
      this formulation prevents a proposition of the form $R(R)$. Assume for a
      contradiction that $R(R)$ is a proposition, then we have that (by looking
      at the outer occurrence) $R$ has type $(A)$ for some type $A$ and thus
      (by looking at the inner occurrence) $R$ has type $A$ but $A‚â†(A)$. This
      observation is the key for avoiding Russel's paradox using types.

      The more habitual definition of types is the one that stems from Church's
      formalization of lambda calculus which includes functions as primitive
      objects.
      1. $i$ is the type of individuals;
      2. $o$ is the type of propositions;
      3. if $A$ and $B$ are types then $A‚ÜíB$ is the type of functions from $A$ to $B$.
      We may observe that $i‚Üío$ is the type of predicates on individuals, $i‚Üíi$ is
      the type of functions on individuals and $\underbrace{i‚Üí(i‚Üí‚Ä¶‚Üí(i}_{n}‚Üío))$ is
      an \text{$n$-ary} relation. Although this definition of types is relevant
      for historical reasons, it has become obsolete and we proceed by giving a
      short introduction to three (out of many) versions of lambda calculus
      available today.

*** Untyped lambda calculus
     For the language of terms we present a refinement of Church's version due to
     Curry:
     1. /variable/: every variable is a term;
     2. /function application/: If $A$ and $B$ are terms then $A\ B$ is a term.
        Note that application associates to the left, thus $A\ B\ C=(A\ B)\ C$.
     3. /lambda abstraction/: If $x$ is a variable and $A$ is a term then $Œªx.A$
        is a term. The body of a lambda abstraction (the expression after the
        .) extends to the rightmost part. Thus $Œªx.Œªy.x\ y=Œªx.(Œªy.x\ y)$.
     This can be more succinctly expressed in the so-called Backus-Naur form
     (BNF for short): \[T‚âîx\ |\ T\ T\ |\ Œªx.T\] In lambda calculus we have the
     following equation known as \text{$Œ≤$-reduction}. \[(Œªx.T)\ A=T[x‚Ü¶A]\]
     This equation is often given as a reduction rule from left to right,
     giving computational value to lambda terms. In other words,
     \text{$Œ≤$-reduction} gives an algorithm based on a rewrite rule that
     /reduces/, /evaluates/ or /computes/ a lambda term until it can no longer
     be reduced. When a term cannot be reduced we say that it is in /normal
     form/. Note that not every term can be reduced to a normal form term as
     showcased by the following term, which reduces to itself: \[(Œªx.x\ x)\
     (Œªx.x\ x) \] Notice how this term is of the form $R(R)$ (or $R\ R$, in the
     new syntax), which we were able to rule out before by using types. In
     fact, in the next section we will see how this term cannot be assigned a
     type.

     Turing showed that untyped lambda calculus is equivalent in terms of
     computability to Turing machines (cite:turing1937computability), therefore
     any computable function has a lambda term that computes it.

     It might be difficult to imagine how we could express every computable
     function in a lambda term. We believe that showing some practical examples
     will be enlightening, thus we will briefly introduce the /Church
     encoding/ for Booleans and natural numbers.
     - *Booleans*. We define /true/ and /false/ thus: \[true:=Œªa.Œªb.a;\ \ \
       false‚âîŒªa.Œªb.b\] As we can see, both /true/ and /false/ are defined as a
       function that takes two arguments. The former returns the first argument
       while the latter returns the second. Thus, this encoding of Booleans
       conveniently allows us to define an /if then else/ expression.
       \[ite‚âîŒªb.Œªx.Œªy.b\ x\ y\] It is immediate to see by means of
       \text{$Œ≤$-reduction} that \[ite\ b\ x\ y=b\ x\ y\] hence, we will
       usually prefer to write $b\ x\ y$ instead of $ite\ b\ x\ y$. We can use
       the /if then else/ concept to encode the /and/ and /or/ operators. It
       may help to read the /and/ as ``if the first argument is true return the
       second argument else return false''. Likewise for the /or/.
       \[and:=Œªa.Œªb.a\ b\ false;\ \ \ or‚âîŒªa.Œªb. a\ true\ b\]
     - *Natural numbers*. The natural number $n$ is encoded as a lambda term
       that applies $n$ times some parameter function $f$.
       \[0:=Œªf.Œªa.a;\ \ \ 1‚âîŒªf.Œªa.f\ a;\ \ \ 2‚âîŒªf.Œªa.f\ (f\ a); \ \ \ ‚Ä¶\]
       Then we can define the successor function:
       \[suc‚âîŒªn.Œªf.Œªa.f\ (n\ f\ a)\]
       Let us show that the successor of 1 is indeed 2.
       \begin{flalign*}
       suc\ 1 &= (Œªn.Œªf.Œªa.f\ (n\ f\ a))\ (Œªf.Œªa.f\ a) & \text{Def}\\
        &= Œªf.Œªa.f\ ((Œªf.Œªa.f\ a)\ f\ a)  & \text{$Œ≤$-reduction for $n$}\\
        &= Œªf.Œªa.f\ (Œªa.f\ a)\ a  & \text{$Œ≤$-reduction for $f$}\\
        &= Œªf.Œªa.f\ (f\ a)  & \text{$Œ≤$-reduction for $a$}\\
        &= 2 & \text{Def}
       \end{flalign*}
       It is also easy to define addition and multiplication. It may help to
       read /add n m/ as ``apply $m$ times $f$, then apply $n$ times $f$'' and
       /mul n m/ as ``apply $n$ times (apply $m$ times)''. \[add‚âîŒªn.Œªm.Œªf.Œªa.n\ f\ (m\ f\
       a);\ \ \ mul‚âîŒªn.Œªm.Œªf.Œªa.n\ (m\ f)\ a \]

*** Simply typed lambda calculus
     Let us introduce the idea of types in lambda calculus due to Curry. We
     view types as predicates on lambda terms. We write $T:A$ to say that the
     term $T$ has type $A$.

     We fix a set of base types $ùêÅ$ and a set of term constants
     \[Œì=\{‚ü®c‚ÇÄ^0:B‚ÇÄ‚ü©,‚ü®c‚ÇÄ^1:B‚ÇÄ‚ü©,‚Ä¶,‚ü®c‚ÇÅ^0:B‚ÇÅ‚ü©,‚ü®c‚ÇÅ^1:B‚ÇÅ‚ü©,‚Ä¶\},\] where each $B_i‚ààùêÅ$.

     The syntax of terms is defined thus. \[T‚âîx\ |\ T\ T\ |\ Œª(x:S).T\ |\ c\]
     Where $S$ is a type, $c$ a term constant and $x$ a variable.

     The syntax of types is defined thus. \[S‚âîB\ |\ S‚ÜíS\] With $B‚ààùêÅ$. The $‚Üí$
     symbol has right associativity, so $A‚ÜíB‚ÜíC=A‚Üí(B‚ÜíC)$.

     Then we define typing rules to assign a type to suitable terms. We define
     a context to be a set of tuples $‚ü®x:A‚ü©$ where $x$ is either a variable or
     a constant and $A$ is a type. If $Œì$ is a context write $Œì‚ä¢t:A$ to mean
     that $y$ has type $A$ in context $Œì$. When a term can be assigned a type
     in a context we say that it is well-typed in that context. Only well-typed
     terms are considered valid in simply typed lambda calculus.
     #+caption: Typing rules for simply typed lambda calculus.
     #+name: fig:simply_typed
     #+attr_latex: :float
     \begin{figure}[H]
     \begin{mathpar}
     \inferrule[Id]{c : A ‚àà Œì}{Œì ‚ä¢ c : A}
     \and
     \inferrule[App]{Œì ‚ä¢ f : A ‚Üí B \\ Œì ‚ä¢ t : A}{Œì‚ä¢f\ t : B}
     \and
     \inferrule[Abstraction]{Œì‚à™\{‚ü®x:A‚ü©\} ‚ä¢ t : B}{Œì‚ä¢Œª(x:S).t :A ‚Üí B}
     \end{mathpar}
     \end{figure}

     Let us now see how we can give types to Booleans and natural numbers
     following the encoding given in the previous section. For that, we
     consider a singleton set of base types $B‚âî\{Œ±\}$.
     - *Booleans*. We define the type of Booleans thus: \[ùîπ‚âîŒ±‚ÜíŒ±‚ÜíŒ±\]
       \[true:=Œª(a:Œ±).Œª(b:Œ±).a;\ \ \ false‚âîŒª(a:Œ±).Œª(b:Œ±).b\]
       We proceed by showing that $‚àÖ‚ä¢true:ùîπ$.
       \begin{figure}[H]
       \begin{mathpar}
       \inferrule*[Left=Def]{
       \inferrule*[Left=Abs]{
       \inferrule*[Left=Abs]{
       \inferrule*[Left=Id]
       {\ }
       {\{‚ü®a:Œ±‚ü©,‚ü®b:Œ±‚ü©\} ‚ä¢a:Œ±}}
       {\{‚ü®a:Œ±‚ü©\} ‚ä¢Œª(b:Œ±).a:Œ±‚ÜíŒ±}}
       {‚àÖ ‚ä¢Œª(a:Œ±).Œª(b:Œ±).a:Œ±‚ÜíŒ±‚ÜíŒ±}}{‚àÖ ‚ä¢ true : ùîπ}
       \end{mathpar}
       \end{figure}
       Likewise we can show that $‚àÖ‚ä¢false:ùîπ$. It is routine to check that
       $‚àÖ‚ä¢and:ùîπ‚Üíùîπ‚Üíùîπ$ and that $‚àÖ‚ä¢or:ùîπ‚Üíùîπ‚Üíùîπ$. As we can see, types give us
       information about the nature of the term. For instance, $and:ùîπ‚Üíùîπ‚Üíùîπ$ tells
       us that $and$ is a lambda term that expects two Booleans as arguments and
       returns a Boolean.

     - *Natural numbers*. We define the type of natural numbers thus:
       \[‚Ñï‚âî(Œ±‚ÜíŒ±)‚ÜíŒ±‚ÜíŒ±\] \[0:=Œª(f:Œ±‚ÜíŒ±).Œª(a:Œ±).a;\ \ \ 1‚âîŒª(f:Œ±‚ÜíŒ±).Œª(a:Œ±).f\ a; \ \
       \ ‚Ä¶\] We can routinely check that for any natural number $n$ we have
       $‚àÖ‚ä¢n:‚Ñï$ and $‚àÖ‚ä¢add:‚Ñï‚Üí‚Ñï‚Üí‚Ñï$ and $‚àÖ‚ä¢mul:‚Ñï‚Üí‚Ñï‚Üí‚Ñï$.

     It is a well known property that simply typed lambda calculus is /strongly
     normalizing/, which means that every well-typed term can be reduced to a
     normal form. Thus it must be the case, and it is easy to observe, that
     the non-normalizing term we presented before cannot be typed for any
     choice of $A$. \[(Œª(x:A).x\ x)\ (Œª(x:A).x\ x)\]

     \jan{is next paragraph needed?}
     Strong normalization is a desirable property, but it comes at the price of
     losing equivalence to Turing machines as there are many computable
     functions that cannot be expressed in simply typed lambda calculus.
     To circumvent this, some extensions of simply typed lambda calculus are
     extended with Curry's $Y$ combinator defined below. The $Y$ combinator, also
     known as the fixed-point combinator, is a primitive lambda term that can
     be added to the language and be assigned the type $(A ‚ÜíA)‚ÜíA$ for any type
     $A$. \[Y‚âîŒªg.(Œªx.g\ (x\ x))\ (Œªx.g\ (x\ x))\] The $Y$ combinator gives general
     recursion and thus the strong normalization property no longer holds.

*** Dependently typed lambda calculus
    There is no way to briefly present a description of a type system with
    dependent types in an analogous from to untyped and simply typed lambda
    calculus. For this reason, we prefer to dedicate a longer section to it. In
    the next Section ([[sec:martin-lof]]) we present a full description of a theory
    which is based on dependent types and is the logical basis of Agda.
** Martin L√∂f's logical framework
   <<sec:martin-lof>> In this section we will present the intuitionistic type
   theory presented in cite:nordstrom1990programming. We will refer to this
   logic as /Martin L√∂f's logical framework/ or LF for short. {{{jan(needs a
   longer intro.)}}}

   In this logic we have four types of judgment:
   1. ``$a$ has type $A$''. We write $a:A$. Crucially, in a type theory that
      follows the paradigm of /propositions as types/ we may interpret the
      statement $a:A$ in several ways, all of them equivalent in such paradigm:
      - The term $a$ has type $A$;
      - the term $a$ satisfies the proposition $A$;
      - the term $a$ is a proof of the proposition $A$;
      - the term $a$ is a program that satisfies the specification $A$.
   2. ``$A$ is a type''. We write $A:\mathsf{Type}$.
   3. ``$A_1$ and $A_2$ are equal types''. We write $A_1‚â°A_2:\mathsf{Type}$.
   4. ``$a_1$ and $a_2$ are equal elements of the type $A$''. We write $a_1‚â°a_2:A$.

   We say that some proposition (or type) $A$ is true if there exists some $t$
   such that $t:A$.

   The concept of /type/. We say that $A$ is a type if we have a precise
   definition of the objects in that type and a decidable equivalence relation
   for the objects of the type.

   The first type that we define is the type /Set/[fn::The concept of /set/ used
   here differs from the one in set theory.]. The objects of the type /Set/ are
   /sets/. A /set/ $A$ is an inductive description of how the /canonical
   elements/ of $A$ are built, plus a decidable equality relation between canonical
   elements. Two sets are equal if a canonical element of one set is a canonical
   element of the other set and moreover, if two equal canonical elements in one
   set also are equal in the other set.

   For instance, if we want to define the set of natural numbers, we have two
   canonical elements: /zero/ and the /successor/ of a natural number. The
   equality relation can be defined as expected. In section [[sec:def-new-types]] we
   will see how we can define the natural numbers, among other sets, in more
   detail.

   Hence we have the axiom:
   \begin{mathpar}
   \inferrule[Set]{\ }{\mathsf{Set}:\mathsf{Type}}
   \end{mathpar}

   If $A$ is a set, then the elements of $A$ in conjunction with their
   equivalence relation forms a type.
   \begin{mathpar}
   \inferrule[El]{A:\set{} }{\sf{El}(A):\sf{Type}}
   \and
   \inferrule[El=]{A=B:\set{} }{\sf{El}(A)=\sf{El}(B):\sf{Type}}
   \end{mathpar}

*** Syntax of types old :noexport:
      We will proceed by introducing the syntax of types:
      1. /Bottom/. The constant $‚ä•$ is a type;
        \begin{mathpar}
        \inferrule{\ }{‚ä•:\mathsf{Type}}
        \end{mathpar}
      2. /Disjoint sum/. If $A$ and $B$ are types then $A‚äéB$ is a type;
        \begin{mathpar}
        \inferrule{A:\mathsf{Type} \\  B:\mathsf{Type}}{A‚äéB:\mathsf{Type}}
        \end{mathpar}
      3. /Dependent product/. If $x$ is a variable, $A$ is a type and $B(x)$ is a
         type that may depend on $x$, then $Œ£\ (x: A)\ B(x)$ is a type. When
         $B$ is independent of $x$ we may write $A √ó B$ instead;
        \begin{mathpar}
        \inferrule{x‚àà\mathsf{Var} \\ A:\mathsf{Type} \\  B(x):\mathsf{Type}}{Œ£\ (x: A)\ B(x):\mathsf{Type}}
        \end{mathpar}
      4. /Dependent function/. If $x$ is a variable, $A$ is a type and $B(x)$ is a
         type that may depend on $x$, then $(x: A) ‚Üí B(x)$ is a type. When $B$
         is independent of $x$ we may write $A ‚Üí B$ instead.
        \begin{mathpar}
        \inferrule{x‚àà\mathsf{Var} \\ A:\mathsf{Type} \\  B(x):\mathsf{Type}}{(x: A)‚Üí B(x):\mathsf{Type}}
        \end{mathpar}
      Summarizing in BNF we have: \[S‚âî ‚ä• \ |\ S‚äéS\ |\ Œ£\ (x : S)\ S(x)\ |\
      (x:S)‚ÜíS(x)\]

      while identifying in the sense of Heyting (cite:heyting1966intuitionism)
      the types with the logical constants and operators, namely $‚àß,‚à®,‚Üí,‚ä•$.
      1. A proof of $A‚ÜíB$ is an algorithm that transforms an arbitrary proof of
         $A$ into a proof of $B$;
      2. a proof of $A√óB$ is a proof of $A$ and a proof of $B$;
      3. a proof of $A‚à®B$ is an algorithm telling to which of $A$ or $B$ we
         commit to and according to that, a proof of $A$ or a proof of $B$;
      4. nothing is a proof of $‚ä•$;
      5. $‚ä§$ is always true and provable.

*** Syntax of types and terms
    In a theory that features dependent types, presenting types and terms
    separately is not possible as they are tightly intertwined. In fact, terms
    may appear inside types and vice versa. We will first give a short intuitive
    presentation of the syntax that will give an overall idea and hopefully make
    the rest of the section easier to follow.

    The syntax of terms is the same as the one presented in simply typed
    lambda calculus:
    \[T‚âîx\ |\ T\ T\ |\ Œª(x:A).T\ |\ c\]

    Recall the syntax of types in simply typed lambda calculus:
    \[S‚âîB\ |\ S‚ÜíS\]

    In this theory we expand the syntax of types in a way that resembles the
    syntax of terms: \[S‚âîx\ |\ (x:S)‚Ü†S\ |\ S\ S\ |\ c\] We want to highlight the
    construction $(x:S)‚Ü†S$. This is the type of dependent functions. If we have
    $(a:A)‚Ü†B$ then this is the type of functions from $A$ to $B$. However, in
    this case the type $B$ may depend on $a$. As we will see, this is the
    cornerstone and gives the name to /dependent types/.


    As we did with simply typed lambda calculus, we introduce the concept of a
    /context/. Intuitively, a context, is a sequence of typed variables, where
    each type may depend on the preceding variables in the sequence.

    More precisely, a context is a finite sequence of the form \[x‚ÇÅ:S‚ÇÅ,‚Ä¶,x‚Çô:S‚Çô\]
    Where $x·µ¢$ denotes a variable[fn::Every variable must be different than the
    rest, that is, for every $i,j$ such that $i‚â†j$ we have $x·µ¢‚â†x‚±º$.].
    Furthermore, for every $1‚â§i‚â§ n$ we have that given arbitrary terms
    $a‚ÇÅ,‚Ä¶,a_{i-1}$ such that
    \begin{flalign*}
   \label{context-cond}
   S‚ÇÅ:\sf{Type} &\text{ and } a‚ÇÅ:S‚ÇÅ \\
   S‚ÇÇ[x‚ÇÅ‚Ü¶a‚ÇÅ]:\sf{Type} &\text{ and } a‚ÇÇ:S‚ÇÇ[x‚ÇÅ‚Ü¶a‚ÇÅ] \\
   & ‚Ä¶ \\
   S_{i-1}[x‚ÇÅ‚Ü¶a‚ÇÅ,‚Ä¶,x_{i-2}‚Ü¶a_{i-2}]:\sf{Type} &\text{ and } a_{i-1}:S_{i-1}[x‚ÇÅ‚Ü¶a‚ÇÅ,‚Ä¶,x_{i-2}‚Ü¶a_{i-2}]
    \end{flalign*}
    then
    \[S·µ¢[x‚ÇÅ‚Ü¶a‚ÇÅ,‚Ä¶,x_{i-1}‚Ü¶a_{i-1}]:\sf{Type}\].
    Then, if $Œì$ is a context, we write:
    1. $Œì‚ä¢t:A$ to say that term $t$ has type
      $A$ in the context $Œì$. We write $t:A$ instead of $‚àÖ‚ä¢t:A$. As expected, we
    2. $Œì‚ä¢S:\sf{Type}$ to say that $S$ is a type in context $Œì$.
    3. $Œì‚ä¢a=b:S$ to say that $a$ and $b$ are equal terms of type $S$ in context $Œì$.
    4. $Œì‚ä¢A=B:\sf{Type}$ to say that $A$ and $B$ are equal types in context $Œì$.
    In any case, in order to avoid cluttered rules, if the context is the same
    for all the parts of a rule, we will not mention it explicitly. For
    instance, we will prefer to use the notation of the right rule over the
    notation used in the left rule when possible:
    \begin{mathpar}
    \inferrule[Refl]{Œì‚ä¢A:\sf{Type} \\ Œì‚ä¢a:A}{Œì‚ä¢a=a:A} \and
    \inferrule[Refl]{A:\sf{Type} \\ a:A}{a=a:A}
    \end{mathpar}
    Additionally, when the judgment does not depend on the context (\ie{} the
    context is allowed to be empty), we will drop the ``$Œì‚ä¢$'' part.

*** General rules
    As expected, we have the following rule:
    \begin{mathpar}
    \inferrule[Assum]{Œì‚ä¢A:\sf{Type}}
    {Œì,x:A‚ä¢x:A}
    \end{mathpar}
    Note that $x:A$ does not necessarily need to be at the rightmost position in
    the context.

    Since equality is an equivalence relation we have the corresponding rules
    for equality on types and on terms.
    For terms we have:
    \begin{mathpar}
    \inferrule[Refl]{A:\sf{Type} \\ a:A}{a=a:A} \and
    \inferrule[Sym]{A:\sf{Type} \\ a=b:A}{b=a:A} \and
    \inferrule[Trans]{A:\sf{Type} \\ a=b:A \\ b=c:A}{a=c:A}
    \end{mathpar}
    Analogously, for types we have:
    \begin{mathpar}
    \inferrule[Refl]{A:\sf{Type}}{A=A:\sf{Type}} \and
    \inferrule[Sym]{ A=B:\sf{Type} }{B=A:\sf{Type}} \and
    \inferrule[Trans]{B=C:\sf{Type}}{A=C:\sf{Type}}
    \end{mathpar}
    Furthermore we can substitute equal types.
    \begin{mathpar}
    \inferrule[Id1]{A=B:\sf{Type}\\a:A }{a:B} \and
    \inferrule[Id2]{A=B:\sf{Type} \\a=b:A}{a=b:B}
    \end{mathpar}

*** Type family rules
    We say that $A$ is a /family of types/ in the context \[Œì‚âîx‚ÇÅ:A‚ÇÅ,‚Ä¶,x‚Çô:A‚Çô\] if
    $Œì‚ä¢A:\sf{Type}$.

    We proceed by giving some rules for type families.

    Instantiation of a type family:
    \begin{mathpar}
    \inferrule[]{x‚ÇÅ:A‚ÇÅ,‚Ä¶,x‚Çô:A‚Çô‚ä¢C:\sf{Type}\\\\
    a‚ÇÅ:A‚ÇÅ\\‚Ä¶\\a‚Çô:A‚Çô[x‚ÇÅ‚Ü¶a‚ÇÅ,‚Ä¶,x_{n-1}‚Ü¶a_{n-1}]}
    {C[x‚ÇÅ‚Ü¶a‚ÇÅ,‚Ä¶,x‚Çô‚Ü¶a‚Çô]:\sf{Type}}
    \end{mathpar}
    Substitution in a type family:
    \begin{mathpar}
    \inferrule[]{x‚ÇÅ:A‚ÇÅ,‚Ä¶,x‚Çô:A‚Çô‚ä¢C:\sf{Type}\\\\
    a‚ÇÅ=b‚ÇÅ:A‚ÇÅ\\‚Ä¶\\a‚Çô=b‚Çô:A‚Çô[x‚ÇÅ‚Ü¶a‚ÇÅ,‚Ä¶,x_{n-1}‚Ü¶a_{n-1}]}
    {C[x‚ÇÅ‚Ü¶a‚ÇÅ,‚Ä¶,x‚Çô‚Ü¶a‚Çô]=C[x‚ÇÅ‚Ü¶b‚ÇÅ,‚Ä¶,x‚Çô‚Ü¶b‚Çô]}
    \end{mathpar}
    Instantiation of a term of a type family:
    \begin{mathpar}
    \inferrule[]{
    x‚ÇÅ:A‚ÇÅ,‚Ä¶,x‚Çô:A‚Çô‚ä¢c:C\\\\a‚ÇÅ:A‚ÇÅ\\‚Ä¶\\a‚Çô:A‚Çô[x‚ÇÅ‚Ü¶a‚ÇÅ,‚Ä¶,x_{n-1}‚Ü¶a_{n-1}]}
    {c[x‚ÇÅ‚Ü¶a‚ÇÅ,‚Ä¶,x‚Çô‚Ü¶a‚Çô]:C[x‚ÇÅ‚Ü¶a‚ÇÅ,‚Ä¶,x‚Çô‚Ü¶a‚Çô]}
    \end{mathpar}
    Substitution in term of a type family:
    \begin{mathpar}
    \inferrule[]{
    x‚ÇÅ:A‚ÇÅ,‚Ä¶,x‚Çô:A‚Çô‚ä¢c:C\\\\
    a‚ÇÅ=b‚ÇÅ:A‚ÇÅ\\‚Ä¶\\a‚Çô=b‚Çô:A‚Çô[x‚ÇÅ‚Ü¶a‚ÇÅ,‚Ä¶,x_{n-1}‚Ü¶a_{n-1}]}
    {c[x‚ÇÅ‚Ü¶a‚ÇÅ,‚Ä¶,x‚Çô‚Ü¶a‚Çô]=c[x‚ÇÅ‚Ü¶b‚ÇÅ,‚Ä¶,x‚Çô‚Ü¶b‚Çô]:C[x‚ÇÅ‚Ü¶a‚ÇÅ,‚Ä¶,x‚Çô‚Ü¶a‚Çô]}
    \end{mathpar}
    Substitution of a type family.
    \begin{mathpar}
    \inferrule[]{
    x‚ÇÅ:A‚ÇÅ,‚Ä¶,x‚Çô:A‚Çô‚ä¢B=C:\sf{Type}
    \\\\a‚ÇÅ:A‚ÇÅ\\‚Ä¶\\a‚Çô:A‚Çô[x‚ÇÅ‚Ü¶a‚ÇÅ,‚Ä¶,x_{n-1}‚Ü¶a_{n-1}]}
    {B[x‚ÇÅ‚Ü¶a‚ÇÅ,‚Ä¶,x‚Çô‚Ü¶a‚Çô]=C[x‚ÇÅ‚Ü¶a‚ÇÅ,‚Ä¶,x‚Çô‚Ü¶a‚Çô]:B[x‚ÇÅ‚Ü¶a‚ÇÅ,‚Ä¶,x‚Çô‚Ü¶a‚Çô]}
    \end{mathpar}
    Substitution of a type family term.
    \begin{mathpar}
    \inferrule[]{
    x‚ÇÅ:A‚ÇÅ,‚Ä¶,x‚Çô:A‚Çô‚ä¢b=c:C\\\\a‚ÇÅ:A‚ÇÅ\\‚Ä¶\\a‚Çô:A‚Çô[x‚ÇÅ‚Ü¶a‚ÇÅ,‚Ä¶,x_{n-1}‚Ü¶a_{n-1}]}
    {b[x‚ÇÅ‚Ü¶a‚ÇÅ,‚Ä¶,x‚Çô‚Ü¶a‚Çô]=c[x‚ÇÅ‚Ü¶a‚ÇÅ,‚Ä¶,x‚Çô‚Ü¶a‚Çô]:C[x‚ÇÅ‚Ü¶a‚ÇÅ,‚Ä¶,x‚Çô‚Ü¶a‚Çô]}
    \end{mathpar}


    For now we have no primitive constants. In section [[sec:def-new-types]] we will
    define some.

    # We will proceed by introducing the syntax of
    #   types:
    #   1. /Dependent function/. If $x$ is a variable, $A$ is a type and $B(x)$ is a
    #      type that may depend on $x$, then $(x: A) ‚Ü† B$ is a type. When $B$
    #      is independent of $x$ we may write $A ‚Üí B$ instead.
    #     \begin{mathpar}
    #     \inferrule{x‚àà\sf{Var} \\ A:\sf{Type} \\  [x:A]B:\sf{Type}}
    #     {(x: A)‚Üí B:\sf{Type}}
    #     \end{mathpar}
    #   2. /Variable/.
    #   3. /Constant/.
    #   3. /Application/.
    #   Summarizing in BNF we have: \[S‚âî ‚ä• \ |\ S‚äéS\ |\ Œ£\ (x : S)\ S(x)\ |\
    #   (x:S)‚ÜíS(x)\]

    #   \begin{mathpar}
    #   \inferrule[Assum]{A:\sf{Type}}
    #   {[x:A]‚ä¢x:A}
    #   \end{mathpar}

      # while identifying in the sense of Heyting (cite:heyting1966intuitionism)
      # the types with the logical constants and operators, namely $‚àß,‚à®,‚Üí,‚ä•$.
      # 1. A proof of $A‚ÜíB$ is an algorithm that transforms an arbitrary proof of
      #    $A$ into a proof of $B$;
      # 2. a proof of $A√óB$ is a proof of $A$ and a proof of $B$;
      # 3. a proof of $A‚à®B$ is an algorithm telling to which of $A$ or $B$ we
      #    commit to and according to that, a proof of $A$ or a proof of $B$;
      # 4. nothing is a proof of $‚ä•$;
      # 5. $‚ä§$ is always true and provable.

*** Function and application rules
    We can form by the following rule the type of functions from a type $A$ to a
    type $B$ indexed by a term of type $A$.
    \begin{mathpar}
    \inferrule[Fun]{Œì‚ä¢A:\sf{Type}\\Œì,x:A‚ä¢B:\sf{Type}}{Œì‚ä¢(x:A)‚Ü†B:\sf{Type}}
    \end{mathpar}
    Note that $‚Ü†$ has right associativity.
    As another notational convention, when $B$ does not depend on a term of type $A$,
    we will simply write $A‚Ü†B$ instead of $(x:A)‚Ü†B$ as shown by the following
    (redundant) rule.
    \begin{mathpar}
    \inferrule[Fun']{A:\sf{Type}\\B:\sf{Type}}{A‚Ü†B:\sf{Type}}
    \end{mathpar}
    Application and abstraction. \jan{use $‚Üí$ or . ?}
    \begin{mathpar}
    \inferrule[App]{f:(x:A)‚Ü†B \\ a:A}{f\ a:B[x‚Ü¶a]}
    \and \inferrule[Abs]{Œì,x:A‚ä¢b:B}{Œì‚ä¢Œªx‚Üíb:(x:A)‚Ü†B}
    \end{mathpar}
    Application has left associativity.

    Substitution in function types:
    \begin{mathpar}
    \inferrule[]{Œì‚ä¢A=A':\sf{Type}\\\\
     Œì,x:A‚ä¢B=B':\sf{Type}}
     {Œì‚ä¢(x:A)‚Ü†B=(x:A')‚Ü†B'}
    \end{mathpar}

    The rule of \text{$Œ≤$-reduction}. Notice how we have the substitution $x‚Ü¶a$
    also in the type $B$.
    \begin{mathpar}
    \inferrule[$Œ≤$-$=$]{Œì‚ä¢a:A \\ Œì,x:A‚ä¢b:B}{Œì‚ä¢(Œªx‚Üíb)\ a=b[x‚Ü¶a]:B[x‚Ü¶a]}
    \end{mathpar}
    The \text{$Œæ$-$=$} rule tells us that we can replace equal bodies of lambda
    abstraction terms.
    \begin{mathpar}
    \inferrule[$Œæ$-$=$]{Œì,x:A‚ä¢b=b':B}{Œì‚ä¢Œªx‚Üíb=Œªx‚Üíb':(x:A)‚Ü†B}
    \end{mathpar}
    The \text{$Œ±$-$=$} rule tells us that we can rename the abstracted variable
    of lambda abstraction terms. In this rule we assume that $y$ does not
    occur free in $b$.
    \begin{mathpar}
    \inferrule[$Œ±$-$=$]{b:B[x:A]}{Œªx‚Üíb=Œªy‚Üíb[x‚Ü¶y]:(x:A)‚Ü†B}
    \end{mathpar}
    The \text{$Œ∑$-$=$} rule tells us that abstraction and application cancel
    each other. In this rule we assume that $y$ does not occur free in $b$.
    \begin{mathpar}
    \inferrule[$Œ∑$-$=$]{c:(x:A)‚Ü†B}{Œªx‚Üíb=Œªy‚Üíb[x‚Ü¶y]:Œª(x:A)‚Ü†B}
    \end{mathpar}
    Substitution in a function application.
    \begin{mathpar}
    \inferrule[]{f=f':(x:A)‚Ü†B \\ a=a':A}{f\ a=f'\ a':B[x‚Ü¶a]}
    \end{mathpar}

*** Defining new sets
    <<sec:def-new-types>> In this section we will define some new sets that will
    allow us to express...


    We add the following redundant rule. On the left we show the new rule and on
    the right we show the proof that it can be derived.
    \begin{mathpar}
    \inferrule[VarType]
    {\ }
    {P:\set{}‚ä¢\sf{El}(P):\sf{Type}}
    \and
    \inferrule*[Left=El]
    {\inferrule*[Left=Assum]
    {\inferrule*[Left=Set]
    {\ }
    {\set{}:\sf{Type}}}
    {P:\set{}‚ä¢P:\set{}}}
    {P:\set{}‚ä¢\sf{El}(P):\sf{Type}}
    \end{mathpar}
**** Function set
     We introduce the constant that denotes the set of functions from elements
     of a set $A$ to elements of a set $B$: \[‚Ü£:\set‚Ü†\set‚Ü†\set\]
     *Notation*: We will use
     infix notation and write $A\ ‚Ü£\ B$ instead of $‚Ü£\ A\ B$. Also, $‚Ü£$ has
     right associativity.

     We add a constant to introduce elements in this set:
     \[Œõ : (A:\set)‚Ü†(B:\set)‚Ü†(\el{A}‚Ü†\el{B})‚Ü† \el{A\ ‚Ü£\ B} \]

     We add an induction principle:
     \[\sf{case_Œõ} : (A:\set)‚Ü†(B:\set)‚Ü†(\el{A‚Ü£B})‚Ü† \el{A}‚Ü†\el{B} \]
     And the equality:
     \begin{mathpar}
     \inferrule[case$Œõ$]{
     f:\el{A}‚Ü†\el{B} }{\sf{case_Œõ}\ A\ B\ (Œõ\ A\ B\ f)=f:\el{A}‚Ü†\el{B}}
     \end{mathpar}

     The following rules are redundant but they help keeping proofs shorter.
     \begin{mathpar}
     \inferrule[Intro$Œõ$]{f:\el{A}‚Ü†\el{B}}
     {Œõ\ A\ B\ f:\el{A‚Ü£B}}
     \and \inferrule[Abs$Œõ$]{Œì,x:A‚ä¢b:B}
     {Œõ\ A\ B\ (Œªx‚Üíb):\el{A‚Ü£B}}
     \and \inferrule[App$Œõ$]{f:\el{A‚Ü£B} \\ a:\el{A}}
     {\sf{case_Œõ}\ f\ a : \el{B}}
     \end{mathpar}
     *Notation*: When we have $f:\el{A‚Ü£B}$ and $a:\el{A}$ we will write $f\ a$
     instead of $\sf{case_Œõ}\ f\ a$. Note that this notational convention is
     very convenient and adds no ambiguity since $f\ a$ on its own would never
     be a valid term.

     -----

     Consider the fragment of intuitionistic logic with only implication. If $A$
     is a propositional formula then $A^*$ is the type that identifies the
     formula $A$ in LF, where $*$ is a map from propositional formulas to types
     as defined below.
     \begin{flalign*}
     A^*&‚âî\el{‚ü¶A‚üß} \\
     \\
     ‚ü¶p‚üß &‚âî P & \text{where } P:\set{} \\
     ‚ü¶A ‚Üí B‚üß&‚âî ‚ü¶A‚üß ‚Ü£ ‚ü¶B‚üß
     \end{flalign*}
     We map lowercase propositional variables to the same uppercase variable of
     type $\set$, that is, $‚ü¶p‚üß=P$ with $P:\set$, $‚ü¶q‚üß=Q$ with $Q:\set$, and so
     on.

     Let us now show that $(p‚Üíp)^*$ is a theorem in LF. In order to prove
     that, we need to give a term with type $\el{P‚Ü£P}$. This term is in fact the
     identity function wrapped in the function set, as shown below.
     \begin{mathpar}
     \inferrule*[Left=Abs$Œõ$]
     {\inferrule*[Left=Assum]
     {\inferrule*[Left=VarType]
     {\ }
     {P:\set{}‚ä¢\sf{El}(P):\sf{Type}}}
     {P:\set{},x:\sf{El}(P)‚ä¢x:\sf{El}(P)}}
     {P:\set{}‚ä¢Œõ\ P\ P\ (Œªx‚Üíx):\el{P‚Ü£P}}
     \end{mathpar}

     As another example we show that $(p ‚Üí (q ‚Üí p))^*$ is a theorem in LF:
     \begin{mathpar}
     \inferrule*[Left=Abs$Œõ$]
     {\inferrule*[Left=Abs$Œõ$]
     {\inferrule*[Left=Assum]
     {\inferrule*[Left=VarType]
     {\ }
     {P:\set{}, Q:\set{},y:\sf{EL}(Q)‚ä¢\sf{El}(P):\sf{Type}}}
     {P:\set{}, Q:\set{},x:\sf{EL}(P),y:\sf{EL}(Q)‚ä¢x:\sf{El}(P)}}
     {P:\set{}, Q:\set{},x:\sf{EL}(P)‚ä¢ Œõ\ Q\ P\ (Œª y‚Üí x):Q‚Ü£P}}
     {P:\set{}, Q:\set{}‚ä¢Œõ\ P\ (Q‚Ü£P)\ (Œªx‚ÜíŒõ\ Q\ P\ (Œª y‚Üí x)):\el{P‚Ü£Q‚Ü£P}}
     \end{mathpar}
     *Notation*. In order to improve readability, from now on, where we would
     have $Œõ\ A\ B\ (Œªx‚Üíb)$ and $A$ and $B$ are clear from the context, we will
     write $Œõx‚Üíb$ instead. For instance, the last step of the previous proof
     would be written as
     \begin{mathpar}
     \inferrule*[Left=Abs$Œõ$]
     {‚Ä¶}
     {P:\set{}, Q:\set{}‚ä¢Œõx‚ÜíŒõy‚Üí x:\el{P‚Ü£Q‚Ü£P}}
     \end{mathpar}

     We now show the last step of the proof for $((p‚Üí(q‚Üír)) ‚Üí ((p‚Üíq)‚Üí(p‚Üír))^*$.
     It should not be hard for the reader to see how the proof can be finished.
     \begin{mathpar}
     \inferrule*[Left=Abs$Œõ$]
     {‚Ä¶}
     {P:\set{}, Q:\set{}, R:\set{}‚ä¢Œõf‚Üí(Œõ g‚Üí (Œõx‚Üíf\ x\ (g\ x))):\\\\
       \el{(P‚Ü£Q‚Ü£R)‚Ü£(P‚Ü£Q)‚Ü£P‚Ü£R}}
     \end{mathpar}

     Observe now that the modus ponens rule is valid, that is, if $(p‚Üíq)^*$ and
     $p^*$ are theorems in LF, then $q^*$ is also a theorem. From the assumption
     it follows that there are terms $f:\el{P‚Ü£ Q}$ and $a:\sf{EL}(P)$. Then we
     have that $\sf{case_Œõ}\ f\ a$, which we write as $f\ a$, is the desired term.
     \begin{mathpar}
     \inferrule*[Left=App]
     {\inferrule*[]{\ }{P:\set{}, Q:\set{}‚ä¢f:\el{P‚Ü£ Q}}
     \\ \inferrule*[]{\ }{P:\set{}, Q:\set{}‚ä¢a:\sf{El}(P)}}
     {P:\set{}, Q:\set{}‚ä¢f\ a: \sf{El}(Q) }
     \end{mathpar}

     {{{begintheorem}}} {{{endtheorem}}} If $A$ is a theorem in the fragment of
     propositional intuitionistic logic with only implication, then
     $A^*$ is a theorem in LF.
     {{{beginproof}}} By induction on $A$ and using the previous facts. {{{endproof}}}

**** Top set
      We begin by defining the singleton set. We name it $‚ä§$. We say that it
      is a singleton set because it only has one element, namely
      $\sf{tt}$. The $‚ä§$ set represents ``true'' in this theory.

      We add the constant that represents the set: \[‚ä§:\set{}\] We introduce the
      constant that is the only element in the set: \[\sf{tt}:\sf{El}(‚ä§)\] An
      induction principle: \[\sf{case}_{‚ä§}:(P : \sf{El}(‚ä§)‚Ü†\set{})‚Ü†\sf{El}(P\
      \sf{tt})‚Ü†(a:\sf{El}(‚ä§))‚Ü†\sf{El}(P\ a)\] The above type should read as
      follows. Given a predicate $P$, a proof that $P$ holds for the base case,
      that is, an element of the set $P\ \sf{tt}$, and an arbitrary element $a$
      in the set $‚ä§$, we build a term in the set $P\ a$, which is a proof that
      $a$ satisfies $P$.

      We also add the following equality.
      \begin{mathpar}
      \inferrule[case$‚ä§$]{P:\el{‚ä§}‚Ü†\set{} \\ p : \el{ P\ \sf{tt} }}
      {\sf{case}_{‚ä§}\ P\ p\ \sf{tt}=p\ \sf{tt}:\el{P\ \sf{tt}}}
      \end{mathpar}

      As expected from a set representing /true/, it is trivial to provide a term
      of type $\el{‚ä§}$.
      \begin{mathpar}
      \inferrule[]{\ }{\sf{tt}:\el{‚ä§} }
      \end{mathpar}
**** Bottom set
     We define the empty set, $‚ä•$, as we call it. We say that it is the empty
     set because there is no term $t$ such that $t:\el{‚ä•}$. The $‚ä•$ type
     represents ``false'' in this theory.

     We introduce the constant that represents the type: \[‚ä•:\set{}\] We do
     not introduce any constants as elements of this set. We introduce an
     induction principle: \[\sf{case_‚ä•}:(P : \el{‚ä•}‚Ü†\set{})‚Ü†(a:\el{‚ä•})‚Ü†\el{P\ a}\]

     -----

     We add the following equation to the map $‚ü¶.‚üß$:
     \begin{flalign*}
     ‚ü¶‚ä•‚üß ‚âî ‚ä• &&
     \end{flalign*}
     The $‚ä•$ on the right of $‚âî$ is the constant introduced in this section.

     Let us now show that the principle $(‚ä•‚Üíp)^*$ know as /ex falso quodlibet/
     or /principle of explosion/ holds in LF. For that, we provide a term typed
     $(‚ä•‚Üíp)^*$.
     \begin{mathpar}
     \inferrule*[Left=Abs$Œõ$]
     {\inferrule*[Left=App, sep=2em]
     {\inferrule*[Left=App]
     {\inferrule*[]{\ }{\sf{case_‚ä•}:‚Ä¶}
        \\ \inferrule*[Left=Abs]
            {\inferrule*[Left=Assum]{\ }{P:\set, x:\el{‚ä•}‚ä¢P:\set}}
            {P:\set(Œªx‚ÜíP):\el{‚ä•}‚Ü†\set}}
     {P:\set,y:\el{‚ä•}‚ä¢\sf{case_‚ä•}\ (Œªx‚ÜíP):\el{‚ä•}‚Ü†\el{P}}
        \\ \inferrule*[Left=Assum]{\ }{y:\el{‚ä•}‚ä¢y:\el{‚ä•}}}
     {P:\set,y:\el{‚ä•}‚ä¢\sf{case_‚ä•}\ (Œªx‚ÜíP)\ y:\el{P}}}
     {P:\set‚ä¢Œõy‚Üí\sf{case_‚ä•}\ (Œªx‚ÜíP)\ y:\el{‚ä•‚Ü£P}}
     \end{mathpar}
**** Disjoint unions set
     Disjoint unions represent two options.

     We introduce the constant: \[‚äé : \set{}‚Ü†\set{}‚Ü†\set{}\]
     *Notation*.We will use infix notation for $‚äé$, hence we will write $A\ ‚äé\ B$ instead
     of $‚äé\ A\ B$.

     Since we want to represent two options, we introduce two constructors:
     \begin{flalign*}
     \sf{inj}‚ÇÅ &: (A:\set{})‚Ü†(B:\set{})‚Ü†\el{A}‚Ü† \el{A\ ‚äé\ B}\\
     \sf{inj}‚ÇÇ &: (A:\set{})‚Ü†(B:\set{})‚Ü†\el{B}‚Ü† \el{A\ ‚äé\ B}
     \end{flalign*}

     We introduce the following induction principle:
     \begin{flalign*}
     \sf{case}_‚äé &: (A:\set{})‚Ü†(B:\set{})‚Ü†(P : \el{A\ ‚äé\ B} ‚Ü† \set{})\\
     &‚Ü† ((a:\el{A})‚Ü†\el{P\ (\sf{inj}‚ÇÅ\ A\ B\ a)}) \\
     &‚Ü† ((b:\el{B})‚Ü†\el{P\ (\sf{inj}‚ÇÇ\ A\ B\ b)}) \\
     &‚Ü† (u:\el{A\ ‚äé\ B}) \\
     &‚Ü† \el{P\ u}
     \end{flalign*}
     and the following equalities:

     \begin{mathpar}
     \inferrule[Case$‚äé‚ÇÅ$]{P:\el{A\ ‚äé\ B}‚Ü†\set{}\\\\
     p‚ÇÅ:(a:\el{A})‚Ü†\el{P\ (\sf{inj}‚ÇÅ\ A\ B\ a)} \\\\
     p‚ÇÇ:(b:\el{B})‚Ü†\el{P\ (\sf{inj}‚ÇÇ\ A\ B\ b)} \\\\
     a: \el{A}
     }{\sf{case}_‚äé\ A\ B\ P\ p‚ÇÅ\ p‚ÇÇ\ (\sf{inj}‚ÇÅ\ A\ B\ a)=
     p‚ÇÅ\ a:\el{P\ (\sf{inj}‚ÇÅ\ A\ B\ a)}}
     \and
     \inferrule[Case$‚äé‚ÇÇ$]{P:\el{A\ ‚äé\ B}‚Ü†\set{}\\\\
     p‚ÇÅ:(a:\el{A})‚Ü†\el{P\ (\sf{inj}‚ÇÅ\ A\ B\ a)} \\\\
     p‚ÇÇ:(b:\el{B})‚Ü†\el{P\ (\sf{inj}‚ÇÇ\ A\ B\ b)} \\\\
     b: \el{B} }{\sf{case}_‚äé\ A\ B\ P\ p‚ÇÅ\ p‚ÇÇ\ (\sf{inj}‚ÇÇ\ A\ B\ b)=
     p‚ÇÇ\ b:\el{P\ (\sf{inj}‚ÇÇ\ A\ B\ b)}}
     \end{mathpar}

     -----

     We extend the map $‚ü¶.‚üß$ we defined with the following equation:
     \begin{flalign*}
     ‚ü¶A‚à®B‚üß‚âî‚ü¶A‚üß‚äé‚ü¶B‚üß & &
     \end{flalign*}
     We show that $(p‚Üí(p‚à®q))^*$ is a theorem in LF. {{{jan(should I provide a
     full proof?)}}}
     \begin{mathpar}
     \inferrule[]{‚Ä¶ }{P:\set,Q:\set‚ä¢Œõx‚Üí\sf{inj‚ÇÅ}\ P\ Q\ x:\el{P‚Ü£(P\ ‚äé\ Q)}}
     \end{mathpar}
     The proof of $(q‚Üí(p‚à®q))^*$ is analogous.
     \begin{mathpar}
     \inferrule[]{‚Ä¶ }{P:\set{},Q:\set‚ä¢Œõx‚Üí\sf{inj‚ÇÇ}\ P\ Q\ x:\el{Q‚Ü£(P\ ‚äé\ Q)}}
     \end{mathpar}
     Finally we have that $((p‚Üír)‚Üí((q‚Üír)‚Üí((p‚à®q)‚Üír)))^*$ is a theorem in LF.
     Finishing the proof can be made mechanically.
     \begin{mathpar}
     \inferrule[]{‚Ä¶ }{P:\set{},Q:\set{},R:\set{}‚ä¢
     Œõf‚ÜíŒõg‚ÜíŒõx‚Üí\sf{case}_‚äé\ P\ Q\ (Œª x‚Üí R)\ (\sf{case_Œõ}\ f)\ (\sf{case_Œõ}\ g)\ x:\\\\
     \el{(P‚Ü£R)‚Ü£(Q‚Ü£R)‚Ü£(P‚äéQ)‚Ü£R} }
     \end{mathpar}
**** Pairs set
     The following constant which represents the set of pairs:
     \[√ó:\set{}‚Ü†\set{}‚Ü†\set{}\]
     *Notation*. We will use infix notation for $√ó$, hence we will write $A\ √ó B$ instead
     of $√ó A\ B$.

     We introduce one constructor:
     \[\sf{pair} : (A:\set{})‚Ü†(B:\set{})‚Ü†\el{A}‚Ü† \el{B}‚Ü†\el{A\ √ó\ B}\]

     We introduce the following induction principle:
     \begin{flalign*}
     \sf{case}_√ó &: (A:\set{})‚Ü†(B:\set{})‚Ü†(P : \el{A\ √ó\ B} ‚Ü† \set{})\\
     &‚Ü† ((a:\el{A})‚Ü†(b:\el{B})‚Ü†\el{P\ (\sf{pair}\ A\ B\ a\ b)}) \\
     &‚Ü† (u:\el{A\ √ó B}) \\
     &‚Ü† \el{P\ u}
     \end{flalign*}
     and the following equality:
     \begin{mathpar}
     \inferrule[case$√ó$]{P:\el{A\ √ó\ B}‚Ü†\sf{Set}\\\\
     p:(a':\el{A})‚Ü†(b':\el{B})‚Ü†\el{P\ (\sf{pair}\ A\ B\ a'\ b')}\\\\
     a : \el{A} \\ b : \el{B}
     }{
     \sf{case}_√ó\ A\ B\ P\ p\ (\sf{pair}\ A\ B\ a\ b)=
      p\ a\ b:P\ (\sf{pair}\ A\ B\ a\ b)}
     \end{mathpar}

     -----

     Add the following equation to the $‚ü¶.‚üß$ map:
     \begin{flalign*}
     ‚ü¶A‚àßB‚üß‚âî‚ü¶A‚üß√ó‚ü¶B‚üß&&
     \end{flalign*}
     We show that $(p‚àßq‚Üíp)^*$ is a theorem in LF.
     \begin{mathpar}
     \inferrule[]{‚Ä¶ }{P:\set,Q:\set‚ä¢Œõx‚Üí\sf{case}_√ó\ P\ Q\ (Œª v‚Üí P)\ (Œªy‚ÜíŒªz‚Üíy)\ x:\el{(P√óQ)‚Ü£P}}
     \end{mathpar}
     Analogously, the proof for $(p‚àßq‚Üíq)^*$.
     \begin{mathpar}
     \inferrule[]{‚Ä¶ }{P:\set,Q:\set‚ä¢Œõx‚Üí\sf{case}_√ó\ P\ Q\ (Œª v‚Üí Q)\ (Œªy‚ÜíŒªz‚Üíz)\ x:\el{(P√óQ)‚Ü£Q}}
     \end{mathpar}
     Lastly we show that $p‚Üí(q‚Üí(p‚àßq))^*$ is a theorem in LF.
     \begin{mathpar}
     \inferrule[]{‚Ä¶ }{P:\set,Q:\set‚ä¢Œõx‚ÜíÃãŒõy ‚Üí\sf{pair}\ P\ Q\ x\ y: \el{P‚Ü£Q‚Ü£(P√óQ)}}
     \end{mathpar}

**** Dependent functions set
     Dependent functions generalize regular functions in the way that the type
     of the return type depends on the argument value. More precisely, a
     dependent function is a map from elements of a set $A$ to elements of a set
     $B$ indexed by elements of $A$. Thus we introduce the following constant:
     \[‚áù:(A:\set)‚Ü†(B:\el{A}‚Ü†\set)‚Ü†\set\] *Notation*: We will use infix notation
     and write $A\ ‚áù\ B$ instead of $‚áù\ A\ B$. Also, $‚áù$ has right
     associativity.

     We add a constant to introduce elements in this set:
     \[Œõ' : (A:\set)‚Ü†(B:\el{A}‚Ü†\set)‚Ü†((a:\el{A})‚Ü†\el{B\ a})‚Ü† \el{A\ ‚áù\ B} \]

     We add an induction principle:
     \[\sf{case_Œõ}' : (A:\set)‚Ü†(B:\el{A}‚Ü†\set)‚Ü†(\el{A‚áùB})‚Ü† (a:\el{A})‚Ü†\el{B\ a} \]
     And the equality:
     \begin{mathpar}
     \inferrule[case$Œõ$']{
     f:\el{A}‚Ü†\el{B} }{\sf{case_Œõ}'\ A\ B\ (Œõ\ A\ B\ f)=f:(a:\el{A})‚Ü†\el{B\ a}}
     \end{mathpar}

     The following rules are redundant but they help keeping proofs shorter.
     \begin{mathpar}
     \inferrule[Intro$Œõ$']{f:(a:\el{A})‚Ü†\el{B\ a}}
     {Œõ\ A\ B\ f:\el{A‚áùB}}
     \and \inferrule[Abs$Œõ$']{x:A‚ä¢b:B\ x}
     {Œõ\ A\ B\ (Œªx‚Üíb):\el{A‚áùB}}
     \and \inferrule[App$Œõ$']{f:\el{A‚áùB} \\ a:\el{A}}
     {\sf{case_Œõ}\ f\ a : \el{B\ a}}
     \end{mathpar}
     *Notation*: When we have $f:\el{A‚áùB}$ and $a:\el{A}$ we will write $f\ a$
     instead of $\sf{case_Œõ'}\ f\ a$.

**** Œ£ Pairs set
      A $Œ£$ /pair/ generalizes the concept of a regular pair. In a $Œ£$ pair the type
      of the second component depends on the value of the first component.

      We introduce the constant for the set: \[Œ£ : (A : \set)‚Ü†(B : \el{A} ‚Ü†
      \set)‚Ü†\set\] We introduce a constant to build dependent paris:
      \[\sf{pair}_Œ£ : (A : \set)‚Ü†(B : A ‚Ü† \set) ‚Ü† (a : \el{A})‚Ü†(b :
      \el{B\ a})‚Ü† Œ£\ A\ B\] The above constructor takes four arguments: The type
      of the first component, the type of the second component, the term for the
      first component, and the term for the second component. We add the
      following induction principle:
      \begin{flalign*}
      \sf{case}_Œ£:&(A:\set) ‚Ü† (B : \el{A}‚Ü†\set)‚Ü† (P : Œ£\ A\ B‚Ü†\set) \\
        &‚Ü† ((a:\el{A}) ‚Ü† (b:\el{B\ a})‚Ü†P\ (\sf{pair}_Œ£\ A\ B\ a\ b)) \\
        &‚Ü† (u : \el{Œ£\ A\ B})\\
        &‚Ü† \el{P\ u}
      \end{flalign*}
      We also add this equality.
      \begin{mathpar}
      \inferrule[]{P:\el{Œ£\ A\ B}‚Ü†\set\\\\
      p:(a':\el{A})‚Ü†(b':\el{B\ a'})‚Ü†\el{P\ (\sf{pair}_Œ£\ A\ B\ a'\ b')}\\\\
      a : \el{A} \\ b : \el{B\ a}
      }{
      \sf{case}_Œ£\ A\ B\ P\ p\ (\sf{pair}_Œ£\ A\ B\ a\ b)=
       p\ a\ b:P\ (\sf{pair}_Œ£\ A\ B\ a\ b)}
      \end{mathpar}

**** Natural numbers set
     We represent the set of natural numbers with the constant $‚Ñï$:
     \[‚Ñï:\set\]
     We add two constants to build elements in $‚Ñï$.
     \begin{flalign*}
     ùü¨ &: ‚Ñï\\
     \sf{suc}&: ‚Ñï‚Ü†‚Ñï
     \end{flalign*}
     We add an induction principle:
     \begin{flalign*}
     \sf{case}_‚Ñï:\ &(P:\el{‚Ñï}‚Ü†\set)\\
     ‚Ü†\ & \el{P\ ùü¨} \\
     ‚Ü†\ & ((n:\el{‚Ñï})‚Ü† \el{P\ n} ‚Ü† \el{P\ (\sf{suc}\ n)}) \\
     ‚Ü†\ & (a:\el{‚Ñï}) \\
     ‚Ü†\ & \el{P\ a}
     \end{flalign*}
     We add two equalities for the induction principle:
     \begin{mathpar}
     \inferrule[case 0]{P:\el{‚Ñï}‚Ü†\set \\ B:\el{P\ ùü¨}
     \\\\R:(n:\el{‚Ñï})‚Ü† \el{P\ n} ‚Ü† \el{P\ (\sf{suc}\ n)}}
     {\sf{case}_‚Ñï\ P\ B\ R\ ùü¨ =B:\el{P\ ùü¨}}
     \and \inferrule[case suc]{P:\el{‚Ñï}‚Ü†\set \\ B:\el{P\ ùü¨} \\ n:\el{‚Ñï}
     \\\\R:(n:\el{‚Ñï})‚Ü† \el{P\ n} ‚Ü† \el{P\ (\sf{suc}\ n)}}{\sf{case}_‚Ñï\ P\ B\ R\ (\sf{suc}\ n) =
      R\ n\ (\sf{case}_‚Ñï\ P\ B\ R\ n):\el{P\ (\sf{suc}\ n)}}
     \end{mathpar}

     -----

     Let us see how we can define addition:
     \[\sf{add}‚âîŒªn‚ÜíŒªm‚Üí\sf{case}_‚Ñï\ (Œªx‚Üí‚Ñï)\ m\ (Œªx‚ÜíŒªy‚Üí\sf{suc}\ y)\ n\]
     It is easy to show that indeed
     \[\sf{add}:\el{‚Ñï}‚Ü†\el{‚Ñï}‚Ü†\el{‚Ñï}\]
     Let us sketch the proof of $\sf{add}\ 1\ 2=3$.
     \begin{flalign*}
     \sf{add}\ 1\ 2 &= (Œªn‚ÜíŒªm‚Üí\sf{case}_‚Ñï\ (Œªx‚Üí‚Ñï)\ m\ (Œªx‚ÜíŒªy‚Üí\sf{suc}\ y)\ m)\ (\sf{suc}\ ùü¨)\ (\sf{suc}\ (\sf{suc}\ ùü¨)) &\\
     &= \sf{case}_‚Ñï\ (Œªx‚Üí‚Ñï)\ (\sf{suc}\ (\sf{suc}\ ùü¨))\ (Œªx‚ÜíŒªy‚Üí\sf{suc}\ y)\ (\sf{suc}\ ùü¨)&\textsc{Case suc} \\
     &= (Œªx‚ÜíŒªy‚Üí\sf{suc}\ y)\ ùü¨\ (\sf{case}_‚Ñï\ (Œªx‚Üí‚Ñï)\ (\sf{suc}\ (\sf{suc}\ ùü¨))\ (Œªx‚ÜíŒªy‚Üí\sf{suc}\ y)\ ùü¨)& Œ≤\text{-=} \\
     &= \sf{suc}\ (\sf{case}_‚Ñï\ (Œªx‚Üí‚Ñï)\ (\sf{suc}\ (\sf{suc}\ ùü¨))\ (Œªx‚ÜíŒªy‚Üí\sf{suc}\ y)\ ùü¨) &\textsc{Case }ùü¨\\
     &=\sf{suc}\ (\sf{suc}\ (\sf{suc}\ ùü¨)) &\\
     &=3
     \end{flalign*}

     In the next section we will see how we can use induction on the natural
     numbers to prove a property of addition.
**** Identity set
     We denote the identity set (or equality set) with the $‚â°$ constant:
     \[‚â°\ : (S:\set)‚Ü†(x:\el{S})‚Ü†\el{S}‚Ü†\set\]
     *Notation*. We will write $A\ ‚â°_S\ B$ instead of $‚â°\ S\ A\ B$.

     We add the constant $\sf{refl}$ to build elements of this set.
     \[\sf{refl}\ : (S:\set)‚Ü†(x:\el{S})‚Ü†x‚â°_Sx\]

     We add an induction principle:
     \begin{flalign*}
     \sf{case_‚â°} :\ & (S:\set)‚Ü†(x:S)‚Ü† (y:\el{S})\\
       ‚Ü†\ &(P:(x':\el{S})‚Ü†(y':\el{S})‚Ü†\el{x'‚â°_Sy'}‚Ü†\set) \\
       ‚Ü†\ &((z:\el{S})‚Ü†\el{P\ z\ z\ (\sf{refl}\ S\ z)}) \\
       ‚Ü†\ & (e:\el{x‚â°_Sy}) \\
       ‚Ü†\ & \el{P\ x\ y\ e}
     \end{flalign*}
     We add one equality:
     \begin{mathpar}
     \inferrule[Case$‚â°$]{S:\set\\ a:\el{S} \\ y:\el{S} \\\\
     P:(x':\el{S})‚Ü†(y':\el{S})‚Ü†\el{x‚â°_Sy}‚Ü†\set
     \\\\ i:(z:\el{S})‚Ü†\el{P\ z\ z\ (\sf{refl}\ S\ z)} }
     {\sf{case_‚â°}\ S\ x\ y\ P\ i\ (\sf{refl}\ S\ x)=i\ a:\el{P\ x\ x\ (\sf{refl}\ S\ x)} }
     \end{mathpar}

     -----

     With this set we can build a type which states ``for every natural $n$, we
     have $n+0=n$''. Such type is as follows: \[(n:\el{‚Ñï})‚Ü† \el{\sf{add}\ n\ ùü¨
     ‚â°_‚Ñï n}\] If we were to prove this informally we would proceed as follows.
     Perform induction on $n$, for the base case is trivial, for the successor
     case $n=\sf{suc}m$ we have by IH that $\sf{add}\ m\ ùü¨=m$, then we apply
     $\sf{suc}$ on both sides of the IH, so we have $\sf{suc}\ (\sf{add}\ m\ ùü¨)=\sf{suc}\ m$
     which is equivalent to $(\sf{add}\ (\sf{suc}\ m)\ ùü¨)=\sf{suc}\ m$.

     In order to formalize the previous proof we will first show this lemma:
     \[(n:\el{‚Ñï})‚Ü†(m:\el{‚Ñï})‚Ü† \el{n‚â°_‚Ñïm}‚Ü†\el{\sf{suc}\ n‚â°_‚Ñï\sf{suc}\ m}\]
     In order to show that we build a term of the above type:
     \begin{flalign*}
     \sf{lemma} ‚âî Œªn‚ÜíŒªm‚ÜíŒªe‚Üí \sf{case_‚â°}\ &‚Ñï\ n\ m \\
           &(Œªn'‚ÜíŒªm'‚ÜíŒªe'‚Üí\sf{suc}\ n'‚â°_‚Ñï\sf{suc}\ m') \\
           & (Œªz‚Üí\sf{refl}\ ‚Ñï\ (\sf{suc}\ z))\\
           & e
     \end{flalign*}
     Let us explain the proof step by step. We start with three lambda
     abstractions as we have three arguments: two natural numbers and a proof of
     equality between them. Then we use the \sf{case_‚â°} primitive to build the
     desired proof. We now inspect each of the applied arguments. First we have
     $‚Ñï$ because the equalities in the proof are between naturals. Second and
     third we have $n$ and $m$ because they are the two involved naturals. Then
     we have the property that we want to show, namely $(Œªn'‚ÜíŒªm'‚ÜíŒªe'‚Üí\sf{suc}\
     n'‚â°_‚Ñï\sf{suc}\ m')$, we will refer to this term as $P$. After that we need
     to provide a term typed $(z:\el{S})‚Ü†\el{P\ z\ z\ (\sf{refl}\ S\ z)}$. In
     our case we need to replace $S$ by $‚Ñï$ and $P$ by the fourth argument.
     After simplifying with the \(\text{$Œ≤$-reduction}\) rule we get
     $(z:\el{‚Ñï})‚Ü†\el{\sf{suc}\ z‚â°_‚Ñï\sf{suc}\ z}$. We can easily see that
     $(Œªz‚Üí\sf{refl}\ ‚Ñï\ (\sf{suc}\ z))$ has the desired type. The last argument,
     $e$, which has type $\el{n‚â°_‚Ñïm}$ is the equality that we will use. Finally
     we see that the return type is $\el{P\ x\ y\ e}$. After replacing $P$ with
     its definition, $x$ by and $n$ and $y$ by $m$ and simplifying via the
     \(\text{$Œ≤$-reduction}\) rule we get $\el{\sf{suc}\ n‚â°_‚Ñï\sf{suc}\ m}$,
     which is what we wanted.
     # We ask the reader to check that the term is indeed of the claimed type.

     We are now ready to prove the theorem. The term that serves as a proof of
     the theorem, or in other words the term that has the specified type, is
     provided below.
     \begin{flalign*}
     \sf{thm} ‚âî Œªn‚Üí \sf{case}_‚Ñï\ &(Œªn'‚Üí \sf{add}\ n'\ ùü¨ ‚â°_‚Ñïn')\\
                & (\sf{refl}\ ‚Ñï\ ùü¨) &\text{base case} \\
                & (Œªm‚Üí Œªp‚Üí \sf{lemma}\ (\sf{add}\ m\ ùü¨)\ m\ p) &\text{inductive case} \\
                & n
     \end{flalign*}
     Let us break the term \sf{thm} into smaller pieces and analyze them. Since
     we are proving that a property holds for any natural number, we start with
     a lambda abstraction $Œª n‚Üí ‚Ä¶$ and then we proceed by induction on $n$ by
     using the $\sf{case}_‚Ñï$ constant.

     The first argument of $\sf{case}_‚Ñï$, namely $(Œªn'‚Üí \sf{add}\ n'\ ùü¨ ‚â°_‚Ñïn')$,
     expresses the property that we want to prove with the induction. We will
     refer to this argument as $P$. It is easy to observe that $P$ has type
     $\el{‚Ñï}‚Ü†\set$ as required by the type of $\sf{case}_‚Ñï$.

     Then, the second argument, which corresponds to the proof for the base case
     has type $\el{P\ ùü¨}$, which in our case translates into $(Œªn'‚Üí \sf{add}\
     n'\ ùü¨ ‚â°_‚Ñïn')\ ùü¨$ which is the same (by \(\text{$Œ≤$-reduction}\)) as
     $\el{\sf{add}\ ùü¨\ ùü¨ ‚â°_‚Ñïùü¨}$ which is the same (by \textsc{case 0}) as $\el{ùü¨
     ‚â°_‚Ñïùü¨}$. Thus it suffices to provide the term $\sf{refl}\ ‚Ñï\ ùü¨$, which has the desired
     type.

     The third argument corresponds to the proof of the inductive case. The type
     for this argument is[fn::We have renamed the variable $n$ in this argument
     to $m$ to avoid confusion with the previously bound variable $n$. Recall
     that this can be done thanks to the \(\text{$Œ±$-$=$}\) rule.] $((m:\el{‚Ñï})‚Ü†
     \el{P\ m} ‚Ü† \el{P\ (\sf{suc}\ m)})$ which in our case translates into
     $((m:\el{‚Ñï})‚Ü† \el{\sf{add}\ m\ ùü¨ ‚â°_‚Ñïn} ‚Ü† \el{\sf{add}\ (\sf{suc}\ m)\ ùü¨
     ‚â°_‚Ñï\sf{suc}\ m})$. It is easy to see that the lemma we proved before will
     come in handy. In fact, it suffices to observe that the term $(Œªm‚Üí Œªp‚Üí
     \sf{lemma}\ (\sf{add}\ m\ ùü¨)\ m\ p)$ has the desired type. This concludes
     the proof of the inductive case.

     Finally, the fourth argument is the specific natural number for which we
     want to perform the induction and prove the property. We just give it $n$,
     which is bound by the initial $Œªn‚Üí‚Ä¶$. This concludes our proof.

*** Final remarks :noexport:
    With this we conclude the presentation of Martin's L√∂f logical framework.
    Talk about operational semantics.
** Martin-L√∂f dependent type theory :noexport:
   Martin-L√∂fs type theory is also known as intuitionistic type theory, and it
   can serve as the basis for constructive mathematics, furthermore, it can be
   used as the specification of a programming language.

   The results presented in this section have been gathered from
   cite:martin1984intuitionistic,sep-type-theory-intuitionistic,nlab:martin-l√∂f_dependent_type_theory.

   See chapter 5 and 14 of cite:nordstrom1990programming.
** Basic Agda
   In this section we precisely define a moderate subset of Agda. We have tried
   to remain faithful to the semantics of the real Agda language, however, this
   is an incomplete simplification and thus is not meant to be a precise
   reference for the real Agda language. We comment on some of the
   simplifications in Section [[sec:agda-limitations]].

   We introduce several concepts that have cyclic dependencies and thus a linear
   presentation is not possible. {{{jan(write something to help the reader.)}}}
   To ease a first reading we summarize the concepts presented in this section.

   {{{begindef}}} *Identifier*. An identifier is a sequence of characters which
   do not contain any white space or parentheses (normal =()= or curly ={}=) and
   furthermore it is different than all reserved keywords. Some identifier
   examples are =a=, =x=, =¬¨¬¨x=, =A‚ñ∑B=, =A‚ÜíB=, =Some-Long-Word=. For all
   practical purposes, we can assume we have an infinite set of identifiers.

   Some of the Agda reserved keywords are =Œª=, =‚àÄ=, =‚Üí=, ===,
   =data=, =where=, =:=. {{{jan(I don't think this has to be exhaustive.)}}}

   It is worth noting that syntactically constructors and identifiers are
   subject to the same rules. Agda detects constructors by using the datatype
   definitions in scope. For more information on constructors see the definition
   of a datatype ([[def:agda-datatype]]). {{{jan(should this be in?)}}} {{{enddef}}}

   {{{begindef}}} <<def:agda-term>> *Term/Type*. An Agda term is recursively
   defined as shown in the figure below.

   An Agda *type* is a term =A= such that =A : Set ‚Ñì= for some =‚Ñì=. Definition
   [[def:agda-well-typed]] gives a description of the Agda typing rules. We want to
   emphasize, and it is obvious from the definition, that all types are also terms.

   We use =x= to denote an arbitrary identifier, we use =p‚ÇÅ=, ‚Ä¶, =p‚Çô= to denote
   arbitrary patterns (see Definition [[def:agda-pattern]]), we use =A,=, =B=, =A‚ÇÅ=,
   =‚Ä¶=, =A‚Çô= to denote arbitrary terms and we use =c= to denote an arbitrary
   constructor (see Definition [[def:agda-constructor]]).

   # #+caption: The syntax of terms (and types).
   #+name: fig:agda-term
   #+attr_latex: :align llll :float t :center t :placement [H]
    | $term$ | $‚âî$   | =f=                        | identifier;                               |
    |        | \vert | =(x : A) ‚Üí B=              | function type;                            |
    |        | \vert | =Œª x ‚Üí A=                  | lambda abstraction;                       |
    |        | \vert | =Œª {p‚ÇÅ ‚Üí A‚ÇÅ; ‚Ä¶ ; p‚Çô ‚Üí A‚Çô}= | lambda abstraction with pattern matching; |
    |        | \vert | =A B=                      | function application;                     |
    |        | \vert | =Set ‚Ñì=                    | universe $(‚Ñì‚ààœâ)$.                         |

   {{{jan(Is the following presentation preferred?)}}}
   #+name: fig:agda-term2
   #+attr_latex: :align llll :float t :center t :placement [H]
    | $term$ | $‚âî$   | =iden=                           | identifier;                               |
    |        | \vert | =(iden : type) ‚Üí term=           | function type;                       |
    |        | \vert | =Œª iden ‚Üí term=                  | lambda abstraction;                       |
    |        | \vert | =Œª {pat ‚Üí term; ‚Ä¶ ; pat ‚Üí term}= | lambda abstraction with pattern matching; |
    |        | \vert | =term term=                      | function application;                     |
    |        | \vert | =Set ‚Ñì=                          | universe $(‚Ñì‚ààœâ)$.                         |

   The =‚Üí= in the function type has right associativity, hence =(a : A) ‚Üí (b :
   B) ‚Üí C= is the same as =(a : A) ‚Üí ((b : B) ‚Üí C)=. The =‚Üí= in the lambda
   abstraction extends to the rightmost part, hence =Œª x ‚Üí Œª y ‚Üí A B= is the
   same as =(Œª x ‚Üí (Œª y ‚Üí A B))=. Function application has left associativity,
   hence =a b c= is the same as =(a b) c=. Also note that the =i= in =Set i= can
   be an identifier but for simplicity in this section we restrict the =i= to be
   an arbitrary constant natural number.

   An example term:
   #+begin_example
   Œª (A : Set 0) ‚Üí Œª (B : Set 0) ‚Üí (f : A ‚Üí B) ‚Üí (a : A) ‚Üí B
   #+end_example
   {{{enddef}}}


  {{{begindef}}} *Function definition*. A function definition is used to bind a
  new[fn::By new we mean that is has not yet been bound by another definition.]
  identifier to a term.

  /Note/: Maybe the name ``term definition'' or ``term binding'' would be more
  appropriate for the concept defined here. We have decided to use the name
  ``Function definition'' since it is widely used in the field of computer
  science.

  # #+name: fig:agda-fundef
  # #+attr_latex: :align llll :float t :center t :placement [H]
  # | $fundef$ | $‚âî$ | =x : term= | function def; |
  # |          |     | =x = term= |               |

  Below we present two schemes of function definitions:
  #+begin_example
  x : T
  x = A

  y : T'
  y = A'
  #+end_example
  The above code should read as: The identifier =x= is bound to =A=, which is a
  term of type =T=. Likewise, the identifier =y= is bound to =A'= which is a
  term of type =T'=.

  Note that =A : T= and =A' : T'= must be valid according to the typing rules
  (see Section [[sec:typing-rules]]).

  When we deal with two terms =A= and =T= which are related by the typing
  relation =A : T= we will use the word =term= for =A= and the word =type= for
  =T=. {{{jan(This should probably be stated in the section before. WIP)}}}

  Function definitions are evaluated in order, thus, in =T'= and in =A'= we can
  refer to =x=. However, neither in =A= or =T= we can refer to =y=.

  Recursive references are allowed in the term, thus we can refer to =x= in =A=.
  Likewise we can refer to =y= in =A'=.

  Also note that we cannot bind the same identifier twice.
  {{{enddef}}}

  {{{begindef}}} <<def:agda-constructor>> <<def:agda-datatype>> *Datatype
  definition*. Datatype definitions are used to introduce new terms/types to the
  language. We call datatypes the types which have been defined using a datatype
  definition. For instance, we would use a datatype definition to define a type
  representing the natural numbers.

  The general form of the definition of a datatype =D= is the following:
  #+begin_example
    data D (x‚ÇÅ : P‚ÇÅ) ‚Ä¶ (x‚Çñ : P‚Çñ) : (y‚ÇÅ : Q‚ÇÅ) ‚Üí ‚Ä¶ ‚Üí (y‚Çó : Q‚Çó) ‚Üí Set ‚Ñì where
      c‚ÇÅ : T‚ÇÅ
      ‚Ä¶
      c‚Çô : T‚Çô
    #+end_example
  Note that $k‚â•0$, $l‚â•0$ and $n‚â•0$.
  We distinguish the following parts of the declaration:
  1. /Name/. =D= is an identifier, which is the name of the newly introduced
     datatype. =D= is assigned the following type and is brought into scope:
     #+begin_example
     (x‚ÇÅ : P‚ÇÅ) ‚Üí ‚Ä¶ ‚Üí (x‚Çñ : P‚Çñ) ‚Üí (y‚ÇÅ : Q‚ÇÅ) ‚Üí ‚Ä¶ ‚Üí (y‚Çó : Q‚Çó) ‚Üí Set ‚Ñì
     #+end_example
     By bringing =D= into scope we mean that =D= can be referenced in the
     constructor types =T‚ÇÅ=, ‚Ä¶, =T‚Çô=, also in subsequent datatypes definitions
     and in terms defined after the definition of the datatype =D=.
  2. /Indices/. =(y‚ÇÅ : Q‚ÇÅ) ‚Ä¶ (y‚Çó : Q‚Çó)= are the indices of the datatype. For any
     $i‚àà\{1,‚Ä¶,l\}$ we have that:
     1. =y·µ¢= is an identifier with associated type =Q·µ¢=;
     2. the type =Q·µ¢= can reference =x‚±º= for any $j‚àà\{1,‚Ä¶,k\}$;
     3. if $i>1$ we have that the type =Q·µ¢= can reference any =y‚±º= for $j<i$.
  3. /Parameters/. =(x‚ÇÅ : P‚ÇÅ) ‚Ä¶ (x‚Çñ : P‚Çñ)= are the parameters of the datatype.
     For every $i‚àà\{1,‚Ä¶,k\}$ we have that:
     1. =x·µ¢= is an identifier with associated
        type =P·µ¢=;
     2. if $i>1$ we have that the type =P·µ¢= can reference any =x‚±º= for $j<i$.
  4. /Constructors/. =c‚ÇÅ ‚Ä¶ c‚Çô= are identifiers, which we call the constructors
     of the datatype. For every $i‚àà\{1,‚Ä¶,n\}$ we have that:
     1. =T·µ¢= is the type of the constructor =c·µ¢=.
     2. =T·µ¢= has to be of the form
       #+begin_example
       (z‚ÇÅ : B‚ÇÅ) ‚Üí ... ‚Üí (z‚Çò : B‚Çò) ‚Üí D x‚ÇÅ ‚Ä¶ x‚Çñ t‚ÇÅ ‚Ä¶ t‚Çó
     #+end_example
        Where for every $i‚àà\{1,‚Ä¶,l\}$ we have that =t·µ¢ : Q·µ¢=, furthermore =t·µ¢=
        can refer to =z‚±º= for any $j‚àà\{1,‚Ä¶,m\}$.

        If we focus on the return type[fn::The rightmost term which is not a
        function type.] of =c·µ¢=, namely =D x‚ÇÅ ‚Ä¶ x‚Çñ t‚ÇÅ ‚Ä¶ t‚Çó=, we see that the
        first $k$ arguments to =D= are required to be precisely the parameters
        of =D=, while the remaining $l$ arguments, the indices, can be any terms
        =t‚ÇÅ=, ‚Ä¶, =t‚Çó= of type =Q‚ÇÅ=, ‚Ä¶, =Q‚Çó= respectively and may vary for each
        constructor. For that reason, we say that parameters are shared among
        all constructors, while indices are specified on a constructor basis.
        Refer to Section [[sec:agda-ref-datatype]] for a meaningful example.

     The following is fundamental: the only way to build a term of type =D x‚ÇÅ ‚Ä¶
     x‚Çñ t‚ÇÅ ‚Ä¶ t‚Çó= is to build a term of the form =c·µ¢ w‚ÇÅ ... w‚Çò=, for some
     $i‚àà\{1,‚Ä¶,n\}$, assuming =c·µ¢= is declared to have the type =(z‚ÇÅ : B‚ÇÅ) ‚Üí ...
     ‚Üí (z‚Çò : B‚Çò) ‚Üí D x‚ÇÅ ‚Ä¶ x‚Çñ t‚ÇÅ ‚Ä¶ t‚Çó= and =w‚ÇÅ=, ... =w‚Çò= are terms of type =B‚ÇÅ=,
     ... =B‚Çò= respectively.

     There are no datatypes or constructors which are inherent to the language,
     thus, every datatype and constructor will be defined by the user in a
     datatype definition.
  {{{enddef}}}

  {{{begindef}}} <<def:agda-pattern>> *Pattern*. A pattern is recursively
  defined as follows. We use =p‚ÇÅ,= ‚Ä¶, =p‚Çô= to denote patterns.
  #+name: fig:agda-pattern
  #+attr_latex: :align llll :float t :center t :placement [H]
  | $pattern$ | $‚âî$   | =c p‚ÇÅ ‚Ä¶ p‚Çô= | constructor of arity =n ‚â• 0=; |
  |           | \vert | =x=         | identifier.                   |
  A pattern cannot contain repeated identifiers. We define $ids(p)$ to be the
  set of identifiers that appear in a pattern.

  Note that patterns of the form =c p‚ÇÅ ‚Ä¶ p‚Çô= for $n‚â•1$ must be surrounded by
  parentheses. {{{enddef}}}

  {{{begindef}}} *Module*. A module is a sequence of function definitions and
  datatype definitions. Each function definition exposes the bound identifier to
  the subsequent definitions. Each datatype definition exposes the name of the
  datatype and its constructors to the subsequent definitions.

  #+name: fig:agda-module
  #+attr_latex: :align llll :float t :center t :placement [H]
  | $module$ | $‚âî$   | =fundef ‚Üµ module=  | function definition; |
  |          | \vert | =datadef ‚Üµ module= | datatype definition; |
  |          | \vert |                    | empty.               |
  The =‚Üµ= symbol represents a line break.


  An example module which contains a definition of the =Bool=
  datatype and the =not= function:
  #+begin_example
    data Bool : Set 0 where
      true : Bool
      false : Bool

    not : (b : Bool) ‚Üí Bool
    not = Œª { false ‚Üí true; true ‚Üí false}
  #+end_example
  {{{enddef}}}

  # {{{begindef}}} *Well-scoped term*. A well-scoped term is a term where every
  # identifier in it is bound. In other words, there are no free identifiers.

  # The set of free identifiers is defined as usual (following the syntax defined
  # in Definition [[def:agda-term]]):
  # \begin{flalign*}
  # &free(x) ‚âî ‚àÖ  &\text{if identifier $x$ is bound.} \\
  # &free(x) ‚âî \{x\} &\text{otherwise.}  \\
  # &free(Œªx‚ÜíA) ‚âî free(A)‚àñ\{x\}  \\
  # &free(Œª\ \{\ p‚ÇÅ‚ÜíA‚ÇÅ;\ ‚Ä¶;\ p‚Çô‚ÜíA‚Çô\}) ‚âî ‚ãÉ_{i}\Big(free(A·µ¢)‚àñids(p·µ¢)\Big)  \\
  # &free(A\ B) ‚âî free(A)‚à™free(B)  \\
  # &free(Set\ i) ‚âî ‚àÖ  \\
  # \end{flalign*}

  # We always assume terms to be well-scoped.
  # {{{enddef}}}

*** Contexts, and typing rules
    <<sec:typing-rules>>

    {{{begindef}}} *Context*. A context is a pair of (finite) sets $‚ü®Œ§,Œî‚ü©$. The
    set $Œ§$ consists of pairs $‚ü®identifier:type‚ü©$. It is used to keep track of
    what identifiers are bound and what is their type. The set $Œî$ consists of
    pairs $‚ü®identifier=term‚ü©$ which are the identifiers which have been assigned
    a term through a function definition.

    In order to simplify things we assume that there is no /shadowing/, which
    means that an identifier which is already bound in the current context
    cannot be bound again. Thus, the term =Œª x ‚Üí Œª x ‚Üí x= would be invalidated
    by this assumption since the identifier =x= is rebound by the second lambda
    function. This restriction is not a limiting as we can always rename our
    identifiers to De Bruijn indices (cite:de1972lambda), which guarantee this
    assumption.

    *Notation*. We refer to contexts by a single letter, thus if $Œì=‚ü®Œ§,Œî‚ü©$ we
    abuse notation and write $a:t‚ààŒì$ instead of $‚ü®a:t‚ü©‚ààŒ§$ and $a=t‚ààŒì$ instead of
    $‚ü®a=t‚ü©‚ààŒî$. Also, we use $Œì;t:A$ as short for $‚ü®Œ§ ‚à™\{‚ü®t:A‚ü©\},Œî‚ü©$.
    {{{enddef}}}

    {{{begindef}}} <<def:agda-well-typed>> *Well-typed term (and patterns)*. We
    say that a term $t$ is well-typed in context $Œì$ if $Œì‚ä¢t:A$ for some type
    $A$. The rules for $‚ä¢$ are presented below. We also define the relation
    $‚ä¢_{Œ°}$, which is for typing patterns. For that purpose we need an auxiliary
    function definition, $œÑ$, which is defined afterwards.

    The structure of a module implicitly assigns a context to each term in it.
    We usually use the concept of well-typed term in the context of a module, in
    that case, we implicitly refer to the context assigned by the structure of
    the module. See Definition [[def:agda-check-module]] for a thorough explanation.
    {{{enddef}}}

   #+caption: Typing rules for terms.
   #+name: fig:type
   #+attr_latex: :float
   \begin{figure}[H]
   \begin{mathpar}
   \inferrule[Id]{t : A ‚àà Œì}{Œì ‚ä¢ t : A}
   \and
   \inferrule[Level]{\ }{Œì‚ä¢Set\ i : Set\ (i+1)}
   \and
   \inferrule[Arrow]{Œì ‚ä¢ A:Set\ i \\ Œì; x:A ‚ä¢ B : Set\ j}{Œì ‚ä¢ (x:A)‚ÜíB:Set\ (i‚äîj)}
   \\
   \inferrule[Abstraction]{x:A; Œì ‚ä¢ t:B }{Œì‚ä¢Œªx‚Üít:(x:A)‚ÜíB}
   \and
   \inferrule[Application]{Œì‚ä¢f:(x:A)‚ÜíB \\ Œì‚ä¢a:A }{Œì‚ä¢f\ a : B[x‚Ü¶t]}
   \\
   \inferrule[Pattern abstraction]{\text{Let } \overline{D}‚âîD\ x‚ÇÅ\ ‚Ä¶\ x‚Çô\ t‚ÇÅ\ ‚Ä¶\ t‚Çô \\\\
     Œì‚ä¢_{Œ°}p‚ÇÅ:\overline{D} \\ ‚Ä¶ \\  Œì‚ä¢_{Œ°}p‚Çô:\overline{D} \\\\
     Œì‚à™œÑ(Œì,\overline{D},p‚ÇÅ)‚ä¢ s‚ÇÅ:B[x‚Ü¶p‚ÇÅ] \\ ‚Ä¶ \\ Œì‚à™œÑ(Œì,\overline{D},p‚Çô)‚ä¢ s‚Çô:B[x‚Ü¶p‚Çô]}
     {Œì‚ä¢Œª\ \{p‚ÇÅ ‚Üís‚ÇÅ;\ ‚Ä¶\ ;\ p‚Çô‚Üís‚Çô\}:(x:\overline{D})‚ÜíB}
   \end{mathpar}
   \end{figure}

   #+caption: Typing rules for patterns.
   #+name: fig:pat-type-rules
   #+attr_latex: :float
   \begin{figure}[H]
   \begin{mathpar}
   \inferrule[Identifier]{\ }{Œì‚ä¢_{Œ°}x : A}
   \\
   \inferrule[Constructor]{c:(b‚ÇÅ:B‚ÇÅ)‚Üí‚Ä¶‚Üí(b‚Çô:B‚Çô)‚ÜíD\ x‚ÇÅ\ ‚Ä¶\ x‚Çô\ t‚ÇÅ\ ‚Ä¶\ t‚Çô ‚ààŒì \\\\
     ‚àÄi‚àà\{1,‚Ä¶,n-1\}.\ Œì‚ä¢_Œ°p·µ¢:B·µ¢[b‚ÇÅ‚Ü¶p‚ÇÅ, ‚Ä¶,b_{i-1}‚Ü¶p_{i-1}]   }{Œì‚ä¢_Œ°c\ p‚ÇÅ\ ‚Ä¶\ p‚Çô : D\ x‚ÇÅ\ ‚Ä¶\ x‚Çô\ t‚ÇÅ\ ‚Ä¶\ t‚Çô}
   \end{mathpar}
   \end{figure}
   {{{jan(explain $[b‚ÇÅ‚Ü¶p‚ÇÅ]$)}}}

   Let $\overline{D}‚âîD\ x‚ÇÅ\ ‚Ä¶\ x‚Çô\ t‚ÇÅ\ ‚Ä¶\ t‚Çô$. We now define
   $œÑ(Œì,\overline{D},p)$, which is the set of identifiers bound by pattern $p$
   paired with their respective types. Assume that $Œì‚ä¢_{Œ°}p:\overline{D}$.
   Finally, let $œÑ$ be defined as follows:
  \begin{flalign*}
  &œÑ(Œì,\overline{D},x)‚âî \{x:\overline{D}\} & \text{Identifier} \\
  &œÑ(Œì,\overline{D},c\ p‚ÇÅ\ ‚Ä¶\ p‚Çô)‚âî œÑ(Œì,p‚ÇÅ,B‚ÇÅ)‚à™‚Ä¶‚à™œÑ(Œì,p‚Çô,B‚Çô) & \text{Constructor} \\
  &\hspace{3.5cm} \text{assuming } c:(b‚ÇÅ:B‚ÇÅ)‚Üí‚Ä¶‚Üí(b‚Çô:B‚Çô)‚Üí\overline{D}‚ààŒì
  \end{flalign*}

  # The precise typing rule for the lambda abstraction with patterns falls out
  # of the scope of this thesis. We ask the reader to refer to Chapter 2 of
  # cite:norell:thesis for that purpose. Here we present a simplification.
  # {{{jan(pending.)}}}

  {{{begindef}}} <<def:agda-check-module>> *Scoping and type checking a module*.
  We understand by /scoping/ the process of implicitly assigning a context to
  each part of the module. We understand by /type checking/ the process of
  checking that all terms in a module are well-typed (in their corresponding
  context) and respect the typing annotations. These processes are tightly tied
  and thus we describe them together.

    # By respecting the
    # typing annotations we mean that if we have the following definition:
    # #+begin_example
    # x : A
    # x = t
    # #+end_example
    # Then we need check that =t= is well-typed and furthermore has type =A=.

    It may be worth noticing that sometimes the annotation =x : A= may be
    redundant since the type of =t= can be automatically inferred to be =A= from
    the rules. Type inference is widely used in the real Agda language, however,
    in this presentation we skip it for simplicity. We lightly touch the topic in
    section {{{jan(???)}}}.

    However, for simplicity we do not differentiate between type inference
    and type checking. assume that the annotation is always required.

    The process of type-checking a module is as follows:
    1. At the beginning of a module we start with an empty context $Œì ‚âî ‚àÖ$.
    2. We look at the next definition.
       - If it is a *function definition*, it is of the form
         #+begin_example
         x : A
         x = t
         #+end_example
         Check there is some $‚Ñì$ such that $Œì‚ä¢A:Set\ ‚Ñì$. Then let $Œì'‚âîŒì;x:A$
         and check $Œì'‚ä¢t:A$.

         We repeat step 2 with context $Œì'$.
       - If it is a *datatype definition*, it is the form
           #+begin_example
       data D (x‚ÇÅ : P‚ÇÅ) ‚Ä¶ (x‚Çñ : P‚Çñ) : (y‚ÇÅ : Q‚ÇÅ) ‚Üí ‚Ä¶ ‚Üí (y‚Çó : Q‚Çó) ‚Üí Set ‚Ñì where
         c‚ÇÅ : T‚ÇÅ
         ‚Ä¶
         c‚Çô : T‚Çô
           #+end_example
           where each =T·µ¢= is of the form
           #+begin_example
           (z‚ÇÅ : B‚ÇÅ) ‚Üí ‚Ä¶ ‚Üí (z‚Çò : B‚Çò) ‚Üí D x‚ÇÅ ‚Ä¶ x‚Çñ t‚ÇÅ ‚Ä¶ t‚Çó
         #+end_example

         We check that:
         1. For each parameter =x·µ¢ : P·µ¢= check that for some $Œµ‚â§‚Ñì$ we have
            \[Œì;x‚ÇÅ:P‚ÇÅ;‚Ä¶;x_{i-1}:P_{i-1}‚ä¢P·µ¢:Set\ Œµ.\]
         2. Then let
            \begin{flalign*}
             Œì'‚âî&Œì;x‚ÇÅ : P‚ÇÅ; ‚Ä¶; x‚Çñ : P‚Çñ; \\
               &D : (x‚ÇÅ : P‚ÇÅ) ‚Üí ‚Ä¶ ‚Üí (x‚Çñ : P‚Çñ) ‚Üí (y‚ÇÅ : Q‚ÇÅ) ‚Üí ‚Ä¶ ‚Üí (y‚Çó :
              Q‚Çó) ‚Üí Set\ ‚Ñì.
            \end{flalign*}
             # \[Œì'‚âîŒì;x‚ÇÅ : P‚ÇÅ; ‚Ä¶; x‚Çñ : P‚Çñ;D : (x‚ÇÅ : P‚ÇÅ) ‚Üí ‚Ä¶ ‚Üí (x‚Çñ : P‚Çñ) ‚Üí (y‚ÇÅ : Q‚ÇÅ) ‚Üí ‚Ä¶ ‚Üí (y‚Çó :
             #  Q‚Çó) ‚Üí Set\ ‚Ñì. \]
            For each $i‚àà\{1,‚Ä¶,n\}$ check that
            \[Œì'‚ä¢ (z‚ÇÅ : B‚ÇÅ) ‚Üí ‚Ä¶ ‚Üí (z‚Çò : B‚Çò) ‚Üí D\ x‚ÇÅ\ ‚Ä¶\ x‚Çñ\ t‚ÇÅ\ ‚Ä¶\ t‚Çó : Set\ ‚Ñì.\]
            # #+begin_example
            # c·µ¢ : (z‚ÇÅ : B‚ÇÅ) ‚Üí ‚Ä¶ ‚Üí (z‚Çò : B‚Çò) ‚Üí D x‚ÇÅ ‚Ä¶ x‚Çñ t‚ÇÅ ‚Ä¶ t‚Çó
            # #+end_example
            #  We check that for all
            # $j‚àà\{1,‚Ä¶,m\}$ there is some $Œµ‚â§‚Ñì$ such that
            # \[Œì';x‚ÇÅ:P‚ÇÅ;‚Ä¶;x_{k}:P_{k}‚ä¢B_j :Set\ Œµ.\] Furthermore, for all
            # $j‚àà\{1,‚Ä¶,l\}$ we check that
            # \[Œì';x‚ÇÅ:P‚ÇÅ;‚Ä¶;x_{k}:P_{k};z‚ÇÅ:B‚ÇÅ;‚Ä¶;z‚Çò:B‚Çò;t‚ÇÅ:Q‚ÇÅ;‚Ä¶;t_{j-1}:Q_{j-1}‚ä¢
            # t‚±º:Q‚±º. \]
            Then let
            \begin{flalign*}
             Œì''‚âî&Œì;\\
              &D : (x‚ÇÅ : P‚ÇÅ) ‚Üí ‚Ä¶ ‚Üí (x‚Çñ : P‚Çñ) ‚Üí (y‚ÇÅ : Q‚ÇÅ) ‚Üí ‚Ä¶ ‚Üí (y‚Çó :
              Q‚Çó) ‚Üí Set\ ‚Ñì; \\
              &c‚ÇÅ : (z^1‚ÇÅ : B^1‚ÇÅ) ‚Üí ‚Ä¶ ‚Üí (z^1‚Çò : B^1‚Çò) ‚Üí D\ x‚ÇÅ\ ‚Ä¶\ x‚Çñ\ t^1‚ÇÅ\ ‚Ä¶\ t^1‚Çó; \\
              & ‚ãÆ \\
              &c‚Çô : (z^n‚ÇÅ : B^n‚ÇÅ) ‚Üí ‚Ä¶ ‚Üí (z^n‚Çò : B^n‚Çò) ‚Üí D\ x‚ÇÅ\ ‚Ä¶\ x‚Çñ\ t^n‚ÇÅ\ ‚Ä¶\ t^n‚Çó
            \end{flalign*}
            and continue to step 2 with context $Œì''$.
    {{{enddef}}}
*** Normalization
    <<sec:agda-normalization>> Normalization is refers to the process of
    simplifying or evaluating a term via rewrite rules.

    In real Agda normalization is done at the same time as type-checking via an
    involved algorithm (see Section 3.3.2 of cite:norell:thesis). Here we
    present a collection normalization rules which are detached from the
    type-checking process. Our aim is to provide an intuition of how well-typed
    terms are simplified automatically in Agda rather than giving details of the
    algorithm.

    The reader may be already acquainted with the \textsc{$Œ≤$-reduction} rule,
    which is present in untyped lambda calculus, the most basic form of lambda
    calculus. Here we present the mentioned rule among others. We use the
    notation $Œî‚ä¢_Nt‚Üìt'$ to say that term $t$ normalizes to term $t'$ in context
    $Œî$. We extend the definition of context to also contain all the pairs
    $‚ü®identifier=term‚ü©$ which are defined in a function definition above in the
    module. To be more precise, now a context consists of two sets: One contains
    the typing relations $‚ü®identifier:term‚ü©$ and the other contains the binding
    relations $‚ü®identifier=term‚ü©$.

    Normalization can happen in nested terms. For instance, if we have that
    $t‚Üìt'$ then $Œª x‚Üí t‚ÜìŒªx‚Üít'$. Likewise for the other kinds of terms.

    In the rule \textsc{Match} we use the notation $‚àÉ^{min}i$ to mean that in
    case there exist multiple values for $i$ such that the function
    $match(p·µ¢,b)$ succeeds and returns a substitution $œÉ$, then we must take the
    minimum of such \text{$i$s}. In other words, we check patterns in order and
    we use the first that succeeds.

    We use $a,b,c,t$ to denote arbitrary terms and $x,f$ to denote arbitrary
    identifiers.
   #+caption: Normalization rules for terms.
   #+name: fig:normalization
   #+attr_latex: :float
    \begin{figure}[H]
    \begin{mathpar}
    \inferrule[$Œ≤$-reduction]{\ }{Œî‚ä¢_N(Œª x ‚Üí t)\ a‚Üìt[x‚Ü¶a] } \and
    \inferrule[Transitivity]{Œî‚ä¢_Na‚Üìb \\ Œî‚ä¢_Nb‚Üìc }{Œî‚ä¢_Na‚Üìc} \and
    \inferrule[Definition]{f=t‚ààŒî  }{Œî‚ä¢_Nf‚Üìt}
    \\
    \inferrule[Match]{Œî‚ä¢_Na‚Üìb \\ ‚àÉ^{min}i.match(p·µ¢,b)=œÉ  }{Œî‚ä¢_NŒª\ \{p‚ÇÅ‚Üít‚ÇÅ;‚Ä¶;p‚Çô‚Üít‚Çô\}\ a‚ÜìœÉ(t·µ¢)}
    \end{mathpar}
    \end{figure}

    Here we define the partial function $match$, which takes a pattern and a
    term, then either fails or returns a substitution. We represent a substitution
    by a set of pairs of the form $‚ü®x‚Ü¶t‚ü©$, which means ``replace identifier $x$
    by term $t$''. Keep in mind that a pattern does not contain repeated
    identifiers, so the result (if it succeeds) of $match$ is a proper function.
    \begin{flalign*}
    &match(x, t)‚âî \{‚ü®x‚Ü¶t‚ü©\} \\
    &match(c\ p‚ÇÅ\ ‚Ä¶\ p‚Çô, c'\ t‚ÇÅ\ ‚Ä¶\ t‚Çô)‚âî \begin{cases}
             ‚ãÉ_i(match(p·µ¢,t·µ¢)) & \text{if $c=c'$ and all recursive calls succed;}  \\
             \text{fail} & \text{otherwise.}\end{cases}
    \end{flalign*}

    Some examples for the \textsc{$Œ≤$-reduction} rule:
    \begin{flalign*}
    &Œª y ‚Üí (Œªx‚Üíx)\ y ‚Üì Œª y ‚Üí y & \\
    &(Œªx‚Üíx)\ a ‚Üì a &
    \end{flalign*}
    To see examples for the \textsc{Match} rule assume we have the following
    definition in scope:
    #+begin_example
    data Nat : Set 0 where
      zero : Nat
      suc : Nat ‚Üí Nat

    plus : Nat ‚Üí Nat ‚Üí Nat
    plus = Œª { zero ‚Üí (Œª b ‚Üí b); (suc a) ‚Üí (Œª b ‚Üí suc (plus a b) ) }
    #+end_example
    Then see that the term =plus zero= normalizes to the identity function:
    \begin{flalign*}
    &plus\ zero‚ÜìŒª b ‚Üí b &
    \end{flalign*}

    As another example, see that the term =plus (suc zero)= normalizes to =Œª b ‚Üí
    suc b=. We present this example step by step.
    \begin{flalign*}
    plus\ (suc\ zero)&‚Üì &\textsc{Def}
    \\ Œª\ \{ zero ‚Üí (Œª b ‚Üí b);\ (suc\ a) ‚Üí (Œª b ‚Üí suc\ (plus\ a\ b) )\}\ (suc\ zero)& ‚Üì & \textsc{Match}
    \\ Œª b ‚Üí suc\ (plus\ zero\ b) &‚Üì & \textsc{Def}
    \\ Œª b ‚Üí suc\ ((Œª b' ‚Üí b')\ b) &‚Üì &\textsc{$Œ≤$-reduction}
    \\ Œª b ‚Üí suc\ b
    \end{flalign*}


    {{{begintheorem}}}
    Normalization is type-preserving.
    \begin{figure}[H]
    \begin{mathpar}
    \inferrule[]{Œì‚ä¢_N t‚Üìt' \\ Œì‚ä¢t:A }{Œì‚ä¢t':A }
    \end{mathpar}
    \end{figure}
    {{{endtheorem}}}
    {{{beginproof}}}
    By an easy proof by induction.
    {{{endproof}}}

*** Totality
    <<sec:agda-totality>>
    In order to be a sound system, Agda requires all of its terms to be
    total. Thus, it needs to assure that:
    1. Every lambda abstraction with pattern matching of the form =Œª {p‚ÇÅ ‚Üí A‚ÇÅ; ‚Ä¶
       ; p‚Çô ‚Üí A‚Çô}= must have a set of exhaustive patterns =p‚ÇÅ=, ‚Ä¶, =p‚Çô=. For
       instance if we have the following:
       #+begin_example
       data Bool : Set 0 where
         true : Bool
         false : Bool

       wrong : (b : Bool) ‚Üí Bool
       wrong = Œª { true ‚Üí true }
       #+end_example
       Then the definition of =wrong= is rejected since it does not have the
       =false= pattern. The coverage algorithm (the algorithm which checks
       the exhaustivity of patterns) is described in
       cite:norell:thesis.
    2. There are no infinite loops. For instance
       #+begin_example
       loop : (A : Set 0) ‚Üí A
       loop = Œª A ‚Üí loop A
       #+end_example
       In order to do so Agda analyses every recursive call and tries to find a
       well-founded order on its arguments. If it succeeds the recursive call is
       considered save, otherwise it is rejected. The Agda online documentation
       (cite:agda-doc) references cite:abel1998foetus as the basis of the
       termination checker implemented in Agda. For instance, the checker is
       sophisticated enough to accept the definition of the Ackermann function
       (cite:agda-doc), which is non-primitive recursive.

*** Limitations
    <<sec:agda-limitations>>
    As mentioned at the beginning of this section we did not give a complete
    presentation of the language due to its complexity. Moreover, we had to
    simplify some of the concepts presented. Here we comment on those
    simplifications.

**** Pattern matching on indexed datatypes
     The typing rules given in section [[sec:typing-rules]] are not enough to
     sensibly deal with datatypes which have indices.

     Consider the following example:
     #+begin_example
     data Bool : Set 0 where
       true : Bool
       false : Bool

     data IsTrue : (b : Bool) ‚Üí Set 0 where
       is-true : IsTrue true

     data IsFalse : (b : Bool) ‚Üí Set 0 where
       is-false : IsFalse false

     not : (b : Bool) ‚Üí Bool
     not = Œª {true ‚Üí false; false ‚Üí true}
     #+end_example
     We see that we have the usual definition of =Bool=. We also an indexed
     datatype called =IsTrue=. Observe that it has a single constructor called
     =is-true= which gives a term of type =IsTrue true=. Since =is-true= is
     the only constructor it is impossible to build a term of type =IsTrue
     false=. After this we have a dual definition called =IsFalse=. Then we have
     the definition of the =not= function with the expected definition.

     We expect that we should be able to prove that if have a term =b : Bool=
     and a term of type =IsTrue b= we should be able to give a term of type
     =IsFalse (not b)=. We represent this property with the following type:
     #+begin_example
     property : (b : Bool) ‚Üí (p : IsTrue b) ‚Üí IsFalse (not b)
     #+end_example
     Providing a term of this type can be done in real Agda as follows:
     #+begin_example
     property : (b : Bool) ‚Üí (p : IsTrue b) ‚Üí IsFalse (not b)
     property = Œª b ‚Üí Œª { is-true ‚Üí is-false }
     #+end_example
     Unfortunately, giving a term of this type is not possible with the typing
     rules that we gave. To see this, consider the context $Œì$ at the =?= site
     below.
     #+begin_example
     property : (b : Bool) ‚Üí (p : IsTrue b) ‚Üí IsFalse (not b)
     property = Œª b ‚Üí Œª p ‚Üí ?
     #+end_example
     We have $b:Bool‚ààŒì$ and $p : IsTrue\ b ‚ààŒì$. We can try to pattern match on
     =b=.
     #+begin_example
     property : (b : Bool) ‚Üí (p : IsTrue b) ‚Üí IsFalse (not b)
     property = Œª {true ‚Üí Œª pt ‚Üí is-false; false ‚Üí Œª pf ‚Üí ? }
     #+end_example
     Filling in the case where =b= is equal to =true= is straightforward because
     here the goal is to provide a term of type =IsFalse (not true)=, which
     normalizes to =IsFalse false=, therefore we can use the term =is-false=.
     The conflicting case is when =b= is equal to false. See that in this case
     we have that =pf= has type =IsTrue false=. Clearly we should be able to
     somehow derive a contradiction from this, because it is impossible that a
     term of this type exists. Agda deals with contradictions with absurd
     patterns, which are discussed in the next section.

     Another possibility to tackle the previous problem is to pattern match on
     =p= as we did in real Agda:
     #+begin_example
     property : (b : Bool) ‚Üí (p : IsTrue b) ‚Üí IsFalse (not b)
     property = Œª b ‚Üí Œª { is-true ‚Üí ? }
     #+end_example

     {{{jan(move this comment?)}}}
     See the Chapter 2 of cite:norell:thesis for an overview of how pattern
     matching works in real Agda, including the unification algorithm.

**** Absurd patterns
**** Unreachable patterns
**** Universes
*** Syntax sugar

** Agda tutorial
*** BHK interpretation of propositional logic
   Agda is based on an intuitionistic type theory with dependent types that
   extends Per Martin-L√∂f's type theory (cite:martin1984intuitionistic).
   {{{joost(Really\, who are you writing for? I guess we can assume that all
   professor (and thus\, intended readers) know what intuitionistic logic is.
   However\, ML type theory and dependent types need explanation. So this sentence
   is in need of some more context\, pointers and or explanation.)}}} Agda's
   constructive nature suggests that a fitting way start the introduction is
   through the BHK interpretation of intuitionistic logic
   (cite:sep-intuitionistic-logic-development). We start with propositional logic
   and later on (Section [[sec:bhk-fol]]) we continue with first order logic.

   The BHK interpretation states that:
   1. A proof of $A‚ÜíB$ is an algorithm that transforms an arbitrary proof of $A$
      into a proof of $B$;
   2. A proof of $A‚àßB$ is a proof of $A$ and a proof of $B$;
   3. A proof of $A‚à®B$ is an algorithm telling to which of $A$ or $B$ we commit to
      and according to that, a proof of $A$ or a proof of $B$;
   4. Nothing is a proof of $‚ä•$;
   5. $‚ä§$ is always true and provable.

   According to the BHK interpretation a proof of $A‚ÜíA$ is an algorithm
   implementing the identity function. We can express this algorithm in Agda by
   writing the identity lambda term {{{joost(So this is exactly why one
   other student missed a lot of points. I know that the formal language of Agda
   (what is that called?) is very extensive. However\, you should formally specify
   your language or at least chunks of it. What are your symbols\, constructors\,
   etc. Reading conventions\, etc. It is BAD PRACTICE to have the reader distil
   this from the practice\, text\, examples and context. I know many introductions
   to type theory and proof assistants get this actually wrong. Please\, be more
   precise and formal. Part of your assignment is showing that you have learned
   this competence in our master. What are the terms? How are they inductively
   defined? What is your alphabet\, etc.)}}}:
   #+begin_src text
   Œª a ‚Üí a
   #+end_src
   {{{joost(full stop?)}}} {{{jan(I prefer not to put stops since they are not
   part of Agda's syntax and it may be confusing to insert them.)}}} See that we
   use the structure =Œª arg‚ÇÅ arg‚ÇÇ ‚Ä¶ ‚Üí term= to define lambda functions. The
   previous term is valid. However, in Agda we must give a name to all the terms
   that we define so we can refer to them in other parts of our code. We will
   name our term =id=:
   #+begin_src text
   id = Œª a ‚Üí a
   #+end_src
   When the term that we are defining is a lambda term, we are allowed to move
   the arguments to the left of the === sign. Furthermore, we should write the
   type {{{joost(what are types? Where do they historically come from? How are
   types defined in Agda? Again\, provide a formal definition of correct
   types)}}} of the function using the =:= symbol. The =:= symbol denotes the
   typing relation{{{joost(a relation between wellformed types and wellformed
   terms?)}}}, hence =a : A= reads as ``term =a= has type =A=''. Sometimes we
   also say that ``the term =a= is a proof of =A=''.
   #+begin_src text
   id : A ‚Üí A
   id a = a
   #+end_src
   {{{joost(How to parse the last line? Maybe say that we write ‚Äùid a‚Äù instead of
   id(a) and that function application goes before =. Do we have both
   term-equality and type equality? What about equality?)}}} The previous
   function is only valid if the type =A= has been defined. Since our intention
   is that it {{{joost(what?)}}} should work for any type, we should rewrite it
   to be polymorphic {{{joost(ou cannot expect the reader to know what
   polymorphism is. This should be properly introduced. I would encourage you to
   rethink the setup of this chapter. You will be judged on your ability to apply
   logical techniques to exposing a field and clearly transmit ideas and concepts
   using crystal-clear definitions. Your current exposition is too informal and
   along the way. If I were in the jury ‚Äì which I will‚Äì I would be annoyed by
   it.)}}}. We can do that by declaring a type variable =A=. We can do this by
   adding an extra argument of the form =(A : Set)=. We see that =A= has type
   =Set=, which is the Agda word for type {{{joost(The new reader will be lost
   here. So we have concrete types? And we have type variables of type type? Does
   Set itself have a type? Please\, rethink your presentation.)}}}. Named
   arguments can be referenced in the right part of the =‚Üí=, thus we can write
   {{{joost((mention right-associativity of the arrow (is it called as
   such?)))}}}:
   #+begin_src text
   id : (A : Set) ‚Üí A ‚Üí A
   id A a = a
   #+end_src
   Since the argument named =A= will always be the type of the second argument
   {{{joost(second argument of what? of the polymorphic identity? Will the
   polymorphic version receive the same name?)}}}, we can infer its value and
   thus it is recommended to use an implicit argument (see Section
   [[sec:agda-implicit-args]]).
   #+begin_src text
   id : {A : Set} ‚Üí A ‚Üí A
   id a = a
   #+end_src
   {{{joost(the reader should be dizzy here: we have defined id using a lambda
   term\, then there are some schemes that follow the format (i deduce\, if
   correct this must be made explicit) type declaration\, term definition. Can we
   all give them the same name? Or should we understand that we erase the
   previous definition and replace it with a new one?)}}} With the technicalities
   out of the way, we can finally say that we have completed our first Agda proof
   of $A‚ÜíA$ according to the BHK interpretation by implementing and typing the
   identity function in Agda. {{{joost(What does it mean to have a proof in
   Agda? Note that A to A is a type.... Be precise please. It may be a good place
   to mention the Curry Howard iso? Anyways\, do it in a structured fashion.)}}}

   Let us see another example involving functions[fn::The =‚Üí= function symbol has
   right associativity.].
   #+begin_src text
   commute : {A B C : Set} ‚Üí (A ‚Üí B ‚Üí C) ‚Üí B ‚Üí A ‚Üí C
   commute f b a = f a b
   #+end_src
   We see that =commute= has three arguments, namely =f : A ‚Üí B ‚Üí C=, =b : B= and
   =a : A=. Then in the right hand side of the === sign we have =f a b=, which
   should read as ``term =f= applied to =a= and =b='' {{{joost(It is good to
   recall this and I would leave it here. But, there should be another structure
   of this section. Maybe something like: basic ideas (what are types, terms,
   etc.), syntax, reading conventions (left associativity of application, right
   associativity of implication/abstraction), computation, etc.)}}}. Notice how
   function application is denoted by simple juxtaposition.

   Let us now put our attention on proofs that revolve around conjunction. For
   instance, let us prove that $A‚àß B ‚Üí B ‚àß A$. {{{joost(Again\, you mean ùê¥ ‚àß ùêµ ‚Üí ùêµ
   ‚àß ùê¥ as proposition? Or as type? What does it mean to prove something in
   Agda?)}}} In order to represent $A‚àßB$ in Agda we need to define a so called
   /product type/. A product type is in rough terms the type of a tuple. Consider
   the following pair definition:
   #+begin_src text
 data _√ó_ (A B : Set) : Set where
   _,_ : A ‚Üí B ‚Üí A √ó B
   #+end_src
   {{{joost(Help\, what is this syntax? What is the iterated ‚Äù:‚Äù supposed to
   mean? Is ‚Äùdata‚Äù part of predefined syntax? Or is it a name? What about the
   bars? So\, we are now seeing something new? This is no longer of the format
   ‚Äùtype declaration\, term definition of the corresponding type‚Äù? We are
   defining new types? So this is another functionality of Agda? What of the
   things exposed here form part of the type constructors? We classic logicians
   get lost by so much computer science implicitness.)}}} This definition defines
   a new datatype {{{joost(help\, Help\, HELP\, HEEEELLP!!!!! All of a sudden
   there are datatypes? So\, they are different from types?)}}}called =_√ó_= with
   parameters =(A B : Set)=. Datatypes with parameters are called parameterized
   datatypes. Parameters are shared among all constructors {{{joost(What does
   this sentence mean?)}}} . It has a single constructor named =_,_=. Underscores
   are used to denote infix operators. We see that the type of the constructor
   =_,_= is =A ‚Üí B ‚Üí A √ó B=. {{{joost(So underscore times underscore A B is the
   same as A times B?)}}} This tells us that =_,_= is a constructor that takes an
   argument of type =A= (or a proof of =A=), an argument of type =B= and then
   returns a term of type =A √ó B=. A constructor is a special kind of function
   {{{joost(from types to types?)}}} that is used to build terms of their
   corresponding datatype. When we /pattern match/ (or deconstruct) a term we
   will have a case for each possible constructor of the type of that term.

   Let us give a proof of the theorem $A‚àß B ‚Üí B ‚àß A$:
   #+begin_src text
   swap : {A B : Set} ‚Üí A √ó B ‚Üí B √ó A
   swap (a , b) = b , a
   #+end_src
   {{{joost(Why are there parenthesis on the left of the equality sign and not on
   the right?)}}} Note that we used pattern matching to deconstruct the term and
   access the components of the pair. For the =_√ó_= type we only have one
   constructor so we only need one case.
   # Refer to Section [[sec:agda-datatype]] for more details on data type definition
   # and pattern matching.

   Let us show some more examples:
   #+begin_src text
   p1 : {A B : Set} ‚Üí A ‚Üí B ‚Üí A √ó B
   p1 a b = a , b

   p2 : {A B : Set} ‚Üí A √ó B ‚Üí A
   p2 (a , b) = a

   p3 : {A B C : Set} ‚Üí (A ‚Üí B ‚Üí C) ‚Üí (A √ó B) ‚Üí C
   p3 f (a , b) = f a b

   p4 : {A B C : Set} ‚Üí ((A √ó B) √ó C) ‚Üí (A √ó (B √ó C))
   p4 ((a , b) , c) = a , (b , c)
   #+end_src
   {{{joost(maybe you can give informative names to the defined terms? Like
   ‚ÄùCurrying‚Äù for p1\, ‚ÄùProjection‚Äù for p2? etc. Why are there parenthesis in p2
   but not in p1? Also\, in p3 and p4 one could have added parenthesis. Say when
   we may omit them.)}}} Now that we are familiarized with conjunction and
   product types we can proceed by exploring disjunction. In order to express
   options we can define a new datatype called sum type thus:
   #+begin_src text
 data _‚äé_ (A B : Set) : Set where
   inj‚ÇÅ : A ‚Üí A ‚äé B
   inj‚ÇÇ : B ‚Üí A ‚äé B
   #+end_src
   We see that the main difference with respect to the pair type is that now we
   have two constructors {{{joost(I think you can somewhere include a general
   discussion on constructors. What are they\, what do they? What is their syntax
   and use?)}}} which we named =inj‚ÇÅ= and =inj‚ÇÇ=. The constructor =inj‚ÇÅ= is used
   to build a proof of =A ‚äé B= by providing a proof of =A=. The constructor
   =inj‚ÇÇ= builds a proof of =A ‚äé B= given a proof of =B=.

   Since we have two constructors, when pattern matching against an argument of
   this type we will need to define two cases (if we want to access its
   contents). See as an example the following theorems {{{joost(theorems? who
   heard theorems? what are theorems?)}}}:
   #+begin_src text
   p1: {A B : Set} ‚Üí A ‚äé B ‚Üí B ‚äé A
   p1 (inj‚ÇÅ a) = inj‚ÇÇ a
   p1 (inj‚ÇÇ b) = inj‚ÇÅ b

   p2 : {A B : Set} ‚Üí A ‚äé B ‚Üí (A ‚Üí C) ‚Üí (B ‚Üí C) ‚Üí C
   p2 (inj‚ÇÅ a) f g = f a
   p2 (inj‚ÇÇ b) f g = g b
   #+end_src
   {{{joost(Note that you have already defined p1 and p2. Are you overwriting
   them?)}}} The reader may have raised the following question in their mind:
   what if we leave out a case for the sum type? {{{joost(What do you mean? In
   defining a term for a non-inhabited type I guess\, but that is not clear from
   what you write.)}}} In other words, is the following definition acceptable?
   #+begin_src text
   wrong : {A B : Set} ‚Üí A ‚äé B ‚Üí A
   wrong : (inj‚ÇÅ a) = a
   #+end_src
   The answer is no. Agda rejects it as it requires all of the definitions to be
   exhaustive, otherwise it would not be a sound system.

   We proceed with $‚ä•$. We can define a datatype which we call /bottom type/ or
   /empty type/.
   #+begin_src text
   data ‚ä• : Set where
   #+end_src
   Notice that =‚ä•= has no constructors and hence it is impossible to construct a
   term with type =‚ä•=. The bottom type is specially useful to define negation,
   which we define in the following way:
   #+begin_src text
   ¬¨ : Set ‚Üí Set
   ¬¨ A = A ‚Üí ‚ä•
   #+end_src
   The principle of explosion {{{joost(Allauakbar\, what is this principle?)}}}
   can be trivially proved as shown below. Agda uses =()= to denote the empty or
   impossible pattern.
   #+begin_src text
   explosion : {A : Set} ‚Üí ‚ä• ‚Üí A
   explosion ()
   #+end_src
   {{{joost(I feel I need some extra explanation here. So explosion () is a term
   of type A. Where is that A reflected in the term? Should explosion not have two
   arguments here?)}}} Since the =‚ä•= type has no constructors, we get the empty
   pattern when pattern matching against the argument of type =‚ä•=.

   As we are in an intuitionistic logic the following properties are not
   provable[fn::See that we use the symbol =¬¨= in the name of the term =¬¨¬¨elim=.
   Here the =¬¨= symbol is just part of the name and serves the same purpose of
   any other character. Hence it is important to note that =¬¨a= (just a name with
   the =¬¨= character) is different from =¬¨ a= (the negation of =a=).]:
   #+begin_src text
   ¬¨¬¨elim : {A : Set} ‚Üí ¬¨ (¬¨ A) ‚Üí A
   ¬¨¬¨elim = ?             -- not provable

   excluded-middle : {A : Set} ‚Üí A ‚äé (¬¨ A)
   excluded-middle = ?    -- not provable
   #+end_src
   However, we can show that $¬¨¬¨¬¨A‚Üí¬¨A$:
   #+begin_src text
   ¬¨¬¨¬¨elim : {A : Set} ‚Üí ¬¨ (¬¨ (¬¨ A)) ‚Üí ¬¨ A
   ¬¨¬¨¬¨elim ¬¨¬¨¬¨a a = ¬¨¬¨¬¨a (Œª ¬¨a ‚Üí ¬¨a a)
   #+end_src
   It might help the reader to see that =¬¨ (¬¨ (¬¨ A)) ‚Üí ¬¨ A = (((A ‚Üí ‚ä•) ‚Üí ‚ä•) ‚Üí ‚ä•)
   ‚Üí A ‚Üí ‚ä•=. {{{joost(Give the reader some more explanation. What is the lambda
   doing there? How does this work? Maybe compare it with a proof in ND (natural
   deduction) of the corresponding proposition?)}}}

   Some more examples:
   #+begin_src text
   p1 : {A B : Set} A ‚Üí ¬¨ A ‚Üí B
   p1 a ¬¨a = explosion (¬¨a a)
   #+end_src
   {{{joost(Are we overwriting p1 again? Again\, how do we see that explosion
   generates something of type B?)}}}

   We finally climb to the $‚ä§$ by defining a datatype which we call the
   /unit type/.
   #+begin_src text
   data ‚ä§ : Set where
     tt : ‚ä§
   #+end_src
   We see that this type has a single constructor (=tt=) with no parameters, hence there
   only exists one term with this type, namely =tt=. Some examples:
   #+begin_src text
   ‚ä§‚ä§ : ‚ä§ √ó ‚ä§
   ‚ä§‚ä§ = tt , tt

   ¬¨¬¨‚ä§ : ¬¨ (¬¨ ‚ä§)
   ¬¨¬¨‚ä§ ¬¨‚ä§ = ¬¨‚ä§ tt
   #+end_src
   {{{joost(What is the purpose of those examples? Make that clear: we prove
   theorems about Top here)}}} This concludes the first part of the introduction.

*** Booleans and case analysis
    <<sec:agda-bool>> The /true or false/ concept is ubiquitous in computer
    science and in logic. In this section we show how we can define a datatype
    that represents this dichotomy and we give a small introduction to
    case analysis through pattern matching.

    In Agda we can define the =Bool= type in a similar fashion to the
    disjunction type we defined before.
    #+begin_src text
    data Bool : Set where
      true : Bool
      false : Bool
    #+end_src
    As a simple example, see how we can define the =not= and =and= Boolean
    operators using pattern matching:
    #+begin_src text
    not : Bool ‚Üí Bool
    not false = true
    not true = false

    and : Bool ‚Üí Bool ‚Üí Bool
    and false b = false
    and true b = b
    #+end_src
    We proceed by defining equality for the =Bool= type[fn::This definition is
    just for illustrative purposes. It is possible to define polymorphic equality
    as described in Section [[sec:agda-equality]].]. We use the symbol
    =‚â°= because === is reserved for Agda.
    #+begin_src text
 data _‚â°_ : Bool ‚Üí Bool ‚Üí Set where
   t‚â°t : true ‚â° true
   f‚â°f : false ‚â° false
    #+end_src
    We see that the type of =_‚â°_= is =Bool ‚Üí Bool ‚Üí Set=. We say that =_‚â°_= is an
    /indexed datatype/, in this case with two =Bool= indices. In contrast to
    parameters (recall the definitions of =_√ó_= and =_‚äé_=) which are shared among
    all constructors, indices are specified on a constructor basis.

    Let us prove the following property:
    #+begin_src text
    notnot : (b : Bool) ‚Üí not (not b) ‚â° b
    notnot true = t‚â°t
    notnot false = f‚â°f
    #+end_src
    There are a number of things that are worth mentioning. First, we see that we
    refer to =b= on the returning result =not (not b) ‚â° b=, which is possible in
    virtue of dependent types. Then we see that we pattern match on =b= and thus
    we need to fill out two cases. We could make an analogy with a hand written
    proof by cases. The case split with pattern matching allows Agda to know via
    /normalization/ that in the =true= case we must provide a term (proof) of
    type =true ‚â° true=, which we can provide using the =t‚â°t= constructor. We
    proceed analogously in the =false= case. Agda normalizes the terms when
    possible, for instance the term =not (not b)= is already normalized because
    we cannot apply any rule. On the other hand the term =not (not true)= can be
    normalized to =not false= and further normalized to =true= by using the
    definition of =not=. For further information on normalization refer to
    cite:norell:thesis. Another thing to notice is that we use the same
    construction (i.e. an Agda function definition) to provide function definitions,
    like =not=, and theorems, like =notnot=.

    Pattern matching (case analysis) is ubiquitous in Agda, be it in definitions
    or in proofs. We show some more examples below:
    #+begin_src text
    p1 : (b : Bool) ‚Üí and false b ‚â° false
    p1 b = f‚â°f

    p2 : (b : Bool) ‚Üí and b false ‚â° false
    p2 true = f‚â°f
    p2 false = f‚â°f
    #+end_src
    See that in the first case we did not need to do pattern matching while in
    the second we had to. This is due to how the definition of =and= is written
    which in our case performs pattern matching on the first argument.
*** Naturals and induction
    <<sec:agda-nat>>
    In this section we will have a look at the simplest possible recursive
    structure, the natural numbers. In Agda natural numbers can be defined in the
    following way:
    #+begin_src
    data Nat : Set where
      zero : Nat
      suc : Nat ‚Üí Nat
    #+end_src
    The definition should be intuitive enough for the reader at this point. We
    can represent the number $1$ with the term =suc zero=, the number $2$ with
    =suc (suc zero)= and so on.

    Let us continue by defining the equality relation for natural
    numbers[fn::Agda does not allow overloading of symbols so we would need to
    use a different name other than =_‚â°_= to avoid the clash with the equality relation
    of Booleans that we defined before.].
    #+begin_src text
    data _‚â°_ : Nat ‚Üí Nat ‚Üí Set where
      z‚â°z : zero ‚â° zero
      s‚â°s : {a b : Nat} ‚Üí a ‚â° b ‚Üí suc a ‚â° suc b
    #+end_src
    We see that it has a similar structure to the datatype for Boolean equality.
    The only difference is that the =s‚â°s= constructor requires a proof of =a ‚â° b=
    as an argument. Let us show that every natural number is equal to itself.
    #+begin_src text
    refl : (n : Nat) ‚Üí n ‚â° n
    refl zero = z‚â°z
    refl (suc n) = s‚â°s (refl n)
    #+end_src
    We see that we pattern match on =n=, for the =zero= case we give the =z‚â°z=
    constructor. For the =suc= case we need to provide a proof of =suc n ‚â° suc
    n=. By performing a recursive call with =n= as argument we get a proof of =n
    ‚â° n=, then we can use the constructor =s‚â°s= to build a term of type =suc n ‚â°
    suc n=. It can be enlightening to observe that in a proof by induction, such
    as the previous one, a recursive call plays the role of an induction
    hypothesis.

    An inexperienced Agda user might try the following:
    #+begin_src text
    refl' : (n : Nat) ‚Üí n ‚â° n
    refl' zero = z‚â°z
    refl' (suc n) = refl' (suc n)
    #+end_src
    While the types match we see that in the inductive case we perform a
    recursive call on the same argument and thus we get an infinite loop. Agda
    has a termination checker that rejects proofs where termination cannot be
    assured and thus rejects the previous definition. We know that termination is
    an undecidable problem hence it is inevitable that Agda will reject some
    programs that in fact would always terminate. For more information on Agda's
    termination checker refer to cite:norell:thesis,agda-doc.

    We now define addition on natural numbers:
    #+begin_src text
    _+_ : Nat ‚Üí Nat ‚Üí Nat
    zero + b = b
    (suc a) + b = suc (a + b)
    #+end_src

    Proving associativity can be achieved by means of an inductive proof
    following a similar structure as before. For the base case we use the =refl=
    property proved above.
    #+begin_src text
 assoc : (a b c : Nat) ‚Üí (a + b) + c ‚â° a + (b + c)
 assoc zero b c = refl (b + c)
 assoc (suc a) b c = s‚â°s (assoc a b c)
    #+end_src

    Consider the following example involving negation. Keep in mind that =¬¨ (n ‚â°
    suc n) = n ‚â° suc n ‚Üí ‚ä•=.
    #+begin_src text
    p1 : (n : Nat) ‚Üí ¬¨ (n ‚â° suc n)
    p1 zero ()
    p1 (suc n) (s‚â°s x) = p1 n x
    #+end_src
    For the base case we have the impossible pattern because when =n = zero= the
    second argument is supposed to have the type =zero ‚â° suc zero= which is not
    unifiable with any type of a constructor and thus we get the empty pattern.
    For more information on Agda unification refer to cite:norell:thesis.

    Finally, let us focus on proving commutativity of addition, which is a more
    involved example. We first prove transitivity of equality, which is proved by
    an easy induction.
    #+begin_src text
 trans : {a b c : Nat} ‚Üí a ‚â° b ‚Üí b ‚â° c ‚Üí a ‚â° c
 trans z‚â°z z‚â°z = z‚â°z
 trans (s‚â°s x) (s‚â°s y) = s‚â°s (trans x y)
    #+end_src
    Notice how there are two missing cases, that is, =z‚â°z= with =s‚â°s= and vice
    versa. We are allowed to do that because Agda was able to
    detect the empty pattern. We could have also omitted the =p1 zero ()= case in
    the theorem above.

    We proceed by proving two lemmas by an easy induction:
    #+begin_src text
 zero-r : (a : Nat) ‚Üí a ‚â° (a + zero)
 zero-r zero = z‚â°z
 zero-r (suc a) = s‚â°s (zero-r a)

 suc-r : (a b : Nat) ‚Üí suc (a + b) ‚â° (a + suc b)
 suc-r zero b = refl (suc b)
 suc-r (suc a) b = s‚â°s (suc-r a  b)
    #+end_src

    At last, we put all the pieces together to prove our theorem:
    #+begin_src text
 +commut : (a b : Nat) ‚Üí (a + b) ‚â° (b + a)
 +commut zero b = zero-r b
 +commut (suc a) b = trans (s‚â°s (+commut a b)) (suc-r b a)
    #+end_src
    For the base case we must prove =0 + b ‚â° b + 0= which normalizes to =b ‚â° b +
    0= and then we can use our =zero-r= lemma. For the inductive case we must
    prove =suc a + b ‚â° b + suc a= which normalizes to =suc (a + b) ‚â° b + suc a=.
    By IH we know that =a + b ‚â° b + a= so by =s‚â°s= we get =suc (a + b) ‚â° suc (b +
    a)=. Then by our lemma =suc-r= we get =suc (b + a) ‚â° b + suc a=. Finally by
    transitivity we get the desired =suc (a + b) ‚â° b + suc a=.

    We hope that at this point the user has a grasp of how properties can be
    proved in Agda.

    # To summarize, we outline the usual course of action when we
    # want to prove a theorem.
    # 1. We define the datatypes and functions that represent our relations,
    #    operators, assumptions and so on. Usually there are multiple
    #    routes that we can take, and it is important to implement definitions in a
    #    way that they are easy to work with.
    # 2. We prove intermediary lemmas...
    # 3. The type of a function can represent a mathematical proposition.
    # 4. The term
*** Universe hierarchy
    <<sec:universe-hierarchy>> In Agda every well-typed term is assigned a type.
    For instance, the type of =true= is =Bool= and the type of =0= is =Nat=. As
    we have seen before, in a dependent type theory we are allowed to mix types
    and terms, hence =Nat= is a term in itself and must be assigned a type. Agda
    calls the type of (small) types =Set=, hence we have that =Nat= has type
    =Set=. But then =Set= is also a term an must be assigned a type as well.
    Could we have that the type of =Set= is =Set=? No. The first version of
    Martin-L√∂f‚Äôs type theory (cite:martin-lof-1971a) had an axiom stating that
    there is a type of all types and thus we would have that the type of =Set= is
    =Set=. However Girard showed (cite:sep-type-theory-intuitionistic) that
    having =Set : Set= allowed the Burali-Forti paradox[fn::The assumption that
    there is a set of all ordinal numbers leads to a contradiction.] to be
    encoded in the theory, and thus the relation =Set : Set= needs to be
    rejected. In order to avoid such inconsistency Agda builds a hierarchy of
    universes where small types such as =Nat= and =Bool= are assigned the type
    =Set 0= and then for every $i‚ààœâ$ we have that =Set i : Set i+1=. Notice
    however, that =Set i : Set i+1= is true while =Set i : Set i+n= does not hold
    for $n>1$. In Agda we write =Set= instead of =Set 0=. When the level is a
    constant natural number we can also write =Set‚ÇÅ=, =Set‚ÇÇ=, etc. instead of
    =Set 1=, =Set 2=, etc.

    It is possible to combine types of different universe levels. The biggest type
    is the one that counts. For instance:
    #+begin_src text
    function : Set‚ÇÉ ‚Üí Set‚ÇÅ ‚Üí Set‚ÇÉ
    function A B = A ‚Üí B
    #+end_src
    The typing rule is analogous for product and sum types.

    Agda provides a primitive[fn::/primitive/ means that it is built in the
    language and it cannot be defined by the user.] type for universe levels called
    =Level=. Essentially it is the same as =Nat= (we have =lzero= for the base
    level and =lsuc= for the successor level), but it is designed to work as a universe
    index. Having the =Level= type allows us to write universe polymorphic
    functions. See the same function as before, but now with universe
    polymorphism.
    #+begin_src text
    function' : {a b : Level} ‚Üí Set a ‚Üí Set b ‚Üí Set (a ‚äî b)
    function' A B = A ‚Üí B
    #+end_src
    The =_‚äî_= operator is a primitive operator of type =Level ‚Üí Level ‚Üí Level=
    that normalizes to the the maximum of its two operands.

    Most of the functions that we have defined before should be rewritten to be
    universe polymorphic if possible. For instance, we can now rewrite the
    identity function thus:
    #+begin_src text
    id : {a : Level} {A : Set a} ‚Üí A ‚Üí A
    id a = a
    #+end_src

    In the most recent version of Agda (2.6.1) there is an option to enable
    /universe cumulativity/ (cite:agda-doc). This extension adds the typing rule
    $Set·µ¢:Set‚±º$ for $i<j$. Hence it allows us to write the following:
    #+begin_src text
    a : Set              -- always allowed
    a = Nat
    b : Set‚ÇÅ             -- only with cumulativity
    b = Nat
    c : {i : Level} ‚Üí Set i    -- only with cumulativity
    c = Nat
    #+end_src
    In our project we have not used this extension.

*** BHK interpretation of first order logic
    <<sec:bhk-fol>>
    <<sec:predicates>>

    We extend the interpretation that we gave before to include the universal and
    existential quantifiers (cite:sep-intuitionistic-logic-development):
    1. A proof of $‚àÄx.P(x)$ is a function that given an arbitrary element $c$ in
       the domain, builds a proof that $c$ satisfies $P$.
    2. A proof of $‚àÉx.P(x)$ is a witness $c$ in the domain and a proof that $c$
      satisfies $P$.
    Before diving into quantifiers we first discuss how to represent relations in
    Agda. Recall the equality relation for natural numbers =_‚â°_= that we defined
    before. Its type is =Nat ‚Üí Nat ‚Üí Set=. Let us say that we want to define a
    generic type =REL= for relations on any type. A first attempt could be:

    #+begin_src text
 REL : Set ‚Üí Set ‚Üí Set‚ÇÅ
 REL A B = A ‚Üí B ‚Üí Set
    #+end_src

    This first definition is somewhat limited. Recall that =Set = Set 0=, thus we
    restrict =A= and =B= to be small types, furthermore, we require the relation
    to be a small type as well. If we make our =REL= definition universe
    polymorphic it turns out like this.\glsadd{REL}
    #+begin_src text
 REL : {a b : Level} ‚Üí Set a ‚Üí Set b ‚Üí (‚Ñì : Level) ‚Üí Set (a ‚äî b ‚äî lsuc ‚Ñì)
 REL A B ‚Ñì = A ‚Üí B ‚Üí Set ‚Ñì
    #+end_src
    This is the definition used in the Agda standard library (cite:agda-stdlib)
    and is the one that we use in our project.

    For homogeneous relations we use the name =Rel=:\glsadd{Rel}
    #+begin_src text
 Rel : {a : Level} ‚Üí Set a ‚Üí (‚Ñì : Level) ‚Üí Set (a ‚äî lsuc ‚Ñì)
 Rel A ‚Ñì = REL A A ‚Ñì
    #+end_src

    By using these new definitions we could have defined the type of =_‚â°_= thus
    (observe that =Rel Nat lzero= normalizes to =Nat ‚Üí Nat ‚Üí Set=):
    #+begin_src text
    data _‚â°_ : Rel Nat lzero where
      ... -- same as before
    #+end_src

    \glsadd{Pred}
    In a similar way we can define predicates:
    #+begin_src text
    Pred : {a : Level} ‚Üí Set a ‚Üí (‚Ñì : Level) ‚Üí Set (a ‚äî lsuc ‚Ñì)
    Pred A ‚Ñì = A ‚Üí Set ‚Ñì
    #+end_src

    We proceed by giving a representation of the universal quantifier:
    #+begin_src text
 data ‚àÄ[_] {a ‚Ñì : Level} (A : Set a) (P : Pred A ‚Ñì) : Set (a ‚äî ‚Ñì) where
   proof‚àÄ : ((a : A) ‚Üí P a) ‚Üí ‚àÄ[ A ] P
    #+end_src
    The definition is straightforward. In fact this datatype is just a wrapper
    for a function of type =(a : A) ‚Üí P a=.

    For instance, let us prove that every successor of a natural number is
    different than zero:
    #+begin_src text
 aux : (n : Nat) ‚Üí ¬¨ (suc n ‚â° zero)
 aux n ()

 s‚â†z : ‚àÄ[ Nat ] (Œª n ‚Üí ¬¨ (suc n ‚â° zero))
 s‚â†z = proof‚àÄ aux
    #+end_src
    Alternatively we could have written a shorter version that does not use an
    auxiliary lemma.
    #+begin_src text
 s‚â†z : ‚àÄ[ Nat ] (Œª n ‚Üí ¬¨ (suc n ‚â° zero))
 s‚â†z = proof‚àÄ Œª {n ()}
    #+end_src
    Proving \text{$‚àÄ$-elimination} (if $‚àÄx.P(x)$ and $c$ is in the domain then
    $P(c)$) is straightforward:
    #+begin_src text
    ‚àÄ-elim : {a ‚Ñì : Level} {A : Set a} {P : Pred A ‚Ñì} ‚Üí ‚àÄ[ A ] P ‚Üí (a : A) ‚Üí P a
    ‚àÄ-elim (proof‚àÄ f) a = f a
    #+end_src

    We now move on to the existential quantifier. Recall that according to the
    BHK interpretation a proof $‚àÉx.P(x)$ is an element $c$ of the domain and a
    proof that $P(c)$. The first plan could be to use the pair type we defined
    before to contain the needed elements. We repeat the definition here:
    #+begin_src text
 data _√ó_ (A B : Set) : Set where
   _,_ : A ‚Üí B ‚Üí A √ó B
    #+end_src
    The problem is that the type of the second component, =B=, is independent of
    the first component and thus we cannot express what we need. Here is where
    the $Œ£$ type (or \gls*{dependent-pair}) comes into play. A
    dependent pair is a structure where the type of the second component depends
    on the value of the first component. This concept is defined by the following
    datatype.
    #+begin_src text
 data Œ£ {‚Ñì ‚Ñì' : Level} (A : Set ‚Ñì) (B : A ‚Üí Set ‚Ñì') : Set (‚Ñì ‚äî ‚Ñì') where
   _,_ : (a : A) ‚Üí B a ‚Üí Œ£ A B
    #+end_src
    Proving \text{$‚àÉ$-introduction} is trivial:
    #+begin_src
    ‚àÉ-intro : {‚Ñì ‚Ñì' : Level} {A : Set ‚Ñì} {P : A ‚Üí Set ‚Ñì'}
      ‚Üí (a : A) ‚Üí P a ‚Üí Œ£ A P
    ‚àÉ-intro a p = a , p
    #+end_src
    We now show that $‚àÄx(P(x))‚áí¬¨‚àÉx(¬¨P(x))$.
    #+begin_src text
    p1 : {‚Ñì ‚Ñì' : Level} {A : Set ‚Ñì} {P : A ‚Üí Set ‚Ñì'}
      ‚Üí ‚àÄ[ A ] P ‚Üí ¬¨ (Œ£ A (Œª x ‚Üí ¬¨ (P x)))
    p1 (proof‚àÄ f) (c , b) = b (f c)
    #+end_src
    Our goal is to give a term of type =‚ä•=. We have that =f= has type =(a : A) ‚Üí
    P a= so =f c= has type =P c=, then =b= has type =¬¨ (P c)= which is the same
    as =P c ‚Üí ‚ä•=, thus by applying =b= to =(f c)= we get a term of type =‚ä•=.

    Of course, as we are in an intuitionistic logic we cannot show
    the other direction, namely $¬¨‚àÉx(¬¨P(x))‚áí‚àÄx(P(x))$.

    *A note on syntax*. The reader may find the $Œ£$ syntax a bit too different
    from the usual existential notation: $‚àÉx(Px)$. We can fix that thanks to
    Agda's syntax versatility. Agda provides a tool to define custom syntax.
    Below we show how we can use that tool to improve the syntax of $Œ£$ pairs. We
    will not go into more detail since this feature is of shallow mathematical
    interest.
    #+begin_src text
 Œ£-syntax : {‚Ñì ‚Ñì' : Level} ‚Üí (A : Set ‚Ñì) ‚Üí (A ‚Üí Set ‚Ñì') ‚Üí Set (‚Ñì ‚äî ‚Ñì')
 Œ£-syntax = Œ£
 syntax Œ£-syntax A (Œª x ‚Üí B) = Œ£[ x ‚àà A ] B
    #+end_src
    With this syntax enhancement we can replace =Œ£ A (Œª c ‚Üí P c)= by =Œ£[ c ‚àà A ] (P c)=.
    The previous theorem becomes:
    #+begin_src text
    ‚àÉ-intro : {‚Ñì ‚Ñì' : Level} {A : Set ‚Ñì} {P : A ‚Üí Set ‚Ñì'}
      ‚Üí (a : A) ‚Üí P a ‚Üí Œ£[ c ‚àà A ] (P c)
    #+end_src
    There is a variation of this notation which omits the type of the variable as
    it can be inferred in many cases. That is, instead of =Œ£[ c ‚àà A ] (P c)= we
    would have =‚àÉ[ c ] (P c)=. We prefer this notation when possible in the
    project[fn::For instance, in the definition of Veltman semantics in Section
    [[sec:agda-ord-semantics]].]. See again the =‚àÉ-intro= theorem type using this
    notation:
    #+begin_src text
    ‚àÉ-intro : {‚Ñì ‚Ñì' : Level} {A : Set ‚Ñì} {P : A ‚Üí Set ‚Ñì'}
      ‚Üí (a : A) ‚Üí P a ‚Üí ‚àÉ[ c ] (P c)
    #+end_src

*** Equality
    <<sec:agda-equality>>

    In Sections [[sec:agda-nat]] and [[sec:agda-bool]] we have seen how we can define
    equality for Booleans and naturals. In this section we explore polymorphic
    equality and some of its properties and limitations. Of course, the main
    advantage of polymorphic equality is that we can use it for every type and
    thus there is no need to redefine it for every new datatype that we
    define.

    Below we present a slight simplification of polymorphic equality as defined in
    cite:agda-stdlib.
    #+begin_example
 data _‚â°_ {a : Level} {A : Set a} (x : A) : A ‚Üí Set a where
   refl : x ‚â° x
    #+end_example

    It may help the reader to read the following description of the polymorphic
    equality datatype defined above taken from cite:plfa2019: For any type =A=
    and for any =x= of type =A=, the constructor =refl= provides evidence that =x
    ‚â° x=. Hence, every value is equal to itself, and we have no other way of
    showing values equal. The definition features an asymmetry, in that the first
    argument to =_‚â°_= is given by the parameter =x : A=, while the second is
    given by an index in =A ‚Üí Set a=. The first argument to =_‚â°_= can be a
    parameter because it does not vary, while the second must be an index, so it
    can be required to be equal to the first.

    It is easy to see that equality is a reflexive relation.
    #+begin_src text
 reflexive : {‚Ñì : Level} {A : Set ‚Ñì} {a : A} ‚Üí a ‚â° a
 reflexive = refl
    #+end_src
    We can also show that it is symmetric.
    #+begin_src text
 symmetric : {‚Ñì : Level} {A : Set ‚Ñì} {a b : A} ‚Üí a ‚â° b ‚Üí b ‚â° a
 symmetric a‚â°b = ?
    #+end_src
    The argument =a‚â°b= has type =a ‚â° b= and our goal is to give a term of type =b
    ‚â° a=. However, the only way to give a term of type =b ‚â° a= is by unifying =a=
    and =b= since we only have the =refl= constructor. We achieve that by pattern
    matching against the argument =a‚â°b=. Then the goal becomes =a ‚â° a= and we can
    use the =refl= constructor.
    #+begin_src text
 symmetric : {‚Ñì : Level} {A : Set ‚Ñì} {a b : A} ‚Üí a ‚â° b ‚Üí b ‚â° a
 symmetric refl = refl
    #+end_src
    We can prove transitivity in an analogous way.
    #+begin_src text
 transitivity : {‚Ñì : Level} {A : Set ‚Ñì} {a b c : A} ‚Üí a ‚â° b ‚Üí b ‚â° c ‚Üí a ‚â° c
 transitivity refl refl = refl
    #+end_src
    We can also show that if =x ‚â° y= then for any =f= we have =f x ‚â° f y=.
    #+begin_src text
 cong : {‚ÑìA ‚ÑìB : Level} {A : Set ‚ÑìA} {B : Set ‚ÑìB} {x y : A}
   ‚Üí (f : A ‚Üí B) ‚Üí x ‚â° y ‚Üí f x ‚â° f y
 cong f refl = refl
    #+end_src

    We now see that this new equality datatype is equivalent to the previously
    defined equality for naturals. To avoid a name clash, we redefine equality
    for naturals with the =_‚Ñï‚â°_= symbol. We also rename reflexivity for =_‚Ñï‚â°_=
    as =‚Ñïrefl=.
    #+begin_src text
    data _‚Ñï‚â°_ : Nat ‚Üí Nat ‚Üí Set where
      z‚â°z : zero ‚Ñï‚â° zero
      s‚â°s : {a b : Nat} ‚Üí a ‚Ñï‚â° b ‚Üí suc a ‚Ñï‚â° suc b

    ‚Ñïrefl : (n : Nat) ‚Üí n ‚Ñï‚â° n
    ‚Ñïrefl zero = z‚â°z
    ‚Ñïrefl (suc n) = s‚â°s (‚Ñïrefl n)
    #+end_src
    We show that the new equality implies the old equality.
    #+begin_example
    ‚â°‚Üí‚Ñï‚â° : {a b : Nat} ‚Üí a ‚â° b ‚Üí a ‚Ñï‚â° b
    ‚â°‚Üí‚Ñï‚â° {a} refl = ‚Ñïrefl a
    #+end_example
    We see that the old equality implies the new equality.
    #+begin_example
    ‚Ñï‚â°‚Üí‚â° : {a b : Nat} ‚Üí a ‚Ñï‚â° b ‚Üí a ‚â° b
    ‚Ñï‚â°‚Üí‚â° z=z = refl
    ‚Ñï‚â°‚Üí‚â° (s=s a‚Ñï‚â°b) = cong suc (‚Ñï‚â°‚Üí‚â° a‚Ñï‚â°b)
    #+end_example

    See Section [[sec:agda-ext]] for a note on extensionality.
*** Predicates as mathematical sets
    <<sec:sets>>
    In this section when we say /set/ we refer to a subset of an Agda type. The
    most natural way to represent subsets in Agda is to use predicates. See
    [[sec:predicates]] for an introduction. A predicate represents the characteristic
    function of the associated subset. For instance consider the predicate:
    #+begin_src text
    Pos : Pred Nat lzero
    Pos n = ¬¨ (n ‚â° 0)
    #+end_src
    It represents the subset of strictly positive natural numbers.

    We proceed by defining the usual concepts related to mathematical sets. In
    order to make the types less verbose we assume that we already have =A : Set
    ‚Ñì= in scope.
     1. \boxed{‚àà} A proof of membership is a simple function application.
        #+begin_src text
        _‚àà_ : REL A (Pred A)
        a ‚àà X = X a
        #+end_src
        This definition is mostly superfluous but it helps to have a syntax closer
        to regular mathematics.
     2. \boxed{‚àâ} A proof of non membership is function from a proof of membership to =‚ä•=.
        #+begin_src text
        _‚àâ_ : REL A (Pred A)
        a ‚àâ X = ¬¨ (a ‚àà X)
        #+end_src
     3. \boxed{‚äÜ} A proof of inclusion =X ‚äÜ Y= is a function that maps a proof of
        membership to =X= to a proof of membership to =Y=.
        #+begin_example
        _‚äÜ_ : Rel (Pred A)
        X ‚äÜ Y = ‚àÄ {x} ‚Üí x ‚àà X ‚Üí x ‚àà Y
        #+end_example
     4. \boxed{‚à©} We use pairs to represent the intersection. Each component is a
        proof of membership to =X= and =Y= respectively.
        #+begin_src text
        _‚à©_ : Pred A ‚Üí Pred A ‚Üí Pred A
        X ‚à© Y = Œª x ‚Üí x ‚àà X √ó x ‚àà Y
        #+end_src
     5. \boxed{‚à™} We use a sum type to represent the union.
        #+begin_src text
        _‚à™_ : Pred A ‚Üí Pred A ‚Üí Pred A
        X ‚à™ Y = Œª x ‚Üí x ‚àà X ‚äé x ‚àà Y
        #+end_src
     6. \boxed{‚àÖ}
        The empty set is represented by a characteristic constant function to =‚ä•=.
        #+begin_src text
        ‚àÖ : Pred A
        ‚àÖ = Œª x ‚Üí ‚ä•
        #+end_src
     7. \boxed{ùüè}
        Similarly, the universe set is represented by a characteristic constant function to =‚ä§=.
        #+begin_src text
        U : Pred A
        U = Œª x ‚Üí ‚ä§
        #+end_src
     8. \(\boxed{\{x\}}\) A singleton set is defined using equality (assuming we
        have equality defined for that type).
        #+begin_example
        ÔΩõ_ÔΩù : A ‚Üí Pred A
        ÔΩõ x ÔΩù = Œª y ‚Üí x ‚â° y
        #+end_example

*** Extensionality
    <<sec:agda-ext>> In Set theory we call axiom of extensionality the property
    that if two sets have the same elements, then they are equal. As in Agda we
    represent sets as functions we reword extensionality for functions: if two
    functions have the same domain and coincide for every element in their domain then
    they are equal. In symbols: \[‚àÄfg.(‚àÄx.f(x)=g(x))‚áíf=g.\]

    In Agda we can represent this concept thus (cite:agda-stdlib):
    #+begin_src text
Extensionality : (a b : Level) ‚Üí Set _
Extensionality a b =
  {A : Set a} {B : A ‚Üí Set b} {f g : (x : A) ‚Üí B x} ‚Üí
  ((x : A) ‚Üí f x ‚â° g x) ‚Üí f ‚â° g
    #+end_src

    {{{jan(give simplified version without dependent function?)}}}

    #+begin_src text
Extensionality : (a b : Level) ‚Üí Set _
Extensionality a b = {A : Set a} {B : Set b} {f g : A ‚Üí B} ‚Üí
  ((x : A) ‚Üí f x ‚â° g x) ‚Üí f ‚â° g
    #+end_src
    It is usually the case that we accept the axiom of extensionality as part of
    our metalogic as it is part of the most popular logical framework
    $\textsf{ZFC}$, however, in Agda the property of extensionality is not an axiom
    nor a provable theorem.

    An direct consequence of the lack of extensionality is that we cannot show
    equality of sets by double inclusion.
    #+begin_src text
    ‚äÜ‚äá‚Üí‚â° : {‚ÑìS ‚ÑìA : Level} {A : Set ‚ÑìA} {X Y : Pred A ‚ÑìS} ‚Üí X ‚äÜ Y ‚Üí Y ‚äÜ X ‚Üí X ‚â° Y
    ‚äÜ‚äá‚Üí‚â° = ? -- not provable
    #+end_src

    We will see that this has a small effect on
    the definition of generalized Veltman frames in Section
    [[sec:agda-gen-semantics]].

*** Positivity
    <<sec:positivity>>

    In this section we present a technicality as described in the Agda
    documentation (cite:agda-doc) regarding datatype definitions that will become
    relevant in Section [[sec:agda-ord-semantics]] where we define ordinary Veltman
    semantics.

    When defining a datatype =D=, Agda poses an additional requirement on the types
    of the constructors of =D=, namely that =D= may only occur strictly positively in
    the types of their arguments. Concretely, for a datatype with constructors
    =c‚ÇÅ : A‚ÇÅ, ‚Ä¶, c‚Çô : A‚Çô=, Agda checks that each =A·µ¢= has the form
    #+begin_src text
    (y‚ÇÅ : B‚ÇÅ) ‚Üí ... ‚Üí (y‚Çó : B‚Çó) ‚Üí D
    #+end_src
    where an argument of type =B·µ¢= of the constructors does not mention =D= or has
    the form
    #+begin_example
    (z‚ÇÅ : C‚ÇÅ) ‚Üí ... ‚Üí (z‚Çñ : C‚Çñ) ‚Üí D
    #+end_example

    The following example showcases the possibility to build a term of type =‚ä•=
    by defining a non strictly positive type =Bad=. As mentioned above, Agda
    rejects the definition of =Bad=.
    #+begin_src text
 data ‚ä• : Set where

 data Bad : Set where
   bad : (Bad ‚Üí ‚ä•) ‚Üí Bad

 self-app : Bad ‚Üí ‚ä•
 self-app (bad f) = f (bad f)

 absurd : ‚ä•
 absurd = self-app (bad self-app)
    #+end_src
* Agda in the project
  <<sec:agda-project>>
  The goal of this section is to guide the reader through some key parts of the
  code that we have implemented. It is worth noting that we have started from
  scratch as we believe that no other previous work in interpretability logics
  has been done in Agda.

  The implementation relies on the Agda standard library (cite:agda-stdlib).

** Naming conventions :noexport:
   1. If we have =f : T= we say that =f= has type =T= or that =f= is a proof of =T=.
   2. If we have =f : A ‚Üí B ‚Üí C= we say =f= has arguments =A= and =B= and it has
      return type =C=.
** Modal formulas
   Here we present the Agda type that represents a formula as defined in section
   [[sec:language]].

   First we define variables to be natural numbers:
   #+begin_src text
Var : Set
Var = Nat
   #+end_src

   We proceed by inductively defining the formula type: =Fm=. We add a
   constructor for variables and one for each primitive operator.
   #+begin_src text
data Fm : Set where
  var : Var ‚Üí Fm
  ‚ä•' : Fm
  _‚Üù_ : Fm ‚Üí Fm ‚Üí Fm
  _‚ñ∑_ : Fm ‚Üí Fm ‚Üí Fm
   #+end_src
   We have named the bottom constructor =‚ä•'= since the symbol =‚ä•= is commonly
   used in Agda as the empty type. We have used the =‚Üù= to denote a implication
   since =‚Üí= is a reserved symbol for the Agda function type.

   We finally add definable operators as Agda functions. For instance, we define
   $¬¨$ and $‚ñ°$ thus:
  #+begin_src text
infix 60 ¬¨'_
¬¨'_ : Fm ‚Üí Fm
¬¨' a = a ‚Üù ‚ä•'

infix 70 ‚ñ°_
‚ñ°_ : Fm ‚Üí Fm
‚ñ°_ a = ¬¨' a ‚ñ∑ ‚ä•'
  #+end_src
  We use the symbol =¬¨'= instead of =¬¨= for the same reason we used =‚ä•'= instead
  of =‚ä•=.

  It is often the case that we define priority and associativity for our infix
  operators in order to minimize the amount of needed parentheses. The following
  code defines the /infixity/ (level or priority) of =_‚Üù_= and =_‚ñ∑_=.
    #+begin_src text
  infixr 20 _‚Üù_
  infixr 50 _‚ñ∑_
    #+end_src
  A greater number means higher priority. Then we can drop the parentheses
  from the previous formula =var 1 ‚ñ∑ var 0 ‚Üù ‚ä•'=. The $r$ in =infixr= stands
  for right associativity.

** Predicates and relations :noexport:
   In this section we give a short description on how to represent predicates
   and relations in Agda.

   We define a predicate to have the following type[fn::We leave universe
   polymorphism out for simplicity.]:\glsadd{Pred}
   #+begin_src text
   Pred : Set ‚Üí Set‚ÇÅ
   Pred A = A ‚Üí Set
   #+end_src
   Hence, a predicate on the elements of some type =A= is a function from =A= to
   =Set=.

   Relations follow the same pattern:\glsadd{REL}
   #+begin_src text
   REL : Set ‚Üí Set ‚Üí Set‚ÇÅ
   REL A B = A ‚Üí B ‚Üí Set
   #+end_src
   For homogeneous relations we use the name =Rel=:\glsadd{Rel}
   #+begin_src text
   Rel : Set ‚Üí Set ‚Üí Set‚ÇÅ
   Rel A = REL A A
   #+end_src

   Now consider as an example the natural numbers and the =‚â§= relation, which is
   defined inductively according to the following definition.
   1. For all $a‚àà‚Ñï$ we have $0‚â§a$;
   2. for all $a,b‚àà‚Ñï$ we have that if $a‚â§b$ then also $a+1‚â§b+1$.
   #+begin_src text
   data Nat : Set where
     zero : Nat
     suc : Nat ‚Üí Nat

   data _‚â§_ : Rel Nat where
     z‚â§n : (a : Nat) ‚Üí zero ‚â§ a
     s‚â§s : {a b : Nat} ‚Üí a ‚â§ b ‚Üí suc a ‚â§ suc b
   #+end_src
   Note that =‚â§= is the first indexed type that we present as it is indexed by
   two natural numbers. Keep in mind that =Rel Nat = Nat ‚Üí Nat ‚Üí Set=.
   If =t : a ‚â§ b= we say that =t= is a proof that =a= is less or equal than =b=.

   Let us prove that $1‚â§2$; hence we need to build a term of type =suc zero ‚â§
   suc (suc zero)=.
   #+begin_src text
   1‚â§2 : suc zero ‚â§ suc (suc zero)
   1‚â§2 = s‚â§s (z‚â§n (suc zero))
   #+end_src
   Note that we did not explicitly give parameters =a, b= for the =s‚â§s=
   constructor as they are declared in curly braces[fn::Arguments defined in
   curly braces do not need to be given explicitly so long as Agda can infer its
   values.] and can be inferred by the type =a ‚â§ b=. Note that we could have
   done the same with the argument =a= of =z‚â§n= but we keep it explicit for
   illustrating the difference.

   We can also build proofs recursively. Let us prove that =_‚â§_= is reflexive by
   induction:
   #+begin_src text
   ‚â§-refl : (a : Nat) ‚Üí a ‚â§ a
   ‚â§-refl zero = z‚â§n zero
   ‚â§-refl (suc a) = s‚â§s (‚â§-refl a)
   #+end_src
   A key feature to notice is that we can name arguments and refer to them in
   subsequent arguments and in the return type. For instance here we have named
   =a= the first argument, which is a natural number. We use the syntax =(a :
   Nat)=. And then we use the name =a= to build the return type, that is: =a ‚â§ a=.

   We can also define the property of transitivity.
   #+begin_src text
   Transitive : {A : Set} ‚Üí Rel A ‚Üí Set
   Transitive R = ‚àÄ {a b c} ‚Üí R a b ‚Üí R b c ‚Üí R a c
   #+end_src
   We see that a proof that some relation is transitive is a function that given
   proofs of =R a b= and =R b c= constructs a proof of =R a c=. Notice that the
   arguments =a b c= are declared implicit as they can be inferred from the types
   =a ‚â§ b= and =b ‚â§ c=. Let us prove that =‚â§= is transitive:
   #+begin_src text
   ‚â§-trans : Transitive _‚â§_
   ‚â§-trans {a} {b} {c} (z‚â§n b) b‚â§c = z‚â§n c
   ‚â§-trans {suc a} {suc b} {suc c} (s‚â§s a‚â§b) (s‚â§s b‚â§c) = s‚â§s (‚â§-trans a‚â§b b‚â§c)
   #+end_src
   The previous proof works as follows. We perform induction on the proof of =a
   ‚â§ b=, that is, the first explicit argument.
   - Case =z‚â§n=; we know that =a = zero= and we can easily build a proof of
     =a ‚â§ c= by using the =z‚â§n= constructor.
   - Case =s‚â§s a‚â§b=; then is must be that the second proof is built using the
     =s‚â§s= constructor since we have =suc b=. Hence we have =a‚â§b : a ‚â§ b= and
     =b‚â§c : b ‚â§ c=. By using a recursive call (induction hypothesis) to
     =‚â§-trans= we can build a proof of =a ‚â§ c=. Finally we can apply the
     constructor =s‚â§s= to obtain a proof of =suc a ‚â§ suc c=.
** Dependent pairs :noexport:
    Consider the following non-dependent pair definition (again, we present a non universe
    polymorphic version for simplicity):
    #+begin_src text
data _√ó_ (A B : Set) : Set where
  _,_ : A ‚Üí B ‚Üí A √ó B
    #+end_src
    Notice that =_√ó_= is a parameterized type as it has parameters =(A B :
    Set)=, which are the types of each component of the pair. Parameters are
    shared parameters by all constructors (in this case there is only one
    constructor).

    See that we can easily build a pair $‚ü®0,1‚ü©$ thus:
    #+begin_src text
    p : Nat √ó Nat
    p = zero , (suc zero)
    #+end_src

    We now introduce the notion of \glspl*{dependent-pair}, also called
    \(Œ£\)-pairs. Consider the following definition.
    #+begin_src text
data Œ£ {a b : Level} (A : Seta a) (B : A ‚Üí Set b) : Set (a ‚äî b) where
  _,_ : (a : A) ‚Üí (b : B a) ‚Üí Œ£ A B
    #+end_src
    The only, although essential, difference, is that the type of the second
    parameter is indexed by the value of the first. This is specially useful to
    represent existential quantification. For instance, we can design a type
    that asserts that some predicate is satisfiable[fn::we could simply write
    =P= instead of =(Œª a ‚Üí P a)= since eta-reductions are valid in Agda.]:
    #+begin_src text
    Satisfiable : {A : Set} ‚Üí Pred A ‚Üí Set
    Satisfiable {A} P = Œ£ A (Œª a ‚Üí P a)
    #+end_src
    For instance:
    #+begin_src text
    TODO: show meaningful example of dependent pair
    #+end_src

    It useful to define the projection of each component:
    #+begin_src text
    proj‚ÇÅ : {A : Set} {B : A ‚Üí Set} ‚Üí Œ£ A B ‚Üí A
    proj‚ÇÅ (a , b) = a

    proj‚ÇÇ : {A : Set} {B : A ‚Üí Set} ‚Üí (p : Œ£ A B) ‚Üí B (proj‚ÇÅ p)
    proj‚ÇÇ (a , b) = b
    #+end_src
** Noetherian relations
   <<sec:agda-noetherian>>
    We say that a relation is \gls*{noetherian} if it is conversely
    well-founded. We begin by formalizing the concept of infinite ascending
    chain in Agda. In order to do that, we define a coinductive record datatype
    (cite:agda-doc,norell:thesis). A coinductive record is allowed to be
    infinite.
    #+begin_src text
record InfiniteChain {‚ÑìW ‚ÑìR} {W : Set ‚ÑìW} (_<_ : Rel W ‚ÑìR) (a : W)
  : Set (‚ÑìR ‚äî ‚ÑìW)where
  coinductive
  constructor infiniteChain
  field
    b : W
    a<b : a < b
    tail : InfiniteChain _<_ b
    #+end_src
    We see that the previous record datatype represents an infinite ascending
    chain starting at =a= of some relation =_<_=. It has three fields. =b=: The
    next element in the chain. =a<b=: A proof that $a < b$ and =tail=: an
    infinite chain starting at =b=.

    Then we can define being Noetherian as the negation of the existence of an
    infinite chain:
    #+begin_src text
Noetherian : ‚àÄ {‚ÑìR ‚ÑìW} {W : Set ‚ÑìW} ‚Üí Rel W ‚ÑìR ‚Üí Set (‚ÑìR ‚äî ‚ÑìW)
Noetherian _<_ = ‚àÄ {a} ‚Üí ¬¨ (InfiniteChain _<_ a)
    #+end_src

    For instance, we can prove that a Noetherian relation is irreflexive. First
    we show that from a proof that $xRx$ we can build an infinite chain:
    #+begin_src text
infiniteRefl : ‚àÄ {‚Ñì} {R : Rel A ‚Ñì} {x} ‚Üí R x x ‚Üí InfiniteChain R x
InfiniteChain.b (infiniteRefl {x = x} Rxx) = x
InfiniteChain.a<b (infiniteRefl {x = x} Rxx) = Rxx
InfiniteChain.tail (infiniteRefl {x = x} Rxx) = infiniteRefl Rxx
    #+end_src
    We see that each equation corresponds to a different field in the record
    datatype. This construction is known as /copattern/. Coinductive
    datatypes must be constructed in this way. Copatterns are for
    coinductive types what patterns are for inductive (finite) types. In
    cite:abel2013programming copatterns are described in detail.

    And then we can apply the Noetherian definition.
    #+begin_src text
Noetherian‚áíIrreflexive : ‚àÄ {‚ÑìR ‚ÑìW} {W : Set ‚ÑìW} {R : Rel W ‚ÑìR}
     ‚Üí Noetherian R ‚Üí ‚àÄ {x} ‚Üí ¬¨ R x x
Noetherian‚áíIrreflexive noetherian Rxx = noetherian (infiniteRefl Rxx)
    #+end_src

    To see another example refer to Section [[sec:agda-L]].
** Ordinary semantics
   <<sec:agda-ord-semantics>>
   In this section we explain how we have represented ordinary Veltman semantics
   in Agda.

   To represent ordinary Veltman semantics in Agda, the first step is to
   define the type of an ordinary Veltman frame:
   #+begin_src text
record Frame {‚ÑìW ‚ÑìR ‚ÑìS : Level} (W : Set ‚ÑìW) (R : Rel W ‚ÑìR) (S : Rel‚ÇÉ W ‚ÑìS)
  : Set (‚ÑìW ‚äî ‚ÑìR ‚äî ‚ÑìS) where
  constructor frame
  field
    witness : W
    R-trans : Transitive R
    R-noetherian : Noetherian R
    Sw‚äÜR[w]¬≤ : ‚àÄ {w u v} ‚Üí S w u v ‚Üí R w u √ó R w v
    Sw-refl : ‚àÄ {w u} ‚Üí R w u ‚Üí S w u u
    Sw-trans : ‚àÄ {w} ‚Üí Transitive (S w)
    R-Sw-trans : ‚àÄ {w u v} ‚Üí R w u ‚Üí R u v ‚Üí S w u v
   #+end_src
   The keyword =record= is used to define a new product type (a tuple) in which
   each component (or field) has a name that we can use to access it.

   We see that the datatype is parameterized by the universe =W=, the =R=
   relation, the =S= relation and their respective universe levels =‚ÑìW, ‚ÑìR, ‚ÑìS=.

   The first component, =witness=, is required to make sure that the set of worlds is
   not empty. The remaining components are the properties that must be satisfied
   according to definition [[def:ordinary-frames]].

   We define a valuation on a frame thus:
   #+begin_src text
Valuation : Frame {‚ÑìW} {‚ÑìR} {‚ÑìS} W R S ‚Üí Set (lsuc lzero ‚äî ‚ÑìW)
Valuation {W = W} F = REL W Var lzero
   #+end_src

   And then we define a model to be a frame parameterized with a valuation on that
   frame.
   #+begin_src text
record Model (W : Set ‚ÑìW) (R : Rel W ‚ÑìR) (S : Rel‚ÇÉ W ‚ÑìS) (V : REL W Var lzero)
  : Set (‚ÑìW ‚äî ‚ÑìR ‚äî ‚ÑìS) where
  constructor model
  field
    F : Frame {‚ÑìW} {‚ÑìR} {‚ÑìS} W R S
   #+end_src

   Our next step is to define the forcing relation.
   #+begin_src text
data _,_‚ä©_ (M : Model {‚ÑìW} {‚ÑìR} {‚ÑìS} W R S V) (w : W)
  : Fm ‚Üí Set (‚ÑìW ‚äî ‚ÑìR ‚äî ‚ÑìS)
   #+end_src
   We set a model and a world of that model as parameters as they should be
   shared by all constructors. We leave the formula as an index as it may vary
   depending on the constructor. We should introduce a constructor for each case
   in definition [[def:ord-forcing]]:
   1. We do not need a constructor for =‚ä•'= as its absence implicitly implies that
      we can never build an instance of =M , w ‚ä© ‚ä•'= regardless of =M= and =w=.
   2. if $x‚àà\var{}$, then $w‚ä©x$ iff $‚ü®w,x‚ü©‚ààV$;
      #+begin_src text
  var : {p : Var} ‚Üí p ‚àà V w ‚Üí M , w ‚ä© var p
      #+end_src
   3. if $A,B‚àà\fm{}$, then $w‚ä©A‚ÜíB$ iff if $w‚ä©A$ then $w‚ä©B$;
      #+begin_src text
  impl : {A B : Fm} ‚Üí ((M , w ‚ä© A) ‚Üí (M , w ‚ä© B)) ‚Üí M , w ‚ä© (A ‚Üù B)
      #+end_src
   4. if $A,B‚àà\fm{}$, then $w‚ä©A‚ñ∑B$ iff if $wRu$ and $u‚ä©A$ then there exists $v$ such
      that $v‚ä©B$ and $uS_wv$.
      #+begin_src text
   rhd : {A B : Fm} ‚Üí
     ({u : W} ‚Üí R w u ‚Üí M , u ‚ä© A ‚Üí (‚àÉ[ v ] (S w u v √ó (M , v ‚ä© B))))
     ‚Üí M , w ‚ä© A ‚ñ∑ B
      #+end_src

   Unfortunately the definition above is not valid in Agda. The reason is that
   constructors =rhd= and =impl= both fail the positivity check (see
   [[sec:positivity]]). For instance, see that in the =impl= constructor type we have
   =(M , w ‚ä© A)= on the left of an arrow =‚Üí=.

   We have circumvented this problem by providing mutually recursive definitions
   for /forcing/ (=_,_‚ä©_=) and /not forcing/ (=_,_‚äÆ_=). Agda allows the
   definition of mutually recursive datatypes (and functions) by first providing
   the type of both[fn::Or more if it is the case.] definitions and after those
   giving the rest of the definition, that is, the constructors for datatypes
   and the equations for functions.

   The type of the two datatypes that we want to define are as follows.
   #+begin_src text
data _,_‚ä©_ (M : Model {‚ÑìW} {‚ÑìR} {‚ÑìS} W R S V) (w : W)
  : Fm ‚Üí Set (‚ÑìW ‚äî ‚ÑìR ‚äî ‚ÑìS) -- forcing relation

data _,_‚äÆ_ (M : Model {‚ÑìW} {‚ÑìR} {‚ÑìS} W R S V) (w : W)
  : Fm ‚Üí Set (‚ÑìW ‚äî ‚ÑìR ‚äî ‚ÑìS) -- not forcing relation
   #+end_src

   Next we provide the strictly positive types of each constructor of the
   =_,_‚ä©_= and =_,_‚äÆ_= relations.
   1. For the =‚ä•'= constant.
      1. Forcing (=_,_‚ä©_=). No constructor is required.
      2. Not forcing (=_,_‚äÆ_=).
        #+begin_example
        bot : M , w ‚äÆ ‚ä•'
        #+end_example
   2. For variables.
    1. Forcing (=_,_‚ä©_=).
       #+begin_src text
  var : {p : Var} ‚Üí p ‚àà V w ‚Üí M , w ‚ä© var p
       #+end_src
    2. Not forcing (=_,_‚äÆ_=).
       #+begin_example
  var : {p : Var} ‚Üí p ‚àâ V w ‚Üí M , w ‚äÆ var p
       #+end_example

   3. For implication (=‚Üù=).
    1. Forcing (=_,_‚ä©_=).
       #+begin_src text
  impl : {A B : Fm} ‚Üí M , w ‚äÆ A ‚äé M , w ‚ä© B ‚Üí M , w ‚ä© A ‚Üù B
       #+end_src
    2. Not forcing (=_,_‚äÆ_=).
       #+begin_src text
  impl : {A B : Fm} ‚Üí M , w ‚ä© A ‚Üí M , w ‚äÆ B ‚Üí M , w ‚äÆ A ‚Üù B
       #+end_src
   4. For interpretability (=‚ñ∑=).
    1. Forcing (=_,_‚ä©_=).
       #+begin_src text
  rhd : {A B : Fm} ‚Üí
    (‚àÄ {u} ‚Üí R w u ‚Üí M , u ‚äÆ A ‚äé (‚àÉ[ v ] (S w u v √ó M , v ‚ä© B)))
    ‚Üí M , w ‚ä© A ‚ñ∑ B
       #+end_src
    2. Not forcing (=_,_‚äÆ_=).
       #+begin_src text
  rhd : {A B : Fm} ‚Üí
    ‚àÉ[ u ] (R w u √ó M , u ‚ä© A √ó ((v : W) ‚Üí (¬¨ S w u v) ‚äé M , v ‚äÆ B))
    ‚Üí M , w ‚äÆ A ‚ñ∑ B
       #+end_src

   Putting it all together results in the following definitions:
   #+begin_src text
data _,_‚ä©_ M w where
  var : {x : Var} ‚Üí V w x ‚Üí M , w ‚ä© var x
  impl : {A B : Fm} ‚Üí M , w ‚äÆ A ‚äé M , w ‚ä© B ‚Üí M , w ‚ä© A ‚Üù B
  rhd : {A B : Fm} ‚Üí
    (‚àÄ {u} ‚Üí R w u ‚Üí M , u ‚äÆ A ‚äé (‚àÉ[ v ] (S w u v √ó M , v ‚ä© B)))
    ‚Üí M , w ‚ä© A ‚ñ∑ B
   #+end_src
   #+begin_src text
data _,_‚äÆ_ M w where
  var : {x : Var} ‚Üí ¬¨ (V w x) ‚Üí M , w ‚äÆ var a
  impl : {A B : Fm} ‚Üí M , w ‚ä© A ‚Üí M , w ‚äÆ B ‚Üí M , w ‚äÆ A ‚Üù B
  rhd : {A B : Fm} ‚Üí
    ‚àÉ[ u ] (R w u √ó M , u ‚ä© A √ó ((v : W) ‚Üí (¬¨ S w u v) ‚äé M , v ‚äÆ B))
    ‚Üí M , w ‚äÆ A ‚ñ∑ B
  bot : M , w ‚äÆ ‚ä•'
   #+end_src

   To prove that =_,_‚ä©= and =_,_‚äÆ= are indeed the negation of each other
   we should prove two lemmas. We define =A ‚áî B ‚âî A ‚Üí B √ó B ‚Üí A=. Then the lemma in
   Agda types is as follows:
   {{{beginlemma}}}
   <<lemma:forcing-neg>>
   \hfill
   1. =‚àÄ {M w A} ‚Üí M , w ‚ä© A ‚áî ¬¨ (M , w ‚äÆ A)=.
   2. =‚àÄ {M w A} ‚Üí ¬¨ (M , w ‚ä© A) ‚áî M , w ‚äÆ A=.
   {{{endlemma}}} For part 1 we can prove $‚áí$ and for part 2 we can prove $‚áê$
   (see lemma [[lemma:equiv]]). However, it is not possible to prove the remaining
   directions. In general terms, this is due to the fact that in Agda (and in
   intuitionistic logic in general) we can prove that =(¬¨ A ‚äé B) ‚Üí A ‚Üí B= but we
   cannot prove =A ‚Üí B ‚Üí (¬¨ A ‚äé B)=. The reason being that we lack the law of
   excluded middle, as it is a non-constructive axiom. In order to prove the
   remaining directions we need to assume that the forcing relation is
   decidable.

   {{{begindef}}} <<def:ord-decidable-model>>

   We say that =M= is \gls*{decidable model} if for any world =w= and formula
   =A= we have that either =M , w ‚ä© A= or =M , w ‚äÆ A=.

   In Agda terms:
   #+begin_src text
DecidableModel : Model ‚Üí Set
DecidableModel M = ‚àÄ w A ‚Üí M , w ‚ä© A ‚äé M , w ‚äÆ A
   #+end_src
   {{{enddef}}}

   {{{beginproof}}}
   {{{agda}}}

   Under the assumption that we restrict ourselves to decidable models we can
   prove lemma [[lemma:forcing-neg]].
   {{{endproof}}}

   {{{beginlemma}}} <<lemma:equiv>> The following is true:

   1. =‚ä©‚ä• : ‚àÄ {M w} ‚Üí ¬¨ (M , w ‚ä© ‚ä•')=;
   2. =‚äÆ‚Üí¬¨‚ä© : ‚àÄ {M w A} ‚Üí M , w ‚äÆ A ‚Üí ¬¨ (M , w ‚ä© A)=;
   3. =‚ä©‚Üí¬¨‚äÆ : ‚àÄ {M w A} ‚Üí M , w ‚ä© A ‚Üí ¬¨ (M , w ‚äÆ A)=;
   4. =‚ä©MP : ‚àÄ {M w A B} ‚Üí M , w ‚ä© A ‚Üù B ‚Üí M , w ‚ä© A ‚Üí M , w ‚ä© B=;
   5. =‚ä©¬¨ : ‚àÄ {M w A} ‚Üí (M , w ‚ä© ¬¨' A) ‚áî (M , w ‚äÆ A)=;
   6. =‚äÆ¬¨ : ‚àÄ {M w A} ‚Üí M , w ‚äÆ ¬¨' A ‚áî M , w ‚ä© A=;
   7. =‚ä©¬¨¬¨ : ‚àÄ {M w A} ‚Üí M , w ‚ä© ¬¨' ¬¨' A ‚áî M , w ‚ä© A=;
   8. =‚äÆ¬¨¬¨ : ‚àÄ {M w A} ‚Üí M , w ‚äÆ ¬¨' ¬¨' A ‚áî M , w ‚äÆ A=;
   9. =‚ä©‚àß : ‚àÄ {M w A B} ‚Üí M , w ‚ä© A ‚àß B ‚áî (M , w ‚ä© A √ó M , w ‚ä© B)=;
   10. =‚äÆ‚àß : ‚àÄ {M w A B} ‚Üí M , w ‚äÆ A ‚àß B ‚áî (M , w ‚äÆ A ‚äé M , w ‚äÆ B)=;
   11. =‚ä©‚à® : ‚àÄ {M w A B} ‚Üí M , w ‚ä© A ‚à® B ‚áî (M , w ‚ä© A ‚äé M , w ‚ä© B)=;
   12. =‚ä©‚ñ° : ‚àÄ {M w A} ‚Üí M , w ‚ä© ‚ñ° A ‚áî (‚àÄ {v} ‚Üí R w v ‚Üí M , v ‚ä© A)=;
   13. =‚äÆ‚ñ° : ‚àÄ {M w A} ‚Üí M , w ‚äÆ ‚ñ° A ‚áî (‚àÉ[ u ] (R w u √ó M , u ‚äÆ A))=;
   14. =‚ä©‚ô¢ : ‚àÄ {M w A} ‚Üí M , w ‚ä© ‚ô¢ A ‚áî (‚àÉ[ u ] (R w u √ó M , u ‚ä© A))=;
   15. =‚äÆ‚ô¢ : ‚àÄ {M w A} ‚Üí M , w ‚äÆ ‚ô¢ A ‚áî (‚àÄ {u} ‚Üí R w u ‚Üí M , u ‚äÆ A)=;
   16. =‚ä©‚Üù‚á® : ‚àÄ {M w A B} ‚Üí M , w ‚ä© A ‚Üù B ‚Üí M , w ‚ä© A ‚Üí M , w ‚ä© B=;
   17. =‚ä©‚ñ∑‚á® : ‚àÄ {M w A B} ‚Üí M , w ‚ä© A ‚ñ∑ B ‚Üí (‚àÄ {u} ‚Üí R w u ‚Üí M , u ‚ä© A ‚Üí ‚àÉ[ v ] (S w u v √ó M , v ‚ä© B)=.
   {{{endlemma}}}
   {{{beginproof}}} {{{agda}}} {{{coq}}} The above properties have been proven
   in Agda and Coq without assuming that the model is decidable. {{{endproof}}}


   {{{beginlemma}}} <<lemma:ord-equiv-dec>> The following series of equivalences
   can be proven for decidable models.

   1. =‚ä©‚Üù : ‚àÄ {w A B} ‚Üí M , w ‚ä© A ‚Üù B ‚áî (M , w ‚ä© A ‚Üí M , w ‚ä© B)=;
   2. =‚ä©‚ñ∑ : ‚àÄ {w A B} ‚Üí M , w ‚ä© A ‚ñ∑ B ‚áî
      (‚àÄ {u} ‚Üí R w u ‚Üí M , u ‚ä© A ‚Üí ‚àÉ[ v ] (S w u v √ó M , v ‚ä© B))=;
   3. =‚ä©‚áî¬¨‚äÆ : ‚àÄ {w A} ‚Üí M , w ‚ä© A ‚áî (¬¨ M , w ‚äÆ A)=;
   4. =‚äÆ‚áî¬¨‚ä© : ‚àÄ {w A} ‚Üí M , w ‚äÆ A ‚áî (¬¨ M , w ‚ä© A)=.
   {{{endlemma}}} {{{beginproof}}} {{{agda}}} {{{coq}}} Note that we only need the
   decidability assumption for 1 ($‚áê$), 2 ($‚áê$), 3 ($‚áê$) and 4 ($‚áê$). {{{endproof}}}

   From now on, we always restrict ourselves to decidable models as the usage of
   lemma [[lemma:ord-equiv-dec]] is ubiquitous. If we were to assume that we are
   outside of Agda and that we accept the law of excluded middle as part of our
   metalogic, the mentioned assumption could be dropped.

** Subsets (predicates revisited) :noexport:
   In Agda, the keyword =Set= refers to an Agda type (insert ref to previous
   section), which is the closest concept to regular mathematics /set/. In this
   section when we say /set/ we refer to a subset of an Agda type. The most
   natural way to represent subsets in Agda is to use predicates. See
   [[sec:predicates]] for an introduction. A predicate represents the characteristic
   function of the associated subset. For instance consider the predicate:
   #+begin_src text
   even : Pred Nat
   even = ...
   #+end_src
   Then =even= represents the subset of natural numbers that are even. It is
   important to note that predicates are always restricted to a specific type,
   in this case =Nat=, and for that reason the term /subset/ may be more adequate.

   Next we present how we represent in Agda common operations on sets.
   Assume for the below definitions that we have some =A : Set= in scope.
** Generalized semantics
   <<sec:agda-gen-semantics>> In this section we explain how we have represented
   generalized Veltman semantics in Agda. As explained in Section [[sec:trans]] we
   consider eight different quasi-transitivity properties, thus, we need to
   define everything related to generalized Veltman semantics to be generic with
   respect to the quasi-transitivity condition used, which was certainly
   presented some challenges.

   Analogously to ordinary semantics we start by defining a frame. We begin by
   defining a datatype that represents a frame without the quasi-transitivity
   condition. See that we define the type =ùïé ‚âî Pred W ‚ÑìW=, which means that a
   term of type =ùïé= is a subset of =W= (see Section [[sec:sets]] for details on how
   to represent mathematical sets in Agda). See that the =S-ext= field adds
   extensionality restricted to the third component of the =S= relation.
   #+begin_src text
record FrameNoTrans (W : Set ‚ÑìW) (R : Rel W ‚ÑìR) (S : REL‚ÇÉ W W (Pred W ‚ÑìW) ‚ÑìS)
  : Set (lsuc lzero ‚äî ‚ÑìR ‚äî ‚ÑìS ‚äî lsuc ‚ÑìW) where
  constructor frame
  ùïé : Set (lsuc ‚ÑìW)
  ùïé = Pred W ‚ÑìW
  field
    witness : W
    Swu-sat : ‚àÄ {w u Y} ‚Üí S w u Y ‚Üí Satisfiable Y
    R-trans : Transitive R
    R-noetherian : Noetherian R
    Sw‚äÜR[w] : ‚àÄ {w u Y} ‚Üí S w u Y ‚Üí R w u
    SwuY‚äÜRw : ‚àÄ {w u Y} ‚Üí S w u Y ‚Üí ‚àÄ {y} ‚Üí y ‚àà Y ‚Üí R w y
    S-quasirefl : ‚àÄ {w u} ‚Üí R w u ‚Üí S w u ÔΩõ u ÔΩù
    R-Sw-trans : ‚àÄ {w u v} ‚Üí R w u ‚Üí R u v ‚Üí S w u ÔΩõ v ÔΩù
    S-ext : ‚àÄ {w x V V'} ‚Üí S w x V ‚Üí V ‚äÜ V' ‚Üí V' ‚äÜ V ‚Üí S w x V'
   #+end_src

   Then we define a new datatype =Frame= which represents a non-transitive
   Generalized Veltman frame plus some quasi-transitivity condition, which is
   left as a parameter =T=.
   #+begin_example
record Frame (W : Set ‚ÑìW) (R : Rel W ‚ÑìR) (S : REL‚ÇÉ W W (Pred W ‚ÑìW) ‚ÑìS)
  (T : (W : Set ‚ÑìW) ‚Üí REL‚ÇÉ W W (Pred W ‚ÑìW) ‚ÑìS ‚Üí Set (lsuc ‚ÑìW ‚äî ‚ÑìS))
  : Set (lsuc ‚ÑìW ‚äî ‚ÑìR ‚äî ‚ÑìS) where
  constructor frame
  field
    frame-0 : FrameNoTrans {‚ÑìW} {‚ÑìR} {‚ÑìS} W R S
    quasitrans : T W S
   #+end_example

   We now define all the quasi-transitivity conditions. Here we only present
   Condition (4).
   #+begin_example
  Trans-4 : (W : Set ‚ÑìW) ‚Üí REL‚ÇÉ W W (Pred W ‚ÑìW) ‚ÑìS ‚Üí Set (lsuc ‚ÑìW ‚äî ‚ÑìS))
  Trans-4 W S = ‚àÄ {x u Y} ‚Üí S x u Y ‚Üí ‚àÉ[ y ] (y ‚àà Y √ó (‚àÄ {Y'} ‚Üí S x y Y' ‚Üí S x u Y'))
   #+end_example

   And finally we can define a datatype that represents a generalized Veltman
   frame for each of the quasi-transitivity conditions as a simple instantiation
   of the generic =Frame= defined before. Here we only present Condition (4).
   #+begin_example
Frame4 : (W : Set ‚ÑìW) (R : Rel W ‚ÑìR) (S : REL‚ÇÉ W W (Pred W ‚ÑìW) ‚ÑìS) ‚Üí Set _
Frame4 W R S = Frame W R S (Trans-4 W S)
   #+end_example


   In order to define the generalized Veltman semantics forcing relation, since
   we need to define it generically to work for any quasi-transitivity condition
   assume that we have some term =T= representing such condition of typed thus:
   #+begin_example
   (T : ‚àÄ {‚ÑìW ‚ÑìS} (W : Set ‚ÑìW) ‚Üí REL‚ÇÉ W W (Pred W ‚ÑìW) ‚ÑìS ‚Üí Set (lsuc ‚ÑìW ‚äî ‚ÑìS))
   #+end_example

   Then we define a generalized model in an analogous way to how we did it for
   ordinary semantics:
   #+begin_example
  record Model
    {‚ÑìW ‚ÑìR ‚ÑìS}
    (W : Set ‚ÑìW)
    (R : Rel W ‚ÑìR)
    (S : REL‚ÇÉ _ _ _ ‚ÑìS)
    (V : REL W Var lzero)
    : Set (lsuc ‚ÑìW ‚äî ‚ÑìR ‚äî ‚ÑìS) where
    constructor model
    field
      F : Frame {‚ÑìW} {‚ÑìR} {‚ÑìS} W R S T
   #+end_example

   And finally we define the forcing relation using mutually recursive datatypes
   as we did for ordinary semantics. The only difference is in the =rhd=
   constructor.
   #+begin_example
  data _,_‚äÆ_ {‚ÑìW ‚ÑìR ‚ÑìS W R S V} (M : Model {‚ÑìW} {‚ÑìR} {‚ÑìS} W R S V) (w : W)
    : Fm ‚Üí Set (lsuc ‚ÑìW ‚äî ‚ÑìR ‚äî ‚ÑìS)

  data _,_‚ä©_ {‚ÑìW ‚ÑìR ‚ÑìS W R S V} (M : Model {‚ÑìW} {‚ÑìR} {‚ÑìS} W R S V) (w : W)
    : Fm ‚Üí Set (lsuc ‚ÑìW ‚äî ‚ÑìR ‚äî ‚ÑìS)

  data _,_‚ä©_ {‚ÑìW} {‚ÑìR} {‚ÑìS} {W} {R} {S} {V} M w where
    var : ‚àÄ {a : Var} ‚Üí a ‚àà V w ‚Üí M , w ‚ä© var a
    impl : ‚àÄ {A B} ‚Üí M , w ‚äÆ A ‚äé M , w ‚ä© B ‚Üí M , w ‚ä© A ‚Üù B
    rhd : ‚àÄ {A B} ‚Üí
      (‚àÄ {u} ‚Üí R w u ‚Üí M , u ‚äÆ A ‚äé (‚àÉ[ Y ] (S w u Y √ó (Y ‚äÜ M ,_‚ä© B))))
      ‚Üí M , w ‚ä© A ‚ñ∑ B

  data _,_‚äÆ_ {‚ÑìW} {‚ÑìR} {‚ÑìS} {W} {R} {S} {V} M w where
    var : ‚àÄ {a : Var} ‚Üí a ‚àâ V w ‚Üí M , w ‚äÆ var a
    impl : ‚àÄ {A B} ‚Üí M , w ‚ä© A ‚Üí M , w ‚äÆ B ‚Üí M , w ‚äÆ A ‚Üù B
    rhd : ‚àÄ {A B} ‚Üí
      ‚àÉ[ u ] (R w u √ó M , u ‚ä© A
      √ó ‚àÄ Y ‚Üí Satisfiable Y ‚Üí (¬¨ S w u Y) ‚äé (Satisfiable (Y ‚à© (M ,_‚äÆ B))))
      ‚Üí M , w ‚äÆ A ‚ñ∑ B
    bot : M , w ‚äÆ ‚ä•'
   #+end_example

   Recall that in section [[sec:agda-ord-semantics]] in order to prove some
   properties we had to assume that the ordinary models where decidable in the
   sense defined in Definition [[def:ord-decidable-model]]. For generalized
   semantics we need to make a stronger assumption described in the next
   definition.

   {{{begindef}}} We say that =M= is \gls*{multi decidable model} if for any set
   of worlds =Y= and formula =A= we can decide whether
   1. for every element =y= in =Y= we have =M , y ‚äÆ A=; or
   2. there is an element =y= in =Y= such that =M , y ‚äÆ A=.

   In Agda terms:
   #+begin_src text
  MultiDecidableModel : ‚àÄ {‚ÑìW ‚ÑìR ‚ÑìS W R S V} ‚Üí Model {‚ÑìW} {‚ÑìR} {‚ÑìS} W R S V
    ‚Üí Set (lsuc ‚ÑìW ‚äî ‚ÑìR ‚äî ‚ÑìS ‚äî lsuc ‚ÑìW)
  MultiDecidableModel {‚ÑìW = ‚ÑìW} {W = W} M =
    ‚àÄ (Y : Pred W ‚ÑìW) A ‚Üí Y ‚äÜ M ,_‚ä© A ‚äé Satisfiable (Y ‚à© (M ,_‚äÆ A))
   #+end_src
   Observe that any multi-decidable model is also decidable.
   {{{enddef}}}

   {{{beginlemma}}} <<lemma:gen-lemmas>> Assuming that we restrict ourselves to
   multi-decidable models then properties in lemmas [[lemma:forcing-neg]],
   [[lemma:equiv]] and [[lemma:ord-equiv-dec]] also hold for generalized semantics.
   {{{endlemma}}} {{{beginproof}}} {{{agda}}}
   {{{endproof}}}

*** A guided Agda proof
    <<sec:agda-L>> In this section we guide the user through a non-trivial Agda
    proof, which will hopefully give the reader a feel of how we can proof
    generalized Veltman semantic properties in Agda. We prove that for any
    generalized Veltman model $M$ and world $w$ we have that $w$ forces L√∂b's
    axiom. In symbols: \[‚àÄMwA.\ M , w ‚ä© ‚ñ° (‚ñ° A ‚Üí A) ‚Üí ‚ñ° A.\] Note that since
    L√∂b's axiom is in $\textsf{IL}$ we need to show this as part of the
    soundness proof.

    We begin by outlining the proof without Agda. Assume that for some world
    $w‚ÇÄ$ we have $w_0‚ä©‚ñ° (‚ñ° A ‚Üí A)$. Assume for a contradiction that $w‚äÆ‚ñ°A$, then
    there exists some $w‚ÇÅ$ such that $w‚ÇÄRw‚ÇÅ‚äÆA$. Since $w‚ÇÄRw‚ÇÅ$ it follows that
    $w‚ÇÅ‚ä©‚ñ°A‚ÜíA$. Then since $w‚ÇÅ‚äÆA$ we necessarily have that $w‚ÇÅ‚äÆ‚ñ°A$. Then there
    exists $w‚ÇÇ$ such that $w‚ÇÅRw‚ÇÇ‚äÆA$. Since $R$ is transitive we have that
    $w‚ÇÄRw‚ÇÇ$ and thus $w‚ÇÇ‚ä©‚ñ°A‚ÜíA$. We can repeat the previous argument indefinitely
    to build an infinite chain $w‚ÇÄRw‚ÇÅR‚Ä¶$, which is a contradiction since $R$ is
    Noetherian. This concludes the pen and paper proof.

    We proceed with the Agda proof. During the course of this example we use
    some lemmas listed below, which we have proved in Agda, however, we just
    display their type here and we omit their proof in order to save space. Also,
    assume that we have some model =M= in scope.
    #+begin_src text
    ‚ä©4' : ‚àÄ {w A} ‚Üí M , w ‚ä© ‚ñ° A ‚Üí M , w ‚ä© ‚ñ° ‚ñ° A
    ‚äÆ‚ñ° : ‚àÄ {w A} ‚Üí M , w ‚äÆ ‚ñ° A ‚áî (‚àÉ[ u ] (R w u √ó M , u ‚äÆ A))
    ‚ä©‚ñ° : ‚àÄ {w A} ‚Üí M , w ‚ä© ‚ñ° A ‚áî (‚àÄ {v} ‚Üí R w v ‚Üí M , v ‚ä© A)
    ‚ä©‚áî¬¨‚äÆ : ‚àÄ {w A} ‚Üí M , w ‚ä© A ‚áî ¬¨ (M , w ‚äÆ A)
    _‚áí_ : ‚àÄ {a b} {A : Set a} {B : Set b} ‚Üí A ‚áî B ‚Üí A ‚Üí B
    #+end_src

    *Naming convention*. In this proof we use the popular convention to name
    variables after their type, which greatly improves the readability of
    proofs. For instance, if we bind some variable of type =R w u= we will name
    it =Rwu=; if we bind a variable of type =M , w ‚ä© A= we will name it =w‚ä©A=;
    and so on.

    We begin by showing a useful lemma: for any $w,u,A$, if $wRu$ and $u‚äÆA$ and
    $w‚ä©‚ñ°(‚ñ°A‚ÜíA)$ then we can build an infinite \text{$R$-chain} starting at $w$.
    The following type expresses the aforementioned property.
    #+begin_src text
    R-chain : ‚àÄ {w u A} ‚Üí R w u ‚Üí M , u ‚äÆ A ‚Üí M , w ‚ä© ‚ñ° (‚ñ° A ‚Üù A) ‚Üí InfiniteChain R w
    #+end_src
    Recall that infinite chains are defined as coinductive datatypes in Section
    [[sec:agda-noetherian]]. Hence we proceed by building the infinite chain using
    copatterns. The first two components are clear:
    #+begin_src text
  InfiniteChain.b (R-chain {w} {u} Rwu uA uF) = u
  InfiniteChain.a<b (R-chain {w} {u} Rwu uA uF) = Rwu
    #+end_src
    Then we must show that there is an infinite chain starting at $u$. The
    argument =w‚ä©‚ñ°‚ü®‚ñ°A‚ÜùA‚ü©= has type =M , w ‚ä© ‚ñ° (‚ñ° A ‚Üù A)=, hence by applying the
    lemma =‚ä©‚ñ°= in the right (=‚áí=) direction and using the fact that =Rwu= has type =R
    w u= we get a term of type =M , u ‚ä© ‚ñ° A ‚Üù A= which we pattern match using
    the =widh= construct[fn::The =width= construct allows us to pattern match
    on terms that can be build from the arguments of the function.]. By the
    definition of the constructor =impl= for the =_,_‚ä©_= datatype it follows
    that we have two cases: either =M , u ‚ä© A= or =M , u ‚äÆ ‚ñ° A=.

    If it is the case that =M , u ‚ä© A= we can build a term of type =‚ä•= by using
    the =‚ä©‚Üí¬¨‚äÆ= lemma and then we can use the principle of explosion to return
    anything.
    #+begin_src text
  InfiniteChain.tail (R-chain Rwu u‚äÆA w‚ä©‚ñ°‚ü®‚ñ°A‚ÜùA‚ü©) with (‚ä©‚ñ° ‚áí w‚ä©‚ñ°‚ü®‚ñ°A‚ÜùA‚ü©) Rwu
  ... | impl (inj‚ÇÇ u‚ä©A) = explosion (‚ä©‚Üí¬¨‚äÆ u‚ä©A u‚äÆA)
    #+end_src

    On the contrary, if we have that =M , u ‚äÆ ‚ñ° A= then by the =‚äÆ‚ñ°= lemma we get
    that there exists some =v= such that =R u v= and =M , v ‚ä© A=. Then we can
    use the =‚ä©4'= lemma to get a term of type =M , w ‚ä© ‚ñ° (‚ñ° (‚ñ° A ‚Üù A))=, then by
    lemma =‚ä©‚ñ°= and the fact we have a proof of =R w u= we can build a term of
    type =M , u ‚ä© ‚ñ° (‚ñ° A ‚Üù A)=. Finally by a recursive call (induction
    hypothesis) to =R-chain= with =R u v= and =v‚ä©A= and the term described above
    we get a term of the desired type.
    #+begin_src text
  ... | impl (inj‚ÇÅ x‚äÆ‚ñ°A) with ‚äÆ‚ñ° ‚áí x‚äÆ‚ñ°A
  ... | (v ‚∏¥ Ruv ‚∏¥ v‚ä©A) = R-chain Ruv v‚ä©A ((‚ä©‚ñ° ‚áí ‚ä©4' w‚ä©‚ñ°‚ü®‚ñ°A‚ÜùA‚ü©) Rwu)
    #+end_src
    This concludes the proof of the lemma. We now proceed to prove our theorem.
    The statement of the theorem is represented by the following type:
    #+begin_src text
  ‚ä©L : ‚àÄ {w A} ‚Üí M , w ‚ä© ‚ñ° (‚ñ° A ‚Üù A) ‚Üù ‚ñ° A
    #+end_src
    We use lemma =‚ä©‚Üù= to get a proof of =M , w ‚ä© ‚ñ° (‚ñ° A ‚Üù A)=. Then we use lemma
    =‚ä©‚ñ°= on the left direction, so we assume =R w u= and our goal is to show =M
    , u ‚ä© A=. By using lemma =‚ä©‚áî¬¨‚äÆ= on the left direction. Our goal is to show
    =¬¨ (M , w ‚äÆ A)= which normalizes to =M , w ‚äÆ A ‚Üí ‚ä•=, hence we assume =M , u
    ‚äÆ A= and we aim to build a proof of =‚ä•=. We can build an infinite chain with
    lemma =R-chain= proved above and the facts that =R w u=, =M , u ‚äÆ A= and =M
    , w ‚ä© ‚ñ° (‚ñ° A ‚Üù A)=. Before the final step it may be useful to recall the
    definition of a =Noetherian= relation (see Section [[sec:agda-noetherian]]):
    #+begin_src text
Noetherian _<_ = ‚àÄ {a} ‚Üí ¬¨ (InfiniteChain _<_ a)
    #+end_src
    Finally we use the property that the =R= relation of the model is Noetherian
    to get a term of type =‚ä•= as desired.
    #+begin_example
  ‚ä©L : ‚àÄ {w A} ‚Üí M , w ‚ä© ‚ñ° (‚ñ° A ‚Üù A) ‚Üù ‚ñ° A
  ‚ä©L {w} {A} = ‚ä©‚Üù ‚áê Œª w‚ä©‚ñ°‚ü®‚ñ°A‚ÜíA‚ü© ‚Üí ‚ä©‚ñ° ‚áê Œª {u} Rwu ‚Üí ‚ä©‚áî¬¨‚äÆ ‚áê
    Œª {u‚äÆA ‚Üí R-noetherian (R-chain Rwu u‚äÆA w‚ä©‚ñ°‚ü®‚ñ°A‚ÜíA‚ü©)}
    #+end_example

    Putting it all together we have:
    #+begin_src text
  R-chain : ‚àÄ {w u A} ‚Üí R w u ‚Üí M , u ‚äÆ A ‚Üí M , w ‚ä© ‚ñ° (‚ñ° A ‚Üù A) ‚Üí InfiniteChain R w
  InfiniteChain.b (R-chain {w} {u} Rwu uA uF) = u
  InfiniteChain.a<b (R-chain {w} {u} Rwu uA uF) = Rwu
  InfiniteChain.tail (R-chain {w} {u} Rwu u‚äÆA w‚ä©‚ñ°‚ü®‚ñ°A‚ÜùA‚ü©)
     with (‚ä©‚ñ° ‚áí w‚ä©‚ñ°‚ü®‚ñ°A‚ÜùA‚ü©) Rwu
  ... | impl (inj‚ÇÇ u‚ä©A) = ‚ä•-elim (‚ä©‚Üí¬¨‚äÆ u‚ä©A u‚äÆA)
  ... | impl (inj‚ÇÅ x‚äÆ‚ñ°A) with ‚äÆ‚ñ° ‚áí x‚äÆ‚ñ°A
  ... | (v ‚∏¥ Ruv ‚∏¥ v‚ä©A) = R-chain Ruv v‚ä©A ((‚ä©‚ñ° ‚áí ‚ä©4' w‚ä©‚ñ°‚ü®‚ñ°A‚ÜùA‚ü©) Rwu)

  ‚ä©L : ‚àÄ {w A} ‚Üí M , w ‚ä© ‚ñ° (‚ñ° A ‚Üù A) ‚Üù ‚ñ° A
  ‚ä©L {w} {A} = ‚ä©‚Üù ‚áê Œª w‚ä©‚ñ°‚ü®‚ñ°A‚ÜíA‚ü© ‚Üí ‚ä©‚ñ° ‚áê Œª {u} Rwu ‚Üí ‚ä©‚áî¬¨‚äÆ ‚áê
    Œª {u‚äÆA ‚Üí R-noetherian (R-chain Rwu u‚äÆA w‚ä©‚ñ°‚ü®‚ñ°A‚ÜíA‚ü©)}
    #+end_src
** \il{} and syntactic proofs
   Here we present our efforts on formalizing syntactic \il{} proofs in Agda. We
   restrict ourselves to finite sets of assumptions.

   We begin by defining the necessary type to represent a finite list:
   #+begin_src text
data List {a : Level} (A : Set a) : Set a where
  []  : List A
  _‚à∑_ : A ‚Üí List A ‚Üí List A
   #+end_src
   Then we can define a proof of membership inductively in the following way:
   #+begin_src text
data _‚àà_ {a : Level} {A : Set a} (a : A) : Pred (List A) a where
  here  : {x : A} {xs : List A} ‚Üí a ‚â° x ‚Üí a ‚àà (x ‚à∑ xs)
  there : {x : A} {xs : List A} ‚Üí a ‚àà xs ‚Üí a ‚àà (x ‚à∑ xs)
   #+end_src

   Now that we have all the necessary tools, we proceed to define the relation
   =_‚ä¢_=, which represents the \il{} logic in Agda.
   #+begin_src text
data _‚ä¢_ (Œ† : List Fm) : Fm ‚Üí Set where
  -- identity rule
  Ax : ‚àÄ {A} ‚Üí A ‚àà Œ† ‚Üí Œ† ‚ä¢ A
  -- classical axioms
  C1 : ‚àÄ {A B} ‚Üí Œ† ‚ä¢ A ‚Üù (B ‚Üù A)
  C2 : ‚àÄ {A B C} ‚Üí Œ† ‚ä¢ (A ‚Üù (B ‚Üù C)) ‚Üù ((A ‚Üù B) ‚Üù (A ‚Üù C))
  C3 : ‚àÄ {A B} ‚Üí Œ† ‚ä¢ (¬¨' A ‚Üù ¬¨' B) ‚Üù (B ‚Üù A)
  -- IL axioms
  K : ‚àÄ {A B} ‚Üí Œ† ‚ä¢ (‚ñ° (A ‚Üù B)) ‚Üù (‚ñ° A ‚Üù ‚ñ° B)
  L : ‚àÄ {A} ‚Üí Œ† ‚ä¢ ‚ñ° (‚ñ° A ‚Üù A) ‚Üù ‚ñ° A
  J1 : ‚àÄ {A B} ‚Üí Œ† ‚ä¢ ‚ñ° (A ‚Üù B) ‚Üù A ‚ñ∑ B
  J2 : ‚àÄ {A B C} ‚Üí Œ† ‚ä¢ A ‚ñ∑ B ‚àß B ‚ñ∑ C ‚Üù A ‚ñ∑ C
  J3 : ‚àÄ {A B C} ‚Üí Œ† ‚ä¢ (A ‚ñ∑ C ‚àß B ‚ñ∑ C) ‚Üù (A ‚à® B) ‚ñ∑ C
  J4 : ‚àÄ {A B} ‚Üí Œ† ‚ä¢ A ‚ñ∑ B ‚Üù ‚ô¢ A ‚Üù ‚ô¢ B
  J5 : ‚àÄ {A} ‚Üí Œ† ‚ä¢ ‚ô¢ A ‚ñ∑ A
  -- rules
  MP : ‚àÄ {A B} ‚Üí Œ† ‚ä¢ A ‚Üù B ‚Üí Œ† ‚ä¢ A ‚Üí Œ† ‚ä¢ B
  nec : ‚àÄ {A} ‚Üí [] ‚ä¢ A ‚Üí Œ† ‚ä¢ ‚ñ° A
   #+end_src
   We include constructor =Ax= so we can use assumptions. We include
   constructors =C1=, =C2= and =C3= so that every classical tautology in the
   language of \il{} can be proved. Then we add the axioms of \il{} and finally we add
   =MP= for modus ponens and =nec= for necessitation. Note that the
   necessitation rule only accepts \il{} theorems (empty set of assumptions) and
   thus this definition is fitting for local semantics.
   We have proven several results about \il, which are presented in Section
   [[sec:il]].

   Consider the pen and paper syntactic proof of $A‚ÜíA$.
   \begin{flalign*}
   0.\ &(A ‚Üí ((A ‚Üí A) ‚Üí A)) ‚Üí ((A ‚Üí (A ‚Üí A)) ‚Üí (A ‚Üí A)) & \text{By } C2 \\
   1.\ &A ‚Üí ((A ‚Üí A) ‚Üí A) & \text{By } C1 \\
   2.\ &A ‚Üí (A ‚Üí A) & \text{By } C1 \\
   3.\ & (A ‚Üí (A ‚Üí A)) ‚Üí A ‚Üí A   &\text{By MP 0, 1} \\
   4.\ & A ‚Üí A   &\text{By MP 3, 2} \\
   ‚ñ†&
   \end{flalign*}
   Now see how we could replicate the proof in Agda using our definition of =_‚ä¢_=.
   #+begin_src text
‚ä¢A‚ÜùA : ‚àÄ {A Œ†} ‚Üí Œ† ‚ä¢ A ‚Üù A
‚ä¢A‚ÜùA {A} = MP (MP (C2 {Œ†} {A} {A ‚Üù A} {A}) (C1 {Œ†} {A} {A ‚Üù A})) (C1 {Œ†} {A} {A})
   #+end_src
   We see that it is extremely verbose and hard to read. We can substantially
   shorten it by relying on Agda's type inference to automatically infer the
   instantiation of almost all of the axiom schemes used. However, it is still
   far from being human friendly.
   #+begin_src text
‚ä¢A‚ÜùA : ‚àÄ {A Œ†} ‚Üí Œ† ‚ä¢ A ‚Üù A
‚ä¢A‚ÜùA {A} = MP (MP C2 C1) (C1 {B = A})
   #+end_src
   For now, we forget about the obscure syntax and we use the previous result to
   prove that $A‚ñ∑A$ is an \il{} theorem. First, the pen and paper proof:
   \begin{flalign*}
        0.\ &  A ‚Üí A                        &\text{By } ‚ä¢A‚ÜíA \\
        1.\ &  ‚ñ° (A ‚Üí A)                    &\text{By necessitation on 0} \\
        2.\ &  ‚ñ° (A ‚Üí A) ‚Üí (A ‚ñ∑ A)          &\text{By J1} \\
        3.\ &  A ‚ñ∑ A                        &\text{By MP 2, 1} \\
       ‚ñ†
   \end{flalign*}
   And now the same proof in Agda.
   #+begin_src text
‚ä¢A‚ñ∑A : ‚àÄ {A Œ†} ‚Üí Œ† ‚ä¢ A ‚ñ∑ A
‚ä¢A‚ñ∑A {A} = MP J1 (nec ‚ä¢A‚ÜùA)
   #+end_src
   Although the Agda proofs of $A‚ÜíA$ and $A‚ñ∑A$ are short, it is very hard for a
   human to fully understand them with the Agda syntax used above. This problem
   motivates our next section, in which we present a way to express syntactic
   proofs in Agda using paper-like syntax.

*** An eDSL for syntactic proofs
    <<sec:edsl>>
     In this section we present a language for writing Hilbert style proofs for
     logic \il. This language was first presented by the author of this paper in
     cite:slug for logic $K$.

     We begin by introducing the concept of eDSL. The acronym eDSL stands for
     /Embedded Domain Specific Language/. It refers to a small language (a set of
     functions and datatypes) embedded in another language (in this case Agda)
     that has been designed to solve a problem in a very specific domain, in this
     case, Hilbert style proofs.

     We begin by showing how we could write the two syntactic proofs presented
     in the previous section in our eDSL. Then we will present the language in
     detail.

     First example:
   #+begin_src text
‚ä¢A‚ÜùA : ‚àÄ {A} ‚Üí [] ‚ä¢ A ‚Üù A
‚ä¢A‚ÜùA {A} =
  begin[ 0 ] (A ‚Üù ((A ‚Üù A) ‚Üù A)) ‚Üù ((A ‚Üù (A ‚Üù A)) ‚Üù (A ‚Üù A)) By C2
       [ 1 ] A ‚Üù ((A ‚Üù A) ‚Üù A)                               By C1
       [ 2 ] A ‚Üù (A ‚Üù A)                                     By C1
       [ 3 ] (A ‚Üù (A ‚Üù A)) ‚Üù A ‚Üù A                           ByMP 0 , 1
       [ 4 ] A ‚Üù A                                           ByMP 3 , 2
       ‚ñ†
   #+end_src

   Second example:
   #+begin_src text
‚ä¢A‚ñ∑A : ‚àÄ {A} ‚Üí [] ‚ä¢ A ‚ñ∑ A
‚ä¢A‚ñ∑A {A} =
  begin[ 0 ] A ‚Üù A                        By ‚ä¢A‚ÜùA
       [ 1 ] ‚ñ° (A ‚Üù A)                    ByNec 0
       [ 2 ] ‚ñ° (A ‚Üù A) ‚Üù (A ‚ñ∑ A)          By J1
       [ 3 ] A ‚ñ∑ A                        ByMP 2 , 1
       ‚ñ†
   #+end_src

   We see that our eDSL allows us to write syntactic proofs in a very similar
   human-friendly syntax which is almost identical to the pen and paper usual
   syntax with the standout benefit that the proof is computer checked. We want
   to emphasize, as it may be surprising to the reader, that the proofs shown
   above are actual Agda code. It is crucial to make clear that this eDSL is
   /not/ an alternative definition of the logic \il{} presented in different
   syntax. The eDSL is just a layer above the definition which allows us to use
   nice syntax while still relying on the simple definition of \il{} we provided
   in the previous section. Of course, we will need to prove that we can
   transform proofs in the nice syntax to proofs in the old format. We will
   comment on it later on this section.

   We proceed by giving a short description of the language, which consists of
   four types of instructions:
   1. =[_]_By_=. This instruction is used to include a theorem in the proof. The
      theorem can be any axiom scheme of \il{} or anything proved to be a theorem.
      More precisely, the theorem can be any =A= if we have =Œ† ‚ä¢ A= for some =Œ†=.
      The first instruction must be of this kind and must be preceded with =begin=.
   2. =[_]_ByNec_=. This instruction applies the necessitation rule to a formula
      in a previous line referenced by its number. This rule can only be applied
      if we have an empty set of assumptions.
   3. =[_]_ByMP_=. This instruction applies the modus ponens rule to two
      formulas in previous lines referenced by their number.
   4. =‚ñ†=. The proof must be closed using this instruction.
   Every instruction must be increasingly numbered starting at 0.

   Thanks to the design of the language, if the user mistakenly numbers one of
   the instructions Agda will report an error indicating where the error is. If
   the user improperly instantiates an axiom scheme or theorem or references an
   incorrect line, it will also be prompted with an error. Summarizing, an error
   will appear if the proof has any deficiency. This holds true as the eDSL is
   implemented in Agda and thus it is verified.

   We proceed by giving a rough approximation on how the language has been
   implemented. Details of the inner workings of the language are left out as
   they fall out of the scope of this paper, however, we encourage the reader to look
   for further information in cite:slug if they are interested.

   We begin by defining the datatype that represents our language.
   #+begin_src text
data HilbertProof : List Fm ‚Üí Fm ‚Üí Nat ‚Üí Set where
  begin : ‚àÄ {Œ£ A} ‚Üí Œ£ ‚ä¢ A ‚Üí HilbertProof Œ£ A 0
  by : ‚àÄ {Œ£ A B n} ‚Üí Œ£ ‚ä¢ B ‚Üí HilbertProof Œ£ A n ‚Üí HilbertProof Œ£ B (suc n)
   Ax : ‚àÄ {Œ£ B n} ‚Üí (A : Fm) ‚Üí HilbertProof Œ£ B n ‚Üí HilbertProof (A ‚à∑ Œ£) A (suc n)
  nec : ‚àÄ {Œ£ n ‚ñ°A C} (H : HilbertProof [] C n) (i : HilbertRef H (‚ñ°A) ‚ñ°_)
    ‚Üí HilbertProof Œ£ (‚ñ°A) (suc n)
  MP : ‚àÄ {n Œ£ A B C} (H : HilbertProof Œ£ C n) ‚Üí HilbertRef H (A ‚Üù B) id
    ‚Üí HilbertRef H A id ‚Üí HilbertProof Œ£ B (suc n)
   #+end_src
   Each instruction (except =‚ñ†=) has its corresponding constructor. We see that
   the datatype is indexed by a list of formulas and a formula. Those are the set of
   assumptions and the formula that is shown to be a theorem. The third index is
   a natural number. This number keeps track of the length of the proof and it
   is needed to ensure that references to previous lines are not out of bounds.
   The type =HilbertRef= represents a reference to a previous line in the proof.
   We omit its definition here as is not crucial for understanding the overall
   idea.

   Then we define the front end syntax for each of the constructors. For
   instance, the definition of the =[_]_By_= instruction is as follows (we omit
   the type for simplicity as it is the same the type of the constructor =by=).
   #+begin_src text
infixl 10 _[_]_By_
_[_]_By_ : ...
H [ n ] B By p = by p H
   #+end_src
   Notice that we also declare the instruction to have left associativity
   (=infixl=), which will allow us to write each subsequent instruction below
   the other without need of parentheses.

   We skip how references work for simplicity, as they use advanced Agda
   features (type classes and instance arguments (cite:agda-doc)) in order to be
   automatically checked without an explicit proof.

   Observe now how we can build a proof in this language.
   #+begin_src text
‚ä¢A‚ñ∑A' : ‚àÄ {A} ‚Üí HilbertProof [] (A ‚ñ∑ A) 3
‚ä¢A‚ñ∑A' {A} =
  begin[ 0 ] A ‚Üù A                 By ‚ä¢A‚ÜùA
       [ 1 ] ‚ñ° (A ‚Üù A)             ByNec 0
       [ 2 ] ‚ñ° (A ‚Üù A) ‚Üù (A ‚ñ∑ A)   By J1
       [ 3 ] A ‚ñ∑ A                 ByMP 2 , 1
   #+end_src
   It is essentially the same as we showcased before but it is lacking the
   closing =‚ñ†= instruction. The type of such instruction is:
   #+begin_src text
_‚ñ† : ‚àÄ {n Œ£ A} ‚Üí HilbertProof Œ£ A n ‚Üí Œ£ ‚ä¢ A
   #+end_src
   We see that =‚ñ†= is defined as a postfix operator which translates a proof
   =HilbertProof Œ£ A n= into a proof =Œ£ ‚ä¢ A=. This translation step is where
   most of the complexity lays. Needless to say, as is implemented and verified
   in Agda it is guaranteed to be correct. To reiterate, by correct we mean that
   every proof in the new syntax can be transformed (and definition of the term
   =‚ñ†=, which can be found in Section [[src:il.edsl]], is actually the
   algorithm which performs the transformation) to a proof using only axioms and
   rules of \il{} as presented in the previous section. This ends the tour of
   the language.

   We strongly believe in the practical utility of this language as it can be
   used by logicians that are not Agda experts due to its simple and familiar
   syntax. We are all aware that long syntactic proofs are error prone. This
   language completely removes such problem. Of course, there is some room for
   improvement, for instance, the language does not include the deduction
   theorem rule, which is frequently used in practice. Note that this limitation
   can be ameliorated as we can use the deduction theorem outside of the eDSL
   and then include the result by using a =[_]_By_= instruction.
* other

\printglossary

\printbibliography[
heading=bibintoc,
title=Bibliography
]

* Appendix
  TODO: include all the necessary unicode characters.
** Official Agda reference
   This section contains a thorough description of some of the topics that were
   touched in the introduction prior to this section. We believe that the
   intuition given in the introduction should be enough for the reader to be
   able to read Section [[sec:agda-project]], however, we encourage the reader to
   resort to the ensuing reference if they wish for more precise information on
   the language. The contents of this section have been merely copied from the
   online Agda documentation (cite:agda-doc).

*** Function definitions and pattern matching
    A function is defined by first declaring its type followed by a number of
    equations called clauses. Each clause consists of the function being defined
    applied to a number of patterns, followed by = and a term called the
    right-hand side. For example:
    #+begin_example
    not : Bool ‚Üí Bool
    not true  = false
    not false = true
    #+end_example
    Functions are allowed to call themselves recursively, for example:
    #+begin_example
    twice : Nat ‚Üí Nat
    twice zero    = zero
    twice (suc n) = suc (suc (twice n))
    #+end_example

    The general form for defining a function is
    #+begin_example
    f : (x‚ÇÅ : A‚ÇÅ) ‚Üí ‚Ä¶ ‚Üí (x‚Çô : A‚Çô) ‚Üí B
    f p‚ÇÅ ‚Ä¶ p‚Çô = d
    ‚Ä¶
    f q‚ÇÅ ‚Ä¶ q‚Çô = e
    #+end_example
    where =f= is a new identifier, =p·µ¢= and =q·µ¢= are patterns of type =A·µ¢=, and =d= and =e=
    are expressions.

    The declaration above gives the identifier =f= the type =(x‚ÇÅ : A‚ÇÅ) ‚Üí ‚Ä¶ ‚Üí (x‚Çô :
    A‚Çô) ‚Üí B= and =f= is defined by the defining equations. Patterns are matched
    from top to bottom, i.e., the first pattern that matches the actual
    parameters is the one that is used.

    By default, Agda checks the following properties of a function definition:
    1. The patterns in the left-hand side of each clause should consist only of
       constructors and variables.
    2. No variable should occur more than once on the left-hand side of a single
       clause.
    3. The patterns of all clauses should together cover all possible inputs of
       the function.
    4. The function should be terminating on all possible inputs.

*** Implicit arguments and automatic inference
    <<sec:agda-implicit-args>>

    It is possible to omit terms that the type checker can figure out for
    itself, replacing them by =_=. If the type checker cannot infer the value of
    an =_= it will report an error. For instance, for the polymorphic identity
    function
    #+begin_example
    id : (A : Set) ‚Üí A ‚Üí A
    #+end_example
    the first argument can be inferred from the type of the second argument, so
    we might write =id _ zero= for the application of the identity function to
    =zero=.

    We can even write this function application without the first argument. In
    that case we declare an implicit function space:
    #+begin_example
    id : {A : Set} ‚Üí A ‚Üí A
    #+end_example
    and then we can use the notation =id zero=.

    Another example:
    #+begin_example
    _==_  : {A : Set} ‚Üí A ‚Üí A ‚Üí Set
    subst : {A : Set} (C : A ‚Üí Set) {x y : A} ‚Üí x == y ‚Üí C x ‚Üí C y
    #+end_example
    Note how the first argument to =_==_= is left implicit. Similarly, we may
    leave out the implicit arguments =A=, =x=, and =y= in an application of
    =subst=. To give an implicit argument explicitly, enclose it in curly braces.
    The following two expressions are equivalent:
    #+begin_example
    x1 = subst C eq cx
    x2 = subst {_} C {_} {_} eq cx
    #+end_example
    It is worth noting that implicit arguments are also inserted at the end of
    an application, if it is required by the type. For example, in the
    following, =y1= and =y2= are equivalent.
    #+begin_example
    y1 : a == b ‚Üí C a ‚Üí C b
    y1 = subst C

    y2 : a == b ‚Üí C a ‚Üí C b
    y2 = subst C {_} {_}
    #+end_example
    Implicit arguments are inserted eagerly in left-hand sides so =y3= and =y4= are
    equivalent. An exception is when no type signature is given, in which case
    no implicit argument insertion takes place. Thus in the definition of =y5= the
    only implicit is the =A= argument of =subst=.
    #+begin_example
    y3 : {x y : A} ‚Üí x == y ‚Üí C x ‚Üí C y
    y3 = subst C

    y4 : {x y : A} ‚Üí x == y ‚Üí C x ‚Üí C y
    y4 {x} {y} = subst C {_} {_}

    y5 = subst C
    #+end_example
    It is also possible to write lambda abstractions with implicit arguments.
    For example, given =id : (A : Set) ‚Üí A ‚Üí A=, we can define the identity
    function with implicit type argument as
    #+begin_example
    id‚Äô = Œª {A} ‚Üí id A
    #+end_example
    Implicit arguments can also be referred to by name, so if we want to give
    the expression =e= explicitly for =y= without giving a value for =x= we can
    write
    #+begin_example
    subst C {y = e} eq cx
    #+end_example
    In rare circumstances it can be useful to separate the name used to give an
    argument by name from the name of the bound variable, for instance if the
    desired name shadows an existing name. To do this you write
    #+begin_example
    id‚ÇÇ : {A = X : Set} ‚Üí X ‚Üí X  -- name of bound variable is X
    id‚ÇÇ x = x

    use-id‚ÇÇ : (Y : Set) ‚Üí Y ‚Üí Y
    use-id‚ÇÇ Y = id‚ÇÇ {A = Y}      -- but the label is A
    #+end_example

    Labeled bindings must appear by themselves when typed, so the type =Set= needs
    to be repeated in this example:
    #+begin_example
    const : {A = X : Set} {B = Y : Set} ‚Üí A ‚Üí B ‚Üí A
    const x y = x
    #+end_example

    When constructing implicit function spaces the implicit argument can be
    omitted, so both expressions below are valid expressions of type ={A : Set}
    ‚Üí A ‚Üí A=:
    #+begin_example
    z1 = Œª {A} x ‚Üí x
    z2 = Œª x ‚Üí x
    #+end_example
    The =‚àÄ= (or =forall=) syntax for function types also has implicit variants:

    #+begin_example
    ‚ë† : (‚àÄ {x : A} ‚Üí B)    is-the-same-as  ({x : A} ‚Üí B)
    ‚ë° : (‚àÄ {x} ‚Üí B)        is-the-same-as  ({x : _} ‚Üí B)
    ‚ë¢ : (‚àÄ {x y} ‚Üí B)      is-the-same-as  (‚àÄ {x} ‚Üí ‚àÄ {y} ‚Üí B)
    #+end_example

    In very special situations it makes sense to declare unnamed hidden
    arguments ={A} ‚Üí B=. In the following =example=, the hidden argument to
    =scons= of type =zero ‚â§ zero= can be solved by \text{$Œ∑$-expansion}, since
    this type reduces to =‚ä§=.
    #+begin_example
    data ‚ä• : Set where

    _‚â§_ : Nat ‚Üí Nat ‚Üí Set
    zero ‚â§ _      = ‚ä§
    suc m ‚â§ zero  = ‚ä•
    suc m ‚â§ suc n = m ‚â§ n

    data SList (bound : Nat) : Set where
    []    : SList bound
    scons : (head : Nat) ‚Üí {head ‚â§ bound} ‚Üí (tail : SList head) ‚Üí SList bound

    example : SList zero
    example = scons zero []
    #+end_example
    There are no restrictions on when a function space can be implicit. Internally,
    explicit and implicit function spaces are treated in the same way. This means
    that there are no guarantees that implicit arguments will be solved. When there
    are unsolved implicit arguments the type checker will give an error message
    indicating which application contains the unsolved arguments. The reason for
    this liberal approach to implicit arguments is that limiting the use of implicit
    argument to the cases where we guarantee that they are solved rules out many
    useful cases in practice.
*** datatype definitions and constructors
    <<sec:agda-ref-datatype>>
    <<sec:agda-datatype>>

    The general form of the definition of a simple datatype =D= is the following
    #+begin_src text
  data D (x‚ÇÅ : P‚ÇÅ) ... (x‚Çñ : P‚Çñ) : (y‚ÇÅ : Q‚ÇÅ) ‚Üí ... ‚Üí (y‚Çó : Q‚Çó) ‚Üí Set ‚Ñì where
    c‚ÇÅ : A‚ÇÅ
    ...
    c‚Çô : A‚Çô
    #+end_src

    The name D of the data type and the names =c‚ÇÅ=, ‚Ä¶, =c‚Çô= of the constructors
    must be new w.r.t. the current signature and context, and the types =A‚ÇÅ=, ‚Ä¶,
    =A‚Çô= must be function types ending in =D=, i.e. they must be of the form
    #+begin_example
    (y‚ÇÅ : B‚ÇÅ) ‚Üí ... ‚Üí (y‚Çò : B‚Çò) ‚Üí D
    #+end_example

    Datatypes can have parameters. They are declared after the name of the
    datatype but before the colon, for example:
    #+begin_example
    data List (A : Set) : Set where
      []  : List A
      _‚à∑_ : A ‚Üí List A ‚Üí List A
    #+end_example

    In addition to parameters, datatypes can also have indices. In contrast to
    parameters which are required to be the same for all constructors, indices
    can vary from constructor to constructor. They are declared after the colon
    as function arguments to =Set=. For example, fixed-length vectors can be
    defined by indexing them over their length of type =Nat=:

    #+begin_example
    data Vector (A : Set) : Nat ‚Üí Set where
      []  : Vector A zero
      _‚à∑_ : {n : Nat} ‚Üí A ‚Üí Vector A n ‚Üí Vector A (suc n)
    #+end_example

    Notice that the parameter =A= is bound once for all constructors, while the
    index ={n : Nat}= must be bound locally in the constructor =_‚à∑_=.

    Indexed datatypes can also be used to describe predicates, for example the
    predicate =Even : Nat ‚Üí Set= can be defined as follows:

    #+begin_example
    data Even : Nat ‚Üí Set where
      even-zero  : Even zero
      even-plus2 : {n : Nat} ‚Üí Even n ‚Üí Even (suc (suc n))
    #+end_example

    The general form of the definition of a (parametrized, indexed) datatype =D=
    is the following
    #+begin_example
    data D (x‚ÇÅ : P‚ÇÅ) ... (x‚Çñ : P‚Çñ) : (y‚ÇÅ : Q‚ÇÅ) ‚Üí ... ‚Üí (y‚Çó : Q‚Çó) ‚Üí Set ‚Ñì where
      c‚ÇÅ : A‚ÇÅ
      ...
      c‚Çô : A‚Çô
    #+end_example

    where the types =A‚ÇÅ=, ‚Ä¶, =A‚Çô= are function types of the form
    #+begin_example
    (z‚ÇÅ : B‚ÇÅ) ‚Üí ... ‚Üí (z‚Çò : B‚Çò) ‚Üí D x‚ÇÅ ... x‚Çñ t‚ÇÅ ... t‚Çó
    #+end_example
*** Function types
    Function types are written =(x : A) ‚Üí B=, or in the case of non-dependent
    functions simply =A ‚Üí B=. For instance, the type of the addition function
    for natural numbers is:
    #+begin_example
    Nat ‚Üí Nat ‚Üí Nat
    #+end_example
    and the type of the addition function for vectors is:
    #+begin_example
    (A : Set) ‚Üí (n : Nat) ‚Üí (u : Vec A n) ‚Üí (v : Vec A n) ‚Üí Vec A n
    #+end_example

    where =Set= is the type of sets and =Vec A n= is the type of vectors with =n=
    elements of type =A=. Arrows between consecutive hypotheses of the form =(x :
    A)= may also be omitted, and =(x : A) (y : A)= may be shortened to =(x y : A)=:
    #+begin_example
    (A : Set) (n : Nat) (u v : Vec A n) ‚Üí Vec A n
    #+end_example

    Functions are constructed by lambda abstractions, which can be either typed
    or untyped. For instance, both expressions below have type =(A : Set) ‚Üí A ‚Üí A=
    (the second expression checks against other types as well):
    #+begin_example
    example‚ÇÅ = Œª (A : Set) (x : A) ‚Üí x
    example‚ÇÇ = Œª A x ‚Üí x
    #+end_example

    The application of a function =f : (x : A) ‚Üí B= to an argument =a : A= is
    written =f a= and the type of this is \texttt{B[x := a]}.

    Some notation conventions follow.
    - Function types:
      #+begin_example
      prop‚ÇÅ : ((x : A) (y : B) ‚Üí C) is-the-same-as   ((x : A) ‚Üí (y : B) ‚Üí C)
      prop‚ÇÇ : ((x y : A) ‚Üí C)      is-the-same-as   ((x : A)(y : A) ‚Üí C)
      prop‚ÇÉ : (‚àÄ (x : A) ‚Üí C)  is-the-same-as   ((x : A) ‚Üí C)
      prop‚ÇÑ : (‚àÄ x ‚Üí C)        is-the-same-as   ((x : _) ‚Üí C)
      prop‚ÇÖ : (‚àÄ x y ‚Üí C)      is-the-same-as   (‚àÄ x ‚Üí ‚àÄ y ‚Üí C)
      #+end_example

    - Functional abstraction:
      #+begin_example
      (Œª x y ‚Üí e)                    is-the-same-as   (Œª x ‚Üí (Œª y ‚Üí e))
      #+end_example

    - Functional application:
      #+begin_example
      (f a b)                       is-the-same-as    ((f a) b)
      #+end_example

*** Record types
    The general form of a record declaration is as follows:
    #+begin_example
    record <recordname> <parameters> : Set <level> where
      <directives>
      constructor <constructorname>
      field
        <fieldname1> : <type1>
        <fieldname2> : <type2>
        -- ...
      <declarations>
    #+end_example
    All the components are optional, and can be given in any order. In
    particular, fields can be given in more than one block, interspersed with
    other declarations. Each field is a component of the record. Types of later
    fields can depend on earlier fields.

    The directives available are eta-equality, no-eta-equality, inductive and
    co-inductive. For more information visit cite:agda-doc.
** Agda library code
   Hi
*** All
    <<src:all>>
    This is a helper module which imports everything in the library. It is used
    to check all the library at once.

    #+include: "latex/All.tex" export latex
*** Base
    <<src:base>>
    This module contains some definitions and helper functions which are used
    throughout the project. It includes, for instance, the definition of a
    Noetherian relation.

  #+include: "latex/Base.tex" export latex
*** Classical
    <<src:classical>>
  #+include: "latex/Classical.tex" export latex
*** Formula
    <<src:formula>>
    The definition of formulas in the language of interpretability logics.

  #+include: "latex/Formula.tex" export latex
*** GeneralizedFrame/Properties
    <<src:generalizedframe.properties>>
    Properties of generalized Veltman frames.

  #+include: "latex/GeneralizedFrame/Properties.tex" export latex
*** GeneralizedFrame
    <<src:generalizedframe>>
  #+include: "latex/GeneralizedFrame.tex" export latex
*** GeneralizedVeltmanSemantics/Properties/GenericFrameCond
    <<src:generalizedveltmansemantics.properties.genericframecond>>
    It contains the proof that we can find a frame condition for any principle.
  #+include: "latex/GeneralizedVeltmanSemantics/Properties/GenericFrameCond.tex" export latex
*** GeneralizedVeltmanSemantics/Properties/Luka
    <<src:generalizedveltmansemantics.properties.luka>>
    It contains the proof that we build an ordinary frame from a generalized model.
  #+include: "latex/GeneralizedVeltmanSemantics/Properties/Luka.tex" export latex
*** GeneralizedVeltmanSemantics/Properties/M
    <<src:generalizedveltmansemantics.properties.m>>
    The frame condition for the \sf{M} principle.
  #+include: "latex/GeneralizedVeltmanSemantics/Properties/M.tex" export latex
*** GeneralizedVeltmanSemantics/Properties/M\sf{‚ÇÄ}
    <<src:generalizedveltmansemantics.properties.msub0>>
    The frame condition for the \sf{M‚ÇÄ} principle.
  #+include: "latex/GeneralizedVeltmanSemantics/Properties/M‚ÇÄ.tex" export latex
*** GeneralizedVeltmanSemantics/Properties/P\sf{‚ÇÄ}
    <<src:generalizedveltmansemantics.properties.psub0>>
    The frame condition for the \sf{P‚ÇÄ} principle.
  #+include: "latex/GeneralizedVeltmanSemantics/Properties/P‚ÇÄ.tex" export latex
*** GeneralizedVeltmanSemantics/Properties/R
    <<src:generalizedveltmansemantics.properties.r>>
    The frame condition for the \sf{R} principle.
  #+include: "latex/GeneralizedVeltmanSemantics/Properties/R.tex" export latex
*** GeneralizedVeltmanSemantics/Properties/R\sf{¬π}
    The frame condition for the \sf{R^1} principle.
    <<src:generalizedveltmansemantics.properties.rsup1>>
  #+include: "latex/GeneralizedVeltmanSemantics/Properties/R¬π.tex" export latex
*** GeneralizedVeltmanSemantics/Properties/R\sf{¬≤}
    <<src:generalizedveltmansemantics.properties.rsup2>>
    The frame condition for the \sf{R^2} principle.
  #+include: "latex/GeneralizedVeltmanSemantics/Properties/R¬≤.tex" export latex
*** GeneralizedVeltmanSemantics/Properties/R\sf{‚Åø}
    <<src:generalizedveltmansemantics.properties.rsupn>>
    The frame condition for the \sf{R^n} principle.
  #+include: "latex/GeneralizedVeltmanSemantics/Properties/R‚Åø.tex" export latex
*** GeneralizedVeltmanSemantics/Properties/R\sf{‚ÇÅ}
    The frame condition for the \sf{R^1} principle.
    <<src:generalizedveltmansemantics.properties.rsub1>>
  #+include: "latex/GeneralizedVeltmanSemantics/Properties/R‚ÇÅ.tex" export latex
*** GeneralizedVeltmanSemantics/Properties/R\sf{‚ÇÇ} :noexport:
    The frame condition for the \sf{R^2} principle.
    <<src:generalizedveltmansemantics.properties.rsub2>>
  #+include: "latex/GeneralizedVeltmanSemantics/Properties/R‚ÇÇ.tex" export latex
*** GeneralizedVeltmanSemantics/Properties/Verbrugge
    <<src:generalizedveltmansemantics.properties.verbrugge>>
  #+include: "latex/GeneralizedVeltmanSemantics/Properties/Verbrugge.tex" export latex
*** GeneralizedVeltmanSemantics/Properties/Vukovic :noexport:
    <<src:generalizedveltmansemantics.properties.vukovic>>
  #+include: "latex/GeneralizedVeltmanSemantics/Properties/Vukovic.tex" export latex
*** GeneralizedVeltmanSemantics/Properties
    <<src:generalizedveltmansemantics.properties>>
  #+include: "latex/GeneralizedVeltmanSemantics/Properties.tex" export latex
*** GeneralizedVeltmanSemantics
    <<src:generalizedveltmansemantics>>
  #+include: "latex/GeneralizedVeltmanSemantics.tex" export latex
*** IL
    <<src:il>>
  #+include: "latex/IL.tex" export latex
*** IL/Edsl
    <<src:il.edsl>>
  #+include: "latex/IL/Edsl.tex" export latex
*** IL/Properties
    <<src:il.properties>>
  #+include: "latex/IL/Properties.tex" export latex
*** OrdinaryFrame
    <<src:ordinaryframe>>
  #+include: "latex/OrdinaryFrame.tex" export latex
*** OrdinaryVeltmanSemantics/Finite
    <<src:ordinaryveltmansemantics.finite>>
  #+include: "latex/OrdinaryVeltmanSemantics/Finite.tex" export latex
*** OrdinaryVeltmanSemantics/Properties/M
    <<src:ordinaryveltmansemantics.properties.m>>
  #+include: "latex/OrdinaryVeltmanSemantics/Properties/M.tex" export latex
*** OrdinaryVeltmanSemantics/Properties/M\sf{‚ÇÄ}
    <<src:ordinaryveltmansemantics.properties.msub0>>
  #+include: "latex/OrdinaryVeltmanSemantics/Properties/M‚ÇÄ.tex" export latex
*** OrdinaryVeltmanSemantics/Properties/P\sf{‚ÇÄ}
    <<src:ordinaryveltmansemantics.properties.psub0>>
  #+include: "latex/OrdinaryVeltmanSemantics/Properties/P‚ÇÄ.tex" export latex
*** OrdinaryVeltmanSemantics/Properties/R
    <<src:ordinaryveltmansemantics.properties.r>>
  #+include: "latex/OrdinaryVeltmanSemantics/Properties/R.tex" export latex
*** OrdinaryVeltmanSemantics/Properties
    <<src:ordinaryveltmansemantics.properties>>
  #+include: "latex/OrdinaryVeltmanSemantics/Properties.tex" export latex
*** OrdinaryVeltmanSemantics
    <<src:ordinaryveltmansemantics>>
  #+include: "latex/OrdinaryVeltmanSemantics.tex" export latex
*** Principles
    <<src:principles>>
  #+include: "latex/Principles.tex" export latex
